{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.optimize as sco\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filePath):\n",
    "#读取文件下的所有文件数据\n",
    "    filelist = os.listdir(filePath)\n",
    "    info = []\n",
    "    total_info = []\n",
    "    for path in filelist:                  #读取一级文件目录\n",
    "        first_domain = os.path.abspath(filePath)\n",
    "        first_path = os.path.join(first_domain,path)    \n",
    "        second_file_list = os.listdir(first_path)\n",
    "        for path in second_file_list:               #读取二级文件目录\n",
    "            second_path = os.path.join(first_path,path)\n",
    "#             code = path.split('.')[0]        #保存文件名信息，作为和后面基金公司连接的主键\n",
    "            try:\n",
    "                info = pd.read_csv(second_path)    #读取文件内容\n",
    "#                 info['code'] = code              #添加合并主键\n",
    "                total_info.append(info)\n",
    "            except:\n",
    "                print('file not found')\n",
    "\n",
    "    return total_info\n",
    "\n",
    "'load data'\n",
    "filepath = '/home/team36/fanjiakuan/data/funds/nav'\n",
    "info = read_file(filepath)\n",
    "\n",
    "\n",
    "'根据字段名称划分基金类型'\n",
    "daily_non = []\n",
    "for i in range(len(info)):\n",
    "    if 'unit_net_value' in info[i]:   #非日结型\n",
    "        daily_non.append(info[i])\n",
    "\n",
    "'删除不用的列'\n",
    "for i in range(len(daily_non)):\n",
    "    daily_non[i].drop(['acc_net_value', 'adjusted_net_value'],axis = 1, inplace=True)\n",
    "    \n",
    "\n",
    "'过滤掉基金交易日小于：252*0.4*5 小于5年交易日的四成'\n",
    "daily_non_filter = []\n",
    "for i in range(len(daily_non)):\n",
    "    daily_non[i].dropna(axis=0, how='any', inplace=True)\n",
    "    if len(daily_non[i])>= 504:\n",
    "        daily_non_filter.append(daily_non[i])\n",
    "\n",
    "\n",
    "'将序列转换成监督学习问题'\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>unit_net_value</th>\n",
       "      <th>subscribe_status</th>\n",
       "      <th>redeem_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-11-20</td>\n",
       "      <td>1.002</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-11-23</td>\n",
       "      <td>1.002</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-11-24</td>\n",
       "      <td>1.003</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-11-25</td>\n",
       "      <td>1.003</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-26</td>\n",
       "      <td>1.003</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-11-27</td>\n",
       "      <td>1.002</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-11-30</td>\n",
       "      <td>1.002</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>1.002</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-12-02</td>\n",
       "      <td>1.002</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-12-03</td>\n",
       "      <td>1.002</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2015-12-04</td>\n",
       "      <td>1.002</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2015-12-07</td>\n",
       "      <td>1.003</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015-12-08</td>\n",
       "      <td>1.003</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2015-12-09</td>\n",
       "      <td>1.003</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015-12-10</td>\n",
       "      <td>1.003</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015-12-11</td>\n",
       "      <td>1.003</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2015-12-14</td>\n",
       "      <td>1.003</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2015-12-15</td>\n",
       "      <td>1.003</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>1.004</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2015-12-17</td>\n",
       "      <td>1.004</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2015-12-18</td>\n",
       "      <td>1.004</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2015-12-21</td>\n",
       "      <td>1.004</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2015-12-22</td>\n",
       "      <td>1.005</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2015-12-23</td>\n",
       "      <td>1.005</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2015-12-24</td>\n",
       "      <td>1.005</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2015-12-25</td>\n",
       "      <td>1.005</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2015-12-28</td>\n",
       "      <td>1.006</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2015-12-29</td>\n",
       "      <td>1.006</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2015-12-30</td>\n",
       "      <td>1.006</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>1.007</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>2018-11-20</td>\n",
       "      <td>1.185</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>2018-11-21</td>\n",
       "      <td>1.188</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>2018-11-22</td>\n",
       "      <td>1.188</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>2018-11-23</td>\n",
       "      <td>1.181</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>2018-11-26</td>\n",
       "      <td>1.180</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>2018-11-27</td>\n",
       "      <td>1.179</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>2018-11-28</td>\n",
       "      <td>1.184</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>1.181</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>1.186</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>2018-12-03</td>\n",
       "      <td>1.196</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>2018-12-04</td>\n",
       "      <td>1.198</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>2018-12-05</td>\n",
       "      <td>1.197</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>2018-12-06</td>\n",
       "      <td>1.187</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>2018-12-07</td>\n",
       "      <td>1.181</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>2018-12-10</td>\n",
       "      <td>1.177</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>2018-12-11</td>\n",
       "      <td>1.180</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>2018-12-12</td>\n",
       "      <td>1.180</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>2018-12-13</td>\n",
       "      <td>1.183</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>2018-12-14</td>\n",
       "      <td>1.178</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>2018-12-17</td>\n",
       "      <td>1.175</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>2018-12-18</td>\n",
       "      <td>1.170</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>2018-12-19</td>\n",
       "      <td>1.164</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>2018-12-20</td>\n",
       "      <td>1.163</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>1.156</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>2018-12-24</td>\n",
       "      <td>1.160</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>2018-12-25</td>\n",
       "      <td>1.159</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>2018-12-26</td>\n",
       "      <td>1.158</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>1.155</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>1.160</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1.160</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>767 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       datetime  unit_net_value subscribe_status redeem_status\n",
       "0    2015-11-20           1.002             Open          Open\n",
       "1    2015-11-23           1.002             Open          Open\n",
       "2    2015-11-24           1.003             Open          Open\n",
       "3    2015-11-25           1.003             Open          Open\n",
       "4    2015-11-26           1.003             Open          Open\n",
       "5    2015-11-27           1.002             Open          Open\n",
       "6    2015-11-30           1.002             Open          Open\n",
       "7    2015-12-01           1.002             Open          Open\n",
       "8    2015-12-02           1.002             Open          Open\n",
       "9    2015-12-03           1.002             Open          Open\n",
       "10   2015-12-04           1.002             Open          Open\n",
       "11   2015-12-07           1.003             Open          Open\n",
       "12   2015-12-08           1.003             Open          Open\n",
       "13   2015-12-09           1.003             Open          Open\n",
       "14   2015-12-10           1.003             Open          Open\n",
       "15   2015-12-11           1.003             Open          Open\n",
       "16   2015-12-14           1.003             Open          Open\n",
       "17   2015-12-15           1.003             Open          Open\n",
       "18   2015-12-16           1.004             Open          Open\n",
       "19   2015-12-17           1.004             Open          Open\n",
       "20   2015-12-18           1.004             Open          Open\n",
       "21   2015-12-21           1.004             Open          Open\n",
       "22   2015-12-22           1.005             Open          Open\n",
       "23   2015-12-23           1.005             Open          Open\n",
       "24   2015-12-24           1.005             Open          Open\n",
       "25   2015-12-25           1.005             Open          Open\n",
       "26   2015-12-28           1.006             Open          Open\n",
       "27   2015-12-29           1.006             Open          Open\n",
       "28   2015-12-30           1.006             Open          Open\n",
       "29   2015-12-31           1.007             Open          Open\n",
       "..          ...             ...              ...           ...\n",
       "737  2018-11-20           1.185             Open          Open\n",
       "738  2018-11-21           1.188             Open          Open\n",
       "739  2018-11-22           1.188             Open          Open\n",
       "740  2018-11-23           1.181             Open          Open\n",
       "741  2018-11-26           1.180             Open          Open\n",
       "742  2018-11-27           1.179             Open          Open\n",
       "743  2018-11-28           1.184             Open          Open\n",
       "744  2018-11-29           1.181             Open          Open\n",
       "745  2018-11-30           1.186             Open          Open\n",
       "746  2018-12-03           1.196             Open          Open\n",
       "747  2018-12-04           1.198             Open          Open\n",
       "748  2018-12-05           1.197             Open          Open\n",
       "749  2018-12-06           1.187             Open          Open\n",
       "750  2018-12-07           1.181             Open          Open\n",
       "751  2018-12-10           1.177             Open          Open\n",
       "752  2018-12-11           1.180             Open          Open\n",
       "753  2018-12-12           1.180             Open          Open\n",
       "754  2018-12-13           1.183             Open          Open\n",
       "755  2018-12-14           1.178             Open          Open\n",
       "756  2018-12-17           1.175             Open          Open\n",
       "757  2018-12-18           1.170             Open          Open\n",
       "758  2018-12-19           1.164             Open          Open\n",
       "759  2018-12-20           1.163             Open          Open\n",
       "760  2018-12-21           1.156             Open          Open\n",
       "761  2018-12-24           1.160             Open          Open\n",
       "762  2018-12-25           1.159             Open          Open\n",
       "763  2018-12-26           1.158             Open          Open\n",
       "764  2018-12-27           1.155             Open          Open\n",
       "765  2018-12-28           1.160             Open          Open\n",
       "766  2018-12-31           1.160             Open          Open\n",
       "\n",
       "[767 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_non_filter[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------starting-----------\n",
      "WARNING:tensorflow:From /home/team36/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Train on 1016 samples, validate on 30 samples\n",
      "WARNING:tensorflow:From /home/team36/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "1016/1016 [==============================] - 2s 2ms/sample - loss: 0.4601 - val_loss: 0.7400\n",
      "Epoch 2/50\n",
      "1016/1016 [==============================] - 0s 89us/sample - loss: 0.3412 - val_loss: 0.5844\n",
      "Epoch 3/50\n",
      "1016/1016 [==============================] - 0s 81us/sample - loss: 0.2483 - val_loss: 0.4290\n",
      "Epoch 4/50\n",
      "1016/1016 [==============================] - 0s 83us/sample - loss: 0.1703 - val_loss: 0.2820\n",
      "Epoch 5/50\n",
      "1016/1016 [==============================] - 0s 81us/sample - loss: 0.1313 - val_loss: 0.1845\n",
      "Epoch 6/50\n",
      "1016/1016 [==============================] - 0s 84us/sample - loss: 0.1377 - val_loss: 0.1780\n",
      "Epoch 7/50\n",
      "1016/1016 [==============================] - 0s 86us/sample - loss: 0.1344 - val_loss: 0.1892\n",
      "Epoch 8/50\n",
      "1016/1016 [==============================] - 0s 83us/sample - loss: 0.1299 - val_loss: 0.1853\n",
      "Epoch 9/50\n",
      "1016/1016 [==============================] - 0s 82us/sample - loss: 0.1270 - val_loss: 0.1794\n",
      "Epoch 10/50\n",
      "1016/1016 [==============================] - 0s 83us/sample - loss: 0.1246 - val_loss: 0.1791\n",
      "Epoch 11/50\n",
      "1016/1016 [==============================] - 0s 85us/sample - loss: 0.1211 - val_loss: 0.1742\n",
      "Epoch 12/50\n",
      "1016/1016 [==============================] - ETA: 0s - loss: 0.134 - 0s 85us/sample - loss: 0.1184 - val_loss: 0.1716\n",
      "Epoch 13/50\n",
      "1016/1016 [==============================] - 0s 85us/sample - loss: 0.1150 - val_loss: 0.1675\n",
      "Epoch 14/50\n",
      "1016/1016 [==============================] - 0s 87us/sample - loss: 0.1119 - val_loss: 0.1648\n",
      "Epoch 15/50\n",
      "1016/1016 [==============================] - 0s 86us/sample - loss: 0.1083 - val_loss: 0.1590\n",
      "Epoch 16/50\n",
      "1016/1016 [==============================] - 0s 86us/sample - loss: 0.1052 - val_loss: 0.1564\n",
      "Epoch 17/50\n",
      "1016/1016 [==============================] - 0s 83us/sample - loss: 0.1012 - val_loss: 0.1504\n",
      "Epoch 18/50\n",
      "1016/1016 [==============================] - 0s 81us/sample - loss: 0.0977 - val_loss: 0.1469\n",
      "Epoch 19/50\n",
      "1016/1016 [==============================] - 0s 86us/sample - loss: 0.0935 - val_loss: 0.1438\n",
      "Epoch 20/50\n",
      "1016/1016 [==============================] - 0s 83us/sample - loss: 0.0891 - val_loss: 0.1384\n",
      "Epoch 21/50\n",
      "1016/1016 [==============================] - 0s 83us/sample - loss: 0.0846 - val_loss: 0.1317\n",
      "Epoch 22/50\n",
      "1016/1016 [==============================] - 0s 85us/sample - loss: 0.0800 - val_loss: 0.1247\n",
      "Epoch 23/50\n",
      "1016/1016 [==============================] - 0s 88us/sample - loss: 0.0750 - val_loss: 0.1190\n",
      "Epoch 24/50\n",
      "1016/1016 [==============================] - 0s 83us/sample - loss: 0.0697 - val_loss: 0.1146\n",
      "Epoch 25/50\n",
      "1016/1016 [==============================] - 0s 89us/sample - loss: 0.0635 - val_loss: 0.1061\n",
      "Epoch 26/50\n",
      "1016/1016 [==============================] - 0s 87us/sample - loss: 0.0577 - val_loss: 0.1007\n",
      "Epoch 27/50\n",
      "1016/1016 [==============================] - 0s 87us/sample - loss: 0.0508 - val_loss: 0.0923\n",
      "Epoch 28/50\n",
      "1016/1016 [==============================] - 0s 83us/sample - loss: 0.0437 - val_loss: 0.0836\n",
      "Epoch 29/50\n",
      "1016/1016 [==============================] - 0s 86us/sample - loss: 0.0361 - val_loss: 0.0745\n",
      "Epoch 30/50\n",
      "1016/1016 [==============================] - 0s 89us/sample - loss: 0.0282 - val_loss: 0.0651\n",
      "Epoch 31/50\n",
      "1016/1016 [==============================] - 0s 83us/sample - loss: 0.0208 - val_loss: 0.0540\n",
      "Epoch 32/50\n",
      "1016/1016 [==============================] - 0s 78us/sample - loss: 0.0156 - val_loss: 0.0492\n",
      "Epoch 33/50\n",
      "1016/1016 [==============================] - 0s 79us/sample - loss: 0.0168 - val_loss: 0.0449\n",
      "Epoch 34/50\n",
      "1016/1016 [==============================] - 0s 82us/sample - loss: 0.0140 - val_loss: 0.0366\n",
      "Epoch 35/50\n",
      "1016/1016 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0222\n",
      "Epoch 36/50\n",
      "1016/1016 [==============================] - 0s 81us/sample - loss: 0.0103 - val_loss: 0.0098\n",
      "Epoch 37/50\n",
      "1016/1016 [==============================] - 0s 80us/sample - loss: 0.0087 - val_loss: 0.0123\n",
      "Epoch 38/50\n",
      "1016/1016 [==============================] - 0s 80us/sample - loss: 0.0092 - val_loss: 0.0099\n",
      "Epoch 39/50\n",
      "1016/1016 [==============================] - 0s 84us/sample - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 40/50\n",
      "1016/1016 [==============================] - 0s 78us/sample - loss: 0.0148 - val_loss: 0.0096\n",
      "Epoch 41/50\n",
      "1016/1016 [==============================] - 0s 79us/sample - loss: 0.0180 - val_loss: 0.0189\n",
      "Epoch 42/50\n",
      "1016/1016 [==============================] - 0s 82us/sample - loss: 0.0118 - val_loss: 0.0095\n",
      "Epoch 43/50\n",
      "1016/1016 [==============================] - 0s 83us/sample - loss: 0.0115 - val_loss: 0.0098\n",
      "Epoch 44/50\n",
      "1016/1016 [==============================] - 0s 86us/sample - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 45/50\n",
      "1016/1016 [==============================] - 0s 83us/sample - loss: 0.0111 - val_loss: 0.0151\n",
      "Epoch 46/50\n",
      "1016/1016 [==============================] - 0s 84us/sample - loss: 0.0177 - val_loss: 0.0162\n",
      "Epoch 47/50\n",
      "1016/1016 [==============================] - 0s 85us/sample - loss: 0.0155 - val_loss: 0.0162\n",
      "Epoch 48/50\n",
      "1016/1016 [==============================] - 0s 86us/sample - loss: 0.0119 - val_loss: 0.0095\n",
      "Epoch 49/50\n",
      "1016/1016 [==============================] - 0s 84us/sample - loss: 0.0119 - val_loss: 0.0123\n",
      "Epoch 50/50\n",
      "1016/1016 [==============================] - 0s 85us/sample - loss: 0.0121 - val_loss: 0.0140\n",
      "第0个数，还剩4123个没有训练\n",
      "inv_hat [1.13917273 1.13917273 1.13811573 1.13811573 1.13811573 1.13811573\n",
      " 1.13811573 1.13811573 1.13917273 1.13917273 1.14023061 1.14128907\n",
      " 1.14128907 1.14234838 1.14234838 1.14234838 1.14101761 1.14234838\n",
      " 1.12130979 1.12026662 1.12026662 1.12026662 1.12026662 1.12130979\n",
      " 1.12130979 1.12130979 1.12130979 1.12235378 1.12235378 1.12444461]\n",
      "Test RMSE: 0.004\n",
      "Train on 736 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "736/736 [==============================] - 0s 91us/sample - loss: 0.0523 - val_loss: 0.0406\n",
      "Epoch 2/50\n",
      "736/736 [==============================] - 0s 85us/sample - loss: 0.0198 - val_loss: 0.0223\n",
      "Epoch 3/50\n",
      "736/736 [==============================] - 0s 89us/sample - loss: 0.0234 - val_loss: 0.0186\n",
      "Epoch 4/50\n",
      "736/736 [==============================] - 0s 87us/sample - loss: 0.0166 - val_loss: 0.0242\n",
      "Epoch 5/50\n",
      "736/736 [==============================] - 0s 85us/sample - loss: 0.0153 - val_loss: 0.0260\n",
      "Epoch 6/50\n",
      "736/736 [==============================] - 0s 88us/sample - loss: 0.0154 - val_loss: 0.0245\n",
      "Epoch 7/50\n",
      "736/736 [==============================] - 0s 84us/sample - loss: 0.0147 - val_loss: 0.0246\n",
      "Epoch 8/50\n",
      "736/736 [==============================] - 0s 86us/sample - loss: 0.0150 - val_loss: 0.0231\n",
      "Epoch 9/50\n",
      "736/736 [==============================] - 0s 82us/sample - loss: 0.0149 - val_loss: 0.0236\n",
      "Epoch 10/50\n",
      "736/736 [==============================] - 0s 88us/sample - loss: 0.0146 - val_loss: 0.0246\n",
      "Epoch 11/50\n",
      "736/736 [==============================] - 0s 88us/sample - loss: 0.0147 - val_loss: 0.0242\n",
      "Epoch 12/50\n",
      "736/736 [==============================] - 0s 84us/sample - loss: 0.0146 - val_loss: 0.0232\n",
      "Epoch 13/50\n",
      "736/736 [==============================] - 0s 79us/sample - loss: 0.0143 - val_loss: 0.0247\n",
      "Epoch 14/50\n",
      "736/736 [==============================] - 0s 79us/sample - loss: 0.0144 - val_loss: 0.0233\n",
      "Epoch 15/50\n",
      "736/736 [==============================] - 0s 79us/sample - loss: 0.0141 - val_loss: 0.0235\n",
      "Epoch 16/50\n",
      "736/736 [==============================] - 0s 79us/sample - loss: 0.0142 - val_loss: 0.0236\n",
      "Epoch 17/50\n",
      "736/736 [==============================] - 0s 78us/sample - loss: 0.0140 - val_loss: 0.0233\n",
      "Epoch 18/50\n",
      "736/736 [==============================] - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0242\n",
      "Epoch 19/50\n",
      "736/736 [==============================] - 0s 80us/sample - loss: 0.0141 - val_loss: 0.0229\n",
      "Epoch 20/50\n",
      "736/736 [==============================] - 0s 79us/sample - loss: 0.0136 - val_loss: 0.0240\n",
      "Epoch 21/50\n",
      "736/736 [==============================] - 0s 79us/sample - loss: 0.0137 - val_loss: 0.0231\n",
      "Epoch 22/50\n",
      "736/736 [==============================] - 0s 79us/sample - loss: 0.0137 - val_loss: 0.0232\n",
      "Epoch 23/50\n",
      "736/736 [==============================] - 0s 78us/sample - loss: 0.0135 - val_loss: 0.0230\n",
      "Epoch 24/50\n",
      "736/736 [==============================] - 0s 79us/sample - loss: 0.0135 - val_loss: 0.0237\n",
      "Epoch 25/50\n",
      "736/736 [==============================] - 0s 79us/sample - loss: 0.0134 - val_loss: 0.0227\n",
      "Epoch 26/50\n",
      "736/736 [==============================] - 0s 79us/sample - loss: 0.0133 - val_loss: 0.0236\n",
      "Epoch 27/50\n",
      "736/736 [==============================] - 0s 77us/sample - loss: 0.0134 - val_loss: 0.0227\n",
      "Epoch 28/50\n",
      "736/736 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0233\n",
      "Epoch 29/50\n",
      "736/736 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0229\n",
      "Epoch 30/50\n",
      "736/736 [==============================] - 0s 82us/sample - loss: 0.0130 - val_loss: 0.0229\n",
      "Epoch 31/50\n",
      "736/736 [==============================] - 0s 79us/sample - loss: 0.0131 - val_loss: 0.0228\n",
      "Epoch 32/50\n",
      "736/736 [==============================] - 0s 79us/sample - loss: 0.0129 - val_loss: 0.0226\n",
      "Epoch 33/50\n",
      "736/736 [==============================] - 0s 78us/sample - loss: 0.0128 - val_loss: 0.0233\n",
      "Epoch 34/50\n",
      "736/736 [==============================] - 0s 82us/sample - loss: 0.0128 - val_loss: 0.0223\n",
      "Epoch 35/50\n",
      "736/736 [==============================] - 0s 88us/sample - loss: 0.0126 - val_loss: 0.0231\n",
      "Epoch 36/50\n",
      "736/736 [==============================] - 0s 85us/sample - loss: 0.0128 - val_loss: 0.0223\n",
      "Epoch 37/50\n",
      "736/736 [==============================] - 0s 84us/sample - loss: 0.0124 - val_loss: 0.0229\n",
      "Epoch 38/50\n",
      "736/736 [==============================] - 0s 88us/sample - loss: 0.0126 - val_loss: 0.0223\n",
      "Epoch 39/50\n",
      "736/736 [==============================] - 0s 86us/sample - loss: 0.0124 - val_loss: 0.0227\n",
      "Epoch 40/50\n",
      "736/736 [==============================] - 0s 91us/sample - loss: 0.0124 - val_loss: 0.0226\n",
      "Epoch 41/50\n",
      "736/736 [==============================] - 0s 85us/sample - loss: 0.0122 - val_loss: 0.0224\n",
      "Epoch 42/50\n",
      "736/736 [==============================] - 0s 85us/sample - loss: 0.0123 - val_loss: 0.0226\n",
      "Epoch 43/50\n",
      "736/736 [==============================] - 0s 82us/sample - loss: 0.0126 - val_loss: 0.0217\n",
      "Epoch 44/50\n",
      "736/736 [==============================] - 0s 85us/sample - loss: 0.0116 - val_loss: 0.0216\n",
      "Epoch 45/50\n",
      "736/736 [==============================] - 0s 83us/sample - loss: 0.0123 - val_loss: 0.0226\n",
      "Epoch 46/50\n",
      "736/736 [==============================] - 0s 92us/sample - loss: 0.0123 - val_loss: 0.0208\n",
      "Epoch 47/50\n",
      "736/736 [==============================] - 0s 86us/sample - loss: 0.0115 - val_loss: 0.0216\n",
      "Epoch 48/50\n",
      "736/736 [==============================] - 0s 89us/sample - loss: 0.0119 - val_loss: 0.0228\n",
      "Epoch 49/50\n",
      "736/736 [==============================] - 0s 83us/sample - loss: 0.0125 - val_loss: 0.0211\n",
      "Epoch 50/50\n",
      "736/736 [==============================] - 0s 82us/sample - loss: 0.0113 - val_loss: 0.0215\n",
      "第1个数，还剩4122个没有训练\n",
      "inv_hat [1.19249892 1.1864005  1.18945034 1.18945034 1.18233235 1.18131501\n",
      " 1.18029763 1.18538371 1.18233235 1.18741727 1.19757665 1.19960649\n",
      " 1.19859172 1.18843394 1.18233235 1.1782625  1.18131501 1.18131501\n",
      " 1.18436664 1.17928004 1.17622692 1.17113692 1.16502742 1.16400899\n",
      " 1.15688034 1.16095381 1.1599355  1.15891704 1.15586196 1.16095381]\n",
      "Test RMSE: 0.005\n",
      "Train on 679 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "679/679 [==============================] - 0s 81us/sample - loss: 0.0255 - val_loss: 0.0176\n",
      "Epoch 2/50\n",
      "679/679 [==============================] - 0s 84us/sample - loss: 0.0331 - val_loss: 0.0209\n",
      "Epoch 3/50\n",
      "679/679 [==============================] - 0s 81us/sample - loss: 0.0167 - val_loss: 0.0134\n",
      "Epoch 4/50\n",
      "679/679 [==============================] - 0s 84us/sample - loss: 0.0171 - val_loss: 0.0114\n",
      "Epoch 5/50\n",
      "679/679 [==============================] - 0s 88us/sample - loss: 0.0136 - val_loss: 0.0120\n",
      "Epoch 6/50\n",
      "679/679 [==============================] - 0s 83us/sample - loss: 0.0137 - val_loss: 0.0098\n",
      "Epoch 7/50\n",
      "679/679 [==============================] - 0s 80us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 8/50\n",
      "679/679 [==============================] - 0s 79us/sample - loss: 0.0121 - val_loss: 0.0098\n",
      "Epoch 9/50\n",
      "679/679 [==============================] - 0s 86us/sample - loss: 0.0127 - val_loss: 0.0100\n",
      "Epoch 10/50\n",
      "679/679 [==============================] - 0s 85us/sample - loss: 0.0126 - val_loss: 0.0105\n",
      "Epoch 11/50\n",
      "679/679 [==============================] - 0s 86us/sample - loss: 0.0122 - val_loss: 0.0091\n",
      "Epoch 12/50\n",
      "679/679 [==============================] - 0s 89us/sample - loss: 0.0128 - val_loss: 0.0123\n",
      "Epoch 13/50\n",
      "679/679 [==============================] - 0s 85us/sample - loss: 0.0126 - val_loss: 0.0113\n",
      "Epoch 14/50\n",
      "679/679 [==============================] - 0s 84us/sample - loss: 0.0120 - val_loss: 0.0090\n",
      "Epoch 15/50\n",
      "679/679 [==============================] - 0s 85us/sample - loss: 0.0123 - val_loss: 0.0093\n",
      "Epoch 16/50\n",
      "679/679 [==============================] - 0s 85us/sample - loss: 0.0125 - val_loss: 0.0103\n",
      "Epoch 17/50\n",
      "679/679 [==============================] - 0s 87us/sample - loss: 0.0125 - val_loss: 0.0119\n",
      "Epoch 18/50\n",
      "679/679 [==============================] - 0s 85us/sample - loss: 0.0124 - val_loss: 0.0099\n",
      "Epoch 19/50\n",
      "679/679 [==============================] - 0s 85us/sample - loss: 0.0121 - val_loss: 0.0093\n",
      "Epoch 20/50\n",
      "679/679 [==============================] - 0s 84us/sample - loss: 0.0126 - val_loss: 0.0104\n",
      "Epoch 21/50\n",
      "679/679 [==============================] - 0s 86us/sample - loss: 0.0121 - val_loss: 0.0092\n",
      "Epoch 22/50\n",
      "679/679 [==============================] - 0s 86us/sample - loss: 0.0128 - val_loss: 0.0124\n",
      "Epoch 23/50\n",
      "679/679 [==============================] - 0s 86us/sample - loss: 0.0127 - val_loss: 0.0104\n",
      "Epoch 24/50\n",
      "679/679 [==============================] - 0s 85us/sample - loss: 0.0120 - val_loss: 0.0093\n",
      "Epoch 25/50\n",
      "679/679 [==============================] - 0s 89us/sample - loss: 0.0126 - val_loss: 0.0106\n",
      "Epoch 26/50\n",
      "679/679 [==============================] - 0s 88us/sample - loss: 0.0121 - val_loss: 0.0089\n",
      "Epoch 27/50\n",
      "679/679 [==============================] - 0s 86us/sample - loss: 0.0126 - val_loss: 0.0116\n",
      "Epoch 28/50\n",
      "679/679 [==============================] - 0s 84us/sample - loss: 0.0124 - val_loss: 0.0095\n",
      "Epoch 29/50\n",
      "679/679 [==============================] - 0s 91us/sample - loss: 0.0122 - val_loss: 0.0099\n",
      "Epoch 30/50\n",
      "679/679 [==============================] - 0s 87us/sample - loss: 0.0121 - val_loss: 0.0090\n",
      "Epoch 31/50\n",
      "679/679 [==============================] - 0s 83us/sample - loss: 0.0123 - val_loss: 0.0104\n",
      "Epoch 32/50\n",
      "679/679 [==============================] - 0s 81us/sample - loss: 0.0124 - val_loss: 0.0121\n",
      "Epoch 33/50\n",
      "679/679 [==============================] - 0s 84us/sample - loss: 0.0123 - val_loss: 0.0106\n",
      "Epoch 34/50\n",
      "679/679 [==============================] - 0s 82us/sample - loss: 0.0116 - val_loss: 0.0094\n",
      "Epoch 35/50\n",
      "679/679 [==============================] - 0s 80us/sample - loss: 0.0120 - val_loss: 0.0103\n",
      "Epoch 36/50\n",
      "679/679 [==============================] - 0s 81us/sample - loss: 0.0125 - val_loss: 0.0095\n",
      "Epoch 37/50\n",
      "679/679 [==============================] - 0s 81us/sample - loss: 0.0130 - val_loss: 0.0120\n",
      "Epoch 38/50\n",
      "679/679 [==============================] - 0s 81us/sample - loss: 0.0135 - val_loss: 0.0114\n",
      "Epoch 39/50\n",
      "679/679 [==============================] - 0s 81us/sample - loss: 0.0120 - val_loss: 0.0096\n",
      "Epoch 40/50\n",
      "679/679 [==============================] - 0s 83us/sample - loss: 0.0121 - val_loss: 0.0101\n",
      "Epoch 41/50\n",
      "679/679 [==============================] - 0s 82us/sample - loss: 0.0125 - val_loss: 0.0094\n",
      "Epoch 42/50\n",
      "679/679 [==============================] - 0s 83us/sample - loss: 0.0126 - val_loss: 0.0107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "679/679 [==============================] - 0s 81us/sample - loss: 0.0131 - val_loss: 0.0129\n",
      "Epoch 44/50\n",
      "679/679 [==============================] - 0s 79us/sample - loss: 0.0128 - val_loss: 0.0107\n",
      "Epoch 45/50\n",
      "679/679 [==============================] - 0s 83us/sample - loss: 0.0122 - val_loss: 0.0116\n",
      "Epoch 46/50\n",
      "679/679 [==============================] - 0s 86us/sample - loss: 0.0139 - val_loss: 0.0098\n",
      "Epoch 47/50\n",
      "679/679 [==============================] - 0s 82us/sample - loss: 0.0145 - val_loss: 0.0146\n",
      "Epoch 48/50\n",
      "679/679 [==============================] - 0s 82us/sample - loss: 0.0149 - val_loss: 0.0115\n",
      "Epoch 49/50\n",
      "679/679 [==============================] - 0s 91us/sample - loss: 0.0122 - val_loss: 0.0097\n",
      "Epoch 50/50\n",
      "679/679 [==============================] - 0s 91us/sample - loss: 0.0124 - val_loss: 0.0112\n",
      "第2个数，还剩4121个没有训练\n",
      "inv_hat [1.11492639 1.11090946 1.11291842 1.11291842 1.1088995  1.1088995\n",
      " 1.1088995  1.10990454 1.10789411 1.11090946 1.11492639 1.11592982\n",
      " 1.11592982 1.11392255 1.11392255 1.11291842 1.11191414 1.11291842\n",
      " 1.11392255 1.11291842 1.11291842 1.11090946 1.1088995  1.1088995\n",
      " 1.10789411 1.10789411 1.1068886  1.1068886  1.1068886  1.1088995 ]\n",
      "Test RMSE: 0.002\n",
      "Train on 988 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "988/988 [==============================] - 0s 81us/sample - loss: 0.0126 - val_loss: 0.0070\n",
      "Epoch 2/50\n",
      "988/988 [==============================] - 0s 80us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 3/50\n",
      "988/988 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0070\n",
      "Epoch 4/50\n",
      "988/988 [==============================] - 0s 85us/sample - loss: 0.0118 - val_loss: 0.0071\n",
      "Epoch 5/50\n",
      "988/988 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0071\n",
      "Epoch 6/50\n",
      "988/988 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 7/50\n",
      "988/988 [==============================] - 0s 81us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 8/50\n",
      "988/988 [==============================] - 0s 77us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 9/50\n",
      "988/988 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 10/50\n",
      "988/988 [==============================] - 0s 78us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 11/50\n",
      "988/988 [==============================] - 0s 81us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 12/50\n",
      "988/988 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 13/50\n",
      "988/988 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 14/50\n",
      "988/988 [==============================] - 0s 79us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 15/50\n",
      "988/988 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 16/50\n",
      "988/988 [==============================] - 0s 81us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 17/50\n",
      "988/988 [==============================] - 0s 81us/sample - loss: 0.0118 - val_loss: 0.0071\n",
      "Epoch 18/50\n",
      "988/988 [==============================] - 0s 82us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 19/50\n",
      "988/988 [==============================] - 0s 81us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 20/50\n",
      "988/988 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 21/50\n",
      "988/988 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 22/50\n",
      "988/988 [==============================] - 0s 80us/sample - loss: 0.0119 - val_loss: 0.0070\n",
      "Epoch 23/50\n",
      "988/988 [==============================] - 0s 81us/sample - loss: 0.0118 - val_loss: 0.0071\n",
      "Epoch 24/50\n",
      "988/988 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 25/50\n",
      "988/988 [==============================] - 0s 84us/sample - loss: 0.0118 - val_loss: 0.0073\n",
      "Epoch 26/50\n",
      "988/988 [==============================] - 0s 82us/sample - loss: 0.0119 - val_loss: 0.0071\n",
      "Epoch 27/50\n",
      "988/988 [==============================] - 0s 84us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 28/50\n",
      "988/988 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 29/50\n",
      "988/988 [==============================] - 0s 77us/sample - loss: 0.0119 - val_loss: 0.0070\n",
      "Epoch 30/50\n",
      "988/988 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0071\n",
      "Epoch 31/50\n",
      "988/988 [==============================] - 0s 82us/sample - loss: 0.0118 - val_loss: 0.0071\n",
      "Epoch 32/50\n",
      "988/988 [==============================] - 0s 81us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 33/50\n",
      "988/988 [==============================] - 0s 85us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 34/50\n",
      "988/988 [==============================] - 0s 82us/sample - loss: 0.0118 - val_loss: 0.0071\n",
      "Epoch 35/50\n",
      "988/988 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 36/50\n",
      "988/988 [==============================] - 0s 82us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 37/50\n",
      "988/988 [==============================] - 0s 85us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 38/50\n",
      "988/988 [==============================] - 0s 82us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 39/50\n",
      "988/988 [==============================] - 0s 83us/sample - loss: 0.0118 - val_loss: 0.0071\n",
      "Epoch 40/50\n",
      "988/988 [==============================] - 0s 84us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 41/50\n",
      "988/988 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0071\n",
      "Epoch 42/50\n",
      "988/988 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0071\n",
      "Epoch 43/50\n",
      "988/988 [==============================] - 0s 82us/sample - loss: 0.0118 - val_loss: 0.0071\n",
      "Epoch 44/50\n",
      "988/988 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 45/50\n",
      "988/988 [==============================] - 0s 78us/sample - loss: 0.0119 - val_loss: 0.0071\n",
      "Epoch 46/50\n",
      "988/988 [==============================] - 0s 82us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 47/50\n",
      "988/988 [==============================] - 0s 76us/sample - loss: 0.0119 - val_loss: 0.0071\n",
      "Epoch 48/50\n",
      "988/988 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0071\n",
      "Epoch 49/50\n",
      "988/988 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0071\n",
      "Epoch 50/50\n",
      "988/988 [==============================] - 0s 77us/sample - loss: 0.0118 - val_loss: 0.0071\n",
      "第3个数，还剩4120个没有训练\n",
      "inv_hat [1.01636337 0.9945452  0.99751789 0.99553602 0.96980518 0.96980518\n",
      " 0.96980518 0.98365252 0.96980518 0.98167329 1.00544888 1.01239317\n",
      " 1.01040868 0.99157341 0.99058294 0.98068368 0.98761225 0.98860241\n",
      " 1.00247409 0.9856322  0.97672656 0.96980518 0.95104181 0.94610974\n",
      " 0.93428276 0.94118018 0.94216589 0.93920896 0.93231299 0.93526777]\n",
      "Test RMSE: 0.011\n",
      "Train on 1025 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1025/1025 [==============================] - 0s 80us/sample - loss: 0.0389 - val_loss: 0.0060\n",
      "Epoch 2/50\n",
      "1025/1025 [==============================] - 0s 80us/sample - loss: 0.0269 - val_loss: 0.0073\n",
      "Epoch 3/50\n",
      "1025/1025 [==============================] - 0s 80us/sample - loss: 0.0181 - val_loss: 0.0060\n",
      "Epoch 4/50\n",
      "1025/1025 [==============================] - 0s 79us/sample - loss: 0.0136 - val_loss: 0.0066\n",
      "Epoch 5/50\n",
      "1025/1025 [==============================] - 0s 80us/sample - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 6/50\n",
      "1025/1025 [==============================] - 0s 80us/sample - loss: 0.0088 - val_loss: 0.0061\n",
      "Epoch 7/50\n",
      "1025/1025 [==============================] - 0s 78us/sample - loss: 0.0093 - val_loss: 0.0055\n",
      "Epoch 8/50\n",
      "1025/1025 [==============================] - 0s 85us/sample - loss: 0.0075 - val_loss: 0.0096\n",
      "Epoch 9/50\n",
      "1025/1025 [==============================] - 0s 87us/sample - loss: 0.0114 - val_loss: 0.0095\n",
      "Epoch 10/50\n",
      "1025/1025 [==============================] - 0s 86us/sample - loss: 0.0122 - val_loss: 0.0058\n",
      "Epoch 11/50\n",
      "1025/1025 [==============================] - 0s 85us/sample - loss: 0.0072 - val_loss: 0.0056\n",
      "Epoch 12/50\n",
      "1025/1025 [==============================] - 0s 89us/sample - loss: 0.0086 - val_loss: 0.0064\n",
      "Epoch 13/50\n",
      "1025/1025 [==============================] - 0s 87us/sample - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 14/50\n",
      "1025/1025 [==============================] - 0s 86us/sample - loss: 0.0075 - val_loss: 0.0088\n",
      "Epoch 15/50\n",
      "1025/1025 [==============================] - 0s 84us/sample - loss: 0.0113 - val_loss: 0.0091\n",
      "Epoch 16/50\n",
      "1025/1025 [==============================] - 0s 85us/sample - loss: 0.0121 - val_loss: 0.0058\n",
      "Epoch 17/50\n",
      "1025/1025 [==============================] - 0s 85us/sample - loss: 0.0074 - val_loss: 0.0056\n",
      "Epoch 18/50\n",
      "1025/1025 [==============================] - 0s 84us/sample - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 19/50\n",
      "1025/1025 [==============================] - 0s 83us/sample - loss: 0.0095 - val_loss: 0.0055\n",
      "Epoch 20/50\n",
      "1025/1025 [==============================] - 0s 82us/sample - loss: 0.0077 - val_loss: 0.0084\n",
      "Epoch 21/50\n",
      "1025/1025 [==============================] - 0s 83us/sample - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 22/50\n",
      "1025/1025 [==============================] - 0s 80us/sample - loss: 0.0128 - val_loss: 0.0057\n",
      "Epoch 23/50\n",
      "1025/1025 [==============================] - 0s 80us/sample - loss: 0.0074 - val_loss: 0.0057\n",
      "Epoch 24/50\n",
      "1025/1025 [==============================] - 0s 81us/sample - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 25/50\n",
      "1025/1025 [==============================] - 0s 81us/sample - loss: 0.0084 - val_loss: 0.0057\n",
      "Epoch 26/50\n",
      "1025/1025 [==============================] - 0s 79us/sample - loss: 0.0072 - val_loss: 0.0095\n",
      "Epoch 27/50\n",
      "1025/1025 [==============================] - 0s 78us/sample - loss: 0.0112 - val_loss: 0.0079\n",
      "Epoch 28/50\n",
      "1025/1025 [==============================] - 0s 81us/sample - loss: 0.0103 - val_loss: 0.0061\n",
      "Epoch 29/50\n",
      "1025/1025 [==============================] - 0s 81us/sample - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 30/50\n",
      "1025/1025 [==============================] - 0s 79us/sample - loss: 0.0080 - val_loss: 0.0056\n",
      "Epoch 31/50\n",
      "1025/1025 [==============================] - 0s 78us/sample - loss: 0.0080 - val_loss: 0.0056\n",
      "Epoch 32/50\n",
      "1025/1025 [==============================] - 0s 77us/sample - loss: 0.0069 - val_loss: 0.0081\n",
      "Epoch 33/50\n",
      "1025/1025 [==============================] - 0s 82us/sample - loss: 0.0089 - val_loss: 0.0112\n",
      "Epoch 34/50\n",
      "1025/1025 [==============================] - 0s 79us/sample - loss: 0.0116 - val_loss: 0.0061\n",
      "Epoch 35/50\n",
      "1025/1025 [==============================] - 0s 84us/sample - loss: 0.0076 - val_loss: 0.0054\n",
      "Epoch 36/50\n",
      "1025/1025 [==============================] - 0s 84us/sample - loss: 0.0084 - val_loss: 0.0056\n",
      "Epoch 37/50\n",
      "1025/1025 [==============================] - 0s 85us/sample - loss: 0.0088 - val_loss: 0.0057\n",
      "Epoch 38/50\n",
      "1025/1025 [==============================] - 0s 78us/sample - loss: 0.0073 - val_loss: 0.0093\n",
      "Epoch 39/50\n",
      "1025/1025 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0078\n",
      "Epoch 40/50\n",
      "1025/1025 [==============================] - 0s 79us/sample - loss: 0.0107 - val_loss: 0.0059\n",
      "Epoch 41/50\n",
      "1025/1025 [==============================] - 0s 81us/sample - loss: 0.0070 - val_loss: 0.0053\n",
      "Epoch 42/50\n",
      "1025/1025 [==============================] - 0s 80us/sample - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 43/50\n",
      "1025/1025 [==============================] - 0s 79us/sample - loss: 0.0083 - val_loss: 0.0060\n",
      "Epoch 44/50\n",
      "1025/1025 [==============================] - 0s 80us/sample - loss: 0.0073 - val_loss: 0.0099\n",
      "Epoch 45/50\n",
      "1025/1025 [==============================] - 0s 81us/sample - loss: 0.0124 - val_loss: 0.0060\n",
      "Epoch 46/50\n",
      "1025/1025 [==============================] - 0s 81us/sample - loss: 0.0097 - val_loss: 0.0055\n",
      "Epoch 47/50\n",
      "1025/1025 [==============================] - 0s 78us/sample - loss: 0.0075 - val_loss: 0.0056\n",
      "Epoch 48/50\n",
      "1025/1025 [==============================] - 0s 86us/sample - loss: 0.0095 - val_loss: 0.0054\n",
      "Epoch 49/50\n",
      "1025/1025 [==============================] - 0s 85us/sample - loss: 0.0088 - val_loss: 0.0089\n",
      "Epoch 50/50\n",
      "1025/1025 [==============================] - 0s 82us/sample - loss: 0.0110 - val_loss: 0.0092\n",
      "第4个数，还剩4119个没有训练\n",
      "inv_hat [1.1256638  1.12471376 1.12661393 1.12376402 1.12186483 1.11996652\n",
      " 1.12091565 1.12376402 1.12756434 1.12756434 1.12946564 1.13612591\n",
      " 1.13803035 1.13993552 1.14184137 1.14565511 1.1466089  1.14756293\n",
      " 1.13707799 1.13612591 1.13327046 1.13422203 1.13803035 1.14184137\n",
      " 1.1408884  1.1408884  1.14279458 1.13898281 1.1408884  1.14756293]\n",
      "Test RMSE: 0.005\n",
      "Train on 717 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "717/717 [==============================] - 0s 80us/sample - loss: 0.0363 - val_loss: 0.0360\n",
      "Epoch 2/50\n",
      "717/717 [==============================] - 0s 82us/sample - loss: 0.0381 - val_loss: 0.0316\n",
      "Epoch 3/50\n",
      "717/717 [==============================] - 0s 76us/sample - loss: 0.0236 - val_loss: 0.0285\n",
      "Epoch 4/50\n",
      "717/717 [==============================] - 0s 79us/sample - loss: 0.0231 - val_loss: 0.0309\n",
      "Epoch 5/50\n",
      "717/717 [==============================] - 0s 80us/sample - loss: 0.0226 - val_loss: 0.0333\n",
      "Epoch 6/50\n",
      "717/717 [==============================] - 0s 76us/sample - loss: 0.0231 - val_loss: 0.0318\n",
      "Epoch 7/50\n",
      "717/717 [==============================] - 0s 77us/sample - loss: 0.0226 - val_loss: 0.0315\n",
      "Epoch 8/50\n",
      "717/717 [==============================] - 0s 77us/sample - loss: 0.0225 - val_loss: 0.0308\n",
      "Epoch 9/50\n",
      "717/717 [==============================] - 0s 80us/sample - loss: 0.0224 - val_loss: 0.0304\n",
      "Epoch 10/50\n",
      "717/717 [==============================] - 0s 85us/sample - loss: 0.0225 - val_loss: 0.0310\n",
      "Epoch 11/50\n",
      "717/717 [==============================] - 0s 79us/sample - loss: 0.0225 - val_loss: 0.0309\n",
      "Epoch 12/50\n",
      "717/717 [==============================] - 0s 80us/sample - loss: 0.0224 - val_loss: 0.0307\n",
      "Epoch 13/50\n",
      "717/717 [==============================] - 0s 79us/sample - loss: 0.0224 - val_loss: 0.0310\n",
      "Epoch 14/50\n",
      "717/717 [==============================] - 0s 79us/sample - loss: 0.0225 - val_loss: 0.0310\n",
      "Epoch 15/50\n",
      "717/717 [==============================] - 0s 78us/sample - loss: 0.0224 - val_loss: 0.0307\n",
      "Epoch 16/50\n",
      "717/717 [==============================] - 0s 80us/sample - loss: 0.0224 - val_loss: 0.0304\n",
      "Epoch 17/50\n",
      "717/717 [==============================] - 0s 82us/sample - loss: 0.0224 - val_loss: 0.0310\n",
      "Epoch 18/50\n",
      "717/717 [==============================] - 0s 85us/sample - loss: 0.0224 - val_loss: 0.0314\n",
      "Epoch 19/50\n",
      "717/717 [==============================] - 0s 83us/sample - loss: 0.0225 - val_loss: 0.0307\n",
      "Epoch 20/50\n",
      "717/717 [==============================] - 0s 86us/sample - loss: 0.0224 - val_loss: 0.0304\n",
      "Epoch 21/50\n",
      "717/717 [==============================] - 0s 84us/sample - loss: 0.0224 - val_loss: 0.0312\n",
      "Epoch 22/50\n",
      "717/717 [==============================] - 0s 79us/sample - loss: 0.0224 - val_loss: 0.0313\n",
      "Epoch 23/50\n",
      "717/717 [==============================] - 0s 76us/sample - loss: 0.0224 - val_loss: 0.0307\n",
      "Epoch 24/50\n",
      "717/717 [==============================] - 0s 77us/sample - loss: 0.0224 - val_loss: 0.0304\n",
      "Epoch 25/50\n",
      "717/717 [==============================] - 0s 76us/sample - loss: 0.0224 - val_loss: 0.0312\n",
      "Epoch 26/50\n",
      "717/717 [==============================] - 0s 78us/sample - loss: 0.0224 - val_loss: 0.0310\n",
      "Epoch 27/50\n",
      "717/717 [==============================] - 0s 86us/sample - loss: 0.0224 - val_loss: 0.0307\n",
      "Epoch 28/50\n",
      "717/717 [==============================] - 0s 84us/sample - loss: 0.0223 - val_loss: 0.0304\n",
      "Epoch 29/50\n",
      "717/717 [==============================] - 0s 82us/sample - loss: 0.0224 - val_loss: 0.0309\n",
      "Epoch 30/50\n",
      "717/717 [==============================] - 0s 78us/sample - loss: 0.0224 - val_loss: 0.0314\n",
      "Epoch 31/50\n",
      "717/717 [==============================] - 0s 81us/sample - loss: 0.0224 - val_loss: 0.0307\n",
      "Epoch 32/50\n",
      "717/717 [==============================] - 0s 78us/sample - loss: 0.0223 - val_loss: 0.0305\n",
      "Epoch 33/50\n",
      "717/717 [==============================] - 0s 75us/sample - loss: 0.0223 - val_loss: 0.0310\n",
      "Epoch 34/50\n",
      "717/717 [==============================] - 0s 77us/sample - loss: 0.0224 - val_loss: 0.0312\n",
      "Epoch 35/50\n",
      "717/717 [==============================] - 0s 83us/sample - loss: 0.0224 - val_loss: 0.0307\n",
      "Epoch 36/50\n",
      "717/717 [==============================] - 0s 84us/sample - loss: 0.0223 - val_loss: 0.0303\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "717/717 [==============================] - 0s 85us/sample - loss: 0.0223 - val_loss: 0.0311\n",
      "Epoch 38/50\n",
      "717/717 [==============================] - 0s 82us/sample - loss: 0.0224 - val_loss: 0.0310\n",
      "Epoch 39/50\n",
      "717/717 [==============================] - 0s 81us/sample - loss: 0.0223 - val_loss: 0.0308\n",
      "Epoch 40/50\n",
      "717/717 [==============================] - 0s 79us/sample - loss: 0.0223 - val_loss: 0.0304\n",
      "Epoch 41/50\n",
      "717/717 [==============================] - 0s 76us/sample - loss: 0.0223 - val_loss: 0.0308\n",
      "Epoch 42/50\n",
      "717/717 [==============================] - 0s 76us/sample - loss: 0.0223 - val_loss: 0.0311\n",
      "Epoch 43/50\n",
      "717/717 [==============================] - 0s 76us/sample - loss: 0.0223 - val_loss: 0.0308\n",
      "Epoch 44/50\n",
      "717/717 [==============================] - 0s 75us/sample - loss: 0.0223 - val_loss: 0.0305\n",
      "Epoch 45/50\n",
      "717/717 [==============================] - 0s 75us/sample - loss: 0.0223 - val_loss: 0.0309\n",
      "Epoch 46/50\n",
      "717/717 [==============================] - 0s 75us/sample - loss: 0.0223 - val_loss: 0.0314\n",
      "Epoch 47/50\n",
      "717/717 [==============================] - 0s 79us/sample - loss: 0.0223 - val_loss: 0.0309\n",
      "Epoch 48/50\n",
      "717/717 [==============================] - 0s 77us/sample - loss: 0.0223 - val_loss: 0.0304\n",
      "Epoch 49/50\n",
      "717/717 [==============================] - 0s 81us/sample - loss: 0.0223 - val_loss: 0.0307\n",
      "Epoch 50/50\n",
      "717/717 [==============================] - 0s 80us/sample - loss: 0.0223 - val_loss: 0.0312\n",
      "第5个数，还剩4118个没有训练\n",
      "inv_hat [1.03426516 1.01500929 1.02744253 1.02655328 1.00575705 1.00231746\n",
      " 1.00408607 1.00801899 0.99996065 1.00447915 1.02823308 1.04000733\n",
      " 1.0483344  1.02023497 0.99956799 0.99329098 1.00015703 0.99662436\n",
      " 1.00605204 0.98389585 0.96703098 0.96605887 0.94398158 0.9410896\n",
      " 0.9298414  0.94031898 0.93627667 0.93377752 0.92208349 0.92256163]\n",
      "Test RMSE: 0.014\n",
      "Train on 591 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "591/591 [==============================] - 0s 85us/sample - loss: 0.0168 - val_loss: 0.0090\n",
      "Epoch 2/50\n",
      "591/591 [==============================] - 0s 84us/sample - loss: 0.0164 - val_loss: 0.0108\n",
      "Epoch 3/50\n",
      "591/591 [==============================] - 0s 84us/sample - loss: 0.0234 - val_loss: 0.0201\n",
      "Epoch 4/50\n",
      "591/591 [==============================] - 0s 86us/sample - loss: 0.0208 - val_loss: 0.0092\n",
      "Epoch 5/50\n",
      "591/591 [==============================] - 0s 83us/sample - loss: 0.0243 - val_loss: 0.0220\n",
      "Epoch 6/50\n",
      "591/591 [==============================] - 0s 84us/sample - loss: 0.0193 - val_loss: 0.0093\n",
      "Epoch 7/50\n",
      "591/591 [==============================] - 0s 81us/sample - loss: 0.0225 - val_loss: 0.0118\n",
      "Epoch 8/50\n",
      "591/591 [==============================] - 0s 81us/sample - loss: 0.0220 - val_loss: 0.0229\n",
      "Epoch 9/50\n",
      "591/591 [==============================] - 0s 83us/sample - loss: 0.0197 - val_loss: 0.0123\n",
      "Epoch 10/50\n",
      "591/591 [==============================] - 0s 87us/sample - loss: 0.0164 - val_loss: 0.0091\n",
      "Epoch 11/50\n",
      "591/591 [==============================] - 0s 87us/sample - loss: 0.0157 - val_loss: 0.0086\n",
      "Epoch 12/50\n",
      "591/591 [==============================] - 0s 87us/sample - loss: 0.0193 - val_loss: 0.0133\n",
      "Epoch 13/50\n",
      "591/591 [==============================] - 0s 85us/sample - loss: 0.0174 - val_loss: 0.0125\n",
      "Epoch 14/50\n",
      "591/591 [==============================] - 0s 87us/sample - loss: 0.0237 - val_loss: 0.0135\n",
      "Epoch 15/50\n",
      "591/591 [==============================] - 0s 90us/sample - loss: 0.0214 - val_loss: 0.0208\n",
      "Epoch 16/50\n",
      "591/591 [==============================] - 0s 87us/sample - loss: 0.0183 - val_loss: 0.0137\n",
      "Epoch 17/50\n",
      "591/591 [==============================] - 0s 90us/sample - loss: 0.0162 - val_loss: 0.0087\n",
      "Epoch 18/50\n",
      "591/591 [==============================] - 0s 89us/sample - loss: 0.0156 - val_loss: 0.0086\n",
      "Epoch 19/50\n",
      "591/591 [==============================] - 0s 87us/sample - loss: 0.0184 - val_loss: 0.0122\n",
      "Epoch 20/50\n",
      "591/591 [==============================] - 0s 85us/sample - loss: 0.0168 - val_loss: 0.0096\n",
      "Epoch 21/50\n",
      "591/591 [==============================] - 0s 88us/sample - loss: 0.0217 - val_loss: 0.0108\n",
      "Epoch 22/50\n",
      "591/591 [==============================] - 0s 89us/sample - loss: 0.0205 - val_loss: 0.0208\n",
      "Epoch 23/50\n",
      "591/591 [==============================] - 0s 87us/sample - loss: 0.0187 - val_loss: 0.0113\n",
      "Epoch 24/50\n",
      "591/591 [==============================] - 0s 86us/sample - loss: 0.0155 - val_loss: 0.0088\n",
      "Epoch 25/50\n",
      "591/591 [==============================] - 0s 86us/sample - loss: 0.0148 - val_loss: 0.0085\n",
      "Epoch 26/50\n",
      "591/591 [==============================] - 0s 85us/sample - loss: 0.0171 - val_loss: 0.0103\n",
      "Epoch 27/50\n",
      "591/591 [==============================] - 0s 83us/sample - loss: 0.0158 - val_loss: 0.0125\n",
      "Epoch 28/50\n",
      "591/591 [==============================] - 0s 88us/sample - loss: 0.0209 - val_loss: 0.0116\n",
      "Epoch 29/50\n",
      "591/591 [==============================] - 0s 87us/sample - loss: 0.0215 - val_loss: 0.0249\n",
      "Epoch 30/50\n",
      "591/591 [==============================] - 0s 88us/sample - loss: 0.0183 - val_loss: 0.0131\n",
      "Epoch 31/50\n",
      "591/591 [==============================] - 0s 85us/sample - loss: 0.0160 - val_loss: 0.0092\n",
      "Epoch 32/50\n",
      "591/591 [==============================] - 0s 82us/sample - loss: 0.0189 - val_loss: 0.0145\n",
      "Epoch 33/50\n",
      "591/591 [==============================] - 0s 85us/sample - loss: 0.0168 - val_loss: 0.0086\n",
      "Epoch 34/50\n",
      "591/591 [==============================] - 0s 90us/sample - loss: 0.0193 - val_loss: 0.0086\n",
      "Epoch 35/50\n",
      "591/591 [==============================] - 0s 86us/sample - loss: 0.0192 - val_loss: 0.0186\n",
      "Epoch 36/50\n",
      "591/591 [==============================] - 0s 89us/sample - loss: 0.0178 - val_loss: 0.0102\n",
      "Epoch 37/50\n",
      "591/591 [==============================] - 0s 92us/sample - loss: 0.0150 - val_loss: 0.0090\n",
      "Epoch 38/50\n",
      "591/591 [==============================] - 0s 92us/sample - loss: 0.0147 - val_loss: 0.0084\n",
      "Epoch 39/50\n",
      "591/591 [==============================] - 0s 93us/sample - loss: 0.0167 - val_loss: 0.0097\n",
      "Epoch 40/50\n",
      "591/591 [==============================] - 0s 95us/sample - loss: 0.0151 - val_loss: 0.0117\n",
      "Epoch 41/50\n",
      "591/591 [==============================] - 0s 85us/sample - loss: 0.0182 - val_loss: 0.0116\n",
      "Epoch 42/50\n",
      "591/591 [==============================] - 0s 83us/sample - loss: 0.0176 - val_loss: 0.0090\n",
      "Epoch 43/50\n",
      "591/591 [==============================] - 0s 83us/sample - loss: 0.0189 - val_loss: 0.0115\n",
      "Epoch 44/50\n",
      "591/591 [==============================] - 0s 83us/sample - loss: 0.0161 - val_loss: 0.0080\n",
      "Epoch 45/50\n",
      "591/591 [==============================] - 0s 83us/sample - loss: 0.0183 - val_loss: 0.0089\n",
      "Epoch 46/50\n",
      "591/591 [==============================] - 0s 84us/sample - loss: 0.0190 - val_loss: 0.0189\n",
      "Epoch 47/50\n",
      "591/591 [==============================] - 0s 83us/sample - loss: 0.0174 - val_loss: 0.0097\n",
      "Epoch 48/50\n",
      "591/591 [==============================] - 0s 89us/sample - loss: 0.0148 - val_loss: 0.0098\n",
      "Epoch 49/50\n",
      "591/591 [==============================] - 0s 90us/sample - loss: 0.0149 - val_loss: 0.0084\n",
      "Epoch 50/50\n",
      "591/591 [==============================] - 0s 86us/sample - loss: 0.0169 - val_loss: 0.0112\n",
      "第6个数，还剩4117个没有训练\n",
      "inv_hat [0.92172717 0.92074261 0.92074261 0.92074261 0.91877527 0.91877527\n",
      " 0.91877527 0.91877527 0.91877527 0.91877527 0.91975866 0.92271233\n",
      " 0.92172717 0.910931   0.90702419 0.90507468 0.90604907 0.90507468\n",
      " 0.90995328 0.89924235 0.89440084 0.89343464 0.88957685 0.88957685\n",
      " 0.88957685 0.88957685 0.88957685 0.8886142  0.88765222 0.8886142 ]\n",
      "Test RMSE: 0.004\n",
      "Train on 643 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "643/643 [==============================] - 0s 85us/sample - loss: 0.0249 - val_loss: 0.0314\n",
      "Epoch 2/50\n",
      "643/643 [==============================] - 0s 85us/sample - loss: 0.0256 - val_loss: 0.0312\n",
      "Epoch 3/50\n",
      "643/643 [==============================] - 0s 85us/sample - loss: 0.0235 - val_loss: 0.0325\n",
      "Epoch 4/50\n",
      "643/643 [==============================] - 0s 81us/sample - loss: 0.0222 - val_loss: 0.0339\n",
      "Epoch 5/50\n",
      "643/643 [==============================] - 0s 81us/sample - loss: 0.0224 - val_loss: 0.0330\n",
      "Epoch 6/50\n",
      "643/643 [==============================] - 0s 80us/sample - loss: 0.0221 - val_loss: 0.0329\n",
      "Epoch 7/50\n",
      "643/643 [==============================] - 0s 80us/sample - loss: 0.0222 - val_loss: 0.0332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "643/643 [==============================] - 0s 83us/sample - loss: 0.0223 - val_loss: 0.0330\n",
      "Epoch 9/50\n",
      "643/643 [==============================] - 0s 82us/sample - loss: 0.0221 - val_loss: 0.0329\n",
      "Epoch 10/50\n",
      "643/643 [==============================] - 0s 84us/sample - loss: 0.0222 - val_loss: 0.0334\n",
      "Epoch 11/50\n",
      "643/643 [==============================] - 0s 83us/sample - loss: 0.0222 - val_loss: 0.0331\n",
      "Epoch 12/50\n",
      "643/643 [==============================] - 0s 78us/sample - loss: 0.0223 - val_loss: 0.0332\n",
      "Epoch 13/50\n",
      "643/643 [==============================] - 0s 83us/sample - loss: 0.0225 - val_loss: 0.0316\n",
      "Epoch 14/50\n",
      "643/643 [==============================] - 0s 77us/sample - loss: 0.0224 - val_loss: 0.0332\n",
      "Epoch 15/50\n",
      "643/643 [==============================] - 0s 86us/sample - loss: 0.0217 - val_loss: 0.0337\n",
      "Epoch 16/50\n",
      "643/643 [==============================] - 0s 83us/sample - loss: 0.0225 - val_loss: 0.0340\n",
      "Epoch 17/50\n",
      "643/643 [==============================] - 0s 86us/sample - loss: 0.0225 - val_loss: 0.0321\n",
      "Epoch 18/50\n",
      "643/643 [==============================] - 0s 85us/sample - loss: 0.0219 - val_loss: 0.0329\n",
      "Epoch 19/50\n",
      "643/643 [==============================] - 0s 81us/sample - loss: 0.0223 - val_loss: 0.0334\n",
      "Epoch 20/50\n",
      "643/643 [==============================] - 0s 82us/sample - loss: 0.0221 - val_loss: 0.0327\n",
      "Epoch 21/50\n",
      "643/643 [==============================] - 0s 82us/sample - loss: 0.0221 - val_loss: 0.0340\n",
      "Epoch 22/50\n",
      "643/643 [==============================] - 0s 84us/sample - loss: 0.0224 - val_loss: 0.0324\n",
      "Epoch 23/50\n",
      "643/643 [==============================] - 0s 85us/sample - loss: 0.0221 - val_loss: 0.0334\n",
      "Epoch 24/50\n",
      "643/643 [==============================] - 0s 83us/sample - loss: 0.0222 - val_loss: 0.0328\n",
      "Epoch 25/50\n",
      "643/643 [==============================] - 0s 84us/sample - loss: 0.0221 - val_loss: 0.0331\n",
      "Epoch 26/50\n",
      "643/643 [==============================] - 0s 83us/sample - loss: 0.0223 - val_loss: 0.0331\n",
      "Epoch 27/50\n",
      "643/643 [==============================] - 0s 80us/sample - loss: 0.0222 - val_loss: 0.0323\n",
      "Epoch 28/50\n",
      "643/643 [==============================] - 0s 78us/sample - loss: 0.0221 - val_loss: 0.0336\n",
      "Epoch 29/50\n",
      "643/643 [==============================] - 0s 75us/sample - loss: 0.0223 - val_loss: 0.0322\n",
      "Epoch 30/50\n",
      "643/643 [==============================] - 0s 77us/sample - loss: 0.0218 - val_loss: 0.0335\n",
      "Epoch 31/50\n",
      "643/643 [==============================] - 0s 80us/sample - loss: 0.0224 - val_loss: 0.0331\n",
      "Epoch 32/50\n",
      "643/643 [==============================] - 0s 83us/sample - loss: 0.0221 - val_loss: 0.0324\n",
      "Epoch 33/50\n",
      "643/643 [==============================] - 0s 77us/sample - loss: 0.0221 - val_loss: 0.0336\n",
      "Epoch 34/50\n",
      "643/643 [==============================] - 0s 77us/sample - loss: 0.0223 - val_loss: 0.0322\n",
      "Epoch 35/50\n",
      "643/643 [==============================] - 0s 79us/sample - loss: 0.0220 - val_loss: 0.0342\n",
      "Epoch 36/50\n",
      "643/643 [==============================] - 0s 80us/sample - loss: 0.0225 - val_loss: 0.0323\n",
      "Epoch 37/50\n",
      "643/643 [==============================] - 0s 77us/sample - loss: 0.0217 - val_loss: 0.0335\n",
      "Epoch 38/50\n",
      "643/643 [==============================] - 0s 79us/sample - loss: 0.0227 - val_loss: 0.0327\n",
      "Epoch 39/50\n",
      "643/643 [==============================] - 0s 83us/sample - loss: 0.0220 - val_loss: 0.0322\n",
      "Epoch 40/50\n",
      "643/643 [==============================] - 0s 78us/sample - loss: 0.0219 - val_loss: 0.0335\n",
      "Epoch 41/50\n",
      "643/643 [==============================] - 0s 81us/sample - loss: 0.0224 - val_loss: 0.0330\n",
      "Epoch 42/50\n",
      "643/643 [==============================] - 0s 78us/sample - loss: 0.0220 - val_loss: 0.0325\n",
      "Epoch 43/50\n",
      "643/643 [==============================] - 0s 78us/sample - loss: 0.0220 - val_loss: 0.0340\n",
      "Epoch 44/50\n",
      "643/643 [==============================] - 0s 79us/sample - loss: 0.0223 - val_loss: 0.0322\n",
      "Epoch 45/50\n",
      "643/643 [==============================] - 0s 78us/sample - loss: 0.0217 - val_loss: 0.0332\n",
      "Epoch 46/50\n",
      "643/643 [==============================] - 0s 77us/sample - loss: 0.0225 - val_loss: 0.0334\n",
      "Epoch 47/50\n",
      "643/643 [==============================] - 0s 78us/sample - loss: 0.0227 - val_loss: 0.0313\n",
      "Epoch 48/50\n",
      "643/643 [==============================] - 0s 78us/sample - loss: 0.0222 - val_loss: 0.0333\n",
      "Epoch 49/50\n",
      "643/643 [==============================] - 0s 80us/sample - loss: 0.0215 - val_loss: 0.0333\n",
      "Epoch 50/50\n",
      "643/643 [==============================] - 0s 76us/sample - loss: 0.0213 - val_loss: 0.0324\n",
      "第7个数，还剩4116个没有训练\n",
      "inv_hat [0.99899841 0.99504954 0.9940659  0.9940659  0.99014692 0.99112421\n",
      " 0.99112421 0.99308372 0.98917134 0.99112421 0.99702119 0.99800917\n",
      " 0.99603466 0.99014692 0.98917134 0.98625522 0.98722541 0.98819745\n",
      " 0.99210316 0.98722541 0.98722541 0.98432053 0.9823937  0.98047517\n",
      " 0.97951905 0.98047517 0.97951905 0.97951905 0.97666419 0.97856518]\n",
      "Test RMSE: 0.003\n",
      "Train on 740 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "740/740 [==============================] - 0s 82us/sample - loss: 0.0375 - val_loss: 0.0315\n",
      "Epoch 2/50\n",
      "740/740 [==============================] - 0s 80us/sample - loss: 0.0330 - val_loss: 0.0178\n",
      "Epoch 3/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0162 - val_loss: 0.0030\n",
      "Epoch 4/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0158 - val_loss: 0.0126\n",
      "Epoch 5/50\n",
      "740/740 [==============================] - 0s 82us/sample - loss: 0.0126 - val_loss: 0.0093\n",
      "Epoch 6/50\n",
      "740/740 [==============================] - 0s 87us/sample - loss: 0.0098 - val_loss: 0.0049\n",
      "Epoch 7/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0065 - val_loss: 0.0045\n",
      "Epoch 8/50\n",
      "740/740 [==============================] - 0s 83us/sample - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 9/50\n",
      "740/740 [==============================] - 0s 86us/sample - loss: 0.0053 - val_loss: 0.0032\n",
      "Epoch 10/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 11/50\n",
      "740/740 [==============================] - 0s 91us/sample - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 12/50\n",
      "740/740 [==============================] - 0s 88us/sample - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 13/50\n",
      "740/740 [==============================] - 0s 88us/sample - loss: 0.0049 - val_loss: 0.0026\n",
      "Epoch 14/50\n",
      "740/740 [==============================] - 0s 86us/sample - loss: 0.0047 - val_loss: 0.0026\n",
      "Epoch 15/50\n",
      "740/740 [==============================] - 0s 81us/sample - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 16/50\n",
      "740/740 [==============================] - 0s 83us/sample - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 17/50\n",
      "740/740 [==============================] - 0s 90us/sample - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 18/50\n",
      "740/740 [==============================] - 0s 82us/sample - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 19/50\n",
      "740/740 [==============================] - 0s 82us/sample - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 20/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 21/50\n",
      "740/740 [==============================] - 0s 92us/sample - loss: 0.0047 - val_loss: 0.0026\n",
      "Epoch 22/50\n",
      "740/740 [==============================] - 0s 86us/sample - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 23/50\n",
      "740/740 [==============================] - 0s 89us/sample - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 24/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 25/50\n",
      "740/740 [==============================] - 0s 90us/sample - loss: 0.0046 - val_loss: 0.0026\n",
      "Epoch 26/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 27/50\n",
      "740/740 [==============================] - 0s 89us/sample - loss: 0.0047 - val_loss: 0.0026\n",
      "Epoch 28/50\n",
      "740/740 [==============================] - 0s 81us/sample - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 29/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 30/50\n",
      "740/740 [==============================] - 0s 82us/sample - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 31/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0047 - val_loss: 0.0026\n",
      "Epoch 32/50\n",
      "740/740 [==============================] - 0s 82us/sample - loss: 0.0046 - val_loss: 0.0027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 34/50\n",
      "740/740 [==============================] - 0s 89us/sample - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 35/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 36/50\n",
      "740/740 [==============================] - 0s 81us/sample - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 37/50\n",
      "740/740 [==============================] - 0s 83us/sample - loss: 0.0047 - val_loss: 0.0026\n",
      "Epoch 38/50\n",
      "740/740 [==============================] - 0s 81us/sample - loss: 0.0046 - val_loss: 0.0026\n",
      "Epoch 39/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 40/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 41/50\n",
      "740/740 [==============================] - 0s 83us/sample - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 42/50\n",
      "740/740 [==============================] - 0s 81us/sample - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 43/50\n",
      "740/740 [==============================] - 0s 82us/sample - loss: 0.0047 - val_loss: 0.0026\n",
      "Epoch 44/50\n",
      "740/740 [==============================] - 0s 82us/sample - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 45/50\n",
      "740/740 [==============================] - 0s 80us/sample - loss: 0.0047 - val_loss: 0.0026\n",
      "Epoch 46/50\n",
      "740/740 [==============================] - 0s 80us/sample - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 47/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0049 - val_loss: 0.0028\n",
      "Epoch 48/50\n",
      "740/740 [==============================] - 0s 81us/sample - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 49/50\n",
      "740/740 [==============================] - 0s 78us/sample - loss: 0.0047 - val_loss: 0.0026\n",
      "Epoch 50/50\n",
      "740/740 [==============================] - 0s 83us/sample - loss: 0.0047 - val_loss: 0.0030\n",
      "第8个数，还剩4115个没有训练\n",
      "inv_hat [2.51722881 2.50811853 2.50811853 2.50609407 2.49900646 2.49900646\n",
      " 2.50204436 2.50406908 2.49596847 2.50103153 2.51419245 2.51318022\n",
      " 2.51115558 2.49900646 2.50305659 2.50305659 2.50508149 2.50508149\n",
      " 2.51115558 2.50305659 2.50204436 2.49596847 2.49293031 2.4919174\n",
      " 2.48786615 2.4919174  2.4898919  2.48786615 2.48685314 2.48887924]\n",
      "Test RMSE: 0.005\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0026\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0096 - val_loss: 0.0080\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0065 - val_loss: 0.0025\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0082 - val_loss: 0.0045\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0072 - val_loss: 0.0026\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0056 - val_loss: 0.0035\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0070 - val_loss: 0.0027\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0053 - val_loss: 0.0032\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0055 - val_loss: 0.0025\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0084 - val_loss: 0.0048\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0049 - val_loss: 0.0025\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0050 - val_loss: 0.0030\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0056 - val_loss: 0.0032\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0070 - val_loss: 0.0049\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0057 - val_loss: 0.0037\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0057 - val_loss: 0.0025\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0056 - val_loss: 0.0030\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0058 - val_loss: 0.0025\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0069 - val_loss: 0.0047\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0060 - val_loss: 0.0025\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0051 - val_loss: 0.0027\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0058 - val_loss: 0.0030\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0059 - val_loss: 0.0029\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0045 - val_loss: 0.0025\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0043 - val_loss: 0.0025\n",
      "第9个数，还剩4114个没有训练\n",
      "inv_hat [1.64458885 1.64260302 1.643596   1.64061684 1.6376367  1.63564942\n",
      " 1.63564942 1.6396237  1.6396237  1.64260302 1.64657398 1.64955086\n",
      " 1.6485587  1.6485587  1.64955086 1.6505429  1.65153486 1.65252657\n",
      " 1.64955086 1.64657398 1.64260302 1.64161005 1.64161005 1.64260302\n",
      " 1.64061684 1.64061684 1.64260302 1.64260302 1.643596   1.64558137]\n",
      "Test RMSE: 0.002\n",
      "Train on 646 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "646/646 [==============================] - 0s 81us/sample - loss: 0.0397 - val_loss: 0.0607\n",
      "Epoch 2/50\n",
      "646/646 [==============================] - 0s 80us/sample - loss: 0.0340 - val_loss: 0.0379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "646/646 [==============================] - 0s 79us/sample - loss: 0.0266 - val_loss: 0.0359\n",
      "Epoch 4/50\n",
      "646/646 [==============================] - 0s 79us/sample - loss: 0.0257 - val_loss: 0.0380\n",
      "Epoch 5/50\n",
      "646/646 [==============================] - 0s 82us/sample - loss: 0.0249 - val_loss: 0.0462\n",
      "Epoch 6/50\n",
      "646/646 [==============================] - 0s 74us/sample - loss: 0.0246 - val_loss: 0.0377\n",
      "Epoch 7/50\n",
      "646/646 [==============================] - 0s 80us/sample - loss: 0.0218 - val_loss: 0.0395\n",
      "Epoch 8/50\n",
      "646/646 [==============================] - 0s 80us/sample - loss: 0.0225 - val_loss: 0.0386\n",
      "Epoch 9/50\n",
      "646/646 [==============================] - 0s 84us/sample - loss: 0.0233 - val_loss: 0.0375\n",
      "Epoch 10/50\n",
      "646/646 [==============================] - 0s 77us/sample - loss: 0.0238 - val_loss: 0.0362\n",
      "Epoch 11/50\n",
      "646/646 [==============================] - 0s 78us/sample - loss: 0.0239 - val_loss: 0.0371\n",
      "Epoch 12/50\n",
      "646/646 [==============================] - 0s 85us/sample - loss: 0.0213 - val_loss: 0.0376\n",
      "Epoch 13/50\n",
      "646/646 [==============================] - 0s 80us/sample - loss: 0.0218 - val_loss: 0.0378\n",
      "Epoch 14/50\n",
      "646/646 [==============================] - 0s 80us/sample - loss: 0.0227 - val_loss: 0.0409\n",
      "Epoch 15/50\n",
      "646/646 [==============================] - 0s 83us/sample - loss: 0.0243 - val_loss: 0.0366\n",
      "Epoch 16/50\n",
      "646/646 [==============================] - 0s 82us/sample - loss: 0.0231 - val_loss: 0.0377\n",
      "Epoch 17/50\n",
      "646/646 [==============================] - 0s 79us/sample - loss: 0.0224 - val_loss: 0.0395\n",
      "Epoch 18/50\n",
      "646/646 [==============================] - 0s 76us/sample - loss: 0.0231 - val_loss: 0.0384\n",
      "Epoch 19/50\n",
      "646/646 [==============================] - 0s 76us/sample - loss: 0.0237 - val_loss: 0.0362\n",
      "Epoch 20/50\n",
      "646/646 [==============================] - 0s 79us/sample - loss: 0.0241 - val_loss: 0.0385\n",
      "Epoch 21/50\n",
      "646/646 [==============================] - 0s 78us/sample - loss: 0.0233 - val_loss: 0.0395\n",
      "Epoch 22/50\n",
      "646/646 [==============================] - 0s 77us/sample - loss: 0.0230 - val_loss: 0.0374\n",
      "Epoch 23/50\n",
      "646/646 [==============================] - 0s 79us/sample - loss: 0.0223 - val_loss: 0.0368\n",
      "Epoch 24/50\n",
      "646/646 [==============================] - 0s 77us/sample - loss: 0.0235 - val_loss: 0.0387\n",
      "Epoch 25/50\n",
      "646/646 [==============================] - 0s 81us/sample - loss: 0.0238 - val_loss: 0.0392\n",
      "Epoch 26/50\n",
      "646/646 [==============================] - 0s 78us/sample - loss: 0.0235 - val_loss: 0.0363\n",
      "Epoch 27/50\n",
      "646/646 [==============================] - 0s 83us/sample - loss: 0.0239 - val_loss: 0.0389\n",
      "Epoch 28/50\n",
      "646/646 [==============================] - 0s 78us/sample - loss: 0.0222 - val_loss: 0.0395\n",
      "Epoch 29/50\n",
      "646/646 [==============================] - 0s 82us/sample - loss: 0.0224 - val_loss: 0.0390\n",
      "Epoch 30/50\n",
      "646/646 [==============================] - 0s 82us/sample - loss: 0.0227 - val_loss: 0.0382\n",
      "Epoch 31/50\n",
      "646/646 [==============================] - 0s 80us/sample - loss: 0.0238 - val_loss: 0.0361\n",
      "Epoch 32/50\n",
      "646/646 [==============================] - 0s 82us/sample - loss: 0.0243 - val_loss: 0.0378\n",
      "Epoch 33/50\n",
      "646/646 [==============================] - 0s 83us/sample - loss: 0.0216 - val_loss: 0.0376\n",
      "Epoch 34/50\n",
      "646/646 [==============================] - 0s 85us/sample - loss: 0.0212 - val_loss: 0.0373\n",
      "Epoch 35/50\n",
      "646/646 [==============================] - 0s 85us/sample - loss: 0.0211 - val_loss: 0.0372\n",
      "Epoch 36/50\n",
      "646/646 [==============================] - 0s 84us/sample - loss: 0.0215 - val_loss: 0.0378\n",
      "Epoch 37/50\n",
      "646/646 [==============================] - 0s 82us/sample - loss: 0.0219 - val_loss: 0.0390\n",
      "Epoch 38/50\n",
      "646/646 [==============================] - 0s 85us/sample - loss: 0.0232 - val_loss: 0.0396\n",
      "Epoch 39/50\n",
      "646/646 [==============================] - 0s 83us/sample - loss: 0.0238 - val_loss: 0.0362\n",
      "Epoch 40/50\n",
      "646/646 [==============================] - 0s 79us/sample - loss: 0.0241 - val_loss: 0.0393\n",
      "Epoch 41/50\n",
      "646/646 [==============================] - 0s 81us/sample - loss: 0.0235 - val_loss: 0.0394\n",
      "Epoch 42/50\n",
      "646/646 [==============================] - 0s 80us/sample - loss: 0.0235 - val_loss: 0.0363\n",
      "Epoch 43/50\n",
      "646/646 [==============================] - 0s 80us/sample - loss: 0.0240 - val_loss: 0.0403\n",
      "Epoch 44/50\n",
      "646/646 [==============================] - 0s 80us/sample - loss: 0.0232 - val_loss: 0.0396\n",
      "Epoch 45/50\n",
      "646/646 [==============================] - 0s 77us/sample - loss: 0.0229 - val_loss: 0.0376\n",
      "Epoch 46/50\n",
      "646/646 [==============================] - 0s 80us/sample - loss: 0.0216 - val_loss: 0.0379\n",
      "Epoch 47/50\n",
      "646/646 [==============================] - 0s 82us/sample - loss: 0.0221 - val_loss: 0.0381\n",
      "Epoch 48/50\n",
      "646/646 [==============================] - 0s 81us/sample - loss: 0.0229 - val_loss: 0.0367\n",
      "Epoch 49/50\n",
      "646/646 [==============================] - 0s 79us/sample - loss: 0.0232 - val_loss: 0.0370\n",
      "Epoch 50/50\n",
      "646/646 [==============================] - 0s 81us/sample - loss: 0.0216 - val_loss: 0.0391\n",
      "第10个数，还剩4113个没有训练\n",
      "inv_hat [1.00138641 0.99642273 0.99642273 0.99543508 0.99150378 0.9905262\n",
      " 0.98955086 0.99150378 0.98955086 0.99248353 0.9984034  0.99939619\n",
      " 0.99741218 0.99346537 0.99444928 0.99248353 0.99346537 0.99444928\n",
      " 0.99939619 0.99543508 0.99543508 0.99248353 0.9905262  0.98857777\n",
      " 0.98663894 0.98760713 0.98663894 0.98760713 0.98663894 0.98760713]\n",
      "Test RMSE: 0.003\n",
      "Train on 733 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "733/733 [==============================] - 0s 87us/sample - loss: 0.0077 - val_loss: 0.0152\n",
      "Epoch 2/50\n",
      "733/733 [==============================] - 0s 85us/sample - loss: 0.0092 - val_loss: 0.0109\n",
      "Epoch 3/50\n",
      "733/733 [==============================] - 0s 86us/sample - loss: 0.0060 - val_loss: 0.0182\n",
      "Epoch 4/50\n",
      "733/733 [==============================] - 0s 87us/sample - loss: 0.0072 - val_loss: 0.0093\n",
      "Epoch 5/50\n",
      "733/733 [==============================] - 0s 85us/sample - loss: 0.0061 - val_loss: 0.0080\n",
      "Epoch 6/50\n",
      "733/733 [==============================] - 0s 84us/sample - loss: 0.0070 - val_loss: 0.0134\n",
      "Epoch 7/50\n",
      "733/733 [==============================] - 0s 91us/sample - loss: 0.0110 - val_loss: 0.0063\n",
      "Epoch 8/50\n",
      "733/733 [==============================] - 0s 85us/sample - loss: 0.0130 - val_loss: 0.0191\n",
      "Epoch 9/50\n",
      "733/733 [==============================] - 0s 84us/sample - loss: 0.0089 - val_loss: 0.0091\n",
      "Epoch 10/50\n",
      "733/733 [==============================] - 0s 85us/sample - loss: 0.0075 - val_loss: 0.0082\n",
      "Epoch 11/50\n",
      "733/733 [==============================] - 0s 81us/sample - loss: 0.0180 - val_loss: 0.0110\n",
      "Epoch 12/50\n",
      "733/733 [==============================] - 0s 84us/sample - loss: 0.0065 - val_loss: 0.0040\n",
      "Epoch 13/50\n",
      "733/733 [==============================] - 0s 92us/sample - loss: 0.0050 - val_loss: 0.0067\n",
      "Epoch 14/50\n",
      "733/733 [==============================] - 0s 90us/sample - loss: 0.0122 - val_loss: 0.0084\n",
      "Epoch 15/50\n",
      "733/733 [==============================] - 0s 89us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 16/50\n",
      "733/733 [==============================] - 0s 91us/sample - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 17/50\n",
      "733/733 [==============================] - 0s 89us/sample - loss: 0.0135 - val_loss: 0.0233\n",
      "Epoch 18/50\n",
      "733/733 [==============================] - 0s 81us/sample - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 19/50\n",
      "733/733 [==============================] - 0s 86us/sample - loss: 0.0081 - val_loss: 0.0075\n",
      "Epoch 20/50\n",
      "733/733 [==============================] - 0s 89us/sample - loss: 0.0177 - val_loss: 0.0086\n",
      "Epoch 21/50\n",
      "733/733 [==============================] - 0s 88us/sample - loss: 0.0058 - val_loss: 0.0039\n",
      "Epoch 22/50\n",
      "733/733 [==============================] - 0s 91us/sample - loss: 0.0059 - val_loss: 0.0101\n",
      "Epoch 23/50\n",
      "733/733 [==============================] - 0s 80us/sample - loss: 0.0139 - val_loss: 0.0135\n",
      "Epoch 24/50\n",
      "733/733 [==============================] - 0s 83us/sample - loss: 0.0070 - val_loss: 0.0085\n",
      "Epoch 25/50\n",
      "733/733 [==============================] - 0s 85us/sample - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 26/50\n",
      "733/733 [==============================] - 0s 90us/sample - loss: 0.0135 - val_loss: 0.0213\n",
      "Epoch 27/50\n",
      "733/733 [==============================] - 0s 87us/sample - loss: 0.0055 - val_loss: 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "733/733 [==============================] - 0s 90us/sample - loss: 0.0089 - val_loss: 0.0023\n",
      "Epoch 29/50\n",
      "733/733 [==============================] - 0s 90us/sample - loss: 0.0151 - val_loss: 0.0097\n",
      "Epoch 30/50\n",
      "733/733 [==============================] - 0s 84us/sample - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 31/50\n",
      "733/733 [==============================] - 0s 82us/sample - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 32/50\n",
      "733/733 [==============================] - 0s 88us/sample - loss: 0.0073 - val_loss: 0.0040\n",
      "Epoch 33/50\n",
      "733/733 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0096\n",
      "Epoch 34/50\n",
      "733/733 [==============================] - 0s 92us/sample - loss: 0.0159 - val_loss: 0.0206\n",
      "Epoch 35/50\n",
      "733/733 [==============================] - 0s 88us/sample - loss: 0.0061 - val_loss: 0.0087\n",
      "Epoch 36/50\n",
      "733/733 [==============================] - 0s 91us/sample - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 37/50\n",
      "733/733 [==============================] - 0s 86us/sample - loss: 0.0134 - val_loss: 0.0255\n",
      "Epoch 38/50\n",
      "733/733 [==============================] - 0s 90us/sample - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 39/50\n",
      "733/733 [==============================] - 0s 90us/sample - loss: 0.0056 - val_loss: 0.0074\n",
      "Epoch 40/50\n",
      "733/733 [==============================] - 0s 90us/sample - loss: 0.0140 - val_loss: 0.0168\n",
      "Epoch 41/50\n",
      "733/733 [==============================] - 0s 84us/sample - loss: 0.0059 - val_loss: 0.0081\n",
      "Epoch 42/50\n",
      "733/733 [==============================] - 0s 84us/sample - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 43/50\n",
      "733/733 [==============================] - 0s 86us/sample - loss: 0.0141 - val_loss: 0.0249\n",
      "Epoch 44/50\n",
      "733/733 [==============================] - 0s 85us/sample - loss: 0.0076 - val_loss: 0.0069\n",
      "Epoch 45/50\n",
      "733/733 [==============================] - 0s 83us/sample - loss: 0.0056 - val_loss: 0.0087\n",
      "Epoch 46/50\n",
      "733/733 [==============================] - 0s 86us/sample - loss: 0.0140 - val_loss: 0.0111\n",
      "Epoch 47/50\n",
      "733/733 [==============================] - 0s 91us/sample - loss: 0.0048 - val_loss: 0.0069\n",
      "Epoch 48/50\n",
      "733/733 [==============================] - 0s 85us/sample - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 49/50\n",
      "733/733 [==============================] - 0s 86us/sample - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 50/50\n",
      "733/733 [==============================] - 0s 84us/sample - loss: 0.0066 - val_loss: 0.0062\n",
      "第11个数，还剩4112个没有训练\n",
      "inv_hat [1.09582106 1.09572166 1.09572166 1.09572166 1.09582106 1.09592055\n",
      " 1.09582106 1.09592055 1.09602005 1.09611952 1.09651736 1.09681553\n",
      " 1.09741171 1.09731234 1.09765971 1.09805432 1.09815294 1.09825145\n",
      " 1.09795568 1.09765971 1.09756101 1.09716631 1.09736374 1.09785703\n",
      " 1.09815294 1.09835005 1.09854723 1.09864581 1.09894136 1.0997292 ]\n",
      "Test RMSE: 0.001\n",
      "Train on 1194 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1194/1194 [==============================] - 0s 76us/sample - loss: 0.0193 - val_loss: 0.0261\n",
      "Epoch 2/50\n",
      "1194/1194 [==============================] - 0s 78us/sample - loss: 0.0207 - val_loss: 0.0268\n",
      "Epoch 3/50\n",
      "1194/1194 [==============================] - 0s 75us/sample - loss: 0.0209 - val_loss: 0.0249\n",
      "Epoch 4/50\n",
      "1194/1194 [==============================] - 0s 79us/sample - loss: 0.0203 - val_loss: 0.0239\n",
      "Epoch 5/50\n",
      "1194/1194 [==============================] - 0s 76us/sample - loss: 0.0201 - val_loss: 0.0228\n",
      "Epoch 6/50\n",
      "1194/1194 [==============================] - 0s 75us/sample - loss: 0.0197 - val_loss: 0.0228\n",
      "Epoch 7/50\n",
      "1194/1194 [==============================] - 0s 76us/sample - loss: 0.0198 - val_loss: 0.0239\n",
      "Epoch 8/50\n",
      "1194/1194 [==============================] - 0s 79us/sample - loss: 0.0200 - val_loss: 0.0241\n",
      "Epoch 9/50\n",
      "1194/1194 [==============================] - 0s 82us/sample - loss: 0.0200 - val_loss: 0.0241\n",
      "Epoch 10/50\n",
      "1194/1194 [==============================] - 0s 81us/sample - loss: 0.0201 - val_loss: 0.0241\n",
      "Epoch 11/50\n",
      "1194/1194 [==============================] - 0s 83us/sample - loss: 0.0201 - val_loss: 0.0241\n",
      "Epoch 12/50\n",
      "1194/1194 [==============================] - 0s 81us/sample - loss: 0.0201 - val_loss: 0.0241\n",
      "Epoch 13/50\n",
      "1194/1194 [==============================] - 0s 76us/sample - loss: 0.0201 - val_loss: 0.0238\n",
      "Epoch 14/50\n",
      "1194/1194 [==============================] - 0s 80us/sample - loss: 0.0200 - val_loss: 0.0240\n",
      "Epoch 15/50\n",
      "1194/1194 [==============================] - 0s 77us/sample - loss: 0.0201 - val_loss: 0.0241\n",
      "Epoch 16/50\n",
      "1194/1194 [==============================] - 0s 85us/sample - loss: 0.0201 - val_loss: 0.0241\n",
      "Epoch 17/50\n",
      "1194/1194 [==============================] - 0s 81us/sample - loss: 0.0201 - val_loss: 0.0240\n",
      "Epoch 18/50\n",
      "1194/1194 [==============================] - 0s 81us/sample - loss: 0.0202 - val_loss: 0.0238\n",
      "Epoch 19/50\n",
      "1194/1194 [==============================] - 0s 83us/sample - loss: 0.0201 - val_loss: 0.0239\n",
      "Epoch 20/50\n",
      "1194/1194 [==============================] - 0s 81us/sample - loss: 0.0201 - val_loss: 0.0242\n",
      "Epoch 21/50\n",
      "1194/1194 [==============================] - 0s 79us/sample - loss: 0.0202 - val_loss: 0.0239\n",
      "Epoch 22/50\n",
      "1194/1194 [==============================] - 0s 82us/sample - loss: 0.0201 - val_loss: 0.0239\n",
      "Epoch 23/50\n",
      "1194/1194 [==============================] - 0s 80us/sample - loss: 0.0202 - val_loss: 0.0243\n",
      "Epoch 24/50\n",
      "1194/1194 [==============================] - 0s 79us/sample - loss: 0.0202 - val_loss: 0.0244\n",
      "Epoch 25/50\n",
      "1194/1194 [==============================] - 0s 87us/sample - loss: 0.0204 - val_loss: 0.0244\n",
      "Epoch 26/50\n",
      "1194/1194 [==============================] - 0s 80us/sample - loss: 0.0204 - val_loss: 0.0244\n",
      "Epoch 27/50\n",
      "1194/1194 [==============================] - 0s 86us/sample - loss: 0.0204 - val_loss: 0.0243\n",
      "Epoch 28/50\n",
      "1194/1194 [==============================] - 0s 83us/sample - loss: 0.0204 - val_loss: 0.0243\n",
      "Epoch 29/50\n",
      "1194/1194 [==============================] - 0s 84us/sample - loss: 0.0204 - val_loss: 0.0245\n",
      "Epoch 30/50\n",
      "1194/1194 [==============================] - 0s 86us/sample - loss: 0.0205 - val_loss: 0.0246\n",
      "Epoch 31/50\n",
      "1194/1194 [==============================] - 0s 81us/sample - loss: 0.0204 - val_loss: 0.0241\n",
      "Epoch 32/50\n",
      "1194/1194 [==============================] - 0s 80us/sample - loss: 0.0203 - val_loss: 0.0245\n",
      "Epoch 33/50\n",
      "1194/1194 [==============================] - 0s 78us/sample - loss: 0.0205 - val_loss: 0.0246\n",
      "Epoch 34/50\n",
      "1194/1194 [==============================] - 0s 77us/sample - loss: 0.0205 - val_loss: 0.0242\n",
      "Epoch 35/50\n",
      "1194/1194 [==============================] - 0s 84us/sample - loss: 0.0203 - val_loss: 0.0243\n",
      "Epoch 36/50\n",
      "1194/1194 [==============================] - 0s 83us/sample - loss: 0.0204 - val_loss: 0.0244\n",
      "Epoch 37/50\n",
      "1194/1194 [==============================] - 0s 83us/sample - loss: 0.0204 - val_loss: 0.0245\n",
      "Epoch 38/50\n",
      "1194/1194 [==============================] - 0s 85us/sample - loss: 0.0205 - val_loss: 0.0246\n",
      "Epoch 39/50\n",
      "1194/1194 [==============================] - 0s 83us/sample - loss: 0.0205 - val_loss: 0.0242\n",
      "Epoch 40/50\n",
      "1194/1194 [==============================] - 0s 79us/sample - loss: 0.0204 - val_loss: 0.0243\n",
      "Epoch 41/50\n",
      "1194/1194 [==============================] - 0s 76us/sample - loss: 0.0204 - val_loss: 0.0244\n",
      "Epoch 42/50\n",
      "1194/1194 [==============================] - 0s 75us/sample - loss: 0.0205 - val_loss: 0.0245\n",
      "Epoch 43/50\n",
      "1194/1194 [==============================] - 0s 80us/sample - loss: 0.0206 - val_loss: 0.0244\n",
      "Epoch 44/50\n",
      "1194/1194 [==============================] - 0s 82us/sample - loss: 0.0205 - val_loss: 0.0242\n",
      "Epoch 45/50\n",
      "1194/1194 [==============================] - 0s 77us/sample - loss: 0.0204 - val_loss: 0.0243\n",
      "Epoch 46/50\n",
      "1194/1194 [==============================] - 0s 76us/sample - loss: 0.0204 - val_loss: 0.0244\n",
      "Epoch 47/50\n",
      "1194/1194 [==============================] - 0s 76us/sample - loss: 0.0205 - val_loss: 0.0246\n",
      "Epoch 48/50\n",
      "1194/1194 [==============================] - 0s 78us/sample - loss: 0.0206 - val_loss: 0.0245\n",
      "Epoch 49/50\n",
      "1194/1194 [==============================] - 0s 78us/sample - loss: 0.0205 - val_loss: 0.0243\n",
      "Epoch 50/50\n",
      "1194/1194 [==============================] - 0s 83us/sample - loss: 0.0205 - val_loss: 0.0246\n",
      "第12个数，还剩4111个没有训练\n",
      "inv_hat [1.77701658 1.75588652 1.76292839 1.76292839 1.75186338 1.763297\n",
      " 1.75789831 1.67956464 1.67054733 1.66754277 1.69560773 1.6865816\n",
      " 1.6645389  1.63253789 1.62754504 1.6095885  1.6255485  1.63853211\n",
      " 1.6555308  1.63353677 1.62754504 1.61158223 1.59862956 1.5846985\n",
      " 1.57475986 1.57376652 1.57134195 1.57134195 1.56483175 1.56483175]\n",
      "Test RMSE: 0.026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0120 - val_loss: 0.0102\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0111 - val_loss: 0.0067\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0097 - val_loss: 0.0041\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0096 - val_loss: 0.0041\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0100 - val_loss: 0.0039\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0104 - val_loss: 0.0041\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0107 - val_loss: 0.0053\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0105 - val_loss: 0.0054\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0101 - val_loss: 0.0044\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0098 - val_loss: 0.0041\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0099 - val_loss: 0.0040\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0101 - val_loss: 0.0042\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0104 - val_loss: 0.0044\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0105 - val_loss: 0.0050\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0102 - val_loss: 0.0045\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0102 - val_loss: 0.0044\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0101 - val_loss: 0.0043\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0101 - val_loss: 0.0042\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0102 - val_loss: 0.0043\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0103 - val_loss: 0.0045\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0104 - val_loss: 0.0043\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0105 - val_loss: 0.0047\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0102 - val_loss: 0.0045\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0102 - val_loss: 0.0044\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0102 - val_loss: 0.0043\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0102 - val_loss: 0.0043\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0104 - val_loss: 0.0046\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0104 - val_loss: 0.0046\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0104 - val_loss: 0.0047\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0103 - val_loss: 0.0045\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0103 - val_loss: 0.0044\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0103 - val_loss: 0.0043\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0104 - val_loss: 0.0046\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0103 - val_loss: 0.0046\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0104 - val_loss: 0.0047\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0104 - val_loss: 0.0046\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0103 - val_loss: 0.0045\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0103 - val_loss: 0.0044\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0103 - val_loss: 0.0045\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0104 - val_loss: 0.0046\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0104 - val_loss: 0.0046\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0104 - val_loss: 0.0048\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0104 - val_loss: 0.0047\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0103 - val_loss: 0.0047\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0103 - val_loss: 0.0047\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0103 - val_loss: 0.0047\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0103 - val_loss: 0.0046\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0104 - val_loss: 0.0046\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0106 - val_loss: 0.0050\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0104 - val_loss: 0.0049\n",
      "第13个数，还剩4110个没有训练\n",
      "inv_hat [0.58785596 0.57432692 0.57143025 0.56853446 0.5511783  0.54925178\n",
      " 0.5511783  0.5588882  0.54539999 0.5511783  0.56853446 0.56756941\n",
      " 0.56467482 0.55696015 0.55696015 0.5511783  0.55599627 0.55406876\n",
      " 0.56274554 0.55021497 0.54636283 0.54539999 0.53962535 0.54058752\n",
      " 0.53770129 0.53962535 0.53770129 0.53577759 0.53097019 0.53289282]\n",
      "Test RMSE: 0.008\n",
      "Train on 607 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "607/607 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0304\n",
      "Epoch 2/50\n",
      "607/607 [==============================] - 0s 86us/sample - loss: 0.0104 - val_loss: 0.0331\n",
      "Epoch 3/50\n",
      "607/607 [==============================] - 0s 87us/sample - loss: 0.0219 - val_loss: 0.0389\n",
      "Epoch 4/50\n",
      "607/607 [==============================] - 0s 88us/sample - loss: 0.0135 - val_loss: 0.0365\n",
      "Epoch 5/50\n",
      "607/607 [==============================] - 0s 87us/sample - loss: 0.0209 - val_loss: 0.0441\n",
      "Epoch 6/50\n",
      "607/607 [==============================] - 0s 87us/sample - loss: 0.0147 - val_loss: 0.0305\n",
      "Epoch 7/50\n",
      "607/607 [==============================] - 0s 91us/sample - loss: 0.0177 - val_loss: 0.0332\n",
      "Epoch 8/50\n",
      "607/607 [==============================] - 0s 87us/sample - loss: 0.0125 - val_loss: 0.0342\n",
      "Epoch 9/50\n",
      "607/607 [==============================] - 0s 84us/sample - loss: 0.0167 - val_loss: 0.0333\n",
      "Epoch 10/50\n",
      "607/607 [==============================] - 0s 82us/sample - loss: 0.0138 - val_loss: 0.0279\n",
      "Epoch 11/50\n",
      "607/607 [==============================] - 0s 81us/sample - loss: 0.0177 - val_loss: 0.0343\n",
      "Epoch 12/50\n",
      "607/607 [==============================] - 0s 83us/sample - loss: 0.0114 - val_loss: 0.0337\n",
      "Epoch 13/50\n",
      "607/607 [==============================] - 0s 83us/sample - loss: 0.0157 - val_loss: 0.0357\n",
      "Epoch 14/50\n",
      "607/607 [==============================] - 0s 83us/sample - loss: 0.0151 - val_loss: 0.0280\n",
      "Epoch 15/50\n",
      "607/607 [==============================] - 0s 94us/sample - loss: 0.0151 - val_loss: 0.0333\n",
      "Epoch 16/50\n",
      "607/607 [==============================] - 0s 84us/sample - loss: 0.0106 - val_loss: 0.0337\n",
      "Epoch 17/50\n",
      "607/607 [==============================] - 0s 84us/sample - loss: 0.0150 - val_loss: 0.0345\n",
      "Epoch 18/50\n",
      "607/607 [==============================] - 0s 82us/sample - loss: 0.0130 - val_loss: 0.0286\n",
      "Epoch 19/50\n",
      "607/607 [==============================] - 0s 84us/sample - loss: 0.0149 - val_loss: 0.0311\n",
      "Epoch 20/50\n",
      "607/607 [==============================] - 0s 84us/sample - loss: 0.0098 - val_loss: 0.0324\n",
      "Epoch 21/50\n",
      "607/607 [==============================] - 0s 85us/sample - loss: 0.0119 - val_loss: 0.0317\n",
      "Epoch 22/50\n",
      "607/607 [==============================] - 0s 86us/sample - loss: 0.0112 - val_loss: 0.0303\n",
      "Epoch 23/50\n",
      "607/607 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0290\n",
      "Epoch 24/50\n",
      "607/607 [==============================] - 0s 80us/sample - loss: 0.0183 - val_loss: 0.0343\n",
      "Epoch 25/50\n",
      "607/607 [==============================] - 0s 80us/sample - loss: 0.0112 - val_loss: 0.0312\n",
      "Epoch 26/50\n",
      "607/607 [==============================] - 0s 81us/sample - loss: 0.0120 - val_loss: 0.0330\n",
      "Epoch 27/50\n",
      "607/607 [==============================] - 0s 85us/sample - loss: 0.0121 - val_loss: 0.0291\n",
      "Epoch 28/50\n",
      "607/607 [==============================] - 0s 82us/sample - loss: 0.0140 - val_loss: 0.0296\n",
      "Epoch 29/50\n",
      "607/607 [==============================] - 0s 82us/sample - loss: 0.0099 - val_loss: 0.0326\n",
      "Epoch 30/50\n",
      "607/607 [==============================] - 0s 83us/sample - loss: 0.0131 - val_loss: 0.0336\n",
      "Epoch 31/50\n",
      "607/607 [==============================] - 0s 80us/sample - loss: 0.0144 - val_loss: 0.0313\n",
      "Epoch 32/50\n",
      "607/607 [==============================] - 0s 85us/sample - loss: 0.0144 - val_loss: 0.0308\n",
      "Epoch 33/50\n",
      "607/607 [==============================] - 0s 88us/sample - loss: 0.0096 - val_loss: 0.0316\n",
      "Epoch 34/50\n",
      "607/607 [==============================] - 0s 88us/sample - loss: 0.0114 - val_loss: 0.0308\n",
      "Epoch 35/50\n",
      "607/607 [==============================] - 0s 85us/sample - loss: 0.0114 - val_loss: 0.0318\n",
      "Epoch 36/50\n",
      "607/607 [==============================] - 0s 80us/sample - loss: 0.0129 - val_loss: 0.0315\n",
      "Epoch 37/50\n",
      "607/607 [==============================] - 0s 94us/sample - loss: 0.0103 - val_loss: 0.0309\n",
      "Epoch 38/50\n",
      "607/607 [==============================] - 0s 92us/sample - loss: 0.0106 - val_loss: 0.0307\n",
      "Epoch 39/50\n",
      "607/607 [==============================] - 0s 86us/sample - loss: 0.0102 - val_loss: 0.0301\n",
      "Epoch 40/50\n",
      "607/607 [==============================] - 0s 88us/sample - loss: 0.0118 - val_loss: 0.0281\n",
      "Epoch 41/50\n",
      "607/607 [==============================] - 0s 84us/sample - loss: 0.0151 - val_loss: 0.0344\n",
      "Epoch 42/50\n",
      "607/607 [==============================] - 0s 84us/sample - loss: 0.0109 - val_loss: 0.0310\n",
      "Epoch 43/50\n",
      "607/607 [==============================] - 0s 87us/sample - loss: 0.0110 - val_loss: 0.0308\n",
      "Epoch 44/50\n",
      "607/607 [==============================] - 0s 87us/sample - loss: 0.0107 - val_loss: 0.0293\n",
      "Epoch 45/50\n",
      "607/607 [==============================] - 0s 88us/sample - loss: 0.0167 - val_loss: 0.0353\n",
      "Epoch 46/50\n",
      "607/607 [==============================] - 0s 88us/sample - loss: 0.0111 - val_loss: 0.0300\n",
      "Epoch 47/50\n",
      "607/607 [==============================] - 0s 85us/sample - loss: 0.0104 - val_loss: 0.0306\n",
      "Epoch 48/50\n",
      "607/607 [==============================] - 0s 92us/sample - loss: 0.0110 - val_loss: 0.0280\n",
      "Epoch 49/50\n",
      "607/607 [==============================] - 0s 83us/sample - loss: 0.0132 - val_loss: 0.0306\n",
      "Epoch 50/50\n",
      "607/607 [==============================] - 0s 83us/sample - loss: 0.0095 - val_loss: 0.0323\n",
      "第14个数，还剩4109个没有训练\n",
      "inv_hat [1.05978126 1.05978126 1.05978126 1.05961824 1.05876954 1.05876954\n",
      " 1.05876954 1.00747371 1.00849855 1.00849855 1.00952415 1.01157698\n",
      " 1.01157698 1.01260426 1.01260426 1.01363203 1.01466012 1.01466012\n",
      " 1.01157698 1.01055035 1.00952415 1.00952415 1.01157698 1.01260426\n",
      " 1.01260426 1.01260426 1.01260426 1.01363203 1.01363203 1.01671761]\n",
      "Test RMSE: 0.009\n",
      "Train on 1128 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1128/1128 [==============================] - 0s 77us/sample - loss: 0.0073 - val_loss: 0.0023\n",
      "Epoch 2/50\n",
      "1128/1128 [==============================] - 0s 82us/sample - loss: 0.0054 - val_loss: 0.0011\n",
      "Epoch 3/50\n",
      "1128/1128 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0025\n",
      "Epoch 4/50\n",
      "1128/1128 [==============================] - 0s 81us/sample - loss: 0.0060 - val_loss: 0.0038\n",
      "Epoch 5/50\n",
      "1128/1128 [==============================] - 0s 81us/sample - loss: 0.0089 - val_loss: 0.0012\n",
      "Epoch 6/50\n",
      "1128/1128 [==============================] - 0s 82us/sample - loss: 0.0119 - val_loss: 0.0141\n",
      "Epoch 7/50\n",
      "1128/1128 [==============================] - 0s 82us/sample - loss: 0.0093 - val_loss: 0.0109\n",
      "Epoch 8/50\n",
      "1128/1128 [==============================] - 0s 81us/sample - loss: 0.0081 - val_loss: 0.0032\n",
      "Epoch 9/50\n",
      "1128/1128 [==============================] - 0s 78us/sample - loss: 0.0136 - val_loss: 0.0125\n",
      "Epoch 10/50\n",
      "1128/1128 [==============================] - 0s 81us/sample - loss: 0.0086 - val_loss: 0.0094\n",
      "Epoch 11/50\n",
      "1128/1128 [==============================] - 0s 76us/sample - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 12/50\n",
      "1128/1128 [==============================] - 0s 82us/sample - loss: 0.0100 - val_loss: 0.0049\n",
      "Epoch 13/50\n",
      "1128/1128 [==============================] - 0s 83us/sample - loss: 0.0099 - val_loss: 0.0230\n",
      "Epoch 14/50\n",
      "1128/1128 [==============================] - 0s 84us/sample - loss: 0.0131 - val_loss: 0.0117\n",
      "Epoch 15/50\n",
      "1128/1128 [==============================] - 0s 82us/sample - loss: 0.0105 - val_loss: 0.0032\n",
      "Epoch 16/50\n",
      "1128/1128 [==============================] - 0s 83us/sample - loss: 0.0093 - val_loss: 7.1577e-04\n",
      "Epoch 17/50\n",
      "1128/1128 [==============================] - 0s 79us/sample - loss: 0.0078 - val_loss: 0.0037\n",
      "Epoch 18/50\n",
      "1128/1128 [==============================] - 0s 80us/sample - loss: 0.0076 - val_loss: 0.0018\n",
      "Epoch 19/50\n",
      "1128/1128 [==============================] - 0s 77us/sample - loss: 0.0091 - val_loss: 0.0084\n",
      "Epoch 20/50\n",
      "1128/1128 [==============================] - 0s 82us/sample - loss: 0.0132 - val_loss: 0.0302\n",
      "Epoch 21/50\n",
      "1128/1128 [==============================] - 0s 81us/sample - loss: 0.0233 - val_loss: 0.0133\n",
      "Epoch 22/50\n",
      "1128/1128 [==============================] - 0s 81us/sample - loss: 0.0184 - val_loss: 0.0050\n",
      "Epoch 23/50\n",
      "1128/1128 [==============================] - 0s 84us/sample - loss: 0.0121 - val_loss: 0.0022\n",
      "Epoch 24/50\n",
      "1128/1128 [==============================] - 0s 80us/sample - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 25/50\n",
      "1128/1128 [==============================] - 0s 81us/sample - loss: 0.0080 - val_loss: 0.0052\n",
      "Epoch 26/50\n",
      "1128/1128 [==============================] - 0s 81us/sample - loss: 0.0086 - val_loss: 0.0048\n",
      "Epoch 27/50\n",
      "1128/1128 [==============================] - 0s 84us/sample - loss: 0.0101 - val_loss: 0.0030\n",
      "Epoch 28/50\n",
      "1128/1128 [==============================] - 0s 79us/sample - loss: 0.0063 - val_loss: 0.0036\n",
      "Epoch 29/50\n",
      "1128/1128 [==============================] - 0s 75us/sample - loss: 0.0084 - val_loss: 0.0024\n",
      "Epoch 30/50\n",
      "1128/1128 [==============================] - 0s 77us/sample - loss: 0.0076 - val_loss: 8.0928e-04\n",
      "Epoch 31/50\n",
      "1128/1128 [==============================] - 0s 83us/sample - loss: 0.0082 - val_loss: 0.0133\n",
      "Epoch 32/50\n",
      "1128/1128 [==============================] - 0s 81us/sample - loss: 0.0128 - val_loss: 0.0267\n",
      "Epoch 33/50\n",
      "1128/1128 [==============================] - 0s 82us/sample - loss: 0.0212 - val_loss: 0.0146\n",
      "Epoch 34/50\n",
      "1128/1128 [==============================] - 0s 81us/sample - loss: 0.0201 - val_loss: 0.0031\n",
      "Epoch 35/50\n",
      "1128/1128 [==============================] - 0s 79us/sample - loss: 0.0211 - val_loss: 0.0151\n",
      "Epoch 36/50\n",
      "1128/1128 [==============================] - 0s 82us/sample - loss: 0.0089 - val_loss: 0.0092\n",
      "Epoch 37/50\n",
      "1128/1128 [==============================] - 0s 83us/sample - loss: 0.0079 - val_loss: 0.0016\n",
      "Epoch 38/50\n",
      "1128/1128 [==============================] - 0s 82us/sample - loss: 0.0075 - val_loss: 0.0072\n",
      "Epoch 39/50\n",
      "1128/1128 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0122\n",
      "Epoch 40/50\n",
      "1128/1128 [==============================] - 0s 80us/sample - loss: 0.0138 - val_loss: 0.0165\n",
      "Epoch 41/50\n",
      "1128/1128 [==============================] - 0s 79us/sample - loss: 0.0132 - val_loss: 0.0078\n",
      "Epoch 42/50\n",
      "1128/1128 [==============================] - 0s 77us/sample - loss: 0.0126 - val_loss: 0.0085\n",
      "Epoch 43/50\n",
      "1128/1128 [==============================] - 0s 82us/sample - loss: 0.0100 - val_loss: 5.7621e-04\n",
      "Epoch 44/50\n",
      "1128/1128 [==============================] - 0s 80us/sample - loss: 0.0072 - val_loss: 0.0044\n",
      "Epoch 45/50\n",
      "1128/1128 [==============================] - 0s 80us/sample - loss: 0.0071 - val_loss: 0.0031\n",
      "Epoch 46/50\n",
      "1128/1128 [==============================] - 0s 78us/sample - loss: 0.0102 - val_loss: 0.0185\n",
      "Epoch 47/50\n",
      "1128/1128 [==============================] - 0s 79us/sample - loss: 0.0098 - val_loss: 0.0074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      "1128/1128 [==============================] - 0s 77us/sample - loss: 0.0089 - val_loss: 0.0027\n",
      "Epoch 49/50\n",
      "1128/1128 [==============================] - 0s 79us/sample - loss: 0.0077 - val_loss: 0.0042\n",
      "Epoch 50/50\n",
      "1128/1128 [==============================] - 0s 78us/sample - loss: 0.0125 - val_loss: 0.0264\n",
      "第15个数，还剩4108个没有训练\n",
      "inv_hat [1.50856868 1.50753422 1.50753422 1.50753422 1.50753422 1.50753422\n",
      " 1.50753422 1.50753422 1.50753422 1.50753422 1.50960305 1.50960305\n",
      " 1.50960305 1.50960305 1.50960305 1.50960305 1.50960305 1.50960305\n",
      " 1.50960305 1.50856868 1.50856868 1.50753422 1.50753422 1.50753422\n",
      " 1.50753422 1.50753422 1.50753422 1.50649989 1.50546548 1.50753422]\n",
      "Test RMSE: 0.037\n",
      "Train on 704 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "704/704 [==============================] - 0s 80us/sample - loss: 0.0174 - val_loss: 0.0317\n",
      "Epoch 2/50\n",
      "704/704 [==============================] - 0s 78us/sample - loss: 0.0187 - val_loss: 0.0049\n",
      "Epoch 3/50\n",
      "704/704 [==============================] - 0s 78us/sample - loss: 0.0074 - val_loss: 0.0180\n",
      "Epoch 4/50\n",
      "704/704 [==============================] - 0s 81us/sample - loss: 0.0075 - val_loss: 0.0151\n",
      "Epoch 5/50\n",
      "704/704 [==============================] - 0s 79us/sample - loss: 0.0068 - val_loss: 0.0054\n",
      "Epoch 6/50\n",
      "704/704 [==============================] - 0s 83us/sample - loss: 0.0114 - val_loss: 0.0143\n",
      "Epoch 7/50\n",
      "704/704 [==============================] - 0s 84us/sample - loss: 0.0075 - val_loss: 0.0090\n",
      "Epoch 8/50\n",
      "704/704 [==============================] - 0s 84us/sample - loss: 0.0084 - val_loss: 0.0193\n",
      "Epoch 9/50\n",
      "704/704 [==============================] - 0s 78us/sample - loss: 0.0142 - val_loss: 0.0083\n",
      "Epoch 10/50\n",
      "704/704 [==============================] - 0s 76us/sample - loss: 0.0080 - val_loss: 0.0108\n",
      "Epoch 11/50\n",
      "704/704 [==============================] - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0012\n",
      "Epoch 12/50\n",
      "704/704 [==============================] - 0s 82us/sample - loss: 0.0129 - val_loss: 0.0130\n",
      "Epoch 13/50\n",
      "704/704 [==============================] - 0s 80us/sample - loss: 0.0065 - val_loss: 0.0087\n",
      "Epoch 14/50\n",
      "704/704 [==============================] - 0s 86us/sample - loss: 0.0074 - val_loss: 0.0139\n",
      "Epoch 15/50\n",
      "704/704 [==============================] - 0s 91us/sample - loss: 0.0102 - val_loss: 0.0133\n",
      "Epoch 16/50\n",
      "704/704 [==============================] - 0s 88us/sample - loss: 0.0102 - val_loss: 0.0011\n",
      "Epoch 17/50\n",
      "704/704 [==============================] - 0s 91us/sample - loss: 0.0120 - val_loss: 0.0085\n",
      "Epoch 18/50\n",
      "704/704 [==============================] - 0s 83us/sample - loss: 0.0095 - val_loss: 0.0056\n",
      "Epoch 19/50\n",
      "704/704 [==============================] - 0s 89us/sample - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 20/50\n",
      "704/704 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0095\n",
      "Epoch 21/50\n",
      "704/704 [==============================] - 0s 78us/sample - loss: 0.0120 - val_loss: 0.0021\n",
      "Epoch 22/50\n",
      "704/704 [==============================] - 0s 82us/sample - loss: 0.0081 - val_loss: 0.0034\n",
      "Epoch 23/50\n",
      "704/704 [==============================] - 0s 83us/sample - loss: 0.0140 - val_loss: 0.0146\n",
      "Epoch 24/50\n",
      "704/704 [==============================] - 0s 86us/sample - loss: 0.0103 - val_loss: 0.0016\n",
      "Epoch 25/50\n",
      "704/704 [==============================] - 0s 87us/sample - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 26/50\n",
      "704/704 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0060\n",
      "Epoch 27/50\n",
      "704/704 [==============================] - 0s 81us/sample - loss: 0.0073 - val_loss: 0.0082\n",
      "Epoch 28/50\n",
      "704/704 [==============================] - 0s 79us/sample - loss: 0.0096 - val_loss: 0.0115\n",
      "Epoch 29/50\n",
      "704/704 [==============================] - 0s 79us/sample - loss: 0.0127 - val_loss: 0.0040\n",
      "Epoch 30/50\n",
      "704/704 [==============================] - 0s 80us/sample - loss: 0.0092 - val_loss: 0.0011\n",
      "Epoch 31/50\n",
      "704/704 [==============================] - 0s 81us/sample - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 32/50\n",
      "704/704 [==============================] - 0s 76us/sample - loss: 0.0093 - val_loss: 0.0049\n",
      "Epoch 33/50\n",
      "704/704 [==============================] - 0s 80us/sample - loss: 0.0071 - val_loss: 0.0049\n",
      "Epoch 34/50\n",
      "704/704 [==============================] - 0s 80us/sample - loss: 0.0057 - val_loss: 0.0024\n",
      "Epoch 35/50\n",
      "704/704 [==============================] - 0s 75us/sample - loss: 0.0099 - val_loss: 0.0039\n",
      "Epoch 36/50\n",
      "704/704 [==============================] - 0s 86us/sample - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 37/50\n",
      "704/704 [==============================] - 0s 85us/sample - loss: 0.0104 - val_loss: 0.0085\n",
      "Epoch 38/50\n",
      "704/704 [==============================] - 0s 83us/sample - loss: 0.0122 - val_loss: 0.0033\n",
      "Epoch 39/50\n",
      "704/704 [==============================] - 0s 79us/sample - loss: 0.0081 - val_loss: 0.0053\n",
      "Epoch 40/50\n",
      "704/704 [==============================] - 0s 82us/sample - loss: 0.0140 - val_loss: 0.0115\n",
      "Epoch 41/50\n",
      "704/704 [==============================] - 0s 79us/sample - loss: 0.0102 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "704/704 [==============================] - 0s 81us/sample - loss: 0.0063 - val_loss: 0.0023\n",
      "Epoch 43/50\n",
      "704/704 [==============================] - 0s 77us/sample - loss: 0.0094 - val_loss: 0.0011\n",
      "Epoch 44/50\n",
      "704/704 [==============================] - 0s 78us/sample - loss: 0.0092 - val_loss: 0.0100\n",
      "Epoch 45/50\n",
      "704/704 [==============================] - 0s 79us/sample - loss: 0.0104 - val_loss: 0.0052\n",
      "Epoch 46/50\n",
      "704/704 [==============================] - 0s 84us/sample - loss: 0.0096 - val_loss: 0.0011\n",
      "Epoch 47/50\n",
      "704/704 [==============================] - 0s 81us/sample - loss: 0.0079 - val_loss: 0.0086\n",
      "Epoch 48/50\n",
      "704/704 [==============================] - 0s 77us/sample - loss: 0.0162 - val_loss: 0.0105\n",
      "Epoch 49/50\n",
      "704/704 [==============================] - 0s 81us/sample - loss: 0.0087 - val_loss: 0.0012\n",
      "Epoch 50/50\n",
      "704/704 [==============================] - 0s 82us/sample - loss: 0.0062 - val_loss: 0.0038\n",
      "第16个数，还剩4107个没有训练\n",
      "inv_hat [1.2402184  1.23923627 1.23923627 1.23923627 1.2402184  1.2402184\n",
      " 1.2402184  1.2402184  1.2402184  1.2402184  1.2402184  1.24120047\n",
      " 1.24120047 1.24120047 1.24145733 1.24145733 1.24145733 1.24145733\n",
      " 1.24145733 1.24145733 1.24145733 1.24145733 1.24145733 1.24145733\n",
      " 1.24145733 1.24145733 1.24145733 1.24145733 1.24243951 1.24342129]\n",
      "Test RMSE: 0.001\n",
      "Train on 856 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "856/856 [==============================] - 0s 83us/sample - loss: 0.0100 - val_loss: 0.0414\n",
      "Epoch 2/50\n",
      "856/856 [==============================] - 0s 81us/sample - loss: 0.0096 - val_loss: 0.0358\n",
      "Epoch 3/50\n",
      "856/856 [==============================] - 0s 78us/sample - loss: 0.0074 - val_loss: 0.0373\n",
      "Epoch 4/50\n",
      "856/856 [==============================] - 0s 78us/sample - loss: 0.0075 - val_loss: 0.0372\n",
      "Epoch 5/50\n",
      "856/856 [==============================] - 0s 78us/sample - loss: 0.0058 - val_loss: 0.0371\n",
      "Epoch 6/50\n",
      "856/856 [==============================] - 0s 78us/sample - loss: 0.0056 - val_loss: 0.0352\n",
      "Epoch 7/50\n",
      "856/856 [==============================] - 0s 80us/sample - loss: 0.0054 - val_loss: 0.0355\n",
      "Epoch 8/50\n",
      "856/856 [==============================] - 0s 78us/sample - loss: 0.0053 - val_loss: 0.0360\n",
      "Epoch 9/50\n",
      "856/856 [==============================] - 0s 76us/sample - loss: 0.0053 - val_loss: 0.0361\n",
      "Epoch 10/50\n",
      "856/856 [==============================] - 0s 86us/sample - loss: 0.0053 - val_loss: 0.0357\n",
      "Epoch 11/50\n",
      "856/856 [==============================] - 0s 80us/sample - loss: 0.0053 - val_loss: 0.0362\n",
      "Epoch 12/50\n",
      "856/856 [==============================] - 0s 78us/sample - loss: 0.0053 - val_loss: 0.0361\n",
      "Epoch 13/50\n",
      "856/856 [==============================] - 0s 76us/sample - loss: 0.0053 - val_loss: 0.0362\n",
      "Epoch 14/50\n",
      "856/856 [==============================] - 0s 76us/sample - loss: 0.0053 - val_loss: 0.0360\n",
      "Epoch 15/50\n",
      "856/856 [==============================] - 0s 76us/sample - loss: 0.0053 - val_loss: 0.0360\n",
      "Epoch 16/50\n",
      "856/856 [==============================] - 0s 78us/sample - loss: 0.0054 - val_loss: 0.0353\n",
      "Epoch 17/50\n",
      "856/856 [==============================] - 0s 77us/sample - loss: 0.0054 - val_loss: 0.0354\n",
      "Epoch 18/50\n",
      "856/856 [==============================] - 0s 81us/sample - loss: 0.0053 - val_loss: 0.0364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "856/856 [==============================] - 0s 79us/sample - loss: 0.0054 - val_loss: 0.0365\n",
      "Epoch 20/50\n",
      "856/856 [==============================] - 0s 79us/sample - loss: 0.0053 - val_loss: 0.0356\n",
      "Epoch 21/50\n",
      "856/856 [==============================] - 0s 76us/sample - loss: 0.0054 - val_loss: 0.0354\n",
      "Epoch 22/50\n",
      "856/856 [==============================] - 0s 78us/sample - loss: 0.0053 - val_loss: 0.0364\n",
      "Epoch 23/50\n",
      "856/856 [==============================] - 0s 79us/sample - loss: 0.0053 - val_loss: 0.0364\n",
      "Epoch 24/50\n",
      "856/856 [==============================] - 0s 83us/sample - loss: 0.0053 - val_loss: 0.0364\n",
      "Epoch 25/50\n",
      "856/856 [==============================] - 0s 82us/sample - loss: 0.0054 - val_loss: 0.0353\n",
      "Epoch 26/50\n",
      "856/856 [==============================] - 0s 82us/sample - loss: 0.0053 - val_loss: 0.0358\n",
      "Epoch 27/50\n",
      "856/856 [==============================] - 0s 79us/sample - loss: 0.0053 - val_loss: 0.0365\n",
      "Epoch 28/50\n",
      "856/856 [==============================] - 0s 79us/sample - loss: 0.0053 - val_loss: 0.0366\n",
      "Epoch 29/50\n",
      "856/856 [==============================] - 0s 78us/sample - loss: 0.0053 - val_loss: 0.0364\n",
      "Epoch 30/50\n",
      "856/856 [==============================] - 0s 79us/sample - loss: 0.0054 - val_loss: 0.0356\n",
      "Epoch 31/50\n",
      "856/856 [==============================] - 0s 78us/sample - loss: 0.0053 - val_loss: 0.0366\n",
      "Epoch 32/50\n",
      "856/856 [==============================] - 0s 78us/sample - loss: 0.0053 - val_loss: 0.0366\n",
      "Epoch 33/50\n",
      "856/856 [==============================] - 0s 81us/sample - loss: 0.0053 - val_loss: 0.0364\n",
      "Epoch 34/50\n",
      "856/856 [==============================] - 0s 82us/sample - loss: 0.0054 - val_loss: 0.0353\n",
      "Epoch 35/50\n",
      "856/856 [==============================] - 0s 80us/sample - loss: 0.0053 - val_loss: 0.0356\n",
      "Epoch 36/50\n",
      "856/856 [==============================] - 0s 77us/sample - loss: 0.0053 - val_loss: 0.0367\n",
      "Epoch 37/50\n",
      "856/856 [==============================] - 0s 77us/sample - loss: 0.0053 - val_loss: 0.0365\n",
      "Epoch 38/50\n",
      "856/856 [==============================] - 0s 82us/sample - loss: 0.0053 - val_loss: 0.0360\n",
      "Epoch 39/50\n",
      "856/856 [==============================] - 0s 78us/sample - loss: 0.0053 - val_loss: 0.0363\n",
      "Epoch 40/50\n",
      "856/856 [==============================] - 0s 79us/sample - loss: 0.0053 - val_loss: 0.0360\n",
      "Epoch 41/50\n",
      "856/856 [==============================] - 0s 79us/sample - loss: 0.0053 - val_loss: 0.0365\n",
      "Epoch 42/50\n",
      "856/856 [==============================] - 0s 82us/sample - loss: 0.0053 - val_loss: 0.0358\n",
      "Epoch 43/50\n",
      "856/856 [==============================] - 0s 81us/sample - loss: 0.0053 - val_loss: 0.0364\n",
      "Epoch 44/50\n",
      "856/856 [==============================] - 0s 79us/sample - loss: 0.0053 - val_loss: 0.0365\n",
      "Epoch 45/50\n",
      "856/856 [==============================] - 0s 82us/sample - loss: 0.0053 - val_loss: 0.0364\n",
      "Epoch 46/50\n",
      "856/856 [==============================] - 0s 83us/sample - loss: 0.0053 - val_loss: 0.0359\n",
      "Epoch 47/50\n",
      "856/856 [==============================] - 0s 84us/sample - loss: 0.0053 - val_loss: 0.0360\n",
      "Epoch 48/50\n",
      "856/856 [==============================] - 0s 83us/sample - loss: 0.0053 - val_loss: 0.0356\n",
      "Epoch 49/50\n",
      "856/856 [==============================] - 0s 83us/sample - loss: 0.0053 - val_loss: 0.0365\n",
      "Epoch 50/50\n",
      "856/856 [==============================] - 0s 80us/sample - loss: 0.0054 - val_loss: 0.0353\n",
      "第17个数，还剩4106个没有训练\n",
      "inv_hat [1.05127951 1.05137739 1.05157297 1.05167079 1.05186635 1.05225709\n",
      " 1.05245239 1.05255001 1.05274517 1.05284272 1.05333    1.05342741\n",
      " 1.05362217 1.05371939 1.053914   1.05430293 1.05449715 1.05459429\n",
      " 1.05478848 1.00029007 1.00077895 1.00087681 1.00107262 1.00117056\n",
      " 1.0013664  1.00175857 1.0019548  1.00205283 1.00224919 1.0023474 ]\n",
      "Test RMSE: 0.010\n",
      "Train on 1090 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1090/1090 [==============================] - 0s 82us/sample - loss: 0.0137 - val_loss: 0.0101\n",
      "Epoch 2/50\n",
      "1090/1090 [==============================] - 0s 79us/sample - loss: 0.0089 - val_loss: 0.0038\n",
      "Epoch 3/50\n",
      "1090/1090 [==============================] - 0s 81us/sample - loss: 0.0092 - val_loss: 0.0044\n",
      "Epoch 4/50\n",
      "1090/1090 [==============================] - 0s 87us/sample - loss: 0.0097 - val_loss: 0.0039\n",
      "Epoch 5/50\n",
      "1090/1090 [==============================] - 0s 84us/sample - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 6/50\n",
      "1090/1090 [==============================] - 0s 86us/sample - loss: 0.0147 - val_loss: 0.0150\n",
      "Epoch 7/50\n",
      "1090/1090 [==============================] - 0s 82us/sample - loss: 0.0183 - val_loss: 0.0067\n",
      "Epoch 8/50\n",
      "1090/1090 [==============================] - 0s 85us/sample - loss: 0.0167 - val_loss: 0.0031\n",
      "Epoch 9/50\n",
      "1090/1090 [==============================] - 0s 85us/sample - loss: 0.0124 - val_loss: 0.0048\n",
      "Epoch 10/50\n",
      "1090/1090 [==============================] - 0s 88us/sample - loss: 0.0144 - val_loss: 0.0133\n",
      "Epoch 11/50\n",
      "1090/1090 [==============================] - 0s 84us/sample - loss: 0.0139 - val_loss: 0.0116\n",
      "Epoch 12/50\n",
      "1090/1090 [==============================] - 0s 84us/sample - loss: 0.0113 - val_loss: 0.0062\n",
      "Epoch 13/50\n",
      "1090/1090 [==============================] - 0s 81us/sample - loss: 0.0107 - val_loss: 0.0031\n",
      "Epoch 14/50\n",
      "1090/1090 [==============================] - 0s 83us/sample - loss: 0.0128 - val_loss: 0.0157\n",
      "Epoch 15/50\n",
      "1090/1090 [==============================] - 0s 87us/sample - loss: 0.0171 - val_loss: 0.0139\n",
      "Epoch 16/50\n",
      "1090/1090 [==============================] - 0s 88us/sample - loss: 0.0185 - val_loss: 0.0044\n",
      "Epoch 17/50\n",
      "1090/1090 [==============================] - 0s 83us/sample - loss: 0.0126 - val_loss: 0.0036\n",
      "Epoch 18/50\n",
      "1090/1090 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 19/50\n",
      "1090/1090 [==============================] - 0s 80us/sample - loss: 0.0140 - val_loss: 0.0124\n",
      "Epoch 20/50\n",
      "1090/1090 [==============================] - 0s 80us/sample - loss: 0.0116 - val_loss: 0.0062\n",
      "Epoch 21/50\n",
      "1090/1090 [==============================] - 0s 83us/sample - loss: 0.0099 - val_loss: 0.0041\n",
      "Epoch 22/50\n",
      "1090/1090 [==============================] - 0s 85us/sample - loss: 0.0119 - val_loss: 0.0098\n",
      "Epoch 23/50\n",
      "1090/1090 [==============================] - 0s 80us/sample - loss: 0.0164 - val_loss: 0.0145\n",
      "Epoch 24/50\n",
      "1090/1090 [==============================] - 0s 78us/sample - loss: 0.0197 - val_loss: 0.0032\n",
      "Epoch 25/50\n",
      "1090/1090 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0036\n",
      "Epoch 26/50\n",
      "1090/1090 [==============================] - 0s 83us/sample - loss: 0.0118 - val_loss: 0.0105\n",
      "Epoch 27/50\n",
      "1090/1090 [==============================] - 0s 80us/sample - loss: 0.0138 - val_loss: 0.0122\n",
      "Epoch 28/50\n",
      "1090/1090 [==============================] - 0s 77us/sample - loss: 0.0124 - val_loss: 0.0065\n",
      "Epoch 29/50\n",
      "1090/1090 [==============================] - 0s 87us/sample - loss: 0.0110 - val_loss: 0.0036\n",
      "Epoch 30/50\n",
      "1090/1090 [==============================] - 0s 83us/sample - loss: 0.0138 - val_loss: 0.0144\n",
      "Epoch 31/50\n",
      "1090/1090 [==============================] - 0s 80us/sample - loss: 0.0164 - val_loss: 0.0104\n",
      "Epoch 32/50\n",
      "1090/1090 [==============================] - 0s 78us/sample - loss: 0.0149 - val_loss: 0.0062\n",
      "Epoch 33/50\n",
      "1090/1090 [==============================] - 0s 79us/sample - loss: 0.0096 - val_loss: 0.0042\n",
      "Epoch 34/50\n",
      "1090/1090 [==============================] - 0s 79us/sample - loss: 0.0104 - val_loss: 0.0060\n",
      "Epoch 35/50\n",
      "1090/1090 [==============================] - 0s 80us/sample - loss: 0.0089 - val_loss: 0.0034\n",
      "Epoch 36/50\n",
      "1090/1090 [==============================] - 0s 79us/sample - loss: 0.0084 - val_loss: 0.0035\n",
      "Epoch 37/50\n",
      "1090/1090 [==============================] - 0s 86us/sample - loss: 0.0086 - val_loss: 0.0048\n",
      "Epoch 38/50\n",
      "1090/1090 [==============================] - 0s 88us/sample - loss: 0.0084 - val_loss: 0.0036\n",
      "Epoch 39/50\n",
      "1090/1090 [==============================] - 0s 82us/sample - loss: 0.0085 - val_loss: 0.0036\n",
      "Epoch 40/50\n",
      "1090/1090 [==============================] - 0s 80us/sample - loss: 0.0090 - val_loss: 0.0033\n",
      "Epoch 41/50\n",
      "1090/1090 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0123\n",
      "Epoch 42/50\n",
      "1090/1090 [==============================] - 0s 83us/sample - loss: 0.0144 - val_loss: 0.0123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "1090/1090 [==============================] - 0s 85us/sample - loss: 0.0160 - val_loss: 0.0044\n",
      "Epoch 44/50\n",
      "1090/1090 [==============================] - 0s 83us/sample - loss: 0.0129 - val_loss: 0.0043\n",
      "Epoch 45/50\n",
      "1090/1090 [==============================] - 0s 85us/sample - loss: 0.0149 - val_loss: 0.0132\n",
      "Epoch 46/50\n",
      "1090/1090 [==============================] - 0s 81us/sample - loss: 0.0144 - val_loss: 0.0082\n",
      "Epoch 47/50\n",
      "1090/1090 [==============================] - 0s 84us/sample - loss: 0.0095 - val_loss: 0.0044\n",
      "Epoch 48/50\n",
      "1090/1090 [==============================] - 0s 80us/sample - loss: 0.0099 - val_loss: 0.0044\n",
      "Epoch 49/50\n",
      "1090/1090 [==============================] - 0s 79us/sample - loss: 0.0107 - val_loss: 0.0083\n",
      "Epoch 50/50\n",
      "1090/1090 [==============================] - 0s 80us/sample - loss: 0.0131 - val_loss: 0.0121\n",
      "第18个数，还剩4105个没有训练\n",
      "inv_hat [1.0384303  1.03785341 1.03823795 1.03775726 1.03660391 1.03641172\n",
      " 1.03689215 1.03670003 1.03727665 1.03718051 1.03852649 1.04016193\n",
      " 1.04016193 1.04083564 1.04122065 1.04285784 1.04305055 1.04343589\n",
      " 1.04170202 1.04035432 1.03958463 1.03939218 1.03929596 1.04054684\n",
      " 1.04093191 1.04093191 1.04141323 1.04160582 1.04189464 1.04507447]\n",
      "Test RMSE: 0.003\n",
      "Train on 485 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "485/485 [==============================] - 0s 83us/sample - loss: 0.0223 - val_loss: 0.0221\n",
      "Epoch 2/50\n",
      "485/485 [==============================] - 0s 80us/sample - loss: 0.0206 - val_loss: 0.0211\n",
      "Epoch 3/50\n",
      "485/485 [==============================] - 0s 78us/sample - loss: 0.0182 - val_loss: 0.0203\n",
      "Epoch 4/50\n",
      "485/485 [==============================] - 0s 88us/sample - loss: 0.0174 - val_loss: 0.0227\n",
      "Epoch 5/50\n",
      "485/485 [==============================] - 0s 83us/sample - loss: 0.0173 - val_loss: 0.0196\n",
      "Epoch 6/50\n",
      "485/485 [==============================] - 0s 86us/sample - loss: 0.0172 - val_loss: 0.0211\n",
      "Epoch 7/50\n",
      "485/485 [==============================] - 0s 87us/sample - loss: 0.0167 - val_loss: 0.0202\n",
      "Epoch 8/50\n",
      "485/485 [==============================] - 0s 82us/sample - loss: 0.0168 - val_loss: 0.0204\n",
      "Epoch 9/50\n",
      "485/485 [==============================] - 0s 82us/sample - loss: 0.0166 - val_loss: 0.0202\n",
      "Epoch 10/50\n",
      "485/485 [==============================] - 0s 82us/sample - loss: 0.0167 - val_loss: 0.0203\n",
      "Epoch 11/50\n",
      "485/485 [==============================] - 0s 80us/sample - loss: 0.0167 - val_loss: 0.0204\n",
      "Epoch 12/50\n",
      "485/485 [==============================] - 0s 80us/sample - loss: 0.0167 - val_loss: 0.0203\n",
      "Epoch 13/50\n",
      "485/485 [==============================] - 0s 82us/sample - loss: 0.0167 - val_loss: 0.0204\n",
      "Epoch 14/50\n",
      "485/485 [==============================] - 0s 84us/sample - loss: 0.0167 - val_loss: 0.0202\n",
      "Epoch 15/50\n",
      "485/485 [==============================] - 0s 80us/sample - loss: 0.0167 - val_loss: 0.0205\n",
      "Epoch 16/50\n",
      "485/485 [==============================] - 0s 81us/sample - loss: 0.0167 - val_loss: 0.0201\n",
      "Epoch 17/50\n",
      "485/485 [==============================] - 0s 79us/sample - loss: 0.0167 - val_loss: 0.0205\n",
      "Epoch 18/50\n",
      "485/485 [==============================] - 0s 79us/sample - loss: 0.0166 - val_loss: 0.0202\n",
      "Epoch 19/50\n",
      "485/485 [==============================] - 0s 80us/sample - loss: 0.0167 - val_loss: 0.0205\n",
      "Epoch 20/50\n",
      "485/485 [==============================] - 0s 88us/sample - loss: 0.0166 - val_loss: 0.0201\n",
      "Epoch 21/50\n",
      "485/485 [==============================] - 0s 86us/sample - loss: 0.0167 - val_loss: 0.0205\n",
      "Epoch 22/50\n",
      "485/485 [==============================] - 0s 88us/sample - loss: 0.0166 - val_loss: 0.0201\n",
      "Epoch 23/50\n",
      "485/485 [==============================] - 0s 85us/sample - loss: 0.0167 - val_loss: 0.0205\n",
      "Epoch 24/50\n",
      "485/485 [==============================] - 0s 86us/sample - loss: 0.0166 - val_loss: 0.0201\n",
      "Epoch 25/50\n",
      "485/485 [==============================] - 0s 85us/sample - loss: 0.0167 - val_loss: 0.0206\n",
      "Epoch 26/50\n",
      "485/485 [==============================] - 0s 89us/sample - loss: 0.0166 - val_loss: 0.0201\n",
      "Epoch 27/50\n",
      "485/485 [==============================] - 0s 86us/sample - loss: 0.0166 - val_loss: 0.0205\n",
      "Epoch 28/50\n",
      "485/485 [==============================] - 0s 87us/sample - loss: 0.0166 - val_loss: 0.0201\n",
      "Epoch 29/50\n",
      "485/485 [==============================] - 0s 92us/sample - loss: 0.0166 - val_loss: 0.0206\n",
      "Epoch 30/50\n",
      "485/485 [==============================] - 0s 89us/sample - loss: 0.0166 - val_loss: 0.0200\n",
      "Epoch 31/50\n",
      "485/485 [==============================] - 0s 89us/sample - loss: 0.0166 - val_loss: 0.0206\n",
      "Epoch 32/50\n",
      "485/485 [==============================] - 0s 85us/sample - loss: 0.0166 - val_loss: 0.0201\n",
      "Epoch 33/50\n",
      "485/485 [==============================] - 0s 84us/sample - loss: 0.0166 - val_loss: 0.0204\n",
      "Epoch 34/50\n",
      "485/485 [==============================] - 0s 86us/sample - loss: 0.0166 - val_loss: 0.0201\n",
      "Epoch 35/50\n",
      "485/485 [==============================] - 0s 85us/sample - loss: 0.0166 - val_loss: 0.0206\n",
      "Epoch 36/50\n",
      "485/485 [==============================] - 0s 81us/sample - loss: 0.0166 - val_loss: 0.0201\n",
      "Epoch 37/50\n",
      "485/485 [==============================] - 0s 80us/sample - loss: 0.0166 - val_loss: 0.0206\n",
      "Epoch 38/50\n",
      "485/485 [==============================] - 0s 87us/sample - loss: 0.0166 - val_loss: 0.0200\n",
      "Epoch 39/50\n",
      "485/485 [==============================] - 0s 90us/sample - loss: 0.0166 - val_loss: 0.0205\n",
      "Epoch 40/50\n",
      "485/485 [==============================] - 0s 83us/sample - loss: 0.0166 - val_loss: 0.0200\n",
      "Epoch 41/50\n",
      "485/485 [==============================] - 0s 81us/sample - loss: 0.0166 - val_loss: 0.0207\n",
      "Epoch 42/50\n",
      "485/485 [==============================] - 0s 85us/sample - loss: 0.0166 - val_loss: 0.0199\n",
      "Epoch 43/50\n",
      "485/485 [==============================] - 0s 86us/sample - loss: 0.0166 - val_loss: 0.0208\n",
      "Epoch 44/50\n",
      "485/485 [==============================] - 0s 85us/sample - loss: 0.0166 - val_loss: 0.0199\n",
      "Epoch 45/50\n",
      "485/485 [==============================] - 0s 84us/sample - loss: 0.0167 - val_loss: 0.0208\n",
      "Epoch 46/50\n",
      "485/485 [==============================] - 0s 89us/sample - loss: 0.0166 - val_loss: 0.0199\n",
      "Epoch 47/50\n",
      "485/485 [==============================] - 0s 94us/sample - loss: 0.0166 - val_loss: 0.0207\n",
      "Epoch 48/50\n",
      "485/485 [==============================] - 0s 84us/sample - loss: 0.0166 - val_loss: 0.0200\n",
      "Epoch 49/50\n",
      "485/485 [==============================] - 0s 80us/sample - loss: 0.0166 - val_loss: 0.0205\n",
      "Epoch 50/50\n",
      "485/485 [==============================] - 0s 80us/sample - loss: 0.0166 - val_loss: 0.0201\n",
      "第19个数，还剩4104个没有训练\n",
      "inv_hat [1.06474628 1.06037317 1.06173695 1.06193157 1.05832232 1.0580288\n",
      " 1.05773528 1.05949496 1.05763737 1.05910434 1.06435876 1.06542372\n",
      " 1.06445568 1.06076307 1.0604707  1.05753944 1.05832232 1.05929961\n",
      " 1.06212602 1.05949496 1.05890888 1.05675574 1.05469472 1.0541049\n",
      " 1.0528255  1.05371137 1.05233283 1.05184001 1.05154411 1.05262845]\n",
      "Test RMSE: 0.002\n",
      "Train on 706 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "706/706 [==============================] - 0s 76us/sample - loss: 0.0192 - val_loss: 0.0195\n",
      "Epoch 2/50\n",
      "706/706 [==============================] - 0s 82us/sample - loss: 0.0191 - val_loss: 0.0174\n",
      "Epoch 3/50\n",
      "706/706 [==============================] - 0s 79us/sample - loss: 0.0190 - val_loss: 0.0188\n",
      "Epoch 4/50\n",
      "706/706 [==============================] - 0s 80us/sample - loss: 0.0190 - val_loss: 0.0178\n",
      "Epoch 5/50\n",
      "706/706 [==============================] - 0s 80us/sample - loss: 0.0190 - val_loss: 0.0186\n",
      "Epoch 6/50\n",
      "706/706 [==============================] - 0s 80us/sample - loss: 0.0189 - val_loss: 0.0180\n",
      "Epoch 7/50\n",
      "706/706 [==============================] - 0s 78us/sample - loss: 0.0190 - val_loss: 0.0187\n",
      "Epoch 8/50\n",
      "706/706 [==============================] - 0s 83us/sample - loss: 0.0189 - val_loss: 0.0181\n",
      "Epoch 9/50\n",
      "706/706 [==============================] - 0s 87us/sample - loss: 0.0190 - val_loss: 0.0188\n",
      "Epoch 10/50\n",
      "706/706 [==============================] - 0s 84us/sample - loss: 0.0189 - val_loss: 0.0181\n",
      "Epoch 11/50\n",
      "706/706 [==============================] - 0s 85us/sample - loss: 0.0190 - val_loss: 0.0188\n",
      "Epoch 12/50\n",
      "706/706 [==============================] - 0s 82us/sample - loss: 0.0189 - val_loss: 0.0182\n",
      "Epoch 13/50\n",
      "706/706 [==============================] - 0s 85us/sample - loss: 0.0190 - val_loss: 0.0188\n",
      "Epoch 14/50\n",
      "706/706 [==============================] - 0s 79us/sample - loss: 0.0189 - val_loss: 0.0182\n",
      "Epoch 15/50\n",
      "706/706 [==============================] - 0s 81us/sample - loss: 0.0190 - val_loss: 0.0188\n",
      "Epoch 16/50\n",
      "706/706 [==============================] - 0s 83us/sample - loss: 0.0189 - val_loss: 0.0182\n",
      "Epoch 17/50\n",
      "706/706 [==============================] - 0s 82us/sample - loss: 0.0190 - val_loss: 0.0189\n",
      "Epoch 18/50\n",
      "706/706 [==============================] - 0s 83us/sample - loss: 0.0189 - val_loss: 0.0182\n",
      "Epoch 19/50\n",
      "706/706 [==============================] - 0s 79us/sample - loss: 0.0190 - val_loss: 0.0189\n",
      "Epoch 20/50\n",
      "706/706 [==============================] - 0s 78us/sample - loss: 0.0189 - val_loss: 0.0182\n",
      "Epoch 21/50\n",
      "706/706 [==============================] - 0s 78us/sample - loss: 0.0190 - val_loss: 0.0189\n",
      "Epoch 22/50\n",
      "706/706 [==============================] - 0s 80us/sample - loss: 0.0189 - val_loss: 0.0182\n",
      "Epoch 23/50\n",
      "706/706 [==============================] - 0s 87us/sample - loss: 0.0190 - val_loss: 0.0189\n",
      "Epoch 24/50\n",
      "706/706 [==============================] - 0s 81us/sample - loss: 0.0189 - val_loss: 0.0182\n",
      "Epoch 25/50\n",
      "706/706 [==============================] - 0s 84us/sample - loss: 0.0190 - val_loss: 0.0190\n",
      "Epoch 26/50\n",
      "706/706 [==============================] - 0s 81us/sample - loss: 0.0189 - val_loss: 0.0183\n",
      "Epoch 27/50\n",
      "706/706 [==============================] - 0s 83us/sample - loss: 0.0190 - val_loss: 0.0188\n",
      "Epoch 28/50\n",
      "706/706 [==============================] - 0s 83us/sample - loss: 0.0189 - val_loss: 0.0184\n",
      "Epoch 29/50\n",
      "706/706 [==============================] - 0s 85us/sample - loss: 0.0189 - val_loss: 0.0188\n",
      "Epoch 30/50\n",
      "706/706 [==============================] - 0s 85us/sample - loss: 0.0189 - val_loss: 0.0184\n",
      "Epoch 31/50\n",
      "706/706 [==============================] - 0s 84us/sample - loss: 0.0189 - val_loss: 0.0189\n",
      "Epoch 32/50\n",
      "706/706 [==============================] - 0s 82us/sample - loss: 0.0189 - val_loss: 0.0183\n",
      "Epoch 33/50\n",
      "706/706 [==============================] - 0s 80us/sample - loss: 0.0190 - val_loss: 0.0190\n",
      "Epoch 34/50\n",
      "706/706 [==============================] - 0s 79us/sample - loss: 0.0189 - val_loss: 0.0183\n",
      "Epoch 35/50\n",
      "706/706 [==============================] - 0s 77us/sample - loss: 0.0190 - val_loss: 0.0189\n",
      "Epoch 36/50\n",
      "706/706 [==============================] - 0s 78us/sample - loss: 0.0189 - val_loss: 0.0184\n",
      "Epoch 37/50\n",
      "706/706 [==============================] - 0s 77us/sample - loss: 0.0190 - val_loss: 0.0189\n",
      "Epoch 38/50\n",
      "706/706 [==============================] - 0s 78us/sample - loss: 0.0189 - val_loss: 0.0184\n",
      "Epoch 39/50\n",
      "706/706 [==============================] - 0s 82us/sample - loss: 0.0189 - val_loss: 0.0189\n",
      "Epoch 40/50\n",
      "706/706 [==============================] - 0s 78us/sample - loss: 0.0189 - val_loss: 0.0184\n",
      "Epoch 41/50\n",
      "706/706 [==============================] - 0s 79us/sample - loss: 0.0189 - val_loss: 0.0189\n",
      "Epoch 42/50\n",
      "706/706 [==============================] - 0s 77us/sample - loss: 0.0189 - val_loss: 0.0185\n",
      "Epoch 43/50\n",
      "706/706 [==============================] - 0s 78us/sample - loss: 0.0189 - val_loss: 0.0188\n",
      "Epoch 44/50\n",
      "706/706 [==============================] - 0s 88us/sample - loss: 0.0189 - val_loss: 0.0186\n",
      "Epoch 45/50\n",
      "706/706 [==============================] - 0s 86us/sample - loss: 0.0189 - val_loss: 0.0187\n",
      "Epoch 46/50\n",
      "706/706 [==============================] - 0s 82us/sample - loss: 0.0189 - val_loss: 0.0186\n",
      "Epoch 47/50\n",
      "706/706 [==============================] - 0s 83us/sample - loss: 0.0189 - val_loss: 0.0189\n",
      "Epoch 48/50\n",
      "706/706 [==============================] - 0s 83us/sample - loss: 0.0189 - val_loss: 0.0185\n",
      "Epoch 49/50\n",
      "706/706 [==============================] - 0s 82us/sample - loss: 0.0189 - val_loss: 0.0189\n",
      "Epoch 50/50\n",
      "706/706 [==============================] - 0s 81us/sample - loss: 0.0189 - val_loss: 0.0185\n",
      "第20个数，还剩4103个没有训练\n",
      "inv_hat [0.60226215 0.60521245 0.59774077 0.59479365 0.58654887 0.58782415\n",
      " 0.58458738 0.56891947 0.57988256 0.57244097 0.57058209 0.58488156\n",
      " 0.58977899 0.58603656 0.58209982 0.57698604 0.58249333 0.57472567\n",
      " 0.57079692 0.55942024 0.52856848 0.5343121  0.51904627 0.52555384\n",
      " 0.52225015 0.52895761 0.52186166 0.51739685 0.53743061 0.53733317]\n",
      "Test RMSE: 0.012\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0133 - val_loss: 0.0031\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 87us/sample - loss: 0.0109 - val_loss: 0.0031\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0104 - val_loss: 0.0031\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0104 - val_loss: 0.0031\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0107 - val_loss: 0.0032\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0108 - val_loss: 0.0032\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0107 - val_loss: 0.0032\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0108 - val_loss: 0.0032\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0109 - val_loss: 0.0032\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0107 - val_loss: 0.0033\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0033\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0032\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0033\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0034\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0037\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0038\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0113 - val_loss: 0.0036\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0112 - val_loss: 0.0035\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0112 - val_loss: 0.0037\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0113 - val_loss: 0.0036\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0035\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 87us/sample - loss: 0.0109 - val_loss: 0.0033\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0033\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0034\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0109 - val_loss: 0.0034\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0109 - val_loss: 0.0033\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0108 - val_loss: 0.0033\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0108 - val_loss: 0.0033\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0106 - val_loss: 0.0032\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0106 - val_loss: 0.0032\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0033\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0107 - val_loss: 0.0032\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0107 - val_loss: 0.0033\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0107 - val_loss: 0.0032\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0106 - val_loss: 0.0032\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0106 - val_loss: 0.0031\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0105 - val_loss: 0.0032\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0106 - val_loss: 0.0032\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0106 - val_loss: 0.0032\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0107 - val_loss: 0.0032\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0105 - val_loss: 0.0031\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0106 - val_loss: 0.0032\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0106 - val_loss: 0.0032\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0106 - val_loss: 0.0031\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0105 - val_loss: 0.0031\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 88us/sample - loss: 0.0106 - val_loss: 0.0031\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0105 - val_loss: 0.0031\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0105 - val_loss: 0.0031\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0106 - val_loss: 0.0032\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0106 - val_loss: 0.0031\n",
      "第21个数，还剩4102个没有训练\n",
      "inv_hat [1.8427418  1.83469266 1.8286562  1.82664449 1.80753433 1.80753433\n",
      " 1.80451751 1.8135685  1.80652869 1.81557986 1.8467668  1.85179842\n",
      " 1.85179842 1.8377108  1.8397233  1.83368632 1.85683056 1.86085636\n",
      " 1.87494926 1.84978582 1.85079199 1.83871696 1.82060892 1.81256268\n",
      " 1.79747911 1.80351214 1.79948986 1.80351214 1.79747911 1.81155705]\n",
      "Test RMSE: 0.012\n",
      "Train on 828 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "828/828 [==============================] - 0s 80us/sample - loss: 0.0128 - val_loss: 0.0075\n",
      "Epoch 2/50\n",
      "828/828 [==============================] - 0s 81us/sample - loss: 0.0125 - val_loss: 0.0074\n",
      "Epoch 3/50\n",
      "828/828 [==============================] - 0s 83us/sample - loss: 0.0129 - val_loss: 0.0075\n",
      "Epoch 4/50\n",
      "828/828 [==============================] - 0s 85us/sample - loss: 0.0134 - val_loss: 0.0077\n",
      "Epoch 5/50\n",
      "828/828 [==============================] - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0077\n",
      "Epoch 6/50\n",
      "828/828 [==============================] - 0s 83us/sample - loss: 0.0145 - val_loss: 0.0075\n",
      "Epoch 7/50\n",
      "828/828 [==============================] - 0s 79us/sample - loss: 0.0138 - val_loss: 0.0076\n",
      "Epoch 8/50\n",
      "828/828 [==============================] - 0s 80us/sample - loss: 0.0134 - val_loss: 0.0076\n",
      "Epoch 9/50\n",
      "828/828 [==============================] - 0s 79us/sample - loss: 0.0130 - val_loss: 0.0078\n",
      "Epoch 10/50\n",
      "828/828 [==============================] - 0s 81us/sample - loss: 0.0128 - val_loss: 0.0075\n",
      "Epoch 11/50\n",
      "828/828 [==============================] - 0s 81us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 12/50\n",
      "828/828 [==============================] - 0s 80us/sample - loss: 0.0130 - val_loss: 0.0076\n",
      "Epoch 13/50\n",
      "828/828 [==============================] - 0s 79us/sample - loss: 0.0134 - val_loss: 0.0075\n",
      "Epoch 14/50\n",
      "828/828 [==============================] - 0s 82us/sample - loss: 0.0135 - val_loss: 0.0075\n",
      "Epoch 15/50\n",
      "828/828 [==============================] - 0s 81us/sample - loss: 0.0133 - val_loss: 0.0076\n",
      "Epoch 16/50\n",
      "828/828 [==============================] - 0s 79us/sample - loss: 0.0130 - val_loss: 0.0077\n",
      "Epoch 17/50\n",
      "828/828 [==============================] - 0s 78us/sample - loss: 0.0128 - val_loss: 0.0075\n",
      "Epoch 18/50\n",
      "828/828 [==============================] - 0s 79us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 19/50\n",
      "828/828 [==============================] - 0s 82us/sample - loss: 0.0128 - val_loss: 0.0076\n",
      "Epoch 20/50\n",
      "828/828 [==============================] - 0s 81us/sample - loss: 0.0131 - val_loss: 0.0077\n",
      "Epoch 21/50\n",
      "828/828 [==============================] - 0s 79us/sample - loss: 0.0134 - val_loss: 0.0076\n",
      "Epoch 22/50\n",
      "828/828 [==============================] - 0s 79us/sample - loss: 0.0132 - val_loss: 0.0077\n",
      "Epoch 23/50\n",
      "828/828 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0077\n",
      "Epoch 24/50\n",
      "828/828 [==============================] - 0s 79us/sample - loss: 0.0131 - val_loss: 0.0077\n",
      "Epoch 25/50\n",
      "828/828 [==============================] - 0s 84us/sample - loss: 0.0128 - val_loss: 0.0075\n",
      "Epoch 26/50\n",
      "828/828 [==============================] - 0s 84us/sample - loss: 0.0128 - val_loss: 0.0075\n",
      "Epoch 27/50\n",
      "828/828 [==============================] - 0s 84us/sample - loss: 0.0128 - val_loss: 0.0075\n",
      "Epoch 28/50\n",
      "828/828 [==============================] - 0s 84us/sample - loss: 0.0126 - val_loss: 0.0075\n",
      "Epoch 29/50\n",
      "828/828 [==============================] - 0s 81us/sample - loss: 0.0125 - val_loss: 0.0075\n",
      "Epoch 30/50\n",
      "828/828 [==============================] - 0s 84us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 31/50\n",
      "828/828 [==============================] - 0s 78us/sample - loss: 0.0129 - val_loss: 0.0077\n",
      "Epoch 32/50\n",
      "828/828 [==============================] - 0s 89us/sample - loss: 0.0130 - val_loss: 0.0077\n",
      "Epoch 33/50\n",
      "828/828 [==============================] - 0s 90us/sample - loss: 0.0128 - val_loss: 0.0076\n",
      "Epoch 34/50\n",
      "828/828 [==============================] - 0s 82us/sample - loss: 0.0128 - val_loss: 0.0076\n",
      "Epoch 35/50\n",
      "828/828 [==============================] - 0s 82us/sample - loss: 0.0129 - val_loss: 0.0076\n",
      "Epoch 36/50\n",
      "828/828 [==============================] - 0s 80us/sample - loss: 0.0128 - val_loss: 0.0076\n",
      "Epoch 37/50\n",
      "828/828 [==============================] - 0s 80us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 38/50\n",
      "828/828 [==============================] - 0s 79us/sample - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 39/50\n",
      "828/828 [==============================] - 0s 79us/sample - loss: 0.0128 - val_loss: 0.0076\n",
      "Epoch 40/50\n",
      "828/828 [==============================] - 0s 82us/sample - loss: 0.0128 - val_loss: 0.0077\n",
      "Epoch 41/50\n",
      "828/828 [==============================] - 0s 78us/sample - loss: 0.0130 - val_loss: 0.0076\n",
      "Epoch 42/50\n",
      "828/828 [==============================] - 0s 83us/sample - loss: 0.0131 - val_loss: 0.0078\n",
      "Epoch 43/50\n",
      "828/828 [==============================] - 0s 80us/sample - loss: 0.0132 - val_loss: 0.0078\n",
      "Epoch 44/50\n",
      "828/828 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0076\n",
      "Epoch 45/50\n",
      "828/828 [==============================] - 0s 80us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 46/50\n",
      "828/828 [==============================] - 0s 88us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 47/50\n",
      "828/828 [==============================] - 0s 85us/sample - loss: 0.0128 - val_loss: 0.0076\n",
      "Epoch 48/50\n",
      "828/828 [==============================] - 0s 79us/sample - loss: 0.0128 - val_loss: 0.0077\n",
      "Epoch 49/50\n",
      "828/828 [==============================] - 0s 80us/sample - loss: 0.0128 - val_loss: 0.0077\n",
      "Epoch 50/50\n",
      "828/828 [==============================] - 0s 84us/sample - loss: 0.0129 - val_loss: 0.0076\n",
      "第22个数，还剩4101个没有训练\n",
      "inv_hat [0.45748266 0.44259934 0.44259934 0.44259934 0.42775733 0.42775733\n",
      " 0.42973379 0.43665743 0.42578166 0.42874545 0.44359032 0.44359032\n",
      " 0.43863732 0.42775733 0.42973379 0.42775733 0.4307223  0.42973379\n",
      " 0.43467829 0.42479411 0.42281967 0.41985944 0.41492984 0.41591536\n",
      " 0.41394453 0.41788697 0.41690106 0.41394453 0.40902115 0.40705326]\n",
      "Test RMSE: 0.006\n",
      "Train on 671 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "671/671 [==============================] - 0s 83us/sample - loss: 0.0077 - val_loss: 0.0040\n",
      "Epoch 2/50\n",
      "671/671 [==============================] - 0s 83us/sample - loss: 0.0105 - val_loss: 0.0061\n",
      "Epoch 3/50\n",
      "671/671 [==============================] - 0s 87us/sample - loss: 0.0089 - val_loss: 0.0066\n",
      "Epoch 4/50\n",
      "671/671 [==============================] - 0s 85us/sample - loss: 0.0186 - val_loss: 0.0228\n",
      "Epoch 5/50\n",
      "671/671 [==============================] - 0s 87us/sample - loss: 0.0209 - val_loss: 0.0171\n",
      "Epoch 6/50\n",
      "671/671 [==============================] - 0s 85us/sample - loss: 0.0116 - val_loss: 0.0163\n",
      "Epoch 7/50\n",
      "671/671 [==============================] - 0s 89us/sample - loss: 0.0062 - val_loss: 0.0027\n",
      "Epoch 8/50\n",
      "671/671 [==============================] - 0s 83us/sample - loss: 0.0097 - val_loss: 0.0093\n",
      "Epoch 9/50\n",
      "671/671 [==============================] - 0s 88us/sample - loss: 0.0070 - val_loss: 0.0041\n",
      "Epoch 10/50\n",
      "671/671 [==============================] - 0s 86us/sample - loss: 0.0079 - val_loss: 0.0029\n",
      "Epoch 11/50\n",
      "671/671 [==============================] - 0s 84us/sample - loss: 0.0075 - val_loss: 0.0066\n",
      "Epoch 12/50\n",
      "671/671 [==============================] - 0s 86us/sample - loss: 0.0067 - val_loss: 0.0049\n",
      "Epoch 13/50\n",
      "671/671 [==============================] - 0s 90us/sample - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 14/50\n",
      "671/671 [==============================] - 0s 92us/sample - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 15/50\n",
      "671/671 [==============================] - 0s 89us/sample - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 16/50\n",
      "671/671 [==============================] - 0s 85us/sample - loss: 0.0061 - val_loss: 0.0036\n",
      "Epoch 17/50\n",
      "671/671 [==============================] - 0s 86us/sample - loss: 0.0060 - val_loss: 0.0037\n",
      "Epoch 18/50\n",
      "671/671 [==============================] - 0s 87us/sample - loss: 0.0059 - val_loss: 0.0028\n",
      "Epoch 19/50\n",
      "671/671 [==============================] - 0s 91us/sample - loss: 0.0058 - val_loss: 0.0027\n",
      "Epoch 20/50\n",
      "671/671 [==============================] - 0s 90us/sample - loss: 0.0057 - val_loss: 0.0027\n",
      "Epoch 21/50\n",
      "671/671 [==============================] - 0s 86us/sample - loss: 0.0056 - val_loss: 0.0026\n",
      "Epoch 22/50\n",
      "671/671 [==============================] - 0s 89us/sample - loss: 0.0054 - val_loss: 0.0020\n",
      "Epoch 23/50\n",
      "671/671 [==============================] - 0s 84us/sample - loss: 0.0054 - val_loss: 0.0021\n",
      "Epoch 24/50\n",
      "671/671 [==============================] - 0s 81us/sample - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 25/50\n",
      "671/671 [==============================] - 0s 87us/sample - loss: 0.0052 - val_loss: 0.0016\n",
      "Epoch 26/50\n",
      "671/671 [==============================] - 0s 84us/sample - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 27/50\n",
      "671/671 [==============================] - 0s 84us/sample - loss: 0.0051 - val_loss: 0.0012\n",
      "Epoch 28/50\n",
      "671/671 [==============================] - 0s 83us/sample - loss: 0.0055 - val_loss: 0.0073\n",
      "Epoch 29/50\n",
      "671/671 [==============================] - 0s 81us/sample - loss: 0.0053 - val_loss: 0.0022\n",
      "Epoch 30/50\n",
      "671/671 [==============================] - 0s 81us/sample - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 31/50\n",
      "671/671 [==============================] - 0s 86us/sample - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 32/50\n",
      "671/671 [==============================] - 0s 84us/sample - loss: 0.0052 - val_loss: 0.0065\n",
      "Epoch 33/50\n",
      "671/671 [==============================] - 0s 87us/sample - loss: 0.0050 - val_loss: 0.0021\n",
      "Epoch 34/50\n",
      "671/671 [==============================] - 0s 84us/sample - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 35/50\n",
      "671/671 [==============================] - 0s 85us/sample - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 36/50\n",
      "671/671 [==============================] - 0s 84us/sample - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 37/50\n",
      "671/671 [==============================] - 0s 88us/sample - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 38/50\n",
      "671/671 [==============================] - 0s 84us/sample - loss: 0.0057 - val_loss: 0.0103\n",
      "Epoch 39/50\n",
      "671/671 [==============================] - 0s 88us/sample - loss: 0.0072 - val_loss: 0.0040\n",
      "Epoch 40/50\n",
      "671/671 [==============================] - 0s 84us/sample - loss: 0.0080 - val_loss: 0.0110\n",
      "Epoch 41/50\n",
      "671/671 [==============================] - 0s 82us/sample - loss: 0.0080 - val_loss: 0.0045\n",
      "Epoch 42/50\n",
      "671/671 [==============================] - 0s 88us/sample - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 43/50\n",
      "671/671 [==============================] - 0s 86us/sample - loss: 0.0048 - val_loss: 0.0021\n",
      "Epoch 44/50\n",
      "671/671 [==============================] - 0s 84us/sample - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 45/50\n",
      "671/671 [==============================] - 0s 85us/sample - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 46/50\n",
      "671/671 [==============================] - 0s 85us/sample - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "671/671 [==============================] - 0s 85us/sample - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 48/50\n",
      "671/671 [==============================] - 0s 86us/sample - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 49/50\n",
      "671/671 [==============================] - 0s 86us/sample - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 50/50\n",
      "671/671 [==============================] - 0s 89us/sample - loss: 0.0037 - val_loss: 0.0011\n",
      "第23个数，还剩4100个没有训练\n",
      "inv_hat [1.79155598 1.79055858 1.78856397 1.78457298 1.78457298 1.78457298\n",
      " 1.7825768  1.78157868 1.7825768  1.78357491 1.78457298 1.78557081\n",
      " 1.78557081 1.78656864 1.78856397 1.78856397 1.78956137 1.79055858\n",
      " 1.79155598 1.79255314 1.79255314 1.79355011 1.79454713 1.79454713\n",
      " 1.79554391 1.79554391 1.79554391 1.79454713 1.79454713 1.79554391]\n",
      "Test RMSE: 0.001\n",
      "Train on 477 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "477/477 [==============================] - 0s 92us/sample - loss: 0.0207 - val_loss: 0.0153\n",
      "Epoch 2/50\n",
      "477/477 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0098\n",
      "Epoch 3/50\n",
      "477/477 [==============================] - 0s 82us/sample - loss: 0.0131 - val_loss: 0.0093\n",
      "Epoch 4/50\n",
      "477/477 [==============================] - 0s 82us/sample - loss: 0.0135 - val_loss: 0.0089\n",
      "Epoch 5/50\n",
      "477/477 [==============================] - 0s 81us/sample - loss: 0.0135 - val_loss: 0.0093\n",
      "Epoch 6/50\n",
      "477/477 [==============================] - 0s 81us/sample - loss: 0.0134 - val_loss: 0.0095\n",
      "Epoch 7/50\n",
      "477/477 [==============================] - 0s 81us/sample - loss: 0.0133 - val_loss: 0.0104\n",
      "Epoch 8/50\n",
      "477/477 [==============================] - 0s 81us/sample - loss: 0.0133 - val_loss: 0.0103\n",
      "Epoch 9/50\n",
      "477/477 [==============================] - 0s 93us/sample - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 10/50\n",
      "477/477 [==============================] - 0s 88us/sample - loss: 0.0134 - val_loss: 0.0095\n",
      "Epoch 11/50\n",
      "477/477 [==============================] - 0s 88us/sample - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 12/50\n",
      "477/477 [==============================] - 0s 87us/sample - loss: 0.0133 - val_loss: 0.0096\n",
      "Epoch 13/50\n",
      "477/477 [==============================] - 0s 89us/sample - loss: 0.0133 - val_loss: 0.0103\n",
      "Epoch 14/50\n",
      "477/477 [==============================] - 0s 85us/sample - loss: 0.0132 - val_loss: 0.0103\n",
      "Epoch 15/50\n",
      "477/477 [==============================] - 0s 84us/sample - loss: 0.0132 - val_loss: 0.0101\n",
      "Epoch 16/50\n",
      "477/477 [==============================] - 0s 82us/sample - loss: 0.0132 - val_loss: 0.0102\n",
      "Epoch 17/50\n",
      "477/477 [==============================] - 0s 81us/sample - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 18/50\n",
      "477/477 [==============================] - 0s 85us/sample - loss: 0.0132 - val_loss: 0.0104\n",
      "Epoch 19/50\n",
      "477/477 [==============================] - 0s 85us/sample - loss: 0.0132 - val_loss: 0.0102\n",
      "Epoch 20/50\n",
      "477/477 [==============================] - 0s 83us/sample - loss: 0.0131 - val_loss: 0.0098\n",
      "Epoch 21/50\n",
      "477/477 [==============================] - 0s 80us/sample - loss: 0.0132 - val_loss: 0.0103\n",
      "Epoch 22/50\n",
      "477/477 [==============================] - 0s 87us/sample - loss: 0.0131 - val_loss: 0.0095\n",
      "Epoch 23/50\n",
      "477/477 [==============================] - 0s 84us/sample - loss: 0.0132 - val_loss: 0.0103\n",
      "Epoch 24/50\n",
      "477/477 [==============================] - 0s 81us/sample - loss: 0.0131 - val_loss: 0.0098\n",
      "Epoch 25/50\n",
      "477/477 [==============================] - 0s 84us/sample - loss: 0.0131 - val_loss: 0.0099\n",
      "Epoch 26/50\n",
      "477/477 [==============================] - 0s 83us/sample - loss: 0.0131 - val_loss: 0.0101\n",
      "Epoch 27/50\n",
      "477/477 [==============================] - 0s 86us/sample - loss: 0.0131 - val_loss: 0.0095\n",
      "Epoch 28/50\n",
      "477/477 [==============================] - 0s 82us/sample - loss: 0.0131 - val_loss: 0.0100\n",
      "Epoch 29/50\n",
      "477/477 [==============================] - 0s 83us/sample - loss: 0.0131 - val_loss: 0.0096\n",
      "Epoch 30/50\n",
      "477/477 [==============================] - 0s 81us/sample - loss: 0.0131 - val_loss: 0.0100\n",
      "Epoch 31/50\n",
      "477/477 [==============================] - 0s 81us/sample - loss: 0.0131 - val_loss: 0.0097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "477/477 [==============================] - 0s 90us/sample - loss: 0.0130 - val_loss: 0.0099\n",
      "Epoch 33/50\n",
      "477/477 [==============================] - 0s 91us/sample - loss: 0.0131 - val_loss: 0.0098\n",
      "Epoch 34/50\n",
      "477/477 [==============================] - 0s 90us/sample - loss: 0.0131 - val_loss: 0.0097\n",
      "Epoch 35/50\n",
      "477/477 [==============================] - 0s 88us/sample - loss: 0.0130 - val_loss: 0.0100\n",
      "Epoch 36/50\n",
      "477/477 [==============================] - 0s 83us/sample - loss: 0.0130 - val_loss: 0.0097\n",
      "Epoch 37/50\n",
      "477/477 [==============================] - 0s 94us/sample - loss: 0.0130 - val_loss: 0.0099\n",
      "Epoch 38/50\n",
      "477/477 [==============================] - 0s 91us/sample - loss: 0.0131 - val_loss: 0.0094\n",
      "Epoch 39/50\n",
      "477/477 [==============================] - 0s 93us/sample - loss: 0.0130 - val_loss: 0.0100\n",
      "Epoch 40/50\n",
      "477/477 [==============================] - 0s 89us/sample - loss: 0.0130 - val_loss: 0.0092\n",
      "Epoch 41/50\n",
      "477/477 [==============================] - 0s 90us/sample - loss: 0.0130 - val_loss: 0.0094\n",
      "Epoch 42/50\n",
      "477/477 [==============================] - 0s 87us/sample - loss: 0.0131 - val_loss: 0.0092\n",
      "Epoch 43/50\n",
      "477/477 [==============================] - 0s 87us/sample - loss: 0.0130 - val_loss: 0.0097\n",
      "Epoch 44/50\n",
      "477/477 [==============================] - 0s 84us/sample - loss: 0.0130 - val_loss: 0.0093\n",
      "Epoch 45/50\n",
      "477/477 [==============================] - 0s 90us/sample - loss: 0.0129 - val_loss: 0.0094\n",
      "Epoch 46/50\n",
      "477/477 [==============================] - 0s 90us/sample - loss: 0.0131 - val_loss: 0.0094\n",
      "Epoch 47/50\n",
      "477/477 [==============================] - 0s 91us/sample - loss: 0.0129 - val_loss: 0.0090\n",
      "Epoch 48/50\n",
      "477/477 [==============================] - 0s 87us/sample - loss: 0.0131 - val_loss: 0.0100\n",
      "Epoch 49/50\n",
      "477/477 [==============================] - 0s 89us/sample - loss: 0.0129 - val_loss: 0.0090\n",
      "Epoch 50/50\n",
      "477/477 [==============================] - 0s 83us/sample - loss: 0.0129 - val_loss: 0.0093\n",
      "第24个数，还剩4099个没有训练\n",
      "inv_hat [1.07384902 1.07185771 1.071758   1.071758   1.07016147 1.07026137\n",
      " 1.06996166 1.07096017 1.07026137 1.07086036 1.07374956 1.07444538\n",
      " 1.0742466  1.07285399 1.07325208 1.07315265 1.07345111 1.07404777\n",
      " 1.07494197 1.07325208 1.07315265 1.07245558 1.07225641 1.07245558\n",
      " 1.07205709 1.07225641 1.07205709 1.07215676 1.07225641 1.07374956]\n",
      "Test RMSE: 0.001\n",
      "Train on 774 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "774/774 [==============================] - 0s 78us/sample - loss: 0.0098 - val_loss: 0.0072\n",
      "Epoch 2/50\n",
      "774/774 [==============================] - 0s 81us/sample - loss: 0.0098 - val_loss: 0.0076\n",
      "Epoch 3/50\n",
      "774/774 [==============================] - 0s 79us/sample - loss: 0.0113 - val_loss: 0.0090\n",
      "Epoch 4/50\n",
      "774/774 [==============================] - 0s 78us/sample - loss: 0.0102 - val_loss: 0.0076\n",
      "Epoch 5/50\n",
      "774/774 [==============================] - 0s 84us/sample - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 6/50\n",
      "774/774 [==============================] - 0s 78us/sample - loss: 0.0106 - val_loss: 0.0097\n",
      "Epoch 7/50\n",
      "774/774 [==============================] - 0s 81us/sample - loss: 0.0106 - val_loss: 0.0104\n",
      "Epoch 8/50\n",
      "774/774 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0077\n",
      "Epoch 9/50\n",
      "774/774 [==============================] - 0s 81us/sample - loss: 0.0096 - val_loss: 0.0070\n",
      "Epoch 10/50\n",
      "774/774 [==============================] - 0s 81us/sample - loss: 0.0095 - val_loss: 0.0069\n",
      "Epoch 11/50\n",
      "774/774 [==============================] - 0s 80us/sample - loss: 0.0091 - val_loss: 0.0077\n",
      "Epoch 12/50\n",
      "774/774 [==============================] - 0s 80us/sample - loss: 0.0096 - val_loss: 0.0120\n",
      "Epoch 13/50\n",
      "774/774 [==============================] - 0s 78us/sample - loss: 0.0101 - val_loss: 0.0079\n",
      "Epoch 14/50\n",
      "774/774 [==============================] - 0s 81us/sample - loss: 0.0097 - val_loss: 0.0085\n",
      "Epoch 15/50\n",
      "774/774 [==============================] - 0s 79us/sample - loss: 0.0102 - val_loss: 0.0114\n",
      "Epoch 16/50\n",
      "774/774 [==============================] - 0s 80us/sample - loss: 0.0099 - val_loss: 0.0071\n",
      "Epoch 17/50\n",
      "774/774 [==============================] - 0s 79us/sample - loss: 0.0092 - val_loss: 0.0080\n",
      "Epoch 18/50\n",
      "774/774 [==============================] - 0s 76us/sample - loss: 0.0090 - val_loss: 0.0077\n",
      "Epoch 19/50\n",
      "774/774 [==============================] - 0s 82us/sample - loss: 0.0090 - val_loss: 0.0079\n",
      "Epoch 20/50\n",
      "774/774 [==============================] - 0s 82us/sample - loss: 0.0089 - val_loss: 0.0090\n",
      "Epoch 21/50\n",
      "774/774 [==============================] - 0s 85us/sample - loss: 0.0094 - val_loss: 0.0077\n",
      "Epoch 22/50\n",
      "774/774 [==============================] - 0s 80us/sample - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 23/50\n",
      "774/774 [==============================] - 0s 77us/sample - loss: 0.0103 - val_loss: 0.0071\n",
      "Epoch 24/50\n",
      "774/774 [==============================] - 0s 77us/sample - loss: 0.0091 - val_loss: 0.0077\n",
      "Epoch 25/50\n",
      "774/774 [==============================] - 0s 86us/sample - loss: 0.0092 - val_loss: 0.0077\n",
      "Epoch 26/50\n",
      "774/774 [==============================] - 0s 87us/sample - loss: 0.0090 - val_loss: 0.0077\n",
      "Epoch 27/50\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.014 - 0s 83us/sample - loss: 0.0090 - val_loss: 0.0082\n",
      "Epoch 28/50\n",
      "774/774 [==============================] - 0s 79us/sample - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 29/50\n",
      "774/774 [==============================] - 0s 84us/sample - loss: 0.0089 - val_loss: 0.0075\n",
      "Epoch 30/50\n",
      "774/774 [==============================] - 0s 84us/sample - loss: 0.0087 - val_loss: 0.0073\n",
      "Epoch 31/50\n",
      "774/774 [==============================] - 0s 82us/sample - loss: 0.0094 - val_loss: 0.0071\n",
      "Epoch 32/50\n",
      "774/774 [==============================] - 0s 84us/sample - loss: 0.0092 - val_loss: 0.0070\n",
      "Epoch 33/50\n",
      "774/774 [==============================] - 0s 85us/sample - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 34/50\n",
      "774/774 [==============================] - 0s 76us/sample - loss: 0.0097 - val_loss: 0.0072\n",
      "Epoch 35/50\n",
      "774/774 [==============================] - 0s 77us/sample - loss: 0.0089 - val_loss: 0.0081\n",
      "Epoch 36/50\n",
      "774/774 [==============================] - 0s 75us/sample - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 37/50\n",
      "774/774 [==============================] - 0s 77us/sample - loss: 0.0100 - val_loss: 0.0079\n",
      "Epoch 38/50\n",
      "774/774 [==============================] - 0s 81us/sample - loss: 0.0100 - val_loss: 0.0093\n",
      "Epoch 39/50\n",
      "774/774 [==============================] - 0s 80us/sample - loss: 0.0108 - val_loss: 0.0074\n",
      "Epoch 40/50\n",
      "774/774 [==============================] - 0s 81us/sample - loss: 0.0092 - val_loss: 0.0071\n",
      "Epoch 41/50\n",
      "774/774 [==============================] - 0s 81us/sample - loss: 0.0089 - val_loss: 0.0082\n",
      "Epoch 42/50\n",
      "774/774 [==============================] - 0s 78us/sample - loss: 0.0089 - val_loss: 0.0073\n",
      "Epoch 43/50\n",
      "774/774 [==============================] - 0s 77us/sample - loss: 0.0086 - val_loss: 0.0074\n",
      "Epoch 44/50\n",
      "774/774 [==============================] - 0s 81us/sample - loss: 0.0088 - val_loss: 0.0074\n",
      "Epoch 45/50\n",
      "774/774 [==============================] - 0s 83us/sample - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 46/50\n",
      "774/774 [==============================] - 0s 81us/sample - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 47/50\n",
      "774/774 [==============================] - 0s 79us/sample - loss: 0.0090 - val_loss: 0.0073\n",
      "Epoch 48/50\n",
      "774/774 [==============================] - 0s 82us/sample - loss: 0.0095 - val_loss: 0.0089\n",
      "Epoch 49/50\n",
      "774/774 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0071\n",
      "Epoch 50/50\n",
      "774/774 [==============================] - 0s 79us/sample - loss: 0.0099 - val_loss: 0.0135\n",
      "第25个数，还剩4098个没有训练\n",
      "inv_hat [1.04126141 1.04126141 1.04126141 1.04229471 1.04229471 1.04229471\n",
      " 1.04229471 1.04229471 1.04332803 1.04229471 1.04332803 1.04332803\n",
      " 1.04436122 1.0453945  1.04642756 1.04229471 1.04229471 1.04229471\n",
      " 1.04126141 1.04126141 1.04126141 1.04022832 1.04126141 1.04126141\n",
      " 1.04126141 1.04229471 1.04229471 1.04229471 1.04126141 1.04229471]\n",
      "Test RMSE: 0.002\n",
      "Train on 508 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "508/508 [==============================] - 0s 90us/sample - loss: 0.0196 - val_loss: 0.0188\n",
      "Epoch 2/50\n",
      "508/508 [==============================] - 0s 86us/sample - loss: 0.0198 - val_loss: 0.0212\n",
      "Epoch 3/50\n",
      "508/508 [==============================] - 0s 90us/sample - loss: 0.0193 - val_loss: 0.0195\n",
      "Epoch 4/50\n",
      "508/508 [==============================] - 0s 94us/sample - loss: 0.0194 - val_loss: 0.0220\n",
      "Epoch 5/50\n",
      "508/508 [==============================] - 0s 99us/sample - loss: 0.0194 - val_loss: 0.0208\n",
      "Epoch 6/50\n",
      "508/508 [==============================] - 0s 94us/sample - loss: 0.0194 - val_loss: 0.0221\n",
      "Epoch 7/50\n",
      "508/508 [==============================] - 0s 91us/sample - loss: 0.0194 - val_loss: 0.0204\n",
      "Epoch 8/50\n",
      "508/508 [==============================] - 0s 94us/sample - loss: 0.0195 - val_loss: 0.0226\n",
      "Epoch 9/50\n",
      "508/508 [==============================] - 0s 92us/sample - loss: 0.0195 - val_loss: 0.0206\n",
      "Epoch 10/50\n",
      "508/508 [==============================] - 0s 89us/sample - loss: 0.0194 - val_loss: 0.0222\n",
      "Epoch 11/50\n",
      "508/508 [==============================] - 0s 90us/sample - loss: 0.0194 - val_loss: 0.0205\n",
      "Epoch 12/50\n",
      "508/508 [==============================] - 0s 97us/sample - loss: 0.0194 - val_loss: 0.0223\n",
      "Epoch 13/50\n",
      "508/508 [==============================] - 0s 91us/sample - loss: 0.0194 - val_loss: 0.0204\n",
      "Epoch 14/50\n",
      "508/508 [==============================] - 0s 95us/sample - loss: 0.0194 - val_loss: 0.0225\n",
      "Epoch 15/50\n",
      "508/508 [==============================] - 0s 95us/sample - loss: 0.0194 - val_loss: 0.0203\n",
      "Epoch 16/50\n",
      "508/508 [==============================] - 0s 93us/sample - loss: 0.0194 - val_loss: 0.0224\n",
      "Epoch 17/50\n",
      "508/508 [==============================] - 0s 95us/sample - loss: 0.0194 - val_loss: 0.0203\n",
      "Epoch 18/50\n",
      "508/508 [==============================] - 0s 92us/sample - loss: 0.0194 - val_loss: 0.0227\n",
      "Epoch 19/50\n",
      "508/508 [==============================] - 0s 93us/sample - loss: 0.0194 - val_loss: 0.0202\n",
      "Epoch 20/50\n",
      "508/508 [==============================] - 0s 92us/sample - loss: 0.0195 - val_loss: 0.0228\n",
      "Epoch 21/50\n",
      "508/508 [==============================] - 0s 95us/sample - loss: 0.0195 - val_loss: 0.0205\n",
      "Epoch 22/50\n",
      "508/508 [==============================] - 0s 92us/sample - loss: 0.0194 - val_loss: 0.0225\n",
      "Epoch 23/50\n",
      "508/508 [==============================] - 0s 89us/sample - loss: 0.0194 - val_loss: 0.0204\n",
      "Epoch 24/50\n",
      "508/508 [==============================] - 0s 87us/sample - loss: 0.0194 - val_loss: 0.0224\n",
      "Epoch 25/50\n",
      "508/508 [==============================] - 0s 88us/sample - loss: 0.0194 - val_loss: 0.0203\n",
      "Epoch 26/50\n",
      "508/508 [==============================] - 0s 92us/sample - loss: 0.0194 - val_loss: 0.0228\n",
      "Epoch 27/50\n",
      "508/508 [==============================] - 0s 89us/sample - loss: 0.0194 - val_loss: 0.0204\n",
      "Epoch 28/50\n",
      "508/508 [==============================] - 0s 89us/sample - loss: 0.0194 - val_loss: 0.0226\n",
      "Epoch 29/50\n",
      "508/508 [==============================] - 0s 91us/sample - loss: 0.0194 - val_loss: 0.0205\n",
      "Epoch 30/50\n",
      "508/508 [==============================] - 0s 87us/sample - loss: 0.0194 - val_loss: 0.0223\n",
      "Epoch 31/50\n",
      "508/508 [==============================] - 0s 90us/sample - loss: 0.0193 - val_loss: 0.0202\n",
      "Epoch 32/50\n",
      "508/508 [==============================] - 0s 88us/sample - loss: 0.0194 - val_loss: 0.0230\n",
      "Epoch 33/50\n",
      "508/508 [==============================] - 0s 87us/sample - loss: 0.0194 - val_loss: 0.0203\n",
      "Epoch 34/50\n",
      "508/508 [==============================] - 0s 86us/sample - loss: 0.0194 - val_loss: 0.0228\n",
      "Epoch 35/50\n",
      "508/508 [==============================] - 0s 87us/sample - loss: 0.0194 - val_loss: 0.0204\n",
      "Epoch 36/50\n",
      "508/508 [==============================] - 0s 91us/sample - loss: 0.0194 - val_loss: 0.0227\n",
      "Epoch 37/50\n",
      "508/508 [==============================] - 0s 95us/sample - loss: 0.0194 - val_loss: 0.0204\n",
      "Epoch 38/50\n",
      "508/508 [==============================] - 0s 88us/sample - loss: 0.0194 - val_loss: 0.0225\n",
      "Epoch 39/50\n",
      "508/508 [==============================] - 0s 94us/sample - loss: 0.0194 - val_loss: 0.0204\n",
      "Epoch 40/50\n",
      "508/508 [==============================] - 0s 95us/sample - loss: 0.0194 - val_loss: 0.0224\n",
      "Epoch 41/50\n",
      "508/508 [==============================] - 0s 95us/sample - loss: 0.0193 - val_loss: 0.0203\n",
      "Epoch 42/50\n",
      "508/508 [==============================] - 0s 95us/sample - loss: 0.0194 - val_loss: 0.0227\n",
      "Epoch 43/50\n",
      "508/508 [==============================] - 0s 95us/sample - loss: 0.0194 - val_loss: 0.0202\n",
      "Epoch 44/50\n",
      "508/508 [==============================] - 0s 91us/sample - loss: 0.0194 - val_loss: 0.0229\n",
      "Epoch 45/50\n",
      "508/508 [==============================] - 0s 88us/sample - loss: 0.0194 - val_loss: 0.0204\n",
      "Epoch 46/50\n",
      "508/508 [==============================] - 0s 88us/sample - loss: 0.0194 - val_loss: 0.0227\n",
      "Epoch 47/50\n",
      "508/508 [==============================] - 0s 87us/sample - loss: 0.0194 - val_loss: 0.0202\n",
      "Epoch 48/50\n",
      "508/508 [==============================] - 0s 87us/sample - loss: 0.0194 - val_loss: 0.0229\n",
      "Epoch 49/50\n",
      "508/508 [==============================] - 0s 91us/sample - loss: 0.0194 - val_loss: 0.0202\n",
      "Epoch 50/50\n",
      "508/508 [==============================] - 0s 90us/sample - loss: 0.0194 - val_loss: 0.0228\n",
      "第26个数，还剩4097个没有训练\n",
      "inv_hat [1.05343208 1.02961319 1.03489155 1.02971088 1.00587842 1.00326433\n",
      " 1.00403864 1.01490178 1.00239356 1.01159956 1.03665286 1.03655509\n",
      " 1.03195806 1.01373588 1.0151934  1.00345793 1.00762264 1.01053207\n",
      " 1.0228818  1.00791337 1.00675039 0.99843018 0.99052179 0.98590405\n",
      " 0.97918572 0.98206271 0.97621659 0.97411177 0.97057621 0.97210438]\n",
      "Test RMSE: 0.012\n",
      "Train on 872 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "872/872 [==============================] - 0s 83us/sample - loss: 0.0124 - val_loss: 0.0337\n",
      "Epoch 2/50\n",
      "872/872 [==============================] - 0s 84us/sample - loss: 0.0145 - val_loss: 0.0351\n",
      "Epoch 3/50\n",
      "872/872 [==============================] - 0s 81us/sample - loss: 0.0119 - val_loss: 0.0344\n",
      "Epoch 4/50\n",
      "872/872 [==============================] - 0s 85us/sample - loss: 0.0121 - val_loss: 0.0343\n",
      "Epoch 5/50\n",
      "872/872 [==============================] - 0s 90us/sample - loss: 0.0123 - val_loss: 0.0334\n",
      "Epoch 6/50\n",
      "872/872 [==============================] - 0s 86us/sample - loss: 0.0126 - val_loss: 0.0342\n",
      "Epoch 7/50\n",
      "872/872 [==============================] - 0s 82us/sample - loss: 0.0128 - val_loss: 0.0330\n",
      "Epoch 8/50\n",
      "872/872 [==============================] - 0s 82us/sample - loss: 0.0134 - val_loss: 0.0343\n",
      "Epoch 9/50\n",
      "872/872 [==============================] - 0s 90us/sample - loss: 0.0132 - val_loss: 0.0331\n",
      "Epoch 10/50\n",
      "872/872 [==============================] - 0s 87us/sample - loss: 0.0136 - val_loss: 0.0332\n",
      "Epoch 11/50\n",
      "872/872 [==============================] - 0s 86us/sample - loss: 0.0126 - val_loss: 0.0336\n",
      "Epoch 12/50\n",
      "872/872 [==============================] - 0s 85us/sample - loss: 0.0135 - val_loss: 0.0330\n",
      "Epoch 13/50\n",
      "872/872 [==============================] - 0s 85us/sample - loss: 0.0138 - val_loss: 0.0332\n",
      "Epoch 14/50\n",
      "872/872 [==============================] - 0s 84us/sample - loss: 0.0127 - val_loss: 0.0332\n",
      "Epoch 15/50\n",
      "872/872 [==============================] - 0s 80us/sample - loss: 0.0133 - val_loss: 0.0330\n",
      "Epoch 16/50\n",
      "872/872 [==============================] - 0s 80us/sample - loss: 0.0132 - val_loss: 0.0336\n",
      "Epoch 17/50\n",
      "872/872 [==============================] - 0s 80us/sample - loss: 0.0140 - val_loss: 0.0332\n",
      "Epoch 18/50\n",
      "872/872 [==============================] - 0s 84us/sample - loss: 0.0144 - val_loss: 0.0330\n",
      "Epoch 19/50\n",
      "872/872 [==============================] - 0s 86us/sample - loss: 0.0147 - val_loss: 0.0332\n",
      "Epoch 20/50\n",
      "872/872 [==============================] - 0s 82us/sample - loss: 0.0147 - val_loss: 0.0335\n",
      "Epoch 21/50\n",
      "872/872 [==============================] - 0s 82us/sample - loss: 0.0163 - val_loss: 0.0334\n",
      "Epoch 22/50\n",
      "872/872 [==============================] - 0s 86us/sample - loss: 0.0186 - val_loss: 0.0344\n",
      "Epoch 23/50\n",
      "872/872 [==============================] - 0s 86us/sample - loss: 0.0212 - val_loss: 0.0379\n",
      "Epoch 24/50\n",
      "872/872 [==============================] - 0s 86us/sample - loss: 0.0203 - val_loss: 0.0389\n",
      "Epoch 25/50\n",
      "872/872 [==============================] - 0s 85us/sample - loss: 0.0182 - val_loss: 0.0382\n",
      "Epoch 26/50\n",
      "872/872 [==============================] - 0s 83us/sample - loss: 0.0178 - val_loss: 0.0381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "872/872 [==============================] - 0s 87us/sample - loss: 0.0171 - val_loss: 0.0380\n",
      "Epoch 28/50\n",
      "872/872 [==============================] - 0s 91us/sample - loss: 0.0152 - val_loss: 0.0362\n",
      "Epoch 29/50\n",
      "872/872 [==============================] - 0s 90us/sample - loss: 0.0138 - val_loss: 0.0345\n",
      "Epoch 30/50\n",
      "872/872 [==============================] - 0s 83us/sample - loss: 0.0135 - val_loss: 0.0339\n",
      "Epoch 31/50\n",
      "872/872 [==============================] - 0s 84us/sample - loss: 0.0131 - val_loss: 0.0336\n",
      "Epoch 32/50\n",
      "872/872 [==============================] - 0s 89us/sample - loss: 0.0136 - val_loss: 0.0331\n",
      "Epoch 33/50\n",
      "872/872 [==============================] - 0s 89us/sample - loss: 0.0149 - val_loss: 0.0330\n",
      "Epoch 34/50\n",
      "872/872 [==============================] - 0s 84us/sample - loss: 0.0161 - val_loss: 0.0333\n",
      "Epoch 35/50\n",
      "872/872 [==============================] - 0s 84us/sample - loss: 0.0188 - val_loss: 0.0353\n",
      "Epoch 36/50\n",
      "872/872 [==============================] - 0s 81us/sample - loss: 0.0203 - val_loss: 0.0393\n",
      "Epoch 37/50\n",
      "872/872 [==============================] - 0s 80us/sample - loss: 0.0181 - val_loss: 0.0379\n",
      "Epoch 38/50\n",
      "872/872 [==============================] - 0s 79us/sample - loss: 0.0154 - val_loss: 0.0357\n",
      "Epoch 39/50\n",
      "872/872 [==============================] - 0s 82us/sample - loss: 0.0145 - val_loss: 0.0351\n",
      "Epoch 40/50\n",
      "872/872 [==============================] - 0s 86us/sample - loss: 0.0131 - val_loss: 0.0340\n",
      "Epoch 41/50\n",
      "872/872 [==============================] - 0s 88us/sample - loss: 0.0127 - val_loss: 0.0332\n",
      "Epoch 42/50\n",
      "872/872 [==============================] - 0s 83us/sample - loss: 0.0131 - val_loss: 0.0332\n",
      "Epoch 43/50\n",
      "872/872 [==============================] - 0s 87us/sample - loss: 0.0126 - val_loss: 0.0332\n",
      "Epoch 44/50\n",
      "872/872 [==============================] - 0s 82us/sample - loss: 0.0124 - val_loss: 0.0332\n",
      "Epoch 45/50\n",
      "872/872 [==============================] - 0s 90us/sample - loss: 0.0139 - val_loss: 0.0333\n",
      "Epoch 46/50\n",
      "872/872 [==============================] - 0s 86us/sample - loss: 0.0145 - val_loss: 0.0331\n",
      "Epoch 47/50\n",
      "872/872 [==============================] - 0s 91us/sample - loss: 0.0148 - val_loss: 0.0332\n",
      "Epoch 48/50\n",
      "872/872 [==============================] - 0s 90us/sample - loss: 0.0162 - val_loss: 0.0337\n",
      "Epoch 49/50\n",
      "872/872 [==============================] - 0s 90us/sample - loss: 0.0172 - val_loss: 0.0349\n",
      "Epoch 50/50\n",
      "872/872 [==============================] - 0s 85us/sample - loss: 0.0178 - val_loss: 0.0368\n",
      "第27个数，还剩4096个没有训练\n",
      "inv_hat [0.88225855 0.87030264 0.87527767 0.87129687 0.85643175 0.85150172\n",
      " 0.85347213 0.86038527 0.85445814 0.86038527 0.88225855 0.88525553\n",
      " 0.88925582 0.87328645 0.86335564 0.85544468 0.86137495 0.86236506\n",
      " 0.87030264 0.85840753 0.85150172 0.84560424 0.83484969 0.83290285\n",
      " 0.82514398 0.83484969 0.83484969 0.83193049 0.82901761 0.8358241 ]\n",
      "Test RMSE: 0.009\n",
      "Train on 842 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "842/842 [==============================] - 0s 84us/sample - loss: 0.0220 - val_loss: 0.0273\n",
      "Epoch 2/50\n",
      "842/842 [==============================] - 0s 78us/sample - loss: 0.0214 - val_loss: 0.0267\n",
      "Epoch 3/50\n",
      "842/842 [==============================] - 0s 84us/sample - loss: 0.0219 - val_loss: 0.0291\n",
      "Epoch 4/50\n",
      "842/842 [==============================] - 0s 84us/sample - loss: 0.0197 - val_loss: 0.0292\n",
      "Epoch 5/50\n",
      "842/842 [==============================] - 0s 82us/sample - loss: 0.0196 - val_loss: 0.0286\n",
      "Epoch 6/50\n",
      "842/842 [==============================] - 0s 80us/sample - loss: 0.0199 - val_loss: 0.0265\n",
      "Epoch 7/50\n",
      "842/842 [==============================] - 0s 80us/sample - loss: 0.0221 - val_loss: 0.0272\n",
      "Epoch 8/50\n",
      "842/842 [==============================] - 0s 80us/sample - loss: 0.0210 - val_loss: 0.0269\n",
      "Epoch 9/50\n",
      "842/842 [==============================] - 0s 84us/sample - loss: 0.0213 - val_loss: 0.0277\n",
      "Epoch 10/50\n",
      "842/842 [==============================] - 0s 87us/sample - loss: 0.0206 - val_loss: 0.0272\n",
      "Epoch 11/50\n",
      "842/842 [==============================] - 0s 83us/sample - loss: 0.0211 - val_loss: 0.0278\n",
      "Epoch 12/50\n",
      "842/842 [==============================] - 0s 86us/sample - loss: 0.0203 - val_loss: 0.0280\n",
      "Epoch 13/50\n",
      "842/842 [==============================] - 0s 86us/sample - loss: 0.0203 - val_loss: 0.0276\n",
      "Epoch 14/50\n",
      "842/842 [==============================] - 0s 85us/sample - loss: 0.0206 - val_loss: 0.0263\n",
      "Epoch 15/50\n",
      "842/842 [==============================] - 0s 80us/sample - loss: 0.0224 - val_loss: 0.0298\n",
      "Epoch 16/50\n",
      "842/842 [==============================] - 0s 80us/sample - loss: 0.0201 - val_loss: 0.0330\n",
      "Epoch 17/50\n",
      "842/842 [==============================] - 0s 79us/sample - loss: 0.0213 - val_loss: 0.0370\n",
      "Epoch 18/50\n",
      "842/842 [==============================] - 0s 81us/sample - loss: 0.0239 - val_loss: 0.0278\n",
      "Epoch 19/50\n",
      "842/842 [==============================] - 0s 86us/sample - loss: 0.0210 - val_loss: 0.0261\n",
      "Epoch 20/50\n",
      "842/842 [==============================] - 0s 82us/sample - loss: 0.0226 - val_loss: 0.0307\n",
      "Epoch 21/50\n",
      "842/842 [==============================] - 0s 87us/sample - loss: 0.0198 - val_loss: 0.0316\n",
      "Epoch 22/50\n",
      "842/842 [==============================] - 0s 83us/sample - loss: 0.0199 - val_loss: 0.0352\n",
      "Epoch 23/50\n",
      "842/842 [==============================] - 0s 84us/sample - loss: 0.0231 - val_loss: 0.0301\n",
      "Epoch 24/50\n",
      "842/842 [==============================] - 0s 83us/sample - loss: 0.0200 - val_loss: 0.0286\n",
      "Epoch 25/50\n",
      "842/842 [==============================] - 0s 83us/sample - loss: 0.0202 - val_loss: 0.0256\n",
      "Epoch 26/50\n",
      "842/842 [==============================] - 0s 86us/sample - loss: 0.0238 - val_loss: 0.0308\n",
      "Epoch 27/50\n",
      "842/842 [==============================] - 0s 86us/sample - loss: 0.0202 - val_loss: 0.0311\n",
      "Epoch 28/50\n",
      "842/842 [==============================] - 0s 80us/sample - loss: 0.0199 - val_loss: 0.0346\n",
      "Epoch 29/50\n",
      "842/842 [==============================] - 0s 80us/sample - loss: 0.0224 - val_loss: 0.0318\n",
      "Epoch 30/50\n",
      "842/842 [==============================] - 0s 87us/sample - loss: 0.0201 - val_loss: 0.0339\n",
      "Epoch 31/50\n",
      "842/842 [==============================] - 0s 81us/sample - loss: 0.0216 - val_loss: 0.0311\n",
      "Epoch 32/50\n",
      "842/842 [==============================] - 0s 78us/sample - loss: 0.0199 - val_loss: 0.0297\n",
      "Epoch 33/50\n",
      "842/842 [==============================] - 0s 79us/sample - loss: 0.0196 - val_loss: 0.0291\n",
      "Epoch 34/50\n",
      "842/842 [==============================] - 0s 78us/sample - loss: 0.0197 - val_loss: 0.0288\n",
      "Epoch 35/50\n",
      "842/842 [==============================] - 0s 77us/sample - loss: 0.0198 - val_loss: 0.0269\n",
      "Epoch 36/50\n",
      "842/842 [==============================] - 0s 82us/sample - loss: 0.0216 - val_loss: 0.0272\n",
      "Epoch 37/50\n",
      "842/842 [==============================] - 0s 82us/sample - loss: 0.0210 - val_loss: 0.0274\n",
      "Epoch 38/50\n",
      "842/842 [==============================] - 0s 81us/sample - loss: 0.0209 - val_loss: 0.0274\n",
      "Epoch 39/50\n",
      "842/842 [==============================] - 0s 81us/sample - loss: 0.0209 - val_loss: 0.0277\n",
      "Epoch 40/50\n",
      "842/842 [==============================] - 0s 81us/sample - loss: 0.0204 - val_loss: 0.0294\n",
      "Epoch 41/50\n",
      "842/842 [==============================] - 0s 78us/sample - loss: 0.0197 - val_loss: 0.0290\n",
      "Epoch 42/50\n",
      "842/842 [==============================] - 0s 81us/sample - loss: 0.0196 - val_loss: 0.0271\n",
      "Epoch 43/50\n",
      "842/842 [==============================] - 0s 82us/sample - loss: 0.0210 - val_loss: 0.0260\n",
      "Epoch 44/50\n",
      "842/842 [==============================] - 0s 80us/sample - loss: 0.0228 - val_loss: 0.0305\n",
      "Epoch 45/50\n",
      "842/842 [==============================] - 0s 82us/sample - loss: 0.0198 - val_loss: 0.0319\n",
      "Epoch 46/50\n",
      "842/842 [==============================] - 0s 85us/sample - loss: 0.0204 - val_loss: 0.0377\n",
      "Epoch 47/50\n",
      "842/842 [==============================] - 0s 85us/sample - loss: 0.0242 - val_loss: 0.0278\n",
      "Epoch 48/50\n",
      "842/842 [==============================] - 0s 84us/sample - loss: 0.0210 - val_loss: 0.0266\n",
      "Epoch 49/50\n",
      "842/842 [==============================] - 0s 79us/sample - loss: 0.0221 - val_loss: 0.0309\n",
      "Epoch 50/50\n",
      "842/842 [==============================] - 0s 83us/sample - loss: 0.0197 - val_loss: 0.0331\n",
      "第28个数，还剩4095个没有训练\n",
      "inv_hat [1.03425764 1.01041882 1.00101046 0.99384605 0.95601799 0.95295627\n",
      " 0.96608503 0.97454549 0.94913341 0.95822048 0.99075164 0.98920527\n",
      " 0.97772333 0.95726271 0.96310964 0.96272591 0.9683904  0.9596577\n",
      " 0.96963976 0.94817846 0.93969313 0.93455711 0.92270584 0.92886182\n",
      " 0.92611348 0.93569764 0.93208763 0.92478776 0.90912196 0.90151519]\n",
      "Test RMSE: 0.017\n",
      "Train on 1134 samples, validate on 30 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1134/1134 [==============================] - 0s 81us/sample - loss: 0.0121 - val_loss: 0.0141\n",
      "Epoch 2/50\n",
      "1134/1134 [==============================] - 0s 78us/sample - loss: 0.0087 - val_loss: 0.0119\n",
      "Epoch 3/50\n",
      "1134/1134 [==============================] - 0s 76us/sample - loss: 0.0107 - val_loss: 0.0135\n",
      "Epoch 4/50\n",
      "1134/1134 [==============================] - 0s 78us/sample - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 5/50\n",
      "1134/1134 [==============================] - 0s 80us/sample - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 6/50\n",
      "1134/1134 [==============================] - 0s 81us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 7/50\n",
      "1134/1134 [==============================] - 0s 83us/sample - loss: 0.0120 - val_loss: 0.0107\n",
      "Epoch 8/50\n",
      "1134/1134 [==============================] - 0s 81us/sample - loss: 0.0089 - val_loss: 0.0103\n",
      "Epoch 9/50\n",
      "1134/1134 [==============================] - 0s 79us/sample - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 10/50\n",
      "1134/1134 [==============================] - 0s 78us/sample - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 11/50\n",
      "1134/1134 [==============================] - 0s 80us/sample - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 12/50\n",
      "1134/1134 [==============================] - 0s 77us/sample - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 13/50\n",
      "1134/1134 [==============================] - 0s 82us/sample - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 14/50\n",
      "1134/1134 [==============================] - 0s 86us/sample - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 15/50\n",
      "1134/1134 [==============================] - 0s 82us/sample - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 16/50\n",
      "1134/1134 [==============================] - 0s 80us/sample - loss: 0.0091 - val_loss: 0.0098\n",
      "Epoch 17/50\n",
      "1134/1134 [==============================] - 0s 80us/sample - loss: 0.0086 - val_loss: 0.0098\n",
      "Epoch 18/50\n",
      "1134/1134 [==============================] - 0s 78us/sample - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 19/50\n",
      "1134/1134 [==============================] - 0s 79us/sample - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 20/50\n",
      "1134/1134 [==============================] - 0s 83us/sample - loss: 0.0128 - val_loss: 0.0101\n",
      "Epoch 21/50\n",
      "1134/1134 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0102\n",
      "Epoch 22/50\n",
      "1134/1134 [==============================] - 0s 82us/sample - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 23/50\n",
      "1134/1134 [==============================] - 0s 80us/sample - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 24/50\n",
      "1134/1134 [==============================] - 0s 81us/sample - loss: 0.0089 - val_loss: 0.0123\n",
      "Epoch 25/50\n",
      "1134/1134 [==============================] - 0s 83us/sample - loss: 0.0083 - val_loss: 0.0111\n",
      "Epoch 26/50\n",
      "1134/1134 [==============================] - 0s 79us/sample - loss: 0.0102 - val_loss: 0.0100\n",
      "Epoch 27/50\n",
      "1134/1134 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0112\n",
      "Epoch 28/50\n",
      "1134/1134 [==============================] - 0s 79us/sample - loss: 0.0159 - val_loss: 0.0112\n",
      "Epoch 29/50\n",
      "1134/1134 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0163\n",
      "Epoch 30/50\n",
      "1134/1134 [==============================] - 0s 81us/sample - loss: 0.0214 - val_loss: 0.0235\n",
      "Epoch 31/50\n",
      "1134/1134 [==============================] - 0s 85us/sample - loss: 0.0109 - val_loss: 0.0171\n",
      "Epoch 32/50\n",
      "1134/1134 [==============================] - 0s 83us/sample - loss: 0.0284 - val_loss: 0.0164\n",
      "Epoch 33/50\n",
      "1134/1134 [==============================] - 0s 81us/sample - loss: 0.0166 - val_loss: 0.0369\n",
      "Epoch 34/50\n",
      "1134/1134 [==============================] - 0s 85us/sample - loss: 0.0276 - val_loss: 0.0313\n",
      "Epoch 35/50\n",
      "1134/1134 [==============================] - 0s 84us/sample - loss: 0.0150 - val_loss: 0.0184\n",
      "Epoch 36/50\n",
      "1134/1134 [==============================] - 0s 77us/sample - loss: 0.0331 - val_loss: 0.0173\n",
      "Epoch 37/50\n",
      "1134/1134 [==============================] - 0s 76us/sample - loss: 0.0200 - val_loss: 0.0351\n",
      "Epoch 38/50\n",
      "1134/1134 [==============================] - 0s 77us/sample - loss: 0.0209 - val_loss: 0.0213\n",
      "Epoch 39/50\n",
      "1134/1134 [==============================] - 0s 75us/sample - loss: 0.0101 - val_loss: 0.0173\n",
      "Epoch 40/50\n",
      "1134/1134 [==============================] - 0s 78us/sample - loss: 0.0248 - val_loss: 0.0198\n",
      "Epoch 41/50\n",
      "1134/1134 [==============================] - 0s 74us/sample - loss: 0.0127 - val_loss: 0.0252\n",
      "Epoch 42/50\n",
      "1134/1134 [==============================] - 0s 78us/sample - loss: 0.0264 - val_loss: 0.0286\n",
      "Epoch 43/50\n",
      "1134/1134 [==============================] - 0s 82us/sample - loss: 0.0172 - val_loss: 0.0290\n",
      "Epoch 44/50\n",
      "1134/1134 [==============================] - 0s 84us/sample - loss: 0.0279 - val_loss: 0.0197\n",
      "Epoch 45/50\n",
      "1134/1134 [==============================] - 0s 83us/sample - loss: 0.0150 - val_loss: 0.0235\n",
      "Epoch 46/50\n",
      "1134/1134 [==============================] - 0s 83us/sample - loss: 0.0239 - val_loss: 0.0279\n",
      "Epoch 47/50\n",
      "1134/1134 [==============================] - 0s 85us/sample - loss: 0.0156 - val_loss: 0.0257\n",
      "Epoch 48/50\n",
      "1134/1134 [==============================] - 0s 82us/sample - loss: 0.0274 - val_loss: 0.0178\n",
      "Epoch 49/50\n",
      "1134/1134 [==============================] - 0s 86us/sample - loss: 0.0153 - val_loss: 0.0241\n",
      "Epoch 50/50\n",
      "1134/1134 [==============================] - 0s 83us/sample - loss: 0.0233 - val_loss: 0.0271\n",
      "第29个数，还剩4094个没有训练\n",
      "inv_hat [1.24979818 1.2420391  1.24009525 1.24009525 1.2352286  1.23230398\n",
      " 1.2342541  1.23327928 1.2352286  1.2352286  1.23717641 1.23620264\n",
      " 1.23717641 1.24398135 1.2352286  1.22839927 1.23132831 1.23132831\n",
      " 1.23814977 1.2420391  1.2420391  1.2420391  1.24495191 1.24301049\n",
      " 1.24301049 1.24301049 1.23912265 1.24301049 1.24106732 1.23814977]\n",
      "Test RMSE: 0.008\n",
      "Train on 937 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "937/937 [==============================] - 0s 87us/sample - loss: 0.0183 - val_loss: 0.0211\n",
      "Epoch 2/50\n",
      "937/937 [==============================] - 0s 84us/sample - loss: 0.0180 - val_loss: 0.0122\n",
      "Epoch 3/50\n",
      "937/937 [==============================] - 0s 86us/sample - loss: 0.0169 - val_loss: 0.0113\n",
      "Epoch 4/50\n",
      "937/937 [==============================] - 0s 87us/sample - loss: 0.0157 - val_loss: 0.0114\n",
      "Epoch 5/50\n",
      "937/937 [==============================] - 0s 87us/sample - loss: 0.0153 - val_loss: 0.0111\n",
      "Epoch 6/50\n",
      "937/937 [==============================] - 0s 86us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 7/50\n",
      "937/937 [==============================] - 0s 88us/sample - loss: 0.0150 - val_loss: 0.0110\n",
      "Epoch 8/50\n",
      "937/937 [==============================] - 0s 84us/sample - loss: 0.0150 - val_loss: 0.0110\n",
      "Epoch 9/50\n",
      "937/937 [==============================] - 0s 85us/sample - loss: 0.0150 - val_loss: 0.0110\n",
      "Epoch 10/50\n",
      "937/937 [==============================] - 0s 85us/sample - loss: 0.0150 - val_loss: 0.0112\n",
      "Epoch 11/50\n",
      "937/937 [==============================] - 0s 84us/sample - loss: 0.0151 - val_loss: 0.0112\n",
      "Epoch 12/50\n",
      "937/937 [==============================] - 0s 83us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 13/50\n",
      "937/937 [==============================] - 0s 85us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 14/50\n",
      "937/937 [==============================] - 0s 86us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 15/50\n",
      "937/937 [==============================] - 0s 82us/sample - loss: 0.0150 - val_loss: 0.0110\n",
      "Epoch 16/50\n",
      "937/937 [==============================] - 0s 82us/sample - loss: 0.0150 - val_loss: 0.0110\n",
      "Epoch 17/50\n",
      "937/937 [==============================] - 0s 84us/sample - loss: 0.0150 - val_loss: 0.0110\n",
      "Epoch 18/50\n",
      "937/937 [==============================] - 0s 85us/sample - loss: 0.0150 - val_loss: 0.0110\n",
      "Epoch 19/50\n",
      "937/937 [==============================] - 0s 85us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 20/50\n",
      "937/937 [==============================] - 0s 83us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 21/50\n",
      "937/937 [==============================] - 0s 84us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 22/50\n",
      "937/937 [==============================] - 0s 81us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 23/50\n",
      "937/937 [==============================] - 0s 90us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 24/50\n",
      "937/937 [==============================] - 0s 90us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937/937 [==============================] - 0s 89us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 26/50\n",
      "937/937 [==============================] - 0s 84us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 27/50\n",
      "937/937 [==============================] - 0s 87us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 28/50\n",
      "937/937 [==============================] - 0s 85us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 29/50\n",
      "937/937 [==============================] - 0s 88us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 30/50\n",
      "937/937 [==============================] - 0s 85us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 31/50\n",
      "937/937 [==============================] - 0s 85us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 32/50\n",
      "937/937 [==============================] - 0s 84us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 33/50\n",
      "937/937 [==============================] - 0s 83us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 34/50\n",
      "937/937 [==============================] - 0s 83us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 35/50\n",
      "937/937 [==============================] - 0s 83us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 36/50\n",
      "937/937 [==============================] - 0s 86us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 37/50\n",
      "937/937 [==============================] - 0s 87us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 38/50\n",
      "937/937 [==============================] - 0s 91us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 39/50\n",
      "937/937 [==============================] - 0s 82us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 40/50\n",
      "937/937 [==============================] - 0s 87us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 41/50\n",
      "937/937 [==============================] - 0s 83us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 42/50\n",
      "937/937 [==============================] - 0s 87us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 43/50\n",
      "937/937 [==============================] - 0s 89us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 44/50\n",
      "937/937 [==============================] - 0s 87us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 45/50\n",
      "937/937 [==============================] - 0s 82us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 46/50\n",
      "937/937 [==============================] - 0s 81us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 47/50\n",
      "937/937 [==============================] - 0s 84us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 48/50\n",
      "937/937 [==============================] - 0s 83us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 49/50\n",
      "937/937 [==============================] - 0s 83us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 50/50\n",
      "937/937 [==============================] - 0s 86us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "第30个数，还剩4093个没有训练\n",
      "inv_hat [0.99065631 0.9689517  0.97114931 0.96775334 0.94790984 0.9472129\n",
      " 0.94601832 0.95767475 0.94611787 0.95588013 0.98074659 0.98254743\n",
      " 0.97804609 0.95817331 0.95837281 0.94830812 0.95249157 0.95548138\n",
      " 0.96965086 0.95448466 0.95308947 0.94392836 0.93358827 0.92703543\n",
      " 0.91642735 0.9189041  0.91315974 0.90880586 0.90554275 0.91118026]\n",
      "Test RMSE: 0.010\n",
      "Train on 790 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "790/790 [==============================] - 0s 81us/sample - loss: 0.0166 - val_loss: 0.0280\n",
      "Epoch 2/50\n",
      "790/790 [==============================] - 0s 76us/sample - loss: 0.0176 - val_loss: 0.0346\n",
      "Epoch 3/50\n",
      "790/790 [==============================] - 0s 76us/sample - loss: 0.0176 - val_loss: 0.0289\n",
      "Epoch 4/50\n",
      "790/790 [==============================] - 0s 77us/sample - loss: 0.0156 - val_loss: 0.0273\n",
      "Epoch 5/50\n",
      "790/790 [==============================] - 0s 77us/sample - loss: 0.0160 - val_loss: 0.0276\n",
      "Epoch 6/50\n",
      "790/790 [==============================] - 0s 79us/sample - loss: 0.0164 - val_loss: 0.0285\n",
      "Epoch 7/50\n",
      "790/790 [==============================] - 0s 76us/sample - loss: 0.0158 - val_loss: 0.0301\n",
      "Epoch 8/50\n",
      "790/790 [==============================] - 0s 79us/sample - loss: 0.0162 - val_loss: 0.0273\n",
      "Epoch 9/50\n",
      "790/790 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0280\n",
      "Epoch 10/50\n",
      "790/790 [==============================] - 0s 74us/sample - loss: 0.0164 - val_loss: 0.0277\n",
      "Epoch 11/50\n",
      "790/790 [==============================] - 0s 74us/sample - loss: 0.0161 - val_loss: 0.0277\n",
      "Epoch 12/50\n",
      "790/790 [==============================] - 0s 78us/sample - loss: 0.0155 - val_loss: 0.0293\n",
      "Epoch 13/50\n",
      "790/790 [==============================] - 0s 78us/sample - loss: 0.0159 - val_loss: 0.0277\n",
      "Epoch 14/50\n",
      "790/790 [==============================] - 0s 79us/sample - loss: 0.0156 - val_loss: 0.0278\n",
      "Epoch 15/50\n",
      "790/790 [==============================] - 0s 78us/sample - loss: 0.0172 - val_loss: 0.0291\n",
      "Epoch 16/50\n",
      "790/790 [==============================] - 0s 78us/sample - loss: 0.0176 - val_loss: 0.0280\n",
      "Epoch 17/50\n",
      "790/790 [==============================] - 0s 78us/sample - loss: 0.0158 - val_loss: 0.0302\n",
      "Epoch 18/50\n",
      "790/790 [==============================] - 0s 76us/sample - loss: 0.0168 - val_loss: 0.0273\n",
      "Epoch 19/50\n",
      "790/790 [==============================] - 0s 77us/sample - loss: 0.0166 - val_loss: 0.0278\n",
      "Epoch 20/50\n",
      "790/790 [==============================] - 0s 81us/sample - loss: 0.0166 - val_loss: 0.0288\n",
      "Epoch 21/50\n",
      "790/790 [==============================] - 0s 78us/sample - loss: 0.0159 - val_loss: 0.0298\n",
      "Epoch 22/50\n",
      "790/790 [==============================] - 0s 79us/sample - loss: 0.0166 - val_loss: 0.0276\n",
      "Epoch 23/50\n",
      "790/790 [==============================] - 0s 80us/sample - loss: 0.0167 - val_loss: 0.0281\n",
      "Epoch 24/50\n",
      "790/790 [==============================] - 0s 79us/sample - loss: 0.0167 - val_loss: 0.0280\n",
      "Epoch 25/50\n",
      "790/790 [==============================] - 0s 79us/sample - loss: 0.0156 - val_loss: 0.0300\n",
      "Epoch 26/50\n",
      "790/790 [==============================] - 0s 77us/sample - loss: 0.0167 - val_loss: 0.0275\n",
      "Epoch 27/50\n",
      "790/790 [==============================] - 0s 77us/sample - loss: 0.0169 - val_loss: 0.0282\n",
      "Epoch 28/50\n",
      "790/790 [==============================] - 0s 75us/sample - loss: 0.0167 - val_loss: 0.0284\n",
      "Epoch 29/50\n",
      "790/790 [==============================] - 0s 82us/sample - loss: 0.0157 - val_loss: 0.0296\n",
      "Epoch 30/50\n",
      "790/790 [==============================] - 0s 79us/sample - loss: 0.0165 - val_loss: 0.0276\n",
      "Epoch 31/50\n",
      "790/790 [==============================] - 0s 79us/sample - loss: 0.0168 - val_loss: 0.0282\n",
      "Epoch 32/50\n",
      "790/790 [==============================] - 0s 77us/sample - loss: 0.0167 - val_loss: 0.0282\n",
      "Epoch 33/50\n",
      "790/790 [==============================] - 0s 79us/sample - loss: 0.0159 - val_loss: 0.0299\n",
      "Epoch 34/50\n",
      "790/790 [==============================] - 0s 83us/sample - loss: 0.0167 - val_loss: 0.0276\n",
      "Epoch 35/50\n",
      "790/790 [==============================] - 0s 79us/sample - loss: 0.0169 - val_loss: 0.0284\n",
      "Epoch 36/50\n",
      "790/790 [==============================] - 0s 81us/sample - loss: 0.0169 - val_loss: 0.0282\n",
      "Epoch 37/50\n",
      "790/790 [==============================] - 0s 83us/sample - loss: 0.0159 - val_loss: 0.0301\n",
      "Epoch 38/50\n",
      "790/790 [==============================] - 0s 78us/sample - loss: 0.0167 - val_loss: 0.0275\n",
      "Epoch 39/50\n",
      "790/790 [==============================] - 0s 78us/sample - loss: 0.0169 - val_loss: 0.0283\n",
      "Epoch 40/50\n",
      "790/790 [==============================] - 0s 87us/sample - loss: 0.0168 - val_loss: 0.0284\n",
      "Epoch 41/50\n",
      "790/790 [==============================] - 0s 84us/sample - loss: 0.0157 - val_loss: 0.0295\n",
      "Epoch 42/50\n",
      "790/790 [==============================] - 0s 84us/sample - loss: 0.0164 - val_loss: 0.0275\n",
      "Epoch 43/50\n",
      "790/790 [==============================] - 0s 81us/sample - loss: 0.0170 - val_loss: 0.0284\n",
      "Epoch 44/50\n",
      "790/790 [==============================] - 0s 78us/sample - loss: 0.0170 - val_loss: 0.0286\n",
      "Epoch 45/50\n",
      "790/790 [==============================] - 0s 78us/sample - loss: 0.0158 - val_loss: 0.0293\n",
      "Epoch 46/50\n",
      "790/790 [==============================] - 0s 77us/sample - loss: 0.0162 - val_loss: 0.0274\n",
      "Epoch 47/50\n",
      "790/790 [==============================] - 0s 78us/sample - loss: 0.0165 - val_loss: 0.0283\n",
      "Epoch 48/50\n",
      "790/790 [==============================] - 0s 77us/sample - loss: 0.0165 - val_loss: 0.0274\n",
      "Epoch 49/50\n",
      "790/790 [==============================] - 0s 76us/sample - loss: 0.0155 - val_loss: 0.0287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "790/790 [==============================] - 0s 77us/sample - loss: 0.0154 - val_loss: 0.0294\n",
      "第31个数，还剩4092个没有训练\n",
      "inv_hat [0.97858868 0.96081597 0.96377069 0.96278545 0.94609281 0.94609281\n",
      " 0.94707158 0.96377069 0.95688138 0.96377069 0.98949688 0.99347108\n",
      " 0.99943912 0.97957897 0.97166482 0.96377069 0.97265302 0.97858868\n",
      " 0.98552662 0.96870203 0.96574219 0.95491634 0.94511446 0.940229\n",
      " 0.9295202  0.94120522 0.94120522 0.9353545  0.93438091 0.93438091]\n",
      "Test RMSE: 0.011\n",
      "Train on 814 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "814/814 [==============================] - 0s 82us/sample - loss: 0.0167 - val_loss: 0.0202\n",
      "Epoch 2/50\n",
      "814/814 [==============================] - 0s 80us/sample - loss: 0.0166 - val_loss: 0.0210\n",
      "Epoch 3/50\n",
      "814/814 [==============================] - 0s 85us/sample - loss: 0.0170 - val_loss: 0.0201\n",
      "Epoch 4/50\n",
      "814/814 [==============================] - 0s 85us/sample - loss: 0.0174 - val_loss: 0.0247\n",
      "Epoch 5/50\n",
      "814/814 [==============================] - 0s 86us/sample - loss: 0.0182 - val_loss: 0.0202\n",
      "Epoch 6/50\n",
      "814/814 [==============================] - 0s 89us/sample - loss: 0.0166 - val_loss: 0.0205\n",
      "Epoch 7/50\n",
      "814/814 [==============================] - 0s 82us/sample - loss: 0.0167 - val_loss: 0.0203\n",
      "Epoch 8/50\n",
      "814/814 [==============================] - 0s 83us/sample - loss: 0.0178 - val_loss: 0.0253\n",
      "Epoch 9/50\n",
      "814/814 [==============================] - 0s 83us/sample - loss: 0.0181 - val_loss: 0.0204\n",
      "Epoch 10/50\n",
      "814/814 [==============================] - 0s 82us/sample - loss: 0.0163 - val_loss: 0.0204\n",
      "Epoch 11/50\n",
      "814/814 [==============================] - 0s 85us/sample - loss: 0.0167 - val_loss: 0.0202\n",
      "Epoch 12/50\n",
      "814/814 [==============================] - 0s 84us/sample - loss: 0.0161 - val_loss: 0.0203\n",
      "Epoch 13/50\n",
      "814/814 [==============================] - 0s 84us/sample - loss: 0.0179 - val_loss: 0.0257\n",
      "Epoch 14/50\n",
      "814/814 [==============================] - 0s 86us/sample - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 15/50\n",
      "814/814 [==============================] - 0s 89us/sample - loss: 0.0162 - val_loss: 0.0204\n",
      "Epoch 16/50\n",
      "814/814 [==============================] - 0s 87us/sample - loss: 0.0168 - val_loss: 0.0202\n",
      "Epoch 17/50\n",
      "814/814 [==============================] - 0s 84us/sample - loss: 0.0160 - val_loss: 0.0206\n",
      "Epoch 18/50\n",
      "814/814 [==============================] - 0s 83us/sample - loss: 0.0179 - val_loss: 0.0252\n",
      "Epoch 19/50\n",
      "814/814 [==============================] - 0s 85us/sample - loss: 0.0185 - val_loss: 0.0204\n",
      "Epoch 20/50\n",
      "814/814 [==============================] - 0s 89us/sample - loss: 0.0162 - val_loss: 0.0204\n",
      "Epoch 21/50\n",
      "814/814 [==============================] - 0s 91us/sample - loss: 0.0168 - val_loss: 0.0202\n",
      "Epoch 22/50\n",
      "814/814 [==============================] - 0s 87us/sample - loss: 0.0161 - val_loss: 0.0205\n",
      "Epoch 23/50\n",
      "814/814 [==============================] - 0s 83us/sample - loss: 0.0177 - val_loss: 0.0253\n",
      "Epoch 24/50\n",
      "814/814 [==============================] - 0s 88us/sample - loss: 0.0185 - val_loss: 0.0204\n",
      "Epoch 25/50\n",
      "814/814 [==============================] - 0s 86us/sample - loss: 0.0162 - val_loss: 0.0204\n",
      "Epoch 26/50\n",
      "814/814 [==============================] - 0s 86us/sample - loss: 0.0169 - val_loss: 0.0202\n",
      "Epoch 27/50\n",
      "814/814 [==============================] - 0s 82us/sample - loss: 0.0160 - val_loss: 0.0205\n",
      "Epoch 28/50\n",
      "814/814 [==============================] - 0s 84us/sample - loss: 0.0176 - val_loss: 0.0251\n",
      "Epoch 29/50\n",
      "814/814 [==============================] - 0s 90us/sample - loss: 0.0184 - val_loss: 0.0205\n",
      "Epoch 30/50\n",
      "814/814 [==============================] - 0s 84us/sample - loss: 0.0162 - val_loss: 0.0204\n",
      "Epoch 31/50\n",
      "814/814 [==============================] - 0s 88us/sample - loss: 0.0169 - val_loss: 0.0202\n",
      "Epoch 32/50\n",
      "814/814 [==============================] - 0s 89us/sample - loss: 0.0162 - val_loss: 0.0204\n",
      "Epoch 33/50\n",
      "814/814 [==============================] - 0s 93us/sample - loss: 0.0176 - val_loss: 0.0254\n",
      "Epoch 34/50\n",
      "814/814 [==============================] - 0s 91us/sample - loss: 0.0183 - val_loss: 0.0205\n",
      "Epoch 35/50\n",
      "814/814 [==============================] - 0s 82us/sample - loss: 0.0161 - val_loss: 0.0204\n",
      "Epoch 36/50\n",
      "814/814 [==============================] - 0s 84us/sample - loss: 0.0170 - val_loss: 0.0202\n",
      "Epoch 37/50\n",
      "814/814 [==============================] - 0s 83us/sample - loss: 0.0161 - val_loss: 0.0206\n",
      "Epoch 38/50\n",
      "814/814 [==============================] - 0s 82us/sample - loss: 0.0177 - val_loss: 0.0253\n",
      "Epoch 39/50\n",
      "814/814 [==============================] - 0s 81us/sample - loss: 0.0183 - val_loss: 0.0206\n",
      "Epoch 40/50\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.015 - 0s 81us/sample - loss: 0.0162 - val_loss: 0.0204\n",
      "Epoch 41/50\n",
      "814/814 [==============================] - 0s 81us/sample - loss: 0.0169 - val_loss: 0.0202\n",
      "Epoch 42/50\n",
      "814/814 [==============================] - 0s 86us/sample - loss: 0.0161 - val_loss: 0.0205\n",
      "Epoch 43/50\n",
      "814/814 [==============================] - 0s 84us/sample - loss: 0.0175 - val_loss: 0.0253\n",
      "Epoch 44/50\n",
      "814/814 [==============================] - 0s 83us/sample - loss: 0.0181 - val_loss: 0.0206\n",
      "Epoch 45/50\n",
      "814/814 [==============================] - 0s 81us/sample - loss: 0.0161 - val_loss: 0.0204\n",
      "Epoch 46/50\n",
      "814/814 [==============================] - 0s 84us/sample - loss: 0.0170 - val_loss: 0.0202\n",
      "Epoch 47/50\n",
      "814/814 [==============================] - 0s 84us/sample - loss: 0.0162 - val_loss: 0.0205\n",
      "Epoch 48/50\n",
      "814/814 [==============================] - 0s 84us/sample - loss: 0.0176 - val_loss: 0.0252\n",
      "Epoch 49/50\n",
      "814/814 [==============================] - 0s 82us/sample - loss: 0.0183 - val_loss: 0.0205\n",
      "Epoch 50/50\n",
      "814/814 [==============================] - 0s 81us/sample - loss: 0.0160 - val_loss: 0.0204\n",
      "第32个数，还剩4091个没有训练\n",
      "inv_hat [1.19348747 1.17973885 1.18544684 1.18188011 1.16299035 1.16391039\n",
      " 1.1615588  1.17106353 1.15910413 1.16145653 1.16871399 1.16391039\n",
      " 1.16391039 1.15777435 1.16022919 1.15501189 1.16421714 1.16799877\n",
      " 1.17759675 1.16677255 1.16912259 1.15705824 1.15542114 1.15654659\n",
      " 1.14590187 1.14364927 1.14211329 1.1438541  1.14149891 1.1497922 ]\n",
      "Test RMSE: 0.007\n",
      "Train on 555 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "555/555 [==============================] - 0s 83us/sample - loss: 0.0065 - val_loss: 0.0040\n",
      "Epoch 2/50\n",
      "555/555 [==============================] - 0s 88us/sample - loss: 0.0097 - val_loss: 0.0069\n",
      "Epoch 3/50\n",
      "555/555 [==============================] - 0s 84us/sample - loss: 0.0170 - val_loss: 0.0079\n",
      "Epoch 4/50\n",
      "555/555 [==============================] - 0s 84us/sample - loss: 0.0201 - val_loss: 0.0245\n",
      "Epoch 5/50\n",
      "555/555 [==============================] - 0s 83us/sample - loss: 0.0068 - val_loss: 0.0054\n",
      "Epoch 6/50\n",
      "555/555 [==============================] - 0s 83us/sample - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 7/50\n",
      "555/555 [==============================] - 0s 84us/sample - loss: 0.0060 - val_loss: 0.0064\n",
      "Epoch 8/50\n",
      "555/555 [==============================] - 0s 84us/sample - loss: 0.0067 - val_loss: 0.0033\n",
      "Epoch 9/50\n",
      "555/555 [==============================] - 0s 85us/sample - loss: 0.0085 - val_loss: 0.0048\n",
      "Epoch 10/50\n",
      "555/555 [==============================] - 0s 83us/sample - loss: 0.0080 - val_loss: 0.0090\n",
      "Epoch 11/50\n",
      "555/555 [==============================] - 0s 82us/sample - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 12/50\n",
      "555/555 [==============================] - 0s 81us/sample - loss: 0.0051 - val_loss: 0.0025\n",
      "Epoch 13/50\n",
      "555/555 [==============================] - 0s 81us/sample - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 14/50\n",
      "555/555 [==============================] - 0s 83us/sample - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 15/50\n",
      "555/555 [==============================] - 0s 85us/sample - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 16/50\n",
      "555/555 [==============================] - 0s 89us/sample - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 17/50\n",
      "555/555 [==============================] - 0s 89us/sample - loss: 0.0066 - val_loss: 0.0090\n",
      "Epoch 18/50\n",
      "555/555 [==============================] - 0s 85us/sample - loss: 0.0100 - val_loss: 0.0058\n",
      "Epoch 19/50\n",
      "555/555 [==============================] - 0s 87us/sample - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 20/50\n",
      "555/555 [==============================] - 0s 88us/sample - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 21/50\n",
      "555/555 [==============================] - 0s 85us/sample - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 22/50\n",
      "555/555 [==============================] - 0s 88us/sample - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 23/50\n",
      "555/555 [==============================] - 0s 86us/sample - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 24/50\n",
      "555/555 [==============================] - 0s 83us/sample - loss: 0.0070 - val_loss: 0.0040\n",
      "Epoch 25/50\n",
      "555/555 [==============================] - 0s 90us/sample - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 26/50\n",
      "555/555 [==============================] - 0s 87us/sample - loss: 0.0057 - val_loss: 0.0093\n",
      "Epoch 27/50\n",
      "555/555 [==============================] - 0s 88us/sample - loss: 0.0067 - val_loss: 0.0025\n",
      "Epoch 28/50\n",
      "555/555 [==============================] - 0s 85us/sample - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 29/50\n",
      "555/555 [==============================] - 0s 85us/sample - loss: 0.0075 - val_loss: 0.0098\n",
      "Epoch 30/50\n",
      "555/555 [==============================] - 0s 83us/sample - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 31/50\n",
      "555/555 [==============================] - 0s 81us/sample - loss: 0.0060 - val_loss: 0.0023\n",
      "Epoch 32/50\n",
      "555/555 [==============================] - 0s 84us/sample - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 33/50\n",
      "555/555 [==============================] - 0s 84us/sample - loss: 0.0081 - val_loss: 0.0088\n",
      "Epoch 34/50\n",
      "555/555 [==============================] - 0s 83us/sample - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 35/50\n",
      "555/555 [==============================] - 0s 83us/sample - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 36/50\n",
      "555/555 [==============================] - 0s 83us/sample - loss: 0.0054 - val_loss: 0.0027\n",
      "Epoch 37/50\n",
      "555/555 [==============================] - 0s 83us/sample - loss: 0.0094 - val_loss: 0.0093\n",
      "Epoch 38/50\n",
      "555/555 [==============================] - 0s 83us/sample - loss: 0.0074 - val_loss: 0.0043\n",
      "Epoch 39/50\n",
      "555/555 [==============================] - 0s 82us/sample - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 40/50\n",
      "555/555 [==============================] - 0s 86us/sample - loss: 0.0053 - val_loss: 0.0071\n",
      "Epoch 41/50\n",
      "555/555 [==============================] - 0s 83us/sample - loss: 0.0065 - val_loss: 0.0028\n",
      "Epoch 42/50\n",
      "555/555 [==============================] - 0s 84us/sample - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 43/50\n",
      "555/555 [==============================] - 0s 82us/sample - loss: 0.0081 - val_loss: 0.0102\n",
      "Epoch 44/50\n",
      "555/555 [==============================] - 0s 81us/sample - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 45/50\n",
      "555/555 [==============================] - 0s 86us/sample - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 46/50\n",
      "555/555 [==============================] - 0s 81us/sample - loss: 0.0057 - val_loss: 0.0024\n",
      "Epoch 47/50\n",
      "555/555 [==============================] - 0s 80us/sample - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 48/50\n",
      "555/555 [==============================] - 0s 89us/sample - loss: 0.0077 - val_loss: 0.0052\n",
      "Epoch 49/50\n",
      "555/555 [==============================] - 0s 84us/sample - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 50/50\n",
      "555/555 [==============================] - 0s 83us/sample - loss: 0.0046 - val_loss: 0.0040\n",
      "第33个数，还剩4090个没有训练\n",
      "inv_hat [1.06274702 1.06274702 1.06284398 1.06284398 1.06294089 1.06303779\n",
      " 1.06303779 1.06294089 1.06303779 1.06323154 1.06352193 1.06371553\n",
      " 1.06419909 1.06439242 1.06458333 1.06477673 1.06496992 1.06506656\n",
      " 1.06487339 1.06458333 1.0644866  1.06409966 1.06419633 1.06458333\n",
      " 1.06487339 1.06525978 1.06506656 1.06506656 1.06535635 1.06603178]\n",
      "Test RMSE: 0.000\n",
      "Train on 1025 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1025/1025 [==============================] - 0s 81us/sample - loss: 0.0170 - val_loss: 0.0091\n",
      "Epoch 2/50\n",
      "1025/1025 [==============================] - 0s 81us/sample - loss: 0.0169 - val_loss: 0.0087\n",
      "Epoch 3/50\n",
      "1025/1025 [==============================] - 0s 79us/sample - loss: 0.0162 - val_loss: 0.0085\n",
      "Epoch 4/50\n",
      "1025/1025 [==============================] - 0s 81us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 5/50\n",
      "1025/1025 [==============================] - 0s 80us/sample - loss: 0.0164 - val_loss: 0.0085\n",
      "Epoch 6/50\n",
      "1025/1025 [==============================] - 0s 81us/sample - loss: 0.0164 - val_loss: 0.0085\n",
      "Epoch 7/50\n",
      "1025/1025 [==============================] - 0s 80us/sample - loss: 0.0164 - val_loss: 0.0085\n",
      "Epoch 8/50\n",
      "1025/1025 [==============================] - 0s 81us/sample - loss: 0.0164 - val_loss: 0.0085\n",
      "Epoch 9/50\n",
      "1025/1025 [==============================] - 0s 88us/sample - loss: 0.0164 - val_loss: 0.0085\n",
      "Epoch 10/50\n",
      "1025/1025 [==============================] - 0s 87us/sample - loss: 0.0164 - val_loss: 0.0085\n",
      "Epoch 11/50\n",
      "1025/1025 [==============================] - 0s 87us/sample - loss: 0.0164 - val_loss: 0.0085\n",
      "Epoch 12/50\n",
      "1025/1025 [==============================] - 0s 85us/sample - loss: 0.0164 - val_loss: 0.0085\n",
      "Epoch 13/50\n",
      "1025/1025 [==============================] - 0s 84us/sample - loss: 0.0164 - val_loss: 0.0085\n",
      "Epoch 14/50\n",
      "1025/1025 [==============================] - 0s 78us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 15/50\n",
      "1025/1025 [==============================] - 0s 81us/sample - loss: 0.0164 - val_loss: 0.0085\n",
      "Epoch 16/50\n",
      "1025/1025 [==============================] - 0s 81us/sample - loss: 0.0164 - val_loss: 0.0085\n",
      "Epoch 17/50\n",
      "1025/1025 [==============================] - 0s 84us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 18/50\n",
      "1025/1025 [==============================] - 0s 81us/sample - loss: 0.0164 - val_loss: 0.0085\n",
      "Epoch 19/50\n",
      "1025/1025 [==============================] - 0s 79us/sample - loss: 0.0164 - val_loss: 0.0085\n",
      "Epoch 20/50\n",
      "1025/1025 [==============================] - 0s 82us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 21/50\n",
      "1025/1025 [==============================] - 0s 79us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 22/50\n",
      "1025/1025 [==============================] - 0s 82us/sample - loss: 0.0164 - val_loss: 0.0085\n",
      "Epoch 23/50\n",
      "1025/1025 [==============================] - 0s 86us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 24/50\n",
      "1025/1025 [==============================] - 0s 84us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 25/50\n",
      "1025/1025 [==============================] - 0s 79us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 26/50\n",
      "1025/1025 [==============================] - 0s 82us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 27/50\n",
      "1025/1025 [==============================] - 0s 87us/sample - loss: 0.0164 - val_loss: 0.0085\n",
      "Epoch 28/50\n",
      "1025/1025 [==============================] - 0s 83us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 29/50\n",
      "1025/1025 [==============================] - 0s 79us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 30/50\n",
      "1025/1025 [==============================] - 0s 82us/sample - loss: 0.0164 - val_loss: 0.0085\n",
      "Epoch 31/50\n",
      "1025/1025 [==============================] - 0s 82us/sample - loss: 0.0164 - val_loss: 0.0085\n",
      "Epoch 32/50\n",
      "1025/1025 [==============================] - 0s 82us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 33/50\n",
      "1025/1025 [==============================] - 0s 83us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 34/50\n",
      "1025/1025 [==============================] - 0s 85us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 35/50\n",
      "1025/1025 [==============================] - 0s 85us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 36/50\n",
      "1025/1025 [==============================] - 0s 84us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 37/50\n",
      "1025/1025 [==============================] - 0s 80us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 38/50\n",
      "1025/1025 [==============================] - 0s 79us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 39/50\n",
      "1025/1025 [==============================] - 0s 86us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 40/50\n",
      "1025/1025 [==============================] - 0s 85us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 41/50\n",
      "1025/1025 [==============================] - 0s 85us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 42/50\n",
      "1025/1025 [==============================] - 0s 81us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 43/50\n",
      "1025/1025 [==============================] - 0s 80us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1025/1025 [==============================] - 0s 83us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 45/50\n",
      "1025/1025 [==============================] - 0s 86us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 46/50\n",
      "1025/1025 [==============================] - 0s 88us/sample - loss: 0.0165 - val_loss: 0.0086\n",
      "Epoch 47/50\n",
      "1025/1025 [==============================] - 0s 89us/sample - loss: 0.0165 - val_loss: 0.0086\n",
      "Epoch 48/50\n",
      "1025/1025 [==============================] - 0s 87us/sample - loss: 0.0165 - val_loss: 0.0086\n",
      "Epoch 49/50\n",
      "1025/1025 [==============================] - 0s 80us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 50/50\n",
      "1025/1025 [==============================] - 0s 82us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "第34个数，还剩4089个没有训练\n",
      "inv_hat [0.55724264 0.51348338 0.51348338 0.5114972  0.46391096 0.45896319\n",
      " 0.47084068 0.48867585 0.45896319 0.47678331 0.53435327 0.53335886\n",
      " 0.52739349 0.48371943 0.48371943 0.47183102 0.48371943 0.48471059\n",
      " 0.50256297 0.46985054 0.45995259 0.44808448 0.42734056 0.43128925\n",
      " 0.42734056 0.44709596 0.4431425  0.42931477 0.4145156  0.410572  ]\n",
      "Test RMSE: 0.021\n",
      "Train on 512 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "512/512 [==============================] - 0s 85us/sample - loss: 0.0203 - val_loss: 0.0233\n",
      "Epoch 2/50\n",
      "512/512 [==============================] - 0s 89us/sample - loss: 0.0202 - val_loss: 0.0247\n",
      "Epoch 3/50\n",
      "512/512 [==============================] - 0s 96us/sample - loss: 0.0204 - val_loss: 0.0234\n",
      "Epoch 4/50\n",
      "512/512 [==============================] - 0s 95us/sample - loss: 0.0200 - val_loss: 0.0245\n",
      "Epoch 5/50\n",
      "512/512 [==============================] - 0s 85us/sample - loss: 0.0202 - val_loss: 0.0235\n",
      "Epoch 6/50\n",
      "512/512 [==============================] - 0s 90us/sample - loss: 0.0200 - val_loss: 0.0241\n",
      "Epoch 7/50\n",
      "512/512 [==============================] - 0s 93us/sample - loss: 0.0201 - val_loss: 0.0238\n",
      "Epoch 8/50\n",
      "512/512 [==============================] - 0s 93us/sample - loss: 0.0200 - val_loss: 0.0240\n",
      "Epoch 9/50\n",
      "512/512 [==============================] - 0s 92us/sample - loss: 0.0201 - val_loss: 0.0240\n",
      "Epoch 10/50\n",
      "512/512 [==============================] - 0s 89us/sample - loss: 0.0200 - val_loss: 0.0239\n",
      "Epoch 11/50\n",
      "512/512 [==============================] - 0s 93us/sample - loss: 0.0200 - val_loss: 0.0241\n",
      "Epoch 12/50\n",
      "512/512 [==============================] - 0s 88us/sample - loss: 0.0200 - val_loss: 0.0239\n",
      "Epoch 13/50\n",
      "512/512 [==============================] - 0s 91us/sample - loss: 0.0200 - val_loss: 0.0241\n",
      "Epoch 14/50\n",
      "512/512 [==============================] - 0s 88us/sample - loss: 0.0200 - val_loss: 0.0239\n",
      "Epoch 15/50\n",
      "512/512 [==============================] - 0s 90us/sample - loss: 0.0200 - val_loss: 0.0240\n",
      "Epoch 16/50\n",
      "512/512 [==============================] - 0s 94us/sample - loss: 0.0201 - val_loss: 0.0240\n",
      "Epoch 17/50\n",
      "512/512 [==============================] - 0s 90us/sample - loss: 0.0200 - val_loss: 0.0240\n",
      "Epoch 18/50\n",
      "512/512 [==============================] - 0s 88us/sample - loss: 0.0200 - val_loss: 0.0241\n",
      "Epoch 19/50\n",
      "512/512 [==============================] - 0s 86us/sample - loss: 0.0200 - val_loss: 0.0240\n",
      "Epoch 20/50\n",
      "512/512 [==============================] - 0s 87us/sample - loss: 0.0200 - val_loss: 0.0239\n",
      "Epoch 21/50\n",
      "512/512 [==============================] - 0s 94us/sample - loss: 0.0200 - val_loss: 0.0241\n",
      "Epoch 22/50\n",
      "512/512 [==============================] - 0s 89us/sample - loss: 0.0200 - val_loss: 0.0240\n",
      "Epoch 23/50\n",
      "512/512 [==============================] - 0s 93us/sample - loss: 0.0200 - val_loss: 0.0239\n",
      "Epoch 24/50\n",
      "512/512 [==============================] - 0s 89us/sample - loss: 0.0200 - val_loss: 0.0241\n",
      "Epoch 25/50\n",
      "512/512 [==============================] - 0s 95us/sample - loss: 0.0200 - val_loss: 0.0240\n",
      "Epoch 26/50\n",
      "512/512 [==============================] - 0s 90us/sample - loss: 0.0200 - val_loss: 0.0241\n",
      "Epoch 27/50\n",
      "512/512 [==============================] - 0s 91us/sample - loss: 0.0200 - val_loss: 0.0240\n",
      "Epoch 28/50\n",
      "512/512 [==============================] - 0s 87us/sample - loss: 0.0200 - val_loss: 0.0239\n",
      "Epoch 29/50\n",
      "512/512 [==============================] - 0s 92us/sample - loss: 0.0200 - val_loss: 0.0241\n",
      "Epoch 30/50\n",
      "512/512 [==============================] - 0s 91us/sample - loss: 0.0200 - val_loss: 0.0239\n",
      "Epoch 31/50\n",
      "512/512 [==============================] - 0s 91us/sample - loss: 0.0200 - val_loss: 0.0240\n",
      "Epoch 32/50\n",
      "512/512 [==============================] - 0s 95us/sample - loss: 0.0200 - val_loss: 0.0241\n",
      "Epoch 33/50\n",
      "512/512 [==============================] - 0s 89us/sample - loss: 0.0201 - val_loss: 0.0240\n",
      "Epoch 34/50\n",
      "512/512 [==============================] - 0s 93us/sample - loss: 0.0200 - val_loss: 0.0239\n",
      "Epoch 35/50\n",
      "512/512 [==============================] - 0s 87us/sample - loss: 0.0201 - val_loss: 0.0241\n",
      "Epoch 36/50\n",
      "512/512 [==============================] - 0s 86us/sample - loss: 0.0200 - val_loss: 0.0239\n",
      "Epoch 37/50\n",
      "512/512 [==============================] - 0s 95us/sample - loss: 0.0201 - val_loss: 0.0240\n",
      "Epoch 38/50\n",
      "512/512 [==============================] - 0s 90us/sample - loss: 0.0200 - val_loss: 0.0239\n",
      "Epoch 39/50\n",
      "512/512 [==============================] - 0s 88us/sample - loss: 0.0201 - val_loss: 0.0241\n",
      "Epoch 40/50\n",
      "512/512 [==============================] - 0s 94us/sample - loss: 0.0200 - val_loss: 0.0238\n",
      "Epoch 41/50\n",
      "512/512 [==============================] - 0s 89us/sample - loss: 0.0201 - val_loss: 0.0241\n",
      "Epoch 42/50\n",
      "512/512 [==============================] - 0s 92us/sample - loss: 0.0200 - val_loss: 0.0239\n",
      "Epoch 43/50\n",
      "512/512 [==============================] - 0s 88us/sample - loss: 0.0200 - val_loss: 0.0239\n",
      "Epoch 44/50\n",
      "512/512 [==============================] - 0s 95us/sample - loss: 0.0200 - val_loss: 0.0241\n",
      "Epoch 45/50\n",
      "512/512 [==============================] - 0s 95us/sample - loss: 0.0200 - val_loss: 0.0242\n",
      "Epoch 46/50\n",
      "512/512 [==============================] - 0s 97us/sample - loss: 0.0200 - val_loss: 0.0240\n",
      "Epoch 47/50\n",
      "512/512 [==============================] - 0s 98us/sample - loss: 0.0200 - val_loss: 0.0239\n",
      "Epoch 48/50\n",
      "512/512 [==============================] - 0s 97us/sample - loss: 0.0200 - val_loss: 0.0241\n",
      "Epoch 49/50\n",
      "512/512 [==============================] - 0s 95us/sample - loss: 0.0200 - val_loss: 0.0240\n",
      "Epoch 50/50\n",
      "512/512 [==============================] - 0s 92us/sample - loss: 0.0201 - val_loss: 0.0242\n",
      "第35个数，还剩4088个没有训练\n",
      "inv_hat [1.12482913 1.10678179 1.12984717 1.12683619 1.10277512 1.1007724\n",
      " 1.09977115 1.11279476 1.09977115 1.11279476 1.15195006 1.16905188\n",
      " 1.18314767 1.13285904 1.09276557 1.07577483 1.09076496 1.07277998\n",
      " 1.0887648  1.05483524 1.03494898 1.02998667 0.99832364 0.98748051\n",
      " 0.96978612 0.99142093 0.99931052 0.99240648 0.98649587 0.99043556]\n",
      "Test RMSE: 0.021\n",
      "Train on 917 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "917/917 [==============================] - 0s 84us/sample - loss: 0.0158 - val_loss: 0.0095\n",
      "Epoch 2/50\n",
      "917/917 [==============================] - 0s 80us/sample - loss: 0.0154 - val_loss: 0.0093\n",
      "Epoch 3/50\n",
      "917/917 [==============================] - 0s 79us/sample - loss: 0.0156 - val_loss: 0.0102\n",
      "Epoch 4/50\n",
      "917/917 [==============================] - 0s 82us/sample - loss: 0.0162 - val_loss: 0.0100\n",
      "Epoch 5/50\n",
      "917/917 [==============================] - 0s 80us/sample - loss: 0.0168 - val_loss: 0.0092\n",
      "Epoch 6/50\n",
      "917/917 [==============================] - 0s 77us/sample - loss: 0.0170 - val_loss: 0.0102\n",
      "Epoch 7/50\n",
      "917/917 [==============================] - 0s 76us/sample - loss: 0.0169 - val_loss: 0.0111\n",
      "Epoch 8/50\n",
      "917/917 [==============================] - 0s 77us/sample - loss: 0.0172 - val_loss: 0.0123\n",
      "Epoch 9/50\n",
      "917/917 [==============================] - 0s 78us/sample - loss: 0.0167 - val_loss: 0.0121\n",
      "Epoch 10/50\n",
      "917/917 [==============================] - 0s 79us/sample - loss: 0.0166 - val_loss: 0.0120\n",
      "Epoch 11/50\n",
      "917/917 [==============================] - 0s 82us/sample - loss: 0.0164 - val_loss: 0.0118\n",
      "Epoch 12/50\n",
      "917/917 [==============================] - 0s 79us/sample - loss: 0.0164 - val_loss: 0.0115\n",
      "Epoch 13/50\n",
      "917/917 [==============================] - 0s 80us/sample - loss: 0.0166 - val_loss: 0.0119\n",
      "Epoch 14/50\n",
      "917/917 [==============================] - 0s 77us/sample - loss: 0.0164 - val_loss: 0.0119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "917/917 [==============================] - 0s 86us/sample - loss: 0.0163 - val_loss: 0.0114\n",
      "Epoch 16/50\n",
      "917/917 [==============================] - 0s 84us/sample - loss: 0.0166 - val_loss: 0.0119\n",
      "Epoch 17/50\n",
      "917/917 [==============================] - 0s 82us/sample - loss: 0.0164 - val_loss: 0.0117\n",
      "Epoch 18/50\n",
      "917/917 [==============================] - 0s 81us/sample - loss: 0.0163 - val_loss: 0.0115\n",
      "Epoch 19/50\n",
      "917/917 [==============================] - 0s 82us/sample - loss: 0.0165 - val_loss: 0.0120\n",
      "Epoch 20/50\n",
      "917/917 [==============================] - 0s 80us/sample - loss: 0.0162 - val_loss: 0.0114\n",
      "Epoch 21/50\n",
      "917/917 [==============================] - 0s 83us/sample - loss: 0.0164 - val_loss: 0.0116\n",
      "Epoch 22/50\n",
      "917/917 [==============================] - 0s 84us/sample - loss: 0.0163 - val_loss: 0.0115\n",
      "Epoch 23/50\n",
      "917/917 [==============================] - 0s 82us/sample - loss: 0.0163 - val_loss: 0.0114\n",
      "Epoch 24/50\n",
      "917/917 [==============================] - 0s 82us/sample - loss: 0.0164 - val_loss: 0.0117\n",
      "Epoch 25/50\n",
      "917/917 [==============================] - 0s 82us/sample - loss: 0.0161 - val_loss: 0.0114\n",
      "Epoch 26/50\n",
      "917/917 [==============================] - 0s 79us/sample - loss: 0.0161 - val_loss: 0.0112\n",
      "Epoch 27/50\n",
      "917/917 [==============================] - 0s 79us/sample - loss: 0.0160 - val_loss: 0.0112\n",
      "Epoch 28/50\n",
      "917/917 [==============================] - 0s 80us/sample - loss: 0.0159 - val_loss: 0.0113\n",
      "Epoch 29/50\n",
      "917/917 [==============================] - 0s 81us/sample - loss: 0.0159 - val_loss: 0.0113\n",
      "Epoch 30/50\n",
      "917/917 [==============================] - 0s 81us/sample - loss: 0.0159 - val_loss: 0.0112\n",
      "Epoch 31/50\n",
      "917/917 [==============================] - 0s 83us/sample - loss: 0.0157 - val_loss: 0.0109\n",
      "Epoch 32/50\n",
      "917/917 [==============================] - 0s 82us/sample - loss: 0.0157 - val_loss: 0.0107\n",
      "Epoch 33/50\n",
      "917/917 [==============================] - 0s 79us/sample - loss: 0.0157 - val_loss: 0.0106\n",
      "Epoch 34/50\n",
      "917/917 [==============================] - 0s 81us/sample - loss: 0.0157 - val_loss: 0.0108\n",
      "Epoch 35/50\n",
      "917/917 [==============================] - 0s 79us/sample - loss: 0.0156 - val_loss: 0.0107\n",
      "Epoch 36/50\n",
      "917/917 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0106\n",
      "Epoch 37/50\n",
      "917/917 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0106\n",
      "Epoch 38/50\n",
      "917/917 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0106\n",
      "Epoch 39/50\n",
      "917/917 [==============================] - 0s 81us/sample - loss: 0.0155 - val_loss: 0.0102\n",
      "Epoch 40/50\n",
      "917/917 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0095\n",
      "Epoch 41/50\n",
      "917/917 [==============================] - 0s 83us/sample - loss: 0.0160 - val_loss: 0.0094\n",
      "Epoch 42/50\n",
      "917/917 [==============================] - 0s 82us/sample - loss: 0.0166 - val_loss: 0.0107\n",
      "Epoch 43/50\n",
      "917/917 [==============================] - 0s 79us/sample - loss: 0.0164 - val_loss: 0.0112\n",
      "Epoch 44/50\n",
      "917/917 [==============================] - 0s 77us/sample - loss: 0.0166 - val_loss: 0.0116\n",
      "Epoch 45/50\n",
      "917/917 [==============================] - 0s 77us/sample - loss: 0.0167 - val_loss: 0.0123\n",
      "Epoch 46/50\n",
      "917/917 [==============================] - 0s 80us/sample - loss: 0.0165 - val_loss: 0.0124\n",
      "Epoch 47/50\n",
      "917/917 [==============================] - 0s 83us/sample - loss: 0.0162 - val_loss: 0.0118\n",
      "Epoch 48/50\n",
      "917/917 [==============================] - 0s 83us/sample - loss: 0.0163 - val_loss: 0.0117\n",
      "Epoch 49/50\n",
      "917/917 [==============================] - 0s 81us/sample - loss: 0.0163 - val_loss: 0.0117\n",
      "Epoch 50/50\n",
      "917/917 [==============================] - 0s 80us/sample - loss: 0.0164 - val_loss: 0.0119\n",
      "第36个数，还剩4087个没有训练\n",
      "inv_hat [0.86107374 0.84572034 0.84572034 0.84380509 0.82375065 0.81994248\n",
      " 0.82375065 0.83615332 0.82279826 0.83042406 0.84763641 0.8514713\n",
      " 0.85051226 0.83519783 0.8418908  0.83997741 0.84476262 0.84093398\n",
      " 0.84955345 0.8323329  0.82565613 0.82279826 0.81233776 0.81328754\n",
      " 0.81233776 0.81708888 0.81708888 0.81613818 0.81043905 0.81043905]\n",
      "Test RMSE: 0.011\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0103 - val_loss: 0.0033\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0032\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0100 - val_loss: 0.0042\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0093 - val_loss: 0.0029\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0096 - val_loss: 0.0045\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0094 - val_loss: 0.0037\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0028\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0095 - val_loss: 0.0035\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0097 - val_loss: 0.0044\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0093 - val_loss: 0.0029\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0093 - val_loss: 0.0029\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0097 - val_loss: 0.0046\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0094 - val_loss: 0.0037\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0094 - val_loss: 0.0031\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0097 - val_loss: 0.0043\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0097 - val_loss: 0.0042\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0028\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0095 - val_loss: 0.0037\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0096 - val_loss: 0.0041\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0093 - val_loss: 0.0029\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0094 - val_loss: 0.0032\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0097 - val_loss: 0.0044\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0028\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0093 - val_loss: 0.0029\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0098 - val_loss: 0.0046\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0093 - val_loss: 0.0030\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0028\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0097 - val_loss: 0.0047\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0094 - val_loss: 0.0033\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0094 - val_loss: 0.0031\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0095 - val_loss: 0.0037\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0099 - val_loss: 0.0042\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0093 - val_loss: 0.0028\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0095 - val_loss: 0.0038\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0094 - val_loss: 0.0034\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0031\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0094 - val_loss: 0.0031\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0098 - val_loss: 0.0045\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0093 - val_loss: 0.0028\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0093 - val_loss: 0.0028\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0098 - val_loss: 0.0048\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0028\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0094 - val_loss: 0.0028\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0099 - val_loss: 0.0048\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0030\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0093 - val_loss: 0.0029\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0033\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0096 - val_loss: 0.0040\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0029\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0093 - val_loss: 0.0028\n",
      "第37个数，还剩4086个没有训练\n",
      "inv_hat [0.41681364 0.4074905  0.40680402 0.4061176  0.39720031 0.39573156\n",
      " 0.39690654 0.40141256 0.39592738 0.39945307 0.40925605 0.40964847\n",
      " 0.40798088 0.40062869 0.40190252 0.40053072 0.40298056 0.40347063\n",
      " 0.40886366 0.40356863 0.40111859 0.39788588 0.39357793 0.39367582\n",
      " 0.39044661 0.39191425 0.39113145 0.39025094 0.38888149 0.38937054]\n",
      "Test RMSE: 0.004\n",
      "Train on 812 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "812/812 [==============================] - 0s 87us/sample - loss: 0.0085 - val_loss: 0.0057\n",
      "Epoch 2/50\n",
      "812/812 [==============================] - 0s 86us/sample - loss: 0.0087 - val_loss: 0.0097\n",
      "Epoch 3/50\n",
      "812/812 [==============================] - 0s 86us/sample - loss: 0.0094 - val_loss: 0.0068\n",
      "Epoch 4/50\n",
      "812/812 [==============================] - 0s 88us/sample - loss: 0.0164 - val_loss: 0.0219\n",
      "Epoch 5/50\n",
      "812/812 [==============================] - 0s 85us/sample - loss: 0.0146 - val_loss: 0.0090\n",
      "Epoch 6/50\n",
      "812/812 [==============================] - 0s 89us/sample - loss: 0.0082 - val_loss: 0.0067\n",
      "Epoch 7/50\n",
      "812/812 [==============================] - 0s 88us/sample - loss: 0.0069 - val_loss: 0.0094\n",
      "Epoch 8/50\n",
      "812/812 [==============================] - 0s 85us/sample - loss: 0.0103 - val_loss: 0.0061\n",
      "Epoch 9/50\n",
      "812/812 [==============================] - 0s 84us/sample - loss: 0.0128 - val_loss: 0.0139\n",
      "Epoch 10/50\n",
      "812/812 [==============================] - 0s 85us/sample - loss: 0.0171 - val_loss: 0.0042\n",
      "Epoch 11/50\n",
      "812/812 [==============================] - 0s 86us/sample - loss: 0.0161 - val_loss: 0.0137\n",
      "Epoch 12/50\n",
      "812/812 [==============================] - 0s 90us/sample - loss: 0.0099 - val_loss: 0.0046\n",
      "Epoch 13/50\n",
      "812/812 [==============================] - 0s 87us/sample - loss: 0.0092 - val_loss: 0.0068\n",
      "Epoch 14/50\n",
      "812/812 [==============================] - 0s 87us/sample - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 15/50\n",
      "812/812 [==============================] - 0s 85us/sample - loss: 0.0072 - val_loss: 0.0043\n",
      "Epoch 16/50\n",
      "812/812 [==============================] - 0s 90us/sample - loss: 0.0072 - val_loss: 0.0049\n",
      "Epoch 17/50\n",
      "812/812 [==============================] - 0s 90us/sample - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 18/50\n",
      "812/812 [==============================] - 0s 83us/sample - loss: 0.0104 - val_loss: 0.0085\n",
      "Epoch 19/50\n",
      "812/812 [==============================] - 0s 88us/sample - loss: 0.0117 - val_loss: 0.0081\n",
      "Epoch 20/50\n",
      "812/812 [==============================] - 0s 89us/sample - loss: 0.0123 - val_loss: 0.0052\n",
      "Epoch 21/50\n",
      "812/812 [==============================] - 0s 82us/sample - loss: 0.0097 - val_loss: 0.0053\n",
      "Epoch 22/50\n",
      "812/812 [==============================] - 0s 88us/sample - loss: 0.0112 - val_loss: 0.0077\n",
      "Epoch 23/50\n",
      "812/812 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0070\n",
      "Epoch 24/50\n",
      "812/812 [==============================] - 0s 82us/sample - loss: 0.0114 - val_loss: 0.0093\n",
      "Epoch 25/50\n",
      "812/812 [==============================] - 0s 85us/sample - loss: 0.0093 - val_loss: 0.0074\n",
      "Epoch 26/50\n",
      "812/812 [==============================] - 0s 86us/sample - loss: 0.0134 - val_loss: 0.0041\n",
      "Epoch 27/50\n",
      "812/812 [==============================] - 0s 82us/sample - loss: 0.0133 - val_loss: 0.0105\n",
      "Epoch 28/50\n",
      "812/812 [==============================] - 0s 83us/sample - loss: 0.0084 - val_loss: 0.0050\n",
      "Epoch 29/50\n",
      "812/812 [==============================] - 0s 83us/sample - loss: 0.0083 - val_loss: 0.0037\n",
      "Epoch 30/50\n",
      "812/812 [==============================] - 0s 87us/sample - loss: 0.0074 - val_loss: 0.0069\n",
      "Epoch 31/50\n",
      "812/812 [==============================] - 0s 90us/sample - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 32/50\n",
      "812/812 [==============================] - 0s 89us/sample - loss: 0.0111 - val_loss: 0.0158\n",
      "Epoch 33/50\n",
      "812/812 [==============================] - 0s 86us/sample - loss: 0.0138 - val_loss: 0.0055\n",
      "Epoch 34/50\n",
      "812/812 [==============================] - 0s 87us/sample - loss: 0.0104 - val_loss: 0.0039\n",
      "Epoch 35/50\n",
      "812/812 [==============================] - 0s 84us/sample - loss: 0.0087 - val_loss: 0.0071\n",
      "Epoch 36/50\n",
      "812/812 [==============================] - 0s 83us/sample - loss: 0.0110 - val_loss: 0.0047\n",
      "Epoch 37/50\n",
      "812/812 [==============================] - 0s 88us/sample - loss: 0.0133 - val_loss: 0.0152\n",
      "Epoch 38/50\n",
      "812/812 [==============================] - 0s 89us/sample - loss: 0.0102 - val_loss: 0.0071\n",
      "Epoch 39/50\n",
      "812/812 [==============================] - 0s 85us/sample - loss: 0.0107 - val_loss: 0.0039\n",
      "Epoch 40/50\n",
      "812/812 [==============================] - 0s 86us/sample - loss: 0.0084 - val_loss: 0.0047\n",
      "Epoch 41/50\n",
      "812/812 [==============================] - 0s 91us/sample - loss: 0.0085 - val_loss: 0.0035\n",
      "Epoch 42/50\n",
      "812/812 [==============================] - 0s 82us/sample - loss: 0.0109 - val_loss: 0.0049\n",
      "Epoch 43/50\n",
      "812/812 [==============================] - 0s 90us/sample - loss: 0.0141 - val_loss: 0.0133\n",
      "Epoch 44/50\n",
      "812/812 [==============================] - 0s 84us/sample - loss: 0.0092 - val_loss: 0.0066\n",
      "Epoch 45/50\n",
      "812/812 [==============================] - 0s 88us/sample - loss: 0.0091 - val_loss: 0.0087\n",
      "Epoch 46/50\n",
      "812/812 [==============================] - 0s 83us/sample - loss: 0.0093 - val_loss: 0.0039\n",
      "Epoch 47/50\n",
      "812/812 [==============================] - 0s 82us/sample - loss: 0.0094 - val_loss: 0.0107\n",
      "Epoch 48/50\n",
      "812/812 [==============================] - 0s 85us/sample - loss: 0.0192 - val_loss: 0.0219\n",
      "Epoch 49/50\n",
      "812/812 [==============================] - 0s 81us/sample - loss: 0.0084 - val_loss: 0.0055\n",
      "Epoch 50/50\n",
      "812/812 [==============================] - 0s 83us/sample - loss: 0.0071 - val_loss: 0.0048\n",
      "第38个数，还剩4085个没有训练\n",
      "inv_hat [1.19636731 1.19636731 1.19636731 1.19636731 1.19734386 1.19734386\n",
      " 1.19734386 1.19734386 1.19831948 1.19831948 1.19831948 1.19929447\n",
      " 1.19929447 1.19929447 1.19929447 1.19929447 1.19929447 1.19929447\n",
      " 1.19245377 1.19245377 1.19245377 1.19245377 1.19245377 1.19245377\n",
      " 1.19245377 1.19343324 1.19343324 1.19343324 1.19343324 1.19185933]\n",
      "Test RMSE: 0.002\n",
      "Train on 825 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "825/825 [==============================] - 0s 86us/sample - loss: 0.0162 - val_loss: 0.0123\n",
      "Epoch 2/50\n",
      "825/825 [==============================] - 0s 86us/sample - loss: 0.0173 - val_loss: 0.0126\n",
      "Epoch 3/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0154 - val_loss: 0.0140\n",
      "Epoch 4/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0157 - val_loss: 0.0146\n",
      "Epoch 5/50\n",
      "825/825 [==============================] - 0s 79us/sample - loss: 0.0162 - val_loss: 0.0128\n",
      "Epoch 6/50\n",
      "825/825 [==============================] - 0s 78us/sample - loss: 0.0155 - val_loss: 0.0121\n",
      "Epoch 7/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0152 - val_loss: 0.0119\n",
      "Epoch 8/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0119\n",
      "Epoch 9/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0123\n",
      "Epoch 10/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0151 - val_loss: 0.0136\n",
      "Epoch 11/50\n",
      "825/825 [==============================] - 0s 87us/sample - loss: 0.0155 - val_loss: 0.0142\n",
      "Epoch 12/50\n",
      "825/825 [==============================] - 0s 86us/sample - loss: 0.0158 - val_loss: 0.0127\n",
      "Epoch 13/50\n",
      "825/825 [==============================] - 0s 86us/sample - loss: 0.0153 - val_loss: 0.0121\n",
      "Epoch 14/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0152 - val_loss: 0.0119\n",
      "Epoch 15/50\n",
      "825/825 [==============================] - 0s 88us/sample - loss: 0.0152 - val_loss: 0.0120\n",
      "Epoch 16/50\n",
      "825/825 [==============================] - 0s 89us/sample - loss: 0.0151 - val_loss: 0.0123\n",
      "Epoch 17/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0151 - val_loss: 0.0135\n",
      "Epoch 18/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0154 - val_loss: 0.0138\n",
      "Epoch 19/50\n",
      "825/825 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0126\n",
      "Epoch 20/50\n",
      "825/825 [==============================] - 0s 80us/sample - loss: 0.0152 - val_loss: 0.0121\n",
      "Epoch 21/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0152 - val_loss: 0.0119\n",
      "Epoch 22/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0152 - val_loss: 0.0120\n",
      "Epoch 23/50\n",
      "825/825 [==============================] - 0s 86us/sample - loss: 0.0151 - val_loss: 0.0124\n",
      "Epoch 24/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0151 - val_loss: 0.0137\n",
      "Epoch 25/50\n",
      "825/825 [==============================] - 0s 85us/sample - loss: 0.0155 - val_loss: 0.0138\n",
      "Epoch 26/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0156 - val_loss: 0.0126\n",
      "Epoch 27/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0152 - val_loss: 0.0121\n",
      "Epoch 28/50\n",
      "825/825 [==============================] - 0s 81us/sample - loss: 0.0152 - val_loss: 0.0119\n",
      "Epoch 29/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0152 - val_loss: 0.0119\n",
      "Epoch 30/50\n",
      "825/825 [==============================] - 0s 86us/sample - loss: 0.0151 - val_loss: 0.0123\n",
      "Epoch 31/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0151 - val_loss: 0.0135\n",
      "Epoch 32/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0154 - val_loss: 0.0143\n",
      "Epoch 33/50\n",
      "825/825 [==============================] - 0s 81us/sample - loss: 0.0157 - val_loss: 0.0127\n",
      "Epoch 34/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0152 - val_loss: 0.0122\n",
      "Epoch 35/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0152 - val_loss: 0.0119\n",
      "Epoch 36/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0152 - val_loss: 0.0119\n",
      "Epoch 37/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0152 - val_loss: 0.0121\n",
      "Epoch 38/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0151 - val_loss: 0.0136\n",
      "Epoch 39/50\n",
      "825/825 [==============================] - 0s 86us/sample - loss: 0.0155 - val_loss: 0.0147\n",
      "Epoch 40/50\n",
      "825/825 [==============================] - 0s 87us/sample - loss: 0.0160 - val_loss: 0.0132\n",
      "Epoch 41/50\n",
      "825/825 [==============================] - 0s 92us/sample - loss: 0.0153 - val_loss: 0.0122\n",
      "Epoch 42/50\n",
      "825/825 [==============================] - 0s 87us/sample - loss: 0.0152 - val_loss: 0.0119\n",
      "Epoch 43/50\n",
      "825/825 [==============================] - 0s 86us/sample - loss: 0.0153 - val_loss: 0.0119\n",
      "Epoch 44/50\n",
      "825/825 [==============================] - 0s 81us/sample - loss: 0.0152 - val_loss: 0.0122\n",
      "Epoch 45/50\n",
      "825/825 [==============================] - 0s 79us/sample - loss: 0.0151 - val_loss: 0.0136\n",
      "Epoch 46/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0148\n",
      "Epoch 47/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0160 - val_loss: 0.0135\n",
      "Epoch 48/50\n",
      "825/825 [==============================] - 0s 85us/sample - loss: 0.0154 - val_loss: 0.0123\n",
      "Epoch 49/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0119\n",
      "Epoch 50/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0154 - val_loss: 0.0118\n",
      "第39个数，还剩4084个没有训练\n",
      "inv_hat [1.05180363 1.0373375  1.03824152 1.03472585 1.02247399 1.02659084\n",
      " 1.02167077 1.02739422 1.02227315 1.03030663 1.04778501 1.05099992\n",
      " 1.04386711 1.03231538 1.03090927 1.02217286 1.02217286 1.02337768\n",
      " 1.0300054  1.01916093 1.02217286 1.01243587 1.00210214 0.98516315\n",
      " 0.97555207 0.97225037 0.96854988 0.96545065 0.96695017 0.97525188]\n",
      "Test RMSE: 0.008\n",
      "Train on 1193 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0092 - val_loss: 0.0067\n",
      "Epoch 2/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0088 - val_loss: 0.0061\n",
      "Epoch 3/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0090 - val_loss: 0.0067\n",
      "Epoch 4/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0095 - val_loss: 0.0079\n",
      "Epoch 5/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0086 - val_loss: 0.0059\n",
      "Epoch 6/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0088 - val_loss: 0.0064\n",
      "Epoch 7/50\n",
      "1193/1193 [==============================] - 0s 75us/sample - loss: 0.0088 - val_loss: 0.0062\n",
      "Epoch 8/50\n",
      "1193/1193 [==============================] - 0s 75us/sample - loss: 0.0089 - val_loss: 0.0064\n",
      "Epoch 9/50\n",
      "1193/1193 [==============================] - 0s 75us/sample - loss: 0.0094 - val_loss: 0.0077\n",
      "Epoch 10/50\n",
      "1193/1193 [==============================] - 0s 75us/sample - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 11/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0086 - val_loss: 0.0062\n",
      "Epoch 12/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0086 - val_loss: 0.0060\n",
      "Epoch 13/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0087 - val_loss: 0.0063\n",
      "Epoch 14/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0090 - val_loss: 0.0065\n",
      "Epoch 15/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 16/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0085 - val_loss: 0.0059\n",
      "Epoch 17/50\n",
      "1193/1193 [==============================] - 0s 84us/sample - loss: 0.0084 - val_loss: 0.0059\n",
      "Epoch 18/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0086 - val_loss: 0.0060\n",
      "Epoch 19/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 20/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 21/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 22/50\n",
      "1193/1193 [==============================] - 0s 84us/sample - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 23/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0086 - val_loss: 0.0060\n",
      "Epoch 24/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0086 - val_loss: 0.0060\n",
      "Epoch 25/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 26/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0088 - val_loss: 0.0061\n",
      "Epoch 27/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 28/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 29/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0088 - val_loss: 0.0061\n",
      "Epoch 30/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0088 - val_loss: 0.0061\n",
      "Epoch 31/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 32/50\n",
      "1193/1193 [==============================] - 0s 85us/sample - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1193/1193 [==============================] - 0s 85us/sample - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 34/50\n",
      "1193/1193 [==============================] - 0s 84us/sample - loss: 0.0088 - val_loss: 0.0060\n",
      "Epoch 35/50\n",
      "1193/1193 [==============================] - ETA: 0s - loss: 0.010 - 0s 83us/sample - loss: 0.0088 - val_loss: 0.0061\n",
      "Epoch 36/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0088 - val_loss: 0.0061\n",
      "Epoch 37/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0088 - val_loss: 0.0060\n",
      "Epoch 38/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 39/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 40/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 41/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 42/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 43/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 44/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0088 - val_loss: 0.0060\n",
      "Epoch 45/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0089 - val_loss: 0.0061\n",
      "Epoch 46/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0088 - val_loss: 0.0060\n",
      "Epoch 47/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0088 - val_loss: 0.0060\n",
      "Epoch 48/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0089 - val_loss: 0.0061\n",
      "Epoch 49/50\n",
      "1193/1193 [==============================] - 0s 84us/sample - loss: 0.0088 - val_loss: 0.0060\n",
      "Epoch 50/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0088 - val_loss: 0.0060\n",
      "第40个数，还剩4083个没有训练\n",
      "inv_hat [0.82907897 0.77665755 0.78471471 0.78270009 0.72033935 0.71632227\n",
      " 0.72134376 0.74144179 0.70728649 0.72134376 0.76759669 0.77464377\n",
      " 0.76256453 0.73038547 0.73239534 0.71230591 0.72134376 0.72335279\n",
      " 0.74345247 0.70527908 0.70327183 0.69123257 0.6701808  0.67619343\n",
      " 0.66016383 0.67218478 0.6521539  0.64714935 0.63114326 0.63714404]\n",
      "Test RMSE: 0.023\n",
      "Train on 519 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "519/519 [==============================] - 0s 97us/sample - loss: 0.0080 - val_loss: 0.0202\n",
      "Epoch 2/50\n",
      "519/519 [==============================] - 0s 94us/sample - loss: 0.0156 - val_loss: 0.0294\n",
      "Epoch 3/50\n",
      "519/519 [==============================] - 0s 94us/sample - loss: 0.0245 - val_loss: 0.0182\n",
      "Epoch 4/50\n",
      "519/519 [==============================] - 0s 94us/sample - loss: 0.0098 - val_loss: 0.0229\n",
      "Epoch 5/50\n",
      "519/519 [==============================] - 0s 96us/sample - loss: 0.0066 - val_loss: 0.0187\n",
      "Epoch 6/50\n",
      "519/519 [==============================] - 0s 98us/sample - loss: 0.0070 - val_loss: 0.0243\n",
      "Epoch 7/50\n",
      "519/519 [==============================] - 0s 97us/sample - loss: 0.0170 - val_loss: 0.0265\n",
      "Epoch 8/50\n",
      "519/519 [==============================] - 0s 94us/sample - loss: 0.0099 - val_loss: 0.0216\n",
      "Epoch 9/50\n",
      "519/519 [==============================] - 0s 93us/sample - loss: 0.0117 - val_loss: 0.0231\n",
      "Epoch 10/50\n",
      "519/519 [==============================] - 0s 89us/sample - loss: 0.0148 - val_loss: 0.0271\n",
      "Epoch 11/50\n",
      "519/519 [==============================] - 0s 87us/sample - loss: 0.0071 - val_loss: 0.0193\n",
      "Epoch 12/50\n",
      "519/519 [==============================] - 0s 94us/sample - loss: 0.0099 - val_loss: 0.0200\n",
      "Epoch 13/50\n",
      "519/519 [==============================] - 0s 96us/sample - loss: 0.0165 - val_loss: 0.0258\n",
      "Epoch 14/50\n",
      "519/519 [==============================] - 0s 86us/sample - loss: 0.0131 - val_loss: 0.0192\n",
      "Epoch 15/50\n",
      "519/519 [==============================] - 0s 89us/sample - loss: 0.0071 - val_loss: 0.0188\n",
      "Epoch 16/50\n",
      "519/519 [==============================] - 0s 96us/sample - loss: 0.0106 - val_loss: 0.0262\n",
      "Epoch 17/50\n",
      "519/519 [==============================] - 0s 96us/sample - loss: 0.0142 - val_loss: 0.0195\n",
      "Epoch 18/50\n",
      "519/519 [==============================] - 0s 93us/sample - loss: 0.0061 - val_loss: 0.0194\n",
      "Epoch 19/50\n",
      "519/519 [==============================] - 0s 91us/sample - loss: 0.0102 - val_loss: 0.0205\n",
      "Epoch 20/50\n",
      "519/519 [==============================] - 0s 93us/sample - loss: 0.0097 - val_loss: 0.0190\n",
      "Epoch 21/50\n",
      "519/519 [==============================] - 0s 91us/sample - loss: 0.0150 - val_loss: 0.0211\n",
      "Epoch 22/50\n",
      "519/519 [==============================] - 0s 88us/sample - loss: 0.0079 - val_loss: 0.0183\n",
      "Epoch 23/50\n",
      "519/519 [==============================] - 0s 90us/sample - loss: 0.0071 - val_loss: 0.0228\n",
      "Epoch 24/50\n",
      "519/519 [==============================] - 0s 87us/sample - loss: 0.0138 - val_loss: 0.0196\n",
      "Epoch 25/50\n",
      "519/519 [==============================] - 0s 86us/sample - loss: 0.0076 - val_loss: 0.0190\n",
      "Epoch 26/50\n",
      "519/519 [==============================] - 0s 87us/sample - loss: 0.0111 - val_loss: 0.0243\n",
      "Epoch 27/50\n",
      "519/519 [==============================] - 0s 92us/sample - loss: 0.0121 - val_loss: 0.0192\n",
      "Epoch 28/50\n",
      "519/519 [==============================] - 0s 89us/sample - loss: 0.0060 - val_loss: 0.0193\n",
      "Epoch 29/50\n",
      "519/519 [==============================] - 0s 92us/sample - loss: 0.0096 - val_loss: 0.0193\n",
      "Epoch 30/50\n",
      "519/519 [==============================] - 0s 91us/sample - loss: 0.0096 - val_loss: 0.0177\n",
      "Epoch 31/50\n",
      "519/519 [==============================] - 0s 91us/sample - loss: 0.0115 - val_loss: 0.0193\n",
      "Epoch 32/50\n",
      "519/519 [==============================] - 0s 93us/sample - loss: 0.0082 - val_loss: 0.0191\n",
      "Epoch 33/50\n",
      "519/519 [==============================] - 0s 89us/sample - loss: 0.0100 - val_loss: 0.0233\n",
      "Epoch 34/50\n",
      "519/519 [==============================] - 0s 91us/sample - loss: 0.0115 - val_loss: 0.0205\n",
      "Epoch 35/50\n",
      "519/519 [==============================] - 0s 88us/sample - loss: 0.0064 - val_loss: 0.0192\n",
      "Epoch 36/50\n",
      "519/519 [==============================] - 0s 86us/sample - loss: 0.0085 - val_loss: 0.0190\n",
      "Epoch 37/50\n",
      "519/519 [==============================] - 0s 87us/sample - loss: 0.0098 - val_loss: 0.0179\n",
      "Epoch 38/50\n",
      "519/519 [==============================] - 0s 90us/sample - loss: 0.0089 - val_loss: 0.0190\n",
      "Epoch 39/50\n",
      "519/519 [==============================] - 0s 85us/sample - loss: 0.0090 - val_loss: 0.0200\n",
      "Epoch 40/50\n",
      "519/519 [==============================] - 0s 84us/sample - loss: 0.0104 - val_loss: 0.0226\n",
      "Epoch 41/50\n",
      "519/519 [==============================] - 0s 83us/sample - loss: 0.0096 - val_loss: 0.0186\n",
      "Epoch 42/50\n",
      "519/519 [==============================] - 0s 89us/sample - loss: 0.0062 - val_loss: 0.0199\n",
      "Epoch 43/50\n",
      "519/519 [==============================] - 0s 89us/sample - loss: 0.0099 - val_loss: 0.0198\n",
      "Epoch 44/50\n",
      "519/519 [==============================] - 0s 90us/sample - loss: 0.0083 - val_loss: 0.0177\n",
      "Epoch 45/50\n",
      "519/519 [==============================] - 0s 92us/sample - loss: 0.0094 - val_loss: 0.0191\n",
      "Epoch 46/50\n",
      "519/519 [==============================] - 0s 91us/sample - loss: 0.0090 - val_loss: 0.0207\n",
      "Epoch 47/50\n",
      "519/519 [==============================] - 0s 91us/sample - loss: 0.0077 - val_loss: 0.0212\n",
      "Epoch 48/50\n",
      "519/519 [==============================] - 0s 90us/sample - loss: 0.0099 - val_loss: 0.0186\n",
      "Epoch 49/50\n",
      "519/519 [==============================] - 0s 90us/sample - loss: 0.0062 - val_loss: 0.0193\n",
      "Epoch 50/50\n",
      "519/519 [==============================] - 0s 90us/sample - loss: 0.0099 - val_loss: 0.0233\n",
      "第41个数，还剩4082个没有训练\n",
      "inv_hat [1.05675835 1.0562585  1.0560584  1.05615846 1.05615846 1.0562585\n",
      " 1.0560584  1.05595834 1.05635852 1.05665838 1.05715793 1.05745755\n",
      " 1.05795647 1.05805621 1.05805621 1.05795647 1.05795647 1.05820405\n",
      " 1.05795647 1.0578568  1.05805621 1.05755739 1.05725781 1.02647419\n",
      " 1.02732107 1.02718553 1.02728718 1.02738872 1.02759206 1.02993113]\n",
      "Test RMSE: 0.006\n",
      "Train on 845 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "845/845 [==============================] - 0s 84us/sample - loss: 0.0054 - val_loss: 0.0273\n",
      "Epoch 2/50\n",
      "845/845 [==============================] - 0s 80us/sample - loss: 0.0051 - val_loss: 0.0259\n",
      "Epoch 3/50\n",
      "845/845 [==============================] - 0s 81us/sample - loss: 0.0044 - val_loss: 0.0236\n",
      "Epoch 4/50\n",
      "845/845 [==============================] - 0s 77us/sample - loss: 0.0042 - val_loss: 0.0247\n",
      "Epoch 5/50\n",
      "845/845 [==============================] - 0s 78us/sample - loss: 0.0041 - val_loss: 0.0231\n",
      "Epoch 6/50\n",
      "845/845 [==============================] - 0s 78us/sample - loss: 0.0040 - val_loss: 0.0234\n",
      "Epoch 7/50\n",
      "845/845 [==============================] - 0s 78us/sample - loss: 0.0039 - val_loss: 0.0233\n",
      "Epoch 8/50\n",
      "845/845 [==============================] - 0s 77us/sample - loss: 0.0039 - val_loss: 0.0234\n",
      "Epoch 9/50\n",
      "845/845 [==============================] - 0s 76us/sample - loss: 0.0038 - val_loss: 0.0232\n",
      "Epoch 10/50\n",
      "845/845 [==============================] - 0s 77us/sample - loss: 0.0038 - val_loss: 0.0229\n",
      "Epoch 11/50\n",
      "845/845 [==============================] - 0s 86us/sample - loss: 0.0039 - val_loss: 0.0234\n",
      "Epoch 12/50\n",
      "845/845 [==============================] - 0s 84us/sample - loss: 0.0038 - val_loss: 0.0229\n",
      "Epoch 13/50\n",
      "845/845 [==============================] - 0s 83us/sample - loss: 0.0038 - val_loss: 0.0227\n",
      "Epoch 14/50\n",
      "845/845 [==============================] - 0s 80us/sample - loss: 0.0039 - val_loss: 0.0230\n",
      "Epoch 15/50\n",
      "845/845 [==============================] - 0s 78us/sample - loss: 0.0038 - val_loss: 0.0230\n",
      "Epoch 16/50\n",
      "845/845 [==============================] - 0s 81us/sample - loss: 0.0038 - val_loss: 0.0229\n",
      "Epoch 17/50\n",
      "845/845 [==============================] - 0s 84us/sample - loss: 0.0040 - val_loss: 0.0225\n",
      "Epoch 18/50\n",
      "845/845 [==============================] - 0s 79us/sample - loss: 0.0038 - val_loss: 0.0229\n",
      "Epoch 19/50\n",
      "845/845 [==============================] - 0s 77us/sample - loss: 0.0040 - val_loss: 0.0226\n",
      "Epoch 20/50\n",
      "845/845 [==============================] - 0s 79us/sample - loss: 0.0037 - val_loss: 0.0229\n",
      "Epoch 21/50\n",
      "845/845 [==============================] - 0s 80us/sample - loss: 0.0040 - val_loss: 0.0226\n",
      "Epoch 22/50\n",
      "845/845 [==============================] - 0s 77us/sample - loss: 0.0038 - val_loss: 0.0232\n",
      "Epoch 23/50\n",
      "845/845 [==============================] - 0s 77us/sample - loss: 0.0040 - val_loss: 0.0224\n",
      "Epoch 24/50\n",
      "845/845 [==============================] - 0s 78us/sample - loss: 0.0038 - val_loss: 0.0229\n",
      "Epoch 25/50\n",
      "845/845 [==============================] - 0s 80us/sample - loss: 0.0042 - val_loss: 0.0221\n",
      "Epoch 26/50\n",
      "845/845 [==============================] - 0s 79us/sample - loss: 0.0038 - val_loss: 0.0232\n",
      "Epoch 27/50\n",
      "845/845 [==============================] - 0s 79us/sample - loss: 0.0040 - val_loss: 0.0219\n",
      "Epoch 28/50\n",
      "845/845 [==============================] - 0s 79us/sample - loss: 0.0038 - val_loss: 0.0229\n",
      "Epoch 29/50\n",
      "845/845 [==============================] - 0s 76us/sample - loss: 0.0041 - val_loss: 0.0221\n",
      "Epoch 30/50\n",
      "845/845 [==============================] - 0s 79us/sample - loss: 0.0038 - val_loss: 0.0231\n",
      "Epoch 31/50\n",
      "845/845 [==============================] - 0s 78us/sample - loss: 0.0041 - val_loss: 0.0219\n",
      "Epoch 32/50\n",
      "845/845 [==============================] - 0s 76us/sample - loss: 0.0038 - val_loss: 0.0230\n",
      "Epoch 33/50\n",
      "845/845 [==============================] - 0s 79us/sample - loss: 0.0040 - val_loss: 0.0223\n",
      "Epoch 34/50\n",
      "845/845 [==============================] - 0s 79us/sample - loss: 0.0038 - val_loss: 0.0230\n",
      "Epoch 35/50\n",
      "845/845 [==============================] - 0s 81us/sample - loss: 0.0038 - val_loss: 0.0227\n",
      "Epoch 36/50\n",
      "845/845 [==============================] - 0s 82us/sample - loss: 0.0038 - val_loss: 0.0228\n",
      "Epoch 37/50\n",
      "845/845 [==============================] - 0s 80us/sample - loss: 0.0038 - val_loss: 0.0228\n",
      "Epoch 38/50\n",
      "845/845 [==============================] - 0s 77us/sample - loss: 0.0038 - val_loss: 0.0228\n",
      "Epoch 39/50\n",
      "845/845 [==============================] - 0s 80us/sample - loss: 0.0038 - val_loss: 0.0228\n",
      "Epoch 40/50\n",
      "845/845 [==============================] - 0s 80us/sample - loss: 0.0038 - val_loss: 0.0228\n",
      "Epoch 41/50\n",
      "845/845 [==============================] - 0s 79us/sample - loss: 0.0037 - val_loss: 0.0230\n",
      "Epoch 42/50\n",
      "845/845 [==============================] - 0s 81us/sample - loss: 0.0038 - val_loss: 0.0226\n",
      "Epoch 43/50\n",
      "845/845 [==============================] - 0s 80us/sample - loss: 0.0038 - val_loss: 0.0230\n",
      "Epoch 44/50\n",
      "845/845 [==============================] - 0s 80us/sample - loss: 0.0038 - val_loss: 0.0221\n",
      "Epoch 45/50\n",
      "845/845 [==============================] - 0s 79us/sample - loss: 0.0039 - val_loss: 0.0227\n",
      "Epoch 46/50\n",
      "845/845 [==============================] - 0s 82us/sample - loss: 0.0038 - val_loss: 0.0229\n",
      "Epoch 47/50\n",
      "845/845 [==============================] - 0s 83us/sample - loss: 0.0037 - val_loss: 0.0227\n",
      "Epoch 48/50\n",
      "845/845 [==============================] - 0s 78us/sample - loss: 0.0039 - val_loss: 0.0229\n",
      "Epoch 49/50\n",
      "845/845 [==============================] - 0s 77us/sample - loss: 0.0037 - val_loss: 0.0223\n",
      "Epoch 50/50\n",
      "845/845 [==============================] - 0s 78us/sample - loss: 0.0039 - val_loss: 0.0230\n",
      "第42个数，还剩4081个没有训练\n",
      "inv_hat [1.04865712 1.04875738 1.04885776 1.04905847 1.04915884 1.04956006\n",
      " 1.0497607  1.04986101 1.04996131 1.05016189 1.00042924 1.00052593\n",
      " 1.00071935 1.00081599 1.00091275 1.00139691 1.00149369 1.00159061\n",
      " 1.0017845  1.00188148 1.00226949 1.00246368 1.0025608  1.00265794\n",
      " 1.00285229 1.00324112 1.0033384  1.00353303 1.00363026 1.00372763]\n",
      "Test RMSE: 0.009\n",
      "Train on 700 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.0195 - val_loss: 0.0251\n",
      "Epoch 2/50\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.0191 - val_loss: 0.0175\n",
      "Epoch 3/50\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.0182 - val_loss: 0.0191\n",
      "Epoch 4/50\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 0.0184 - val_loss: 0.0172\n",
      "Epoch 5/50\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.0181 - val_loss: 0.0164\n",
      "Epoch 6/50\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.0183 - val_loss: 0.0166\n",
      "Epoch 7/50\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.0182 - val_loss: 0.0156\n",
      "Epoch 8/50\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 0.0182 - val_loss: 0.0159\n",
      "Epoch 9/50\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.0182 - val_loss: 0.0168\n",
      "Epoch 10/50\n",
      "700/700 [==============================] - 0s 78us/sample - loss: 0.0183 - val_loss: 0.0172\n",
      "Epoch 11/50\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.0182 - val_loss: 0.0165\n",
      "Epoch 12/50\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 0.0181 - val_loss: 0.0165\n",
      "Epoch 13/50\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 0.0182 - val_loss: 0.0165\n",
      "Epoch 14/50\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 0.0182 - val_loss: 0.0165\n",
      "Epoch 15/50\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 0.0181 - val_loss: 0.0162\n",
      "Epoch 16/50\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 0.0182 - val_loss: 0.0165\n",
      "Epoch 17/50\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.0182 - val_loss: 0.0169\n",
      "Epoch 18/50\n",
      "700/700 [==============================] - 0s 86us/sample - loss: 0.0181 - val_loss: 0.0162\n",
      "Epoch 19/50\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 0.0181 - val_loss: 0.0164\n",
      "Epoch 20/50\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.0182 - val_loss: 0.0166\n",
      "Epoch 21/50\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 0.0182 - val_loss: 0.0166\n",
      "Epoch 22/50\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 0.0182 - val_loss: 0.0165\n",
      "Epoch 23/50\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.0181 - val_loss: 0.0163\n",
      "Epoch 24/50\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 0.0182 - val_loss: 0.0168\n",
      "Epoch 25/50\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 0.0182 - val_loss: 0.0165\n",
      "Epoch 26/50\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.0181 - val_loss: 0.0161\n",
      "Epoch 27/50\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.0182 - val_loss: 0.0166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 0.0181 - val_loss: 0.0163\n",
      "Epoch 29/50\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 0.0181 - val_loss: 0.0163\n",
      "Epoch 30/50\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.0181 - val_loss: 0.0166\n",
      "Epoch 31/50\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.0182 - val_loss: 0.0166\n",
      "Epoch 32/50\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 0.0181 - val_loss: 0.0160\n",
      "Epoch 33/50\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 0.0181 - val_loss: 0.0156\n",
      "Epoch 34/50\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.0182 - val_loss: 0.0167\n",
      "Epoch 35/50\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 0.0182 - val_loss: 0.0170\n",
      "Epoch 36/50\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 0.0181 - val_loss: 0.0163\n",
      "Epoch 37/50\n",
      "700/700 [==============================] - 0s 85us/sample - loss: 0.0181 - val_loss: 0.0164\n",
      "Epoch 38/50\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.0182 - val_loss: 0.0165\n",
      "Epoch 39/50\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.0181 - val_loss: 0.0163\n",
      "Epoch 40/50\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 0.0181 - val_loss: 0.0164\n",
      "Epoch 41/50\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 0.0182 - val_loss: 0.0167\n",
      "Epoch 42/50\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 0.0181 - val_loss: 0.0159\n",
      "Epoch 43/50\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 0.0181 - val_loss: 0.0155\n",
      "Epoch 44/50\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 0.0181 - val_loss: 0.0163\n",
      "Epoch 45/50\n",
      "700/700 [==============================] - 0s 82us/sample - loss: 0.0182 - val_loss: 0.0174\n",
      "Epoch 46/50\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 0.0182 - val_loss: 0.0166\n",
      "Epoch 47/50\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 0.0181 - val_loss: 0.0161\n",
      "Epoch 48/50\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 0.0181 - val_loss: 0.0160\n",
      "Epoch 49/50\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 0.0181 - val_loss: 0.0159\n",
      "Epoch 50/50\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 0.0181 - val_loss: 0.0162\n",
      "第43个数，还剩4080个没有训练\n",
      "inv_hat [0.75330756 0.72984019 0.7269173  0.72497001 0.70072393 0.69686145\n",
      " 0.70265693 0.71427978 0.69879206 0.7084631  0.73960044 0.73569324\n",
      " 0.73374114 0.71040086 0.71525022 0.71040086 0.71330963 0.70749468\n",
      " 0.71330963 0.69493201 0.68818874 0.68626512 0.67762513 0.67954287\n",
      " 0.6747509  0.68338224 0.68530381 0.67954287 0.67570864 0.67187963]\n",
      "Test RMSE: 0.013\n",
      "Train on 485 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "485/485 [==============================] - 0s 80us/sample - loss: 0.0112 - val_loss: 0.0536\n",
      "Epoch 2/50\n",
      "485/485 [==============================] - 0s 81us/sample - loss: 0.0116 - val_loss: 0.0542\n",
      "Epoch 3/50\n",
      "485/485 [==============================] - 0s 82us/sample - loss: 0.0117 - val_loss: 0.0557\n",
      "Epoch 4/50\n",
      "485/485 [==============================] - 0s 82us/sample - loss: 0.0127 - val_loss: 0.0538\n",
      "Epoch 5/50\n",
      "485/485 [==============================] - 0s 82us/sample - loss: 0.0109 - val_loss: 0.0537\n",
      "Epoch 6/50\n",
      "485/485 [==============================] - 0s 86us/sample - loss: 0.0110 - val_loss: 0.0539\n",
      "Epoch 7/50\n",
      "485/485 [==============================] - 0s 83us/sample - loss: 0.0114 - val_loss: 0.0550\n",
      "Epoch 8/50\n",
      "485/485 [==============================] - 0s 87us/sample - loss: 0.0123 - val_loss: 0.0542\n",
      "Epoch 9/50\n",
      "485/485 [==============================] - 0s 83us/sample - loss: 0.0114 - val_loss: 0.0554\n",
      "Epoch 10/50\n",
      "485/485 [==============================] - 0s 82us/sample - loss: 0.0125 - val_loss: 0.0537\n",
      "Epoch 11/50\n",
      "485/485 [==============================] - 0s 85us/sample - loss: 0.0126 - val_loss: 0.0547\n",
      "Epoch 12/50\n",
      "485/485 [==============================] - 0s 84us/sample - loss: 0.0117 - val_loss: 0.0550\n",
      "Epoch 13/50\n",
      "485/485 [==============================] - 0s 89us/sample - loss: 0.0113 - val_loss: 0.0541\n",
      "Epoch 14/50\n",
      "485/485 [==============================] - 0s 89us/sample - loss: 0.0120 - val_loss: 0.0540\n",
      "Epoch 15/50\n",
      "485/485 [==============================] - 0s 84us/sample - loss: 0.0114 - val_loss: 0.0539\n",
      "Epoch 16/50\n",
      "485/485 [==============================] - 0s 84us/sample - loss: 0.0108 - val_loss: 0.0539\n",
      "Epoch 17/50\n",
      "485/485 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0561\n",
      "Epoch 18/50\n",
      "485/485 [==============================] - 0s 80us/sample - loss: 0.0141 - val_loss: 0.0545\n",
      "Epoch 19/50\n",
      "485/485 [==============================] - 0s 78us/sample - loss: 0.0148 - val_loss: 0.0597\n",
      "Epoch 20/50\n",
      "485/485 [==============================] - 0s 79us/sample - loss: 0.0149 - val_loss: 0.0543\n",
      "Epoch 21/50\n",
      "485/485 [==============================] - 0s 79us/sample - loss: 0.0157 - val_loss: 0.0593\n",
      "Epoch 22/50\n",
      "485/485 [==============================] - 0s 79us/sample - loss: 0.0149 - val_loss: 0.0545\n",
      "Epoch 23/50\n",
      "485/485 [==============================] - 0s 80us/sample - loss: 0.0164 - val_loss: 0.0579\n",
      "Epoch 24/50\n",
      "485/485 [==============================] - 0s 81us/sample - loss: 0.0137 - val_loss: 0.0542\n",
      "Epoch 25/50\n",
      "485/485 [==============================] - 0s 84us/sample - loss: 0.0159 - val_loss: 0.0583\n",
      "Epoch 26/50\n",
      "485/485 [==============================] - 0s 78us/sample - loss: 0.0139 - val_loss: 0.0543\n",
      "Epoch 27/50\n",
      "485/485 [==============================] - 0s 79us/sample - loss: 0.0159 - val_loss: 0.0583\n",
      "Epoch 28/50\n",
      "485/485 [==============================] - 0s 79us/sample - loss: 0.0139 - val_loss: 0.0543\n",
      "Epoch 29/50\n",
      "485/485 [==============================] - 0s 82us/sample - loss: 0.0160 - val_loss: 0.0580\n",
      "Epoch 30/50\n",
      "485/485 [==============================] - 0s 82us/sample - loss: 0.0137 - val_loss: 0.0542\n",
      "Epoch 31/50\n",
      "485/485 [==============================] - 0s 80us/sample - loss: 0.0157 - val_loss: 0.0581\n",
      "Epoch 32/50\n",
      "485/485 [==============================] - 0s 80us/sample - loss: 0.0138 - val_loss: 0.0543\n",
      "Epoch 33/50\n",
      "485/485 [==============================] - 0s 85us/sample - loss: 0.0158 - val_loss: 0.0580\n",
      "Epoch 34/50\n",
      "485/485 [==============================] - 0s 85us/sample - loss: 0.0137 - val_loss: 0.0543\n",
      "Epoch 35/50\n",
      "485/485 [==============================] - 0s 86us/sample - loss: 0.0157 - val_loss: 0.0579\n",
      "Epoch 36/50\n",
      "485/485 [==============================] - 0s 91us/sample - loss: 0.0136 - val_loss: 0.0542\n",
      "Epoch 37/50\n",
      "485/485 [==============================] - 0s 93us/sample - loss: 0.0155 - val_loss: 0.0578\n",
      "Epoch 38/50\n",
      "485/485 [==============================] - 0s 85us/sample - loss: 0.0135 - val_loss: 0.0542\n",
      "Epoch 39/50\n",
      "485/485 [==============================] - 0s 85us/sample - loss: 0.0154 - val_loss: 0.0579\n",
      "Epoch 40/50\n",
      "485/485 [==============================] - 0s 85us/sample - loss: 0.0136 - val_loss: 0.0543\n",
      "Epoch 41/50\n",
      "485/485 [==============================] - 0s 82us/sample - loss: 0.0155 - val_loss: 0.0578\n",
      "Epoch 42/50\n",
      "485/485 [==============================] - 0s 84us/sample - loss: 0.0136 - val_loss: 0.0542\n",
      "Epoch 43/50\n",
      "485/485 [==============================] - 0s 85us/sample - loss: 0.0154 - val_loss: 0.0576\n",
      "Epoch 44/50\n",
      "485/485 [==============================] - 0s 83us/sample - loss: 0.0133 - val_loss: 0.0542\n",
      "Epoch 45/50\n",
      "485/485 [==============================] - 0s 86us/sample - loss: 0.0153 - val_loss: 0.0577\n",
      "Epoch 46/50\n",
      "485/485 [==============================] - 0s 88us/sample - loss: 0.0134 - val_loss: 0.0542\n",
      "Epoch 47/50\n",
      "485/485 [==============================] - 0s 88us/sample - loss: 0.0154 - val_loss: 0.0577\n",
      "Epoch 48/50\n",
      "485/485 [==============================] - 0s 83us/sample - loss: 0.0134 - val_loss: 0.0542\n",
      "Epoch 49/50\n",
      "485/485 [==============================] - 0s 85us/sample - loss: 0.0153 - val_loss: 0.0575\n",
      "Epoch 50/50\n",
      "485/485 [==============================] - 0s 83us/sample - loss: 0.0132 - val_loss: 0.0542\n",
      "第44个数，还剩4079个没有训练\n",
      "inv_hat [1.03305863 1.027335   1.03285782 1.03235549 1.03285782 1.03597214\n",
      " 1.03597214 1.03677599 1.04280496 1.04350826 1.03838373 1.03456555\n",
      " 1.0447138  1.04421153 1.0026487  1.01331116 1.02472623 1.02763616\n",
      " 1.02984481 1.04119727 1.03165239 1.03546981 1.03999152 1.03436457\n",
      " 1.02773655 1.02442527 1.07145303 1.07115404 1.11450924 1.11441314]\n",
      "Test RMSE: 0.015\n",
      "Train on 473 samples, validate on 30 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473/473 [==============================] - 0s 88us/sample - loss: 0.0196 - val_loss: 0.0191\n",
      "Epoch 2/50\n",
      "473/473 [==============================] - 0s 87us/sample - loss: 0.0177 - val_loss: 0.0169\n",
      "Epoch 3/50\n",
      "473/473 [==============================] - 0s 89us/sample - loss: 0.0193 - val_loss: 0.0184\n",
      "Epoch 4/50\n",
      "473/473 [==============================] - 0s 87us/sample - loss: 0.0180 - val_loss: 0.0179\n",
      "Epoch 5/50\n",
      "473/473 [==============================] - 0s 88us/sample - loss: 0.0194 - val_loss: 0.0186\n",
      "Epoch 6/50\n",
      "473/473 [==============================] - 0s 84us/sample - loss: 0.0184 - val_loss: 0.0185\n",
      "Epoch 7/50\n",
      "473/473 [==============================] - 0s 83us/sample - loss: 0.0203 - val_loss: 0.0190\n",
      "Epoch 8/50\n",
      "473/473 [==============================] - 0s 86us/sample - loss: 0.0182 - val_loss: 0.0177\n",
      "Epoch 9/50\n",
      "473/473 [==============================] - 0s 83us/sample - loss: 0.0201 - val_loss: 0.0189\n",
      "Epoch 10/50\n",
      "473/473 [==============================] - 0s 84us/sample - loss: 0.0180 - val_loss: 0.0177\n",
      "Epoch 11/50\n",
      "473/473 [==============================] - 0s 88us/sample - loss: 0.0200 - val_loss: 0.0190\n",
      "Epoch 12/50\n",
      "473/473 [==============================] - 0s 86us/sample - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 13/50\n",
      "473/473 [==============================] - 0s 93us/sample - loss: 0.0202 - val_loss: 0.0189\n",
      "Epoch 14/50\n",
      "473/473 [==============================] - 0s 94us/sample - loss: 0.0181 - val_loss: 0.0178\n",
      "Epoch 15/50\n",
      "473/473 [==============================] - 0s 91us/sample - loss: 0.0200 - val_loss: 0.0187\n",
      "Epoch 16/50\n",
      "473/473 [==============================] - 0s 93us/sample - loss: 0.0180 - val_loss: 0.0179\n",
      "Epoch 17/50\n",
      "473/473 [==============================] - 0s 90us/sample - loss: 0.0201 - val_loss: 0.0190\n",
      "Epoch 18/50\n",
      "473/473 [==============================] - 0s 95us/sample - loss: 0.0181 - val_loss: 0.0178\n",
      "Epoch 19/50\n",
      "473/473 [==============================] - 0s 89us/sample - loss: 0.0200 - val_loss: 0.0186\n",
      "Epoch 20/50\n",
      "473/473 [==============================] - 0s 87us/sample - loss: 0.0179 - val_loss: 0.0176\n",
      "Epoch 21/50\n",
      "473/473 [==============================] - 0s 89us/sample - loss: 0.0198 - val_loss: 0.0188\n",
      "Epoch 22/50\n",
      "473/473 [==============================] - 0s 94us/sample - loss: 0.0180 - val_loss: 0.0179\n",
      "Epoch 23/50\n",
      "473/473 [==============================] - 0s 89us/sample - loss: 0.0201 - val_loss: 0.0188\n",
      "Epoch 24/50\n",
      "473/473 [==============================] - 0s 89us/sample - loss: 0.0181 - val_loss: 0.0179\n",
      "Epoch 25/50\n",
      "473/473 [==============================] - 0s 85us/sample - loss: 0.0199 - val_loss: 0.0184\n",
      "Epoch 26/50\n",
      "473/473 [==============================] - 0s 89us/sample - loss: 0.0179 - val_loss: 0.0176\n",
      "Epoch 27/50\n",
      "473/473 [==============================] - 0s 82us/sample - loss: 0.0197 - val_loss: 0.0186\n",
      "Epoch 28/50\n",
      "473/473 [==============================] - 0s 91us/sample - loss: 0.0179 - val_loss: 0.0178\n",
      "Epoch 29/50\n",
      "473/473 [==============================] - 0s 90us/sample - loss: 0.0199 - val_loss: 0.0187\n",
      "Epoch 30/50\n",
      "473/473 [==============================] - 0s 92us/sample - loss: 0.0180 - val_loss: 0.0177\n",
      "Epoch 31/50\n",
      "473/473 [==============================] - 0s 87us/sample - loss: 0.0200 - val_loss: 0.0187\n",
      "Epoch 32/50\n",
      "473/473 [==============================] - 0s 85us/sample - loss: 0.0179 - val_loss: 0.0174\n",
      "Epoch 33/50\n",
      "473/473 [==============================] - 0s 91us/sample - loss: 0.0196 - val_loss: 0.0186\n",
      "Epoch 34/50\n",
      "473/473 [==============================] - 0s 91us/sample - loss: 0.0178 - val_loss: 0.0175\n",
      "Epoch 35/50\n",
      "473/473 [==============================] - 0s 91us/sample - loss: 0.0196 - val_loss: 0.0186\n",
      "Epoch 36/50\n",
      "473/473 [==============================] - 0s 86us/sample - loss: 0.0179 - val_loss: 0.0177\n",
      "Epoch 37/50\n",
      "473/473 [==============================] - 0s 85us/sample - loss: 0.0198 - val_loss: 0.0187\n",
      "Epoch 38/50\n",
      "473/473 [==============================] - 0s 86us/sample - loss: 0.0179 - val_loss: 0.0178\n",
      "Epoch 39/50\n",
      "473/473 [==============================] - 0s 95us/sample - loss: 0.0199 - val_loss: 0.0187\n",
      "Epoch 40/50\n",
      "473/473 [==============================] - 0s 91us/sample - loss: 0.0179 - val_loss: 0.0175\n",
      "Epoch 41/50\n",
      "473/473 [==============================] - 0s 84us/sample - loss: 0.0197 - val_loss: 0.0186\n",
      "Epoch 42/50\n",
      "473/473 [==============================] - 0s 91us/sample - loss: 0.0179 - val_loss: 0.0176\n",
      "Epoch 43/50\n",
      "473/473 [==============================] - 0s 85us/sample - loss: 0.0197 - val_loss: 0.0186\n",
      "Epoch 44/50\n",
      "473/473 [==============================] - 0s 93us/sample - loss: 0.0179 - val_loss: 0.0176\n",
      "Epoch 45/50\n",
      "473/473 [==============================] - 0s 93us/sample - loss: 0.0198 - val_loss: 0.0186\n",
      "Epoch 46/50\n",
      "473/473 [==============================] - 0s 84us/sample - loss: 0.0179 - val_loss: 0.0176\n",
      "Epoch 47/50\n",
      "473/473 [==============================] - 0s 81us/sample - loss: 0.0198 - val_loss: 0.0186\n",
      "Epoch 48/50\n",
      "473/473 [==============================] - 0s 84us/sample - loss: 0.0179 - val_loss: 0.0176\n",
      "Epoch 49/50\n",
      "473/473 [==============================] - 0s 89us/sample - loss: 0.0198 - val_loss: 0.0186\n",
      "Epoch 50/50\n",
      "473/473 [==============================] - 0s 86us/sample - loss: 0.0178 - val_loss: 0.0175\n",
      "第45个数，还剩4078个没有训练\n",
      "inv_hat [1.02796807 1.02796807 1.0283668  1.02746907 1.02726926 1.02686934\n",
      " 1.02706935 1.02756882 1.02826713 1.02846645 1.02896416 1.03025512\n",
      " 1.03124453 1.03144207 1.03134332 1.03242761 1.03252587 1.03252587\n",
      " 1.03055223 1.0298584  1.02866566 1.02906365 1.03025512 1.03154079\n",
      " 1.03124453 1.03094809 1.03163948 1.0323292  1.03331143 1.0352646 ]\n",
      "Test RMSE: 0.001\n",
      "Train on 840 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "840/840 [==============================] - 0s 81us/sample - loss: 0.0162 - val_loss: 0.0086\n",
      "Epoch 2/50\n",
      "840/840 [==============================] - 0s 80us/sample - loss: 0.0148 - val_loss: 0.0095\n",
      "Epoch 3/50\n",
      "840/840 [==============================] - 0s 80us/sample - loss: 0.0143 - val_loss: 0.0103\n",
      "Epoch 4/50\n",
      "840/840 [==============================] - 0s 84us/sample - loss: 0.0142 - val_loss: 0.0087\n",
      "Epoch 5/50\n",
      "840/840 [==============================] - 0s 85us/sample - loss: 0.0142 - val_loss: 0.0093\n",
      "Epoch 6/50\n",
      "840/840 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0093\n",
      "Epoch 7/50\n",
      "840/840 [==============================] - 0s 81us/sample - loss: 0.0141 - val_loss: 0.0090\n",
      "Epoch 8/50\n",
      "840/840 [==============================] - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0094\n",
      "Epoch 9/50\n",
      "840/840 [==============================] - 0s 82us/sample - loss: 0.0141 - val_loss: 0.0091\n",
      "Epoch 10/50\n",
      "840/840 [==============================] - 0s 84us/sample - loss: 0.0141 - val_loss: 0.0090\n",
      "Epoch 11/50\n",
      "840/840 [==============================] - 0s 84us/sample - loss: 0.0142 - val_loss: 0.0091\n",
      "Epoch 12/50\n",
      "840/840 [==============================] - 0s 82us/sample - loss: 0.0141 - val_loss: 0.0090\n",
      "Epoch 13/50\n",
      "840/840 [==============================] - 0s 81us/sample - loss: 0.0141 - val_loss: 0.0091\n",
      "Epoch 14/50\n",
      "840/840 [==============================] - 0s 83us/sample - loss: 0.0141 - val_loss: 0.0090\n",
      "Epoch 15/50\n",
      "840/840 [==============================] - 0s 81us/sample - loss: 0.0141 - val_loss: 0.0090\n",
      "Epoch 16/50\n",
      "840/840 [==============================] - 0s 85us/sample - loss: 0.0141 - val_loss: 0.0090\n",
      "Epoch 17/50\n",
      "840/840 [==============================] - 0s 84us/sample - loss: 0.0142 - val_loss: 0.0091\n",
      "Epoch 18/50\n",
      "840/840 [==============================] - 0s 83us/sample - loss: 0.0141 - val_loss: 0.0090\n",
      "Epoch 19/50\n",
      "840/840 [==============================] - 0s 83us/sample - loss: 0.0141 - val_loss: 0.0090\n",
      "Epoch 20/50\n",
      "840/840 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0090\n",
      "Epoch 21/50\n",
      "840/840 [==============================] - 0s 79us/sample - loss: 0.0142 - val_loss: 0.0091\n",
      "Epoch 22/50\n",
      "840/840 [==============================] - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0091\n",
      "Epoch 23/50\n",
      "840/840 [==============================] - 0s 81us/sample - loss: 0.0141 - val_loss: 0.0090\n",
      "Epoch 24/50\n",
      "840/840 [==============================] - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0090\n",
      "Epoch 25/50\n",
      "840/840 [==============================] - 0s 84us/sample - loss: 0.0142 - val_loss: 0.0090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "840/840 [==============================] - 0s 79us/sample - loss: 0.0142 - val_loss: 0.0091\n",
      "Epoch 27/50\n",
      "840/840 [==============================] - 0s 86us/sample - loss: 0.0142 - val_loss: 0.0091\n",
      "Epoch 28/50\n",
      "840/840 [==============================] - 0s 79us/sample - loss: 0.0141 - val_loss: 0.0090\n",
      "Epoch 29/50\n",
      "840/840 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0091\n",
      "Epoch 30/50\n",
      "840/840 [==============================] - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0091\n",
      "Epoch 31/50\n",
      "840/840 [==============================] - 0s 85us/sample - loss: 0.0141 - val_loss: 0.0090\n",
      "Epoch 32/50\n",
      "840/840 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0090\n",
      "Epoch 33/50\n",
      "840/840 [==============================] - 0s 80us/sample - loss: 0.0142 - val_loss: 0.0090\n",
      "Epoch 34/50\n",
      "840/840 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0091\n",
      "Epoch 35/50\n",
      "840/840 [==============================] - 0s 78us/sample - loss: 0.0142 - val_loss: 0.0091\n",
      "Epoch 36/50\n",
      "840/840 [==============================] - 0s 81us/sample - loss: 0.0141 - val_loss: 0.0090\n",
      "Epoch 37/50\n",
      "840/840 [==============================] - 0s 80us/sample - loss: 0.0142 - val_loss: 0.0090\n",
      "Epoch 38/50\n",
      "840/840 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0090\n",
      "Epoch 39/50\n",
      "840/840 [==============================] - 0s 84us/sample - loss: 0.0142 - val_loss: 0.0090\n",
      "Epoch 40/50\n",
      "840/840 [==============================] - 0s 84us/sample - loss: 0.0142 - val_loss: 0.0091\n",
      "Epoch 41/50\n",
      "840/840 [==============================] - 0s 80us/sample - loss: 0.0142 - val_loss: 0.0090\n",
      "Epoch 42/50\n",
      "840/840 [==============================] - 0s 79us/sample - loss: 0.0142 - val_loss: 0.0090\n",
      "Epoch 43/50\n",
      "840/840 [==============================] - 0s 78us/sample - loss: 0.0142 - val_loss: 0.0090\n",
      "Epoch 44/50\n",
      "840/840 [==============================] - 0s 78us/sample - loss: 0.0142 - val_loss: 0.0090\n",
      "Epoch 45/50\n",
      "840/840 [==============================] - 0s 85us/sample - loss: 0.0142 - val_loss: 0.0090\n",
      "Epoch 46/50\n",
      "840/840 [==============================] - 0s 88us/sample - loss: 0.0142 - val_loss: 0.0090\n",
      "Epoch 47/50\n",
      "840/840 [==============================] - 0s 88us/sample - loss: 0.0142 - val_loss: 0.0090\n",
      "Epoch 48/50\n",
      "840/840 [==============================] - 0s 85us/sample - loss: 0.0142 - val_loss: 0.0090\n",
      "Epoch 49/50\n",
      "840/840 [==============================] - 0s 85us/sample - loss: 0.0142 - val_loss: 0.0090\n",
      "Epoch 50/50\n",
      "840/840 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0090\n",
      "第46个数，还剩4077个没有训练\n",
      "inv_hat [0.52859257 0.52183173 0.5237619  0.52086714 0.5150861  0.50931654\n",
      " 0.51027732 0.51893889 0.5150861  0.52086714 0.53246251 0.53536804\n",
      " 0.53730654 0.52859257 0.53052692 0.52665935 0.52762584 0.52955959\n",
      " 0.53439923 0.52279669 0.51990286 0.51797518 0.50931654 0.51219984\n",
      " 0.50931654 0.51604881 0.51219984 0.50931654 0.50643612 0.50931654]\n",
      "Test RMSE: 0.006\n",
      "Train on 658 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "658/658 [==============================] - 0s 91us/sample - loss: 0.0226 - val_loss: 0.0139\n",
      "Epoch 2/50\n",
      "658/658 [==============================] - 0s 86us/sample - loss: 0.0224 - val_loss: 0.0128\n",
      "Epoch 3/50\n",
      "658/658 [==============================] - 0s 85us/sample - loss: 0.0224 - val_loss: 0.0128\n",
      "Epoch 4/50\n",
      "658/658 [==============================] - 0s 83us/sample - loss: 0.0223 - val_loss: 0.0130\n",
      "Epoch 5/50\n",
      "658/658 [==============================] - 0s 84us/sample - loss: 0.0223 - val_loss: 0.0128\n",
      "Epoch 6/50\n",
      "658/658 [==============================] - 0s 87us/sample - loss: 0.0223 - val_loss: 0.0130\n",
      "Epoch 7/50\n",
      "658/658 [==============================] - 0s 82us/sample - loss: 0.0223 - val_loss: 0.0128\n",
      "Epoch 8/50\n",
      "658/658 [==============================] - 0s 82us/sample - loss: 0.0223 - val_loss: 0.0130\n",
      "Epoch 9/50\n",
      "658/658 [==============================] - 0s 83us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 10/50\n",
      "658/658 [==============================] - 0s 84us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 11/50\n",
      "658/658 [==============================] - 0s 98us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 12/50\n",
      "658/658 [==============================] - 0s 99us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 13/50\n",
      "658/658 [==============================] - 0s 90us/sample - loss: 0.0223 - val_loss: 0.0130\n",
      "Epoch 14/50\n",
      "658/658 [==============================] - 0s 95us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 15/50\n",
      "658/658 [==============================] - 0s 94us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 16/50\n",
      "658/658 [==============================] - 0s 90us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 17/50\n",
      "658/658 [==============================] - 0s 88us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 18/50\n",
      "658/658 [==============================] - 0s 93us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 19/50\n",
      "658/658 [==============================] - 0s 85us/sample - loss: 0.0223 - val_loss: 0.0130\n",
      "Epoch 20/50\n",
      "658/658 [==============================] - 0s 86us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 21/50\n",
      "658/658 [==============================] - 0s 85us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 22/50\n",
      "658/658 [==============================] - 0s 84us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 23/50\n",
      "658/658 [==============================] - 0s 86us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 24/50\n",
      "658/658 [==============================] - 0s 86us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 25/50\n",
      "658/658 [==============================] - 0s 90us/sample - loss: 0.0223 - val_loss: 0.0128\n",
      "Epoch 26/50\n",
      "658/658 [==============================] - 0s 87us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 27/50\n",
      "658/658 [==============================] - 0s 89us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 28/50\n",
      "658/658 [==============================] - 0s 88us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 29/50\n",
      "658/658 [==============================] - 0s 90us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 30/50\n",
      "658/658 [==============================] - 0s 92us/sample - loss: 0.0223 - val_loss: 0.0130\n",
      "Epoch 31/50\n",
      "658/658 [==============================] - 0s 87us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 32/50\n",
      "658/658 [==============================] - 0s 85us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 33/50\n",
      "658/658 [==============================] - 0s 82us/sample - loss: 0.0223 - val_loss: 0.0130\n",
      "Epoch 34/50\n",
      "658/658 [==============================] - 0s 87us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 35/50\n",
      "658/658 [==============================] - 0s 85us/sample - loss: 0.0223 - val_loss: 0.0128\n",
      "Epoch 36/50\n",
      "658/658 [==============================] - 0s 89us/sample - loss: 0.0223 - val_loss: 0.0130\n",
      "Epoch 37/50\n",
      "658/658 [==============================] - 0s 86us/sample - loss: 0.0222 - val_loss: 0.0129\n",
      "Epoch 38/50\n",
      "658/658 [==============================] - 0s 85us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 39/50\n",
      "658/658 [==============================] - 0s 87us/sample - loss: 0.0223 - val_loss: 0.0130\n",
      "Epoch 40/50\n",
      "658/658 [==============================] - 0s 83us/sample - loss: 0.0222 - val_loss: 0.0129\n",
      "Epoch 41/50\n",
      "658/658 [==============================] - 0s 88us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 42/50\n",
      "658/658 [==============================] - 0s 90us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 43/50\n",
      "658/658 [==============================] - 0s 87us/sample - loss: 0.0223 - val_loss: 0.0130\n",
      "Epoch 44/50\n",
      "658/658 [==============================] - 0s 88us/sample - loss: 0.0222 - val_loss: 0.0129\n",
      "Epoch 45/50\n",
      "658/658 [==============================] - 0s 92us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 46/50\n",
      "658/658 [==============================] - 0s 87us/sample - loss: 0.0223 - val_loss: 0.0130\n",
      "Epoch 47/50\n",
      "658/658 [==============================] - 0s 86us/sample - loss: 0.0222 - val_loss: 0.0129\n",
      "Epoch 48/50\n",
      "658/658 [==============================] - 0s 90us/sample - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 49/50\n",
      "658/658 [==============================] - 0s 86us/sample - loss: 0.0222 - val_loss: 0.0130\n",
      "Epoch 50/50\n",
      "658/658 [==============================] - 0s 83us/sample - loss: 0.0223 - val_loss: 0.0129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第47个数，还剩4076个没有训练\n",
      "inv_hat [1.0463523  1.04388887 1.04388887 1.04398752 1.0398378  1.03894675\n",
      " 1.03795616 1.04221083 1.04260585 1.04339559 1.04841719 1.05067402\n",
      " 1.05047795 1.04861369 1.04910459 1.0490064  1.04910459 1.05135982\n",
      " 1.04763103 1.04428344 1.04339559 1.04359298 1.04477634 1.04477634\n",
      " 1.04339559 1.04418481 1.04763103 1.04930092 1.05175145 1.05312102]\n",
      "Test RMSE: 0.002\n",
      "Train on 1072 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1072/1072 [==============================] - 0s 79us/sample - loss: 0.0089 - val_loss: 0.0015\n",
      "Epoch 2/50\n",
      "1072/1072 [==============================] - 0s 78us/sample - loss: 0.0101 - val_loss: 0.0014\n",
      "Epoch 3/50\n",
      "1072/1072 [==============================] - 0s 79us/sample - loss: 0.0098 - val_loss: 0.0013\n",
      "Epoch 4/50\n",
      "1072/1072 [==============================] - 0s 80us/sample - loss: 0.0097 - val_loss: 0.0013\n",
      "Epoch 5/50\n",
      "1072/1072 [==============================] - 0s 81us/sample - loss: 0.0095 - val_loss: 0.0014\n",
      "Epoch 6/50\n",
      "1072/1072 [==============================] - 0s 81us/sample - loss: 0.0095 - val_loss: 0.0012\n",
      "Epoch 7/50\n",
      "1072/1072 [==============================] - 0s 81us/sample - loss: 0.0096 - val_loss: 0.0013\n",
      "Epoch 8/50\n",
      "1072/1072 [==============================] - 0s 81us/sample - loss: 0.0096 - val_loss: 0.0013\n",
      "Epoch 9/50\n",
      "1072/1072 [==============================] - 0s 80us/sample - loss: 0.0094 - val_loss: 0.0014\n",
      "Epoch 10/50\n",
      "1072/1072 [==============================] - 0s 79us/sample - loss: 0.0096 - val_loss: 0.0014\n",
      "Epoch 11/50\n",
      "1072/1072 [==============================] - 0s 82us/sample - loss: 0.0093 - val_loss: 0.0011\n",
      "Epoch 12/50\n",
      "1072/1072 [==============================] - 0s 77us/sample - loss: 0.0093 - val_loss: 0.0013\n",
      "Epoch 13/50\n",
      "1072/1072 [==============================] - 0s 79us/sample - loss: 0.0095 - val_loss: 0.0014\n",
      "Epoch 14/50\n",
      "1072/1072 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0014\n",
      "Epoch 15/50\n",
      "1072/1072 [==============================] - 0s 82us/sample - loss: 0.0095 - val_loss: 0.0013\n",
      "Epoch 16/50\n",
      "1072/1072 [==============================] - 0s 77us/sample - loss: 0.0092 - val_loss: 0.0013\n",
      "Epoch 17/50\n",
      "1072/1072 [==============================] - 0s 78us/sample - loss: 0.0090 - val_loss: 0.0018\n",
      "Epoch 18/50\n",
      "1072/1072 [==============================] - 0s 80us/sample - loss: 0.0092 - val_loss: 0.0015\n",
      "Epoch 19/50\n",
      "1072/1072 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0012\n",
      "Epoch 20/50\n",
      "1072/1072 [==============================] - 0s 79us/sample - loss: 0.0095 - val_loss: 0.0011\n",
      "Epoch 21/50\n",
      "1072/1072 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0014\n",
      "Epoch 22/50\n",
      "1072/1072 [==============================] - 0s 81us/sample - loss: 0.0094 - val_loss: 0.0013\n",
      "Epoch 23/50\n",
      "1072/1072 [==============================] - 0s 81us/sample - loss: 0.0093 - val_loss: 0.0012\n",
      "Epoch 24/50\n",
      "1072/1072 [==============================] - 0s 81us/sample - loss: 0.0094 - val_loss: 0.0013\n",
      "Epoch 25/50\n",
      "1072/1072 [==============================] - 0s 78us/sample - loss: 0.0093 - val_loss: 0.0012\n",
      "Epoch 26/50\n",
      "1072/1072 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0014\n",
      "Epoch 27/50\n",
      "1072/1072 [==============================] - 0s 78us/sample - loss: 0.0090 - val_loss: 0.0018\n",
      "Epoch 28/50\n",
      "1072/1072 [==============================] - 0s 75us/sample - loss: 0.0093 - val_loss: 0.0021\n",
      "Epoch 29/50\n",
      "1072/1072 [==============================] - 0s 75us/sample - loss: 0.0094 - val_loss: 0.0013\n",
      "Epoch 30/50\n",
      "1072/1072 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0012\n",
      "Epoch 31/50\n",
      "1072/1072 [==============================] - 0s 82us/sample - loss: 0.0093 - val_loss: 0.0014\n",
      "Epoch 32/50\n",
      "1072/1072 [==============================] - 0s 81us/sample - loss: 0.0093 - val_loss: 0.0012\n",
      "Epoch 33/50\n",
      "1072/1072 [==============================] - 0s 80us/sample - loss: 0.0094 - val_loss: 0.0014\n",
      "Epoch 34/50\n",
      "1072/1072 [==============================] - 0s 77us/sample - loss: 0.0090 - val_loss: 0.0012\n",
      "Epoch 35/50\n",
      "1072/1072 [==============================] - 0s 81us/sample - loss: 0.0092 - val_loss: 0.0012\n",
      "Epoch 36/50\n",
      "1072/1072 [==============================] - 0s 81us/sample - loss: 0.0093 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "1072/1072 [==============================] - 0s 86us/sample - loss: 0.0093 - val_loss: 0.0013\n",
      "Epoch 38/50\n",
      "1072/1072 [==============================] - 0s 78us/sample - loss: 0.0092 - val_loss: 0.0013\n",
      "Epoch 39/50\n",
      "1072/1072 [==============================] - 0s 78us/sample - loss: 0.0090 - val_loss: 0.0014\n",
      "Epoch 40/50\n",
      "1072/1072 [==============================] - 0s 78us/sample - loss: 0.0092 - val_loss: 0.0011\n",
      "Epoch 41/50\n",
      "1072/1072 [==============================] - 0s 77us/sample - loss: 0.0092 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "1072/1072 [==============================] - 0s 74us/sample - loss: 0.0090 - val_loss: 0.0015\n",
      "Epoch 43/50\n",
      "1072/1072 [==============================] - 0s 77us/sample - loss: 0.0091 - val_loss: 0.0013\n",
      "Epoch 44/50\n",
      "1072/1072 [==============================] - 0s 76us/sample - loss: 0.0094 - val_loss: 0.0012\n",
      "Epoch 45/50\n",
      "1072/1072 [==============================] - 0s 78us/sample - loss: 0.0106 - val_loss: 0.0035\n",
      "Epoch 46/50\n",
      "1072/1072 [==============================] - 0s 80us/sample - loss: 0.0114 - val_loss: 0.0052\n",
      "Epoch 47/50\n",
      "1072/1072 [==============================] - 0s 81us/sample - loss: 0.0090 - val_loss: 0.0014\n",
      "Epoch 48/50\n",
      "1072/1072 [==============================] - 0s 78us/sample - loss: 0.0092 - val_loss: 0.0016\n",
      "Epoch 49/50\n",
      "1072/1072 [==============================] - 0s 79us/sample - loss: 0.0094 - val_loss: 0.0013\n",
      "Epoch 50/50\n",
      "1072/1072 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0011\n",
      "第48个数，还剩4075个没有训练\n",
      "inv_hat [1.44992764 1.44691983 1.4479224  1.44691983 1.44491454 1.44491454\n",
      " 1.44491454 1.44691983 1.44691983 1.44691983 1.4509301  1.45293507\n",
      " 1.45293507 1.45193266 1.45193266 1.4509301  1.4509301  1.4509301\n",
      " 1.45193266 1.44892502 1.44892502 1.44691983 1.44691983 1.44691983\n",
      " 1.44691983 1.4479224  1.44691983 1.4479224  1.44691983 1.4479224 ]\n",
      "Test RMSE: 0.001\n",
      "Train on 672 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "672/672 [==============================] - 0s 85us/sample - loss: 0.0091 - val_loss: 0.0082\n",
      "Epoch 2/50\n",
      "672/672 [==============================] - 0s 85us/sample - loss: 0.0157 - val_loss: 0.0101\n",
      "Epoch 3/50\n",
      "672/672 [==============================] - 0s 87us/sample - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 4/50\n",
      "672/672 [==============================] - 0s 88us/sample - loss: 0.0242 - val_loss: 0.0113\n",
      "Epoch 5/50\n",
      "672/672 [==============================] - 0s 83us/sample - loss: 0.0086 - val_loss: 0.0101\n",
      "Epoch 6/50\n",
      "672/672 [==============================] - 0s 86us/sample - loss: 0.0153 - val_loss: 0.0102\n",
      "Epoch 7/50\n",
      "672/672 [==============================] - 0s 84us/sample - loss: 0.0147 - val_loss: 0.0087\n",
      "Epoch 8/50\n",
      "672/672 [==============================] - 0s 85us/sample - loss: 0.0128 - val_loss: 0.0125\n",
      "Epoch 9/50\n",
      "672/672 [==============================] - 0s 83us/sample - loss: 0.0217 - val_loss: 0.0149\n",
      "Epoch 10/50\n",
      "672/672 [==============================] - 0s 84us/sample - loss: 0.0111 - val_loss: 0.0096\n",
      "Epoch 11/50\n",
      "672/672 [==============================] - 0s 82us/sample - loss: 0.0125 - val_loss: 0.0113\n",
      "Epoch 12/50\n",
      "672/672 [==============================] - 0s 79us/sample - loss: 0.0133 - val_loss: 0.0107\n",
      "Epoch 13/50\n",
      "672/672 [==============================] - 0s 82us/sample - loss: 0.0213 - val_loss: 0.0123\n",
      "Epoch 14/50\n",
      "672/672 [==============================] - 0s 86us/sample - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 15/50\n",
      "672/672 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0091\n",
      "Epoch 16/50\n",
      "672/672 [==============================] - 0s 85us/sample - loss: 0.0140 - val_loss: 0.0084\n",
      "Epoch 17/50\n",
      "672/672 [==============================] - 0s 83us/sample - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 18/50\n",
      "672/672 [==============================] - 0s 82us/sample - loss: 0.0208 - val_loss: 0.0141\n",
      "Epoch 19/50\n",
      "672/672 [==============================] - 0s 80us/sample - loss: 0.0086 - val_loss: 0.0088\n",
      "Epoch 20/50\n",
      "672/672 [==============================] - 0s 81us/sample - loss: 0.0145 - val_loss: 0.0090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50\n",
      "672/672 [==============================] - 0s 82us/sample - loss: 0.0127 - val_loss: 0.0102\n",
      "Epoch 22/50\n",
      "672/672 [==============================] - 0s 80us/sample - loss: 0.0158 - val_loss: 0.0113\n",
      "Epoch 23/50\n",
      "672/672 [==============================] - 0s 88us/sample - loss: 0.0180 - val_loss: 0.0123\n",
      "Epoch 24/50\n",
      "672/672 [==============================] - 0s 84us/sample - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 25/50\n",
      "672/672 [==============================] - 0s 80us/sample - loss: 0.0137 - val_loss: 0.0095\n",
      "Epoch 26/50\n",
      "672/672 [==============================] - 0s 88us/sample - loss: 0.0128 - val_loss: 0.0083\n",
      "Epoch 27/50\n",
      "672/672 [==============================] - 0s 85us/sample - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 28/50\n",
      "672/672 [==============================] - 0s 87us/sample - loss: 0.0179 - val_loss: 0.0106\n",
      "Epoch 29/50\n",
      "672/672 [==============================] - 0s 92us/sample - loss: 0.0095 - val_loss: 0.0082\n",
      "Epoch 30/50\n",
      "672/672 [==============================] - 0s 87us/sample - loss: 0.0099 - val_loss: 0.0082\n",
      "Epoch 31/50\n",
      "672/672 [==============================] - 0s 89us/sample - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 32/50\n",
      "672/672 [==============================] - 0s 91us/sample - loss: 0.0119 - val_loss: 0.0093\n",
      "Epoch 33/50\n",
      "672/672 [==============================] - 0s 94us/sample - loss: 0.0174 - val_loss: 0.0112\n",
      "Epoch 34/50\n",
      "672/672 [==============================] - 0s 87us/sample - loss: 0.0094 - val_loss: 0.0107\n",
      "Epoch 35/50\n",
      "672/672 [==============================] - 0s 85us/sample - loss: 0.0150 - val_loss: 0.0107\n",
      "Epoch 36/50\n",
      "672/672 [==============================] - 0s 90us/sample - loss: 0.0133 - val_loss: 0.0095\n",
      "Epoch 37/50\n",
      "672/672 [==============================] - 0s 85us/sample - loss: 0.0089 - val_loss: 0.0094\n",
      "Epoch 38/50\n",
      "672/672 [==============================] - 0s 89us/sample - loss: 0.0146 - val_loss: 0.0087\n",
      "Epoch 39/50\n",
      "672/672 [==============================] - 0s 84us/sample - loss: 0.0091 - val_loss: 0.0087\n",
      "Epoch 40/50\n",
      "672/672 [==============================] - 0s 84us/sample - loss: 0.0160 - val_loss: 0.0107\n",
      "Epoch 41/50\n",
      "672/672 [==============================] - 0s 88us/sample - loss: 0.0100 - val_loss: 0.0094\n",
      "Epoch 42/50\n",
      "672/672 [==============================] - 0s 86us/sample - loss: 0.0114 - val_loss: 0.0091\n",
      "Epoch 43/50\n",
      "672/672 [==============================] - 0s 87us/sample - loss: 0.0115 - val_loss: 0.0083\n",
      "Epoch 44/50\n",
      "672/672 [==============================] - 0s 89us/sample - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 45/50\n",
      "672/672 [==============================] - 0s 88us/sample - loss: 0.0141 - val_loss: 0.0111\n",
      "Epoch 46/50\n",
      "672/672 [==============================] - 0s 86us/sample - loss: 0.0149 - val_loss: 0.0104\n",
      "Epoch 47/50\n",
      "672/672 [==============================] - 0s 89us/sample - loss: 0.0090 - val_loss: 0.0104\n",
      "Epoch 48/50\n",
      "672/672 [==============================] - 0s 84us/sample - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 49/50\n",
      "672/672 [==============================] - 0s 84us/sample - loss: 0.0125 - val_loss: 0.0083\n",
      "Epoch 50/50\n",
      "672/672 [==============================] - 0s 86us/sample - loss: 0.0091 - val_loss: 0.0082\n",
      "第49个数，还剩4074个没有训练\n",
      "inv_hat [1.08177448 1.08083908 1.08083908 1.07990152 1.07801953 1.07801953\n",
      " 1.07801953 1.07896162 1.07896162 1.07990152 1.08177448 1.08177448\n",
      " 1.08177448 1.08083908 1.08083908 1.07990152 1.08083908 1.08083908\n",
      " 1.08177448 1.08083908 1.08083908 1.07990152 1.07896162 1.07896162\n",
      " 1.07801953 1.07896162 1.07801953 1.07707538 1.07707538 1.07801953]\n",
      "Test RMSE: 0.001\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0102 - val_loss: 0.0045\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0079 - val_loss: 0.0037\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0082 - val_loss: 0.0042\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0046\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0096 - val_loss: 0.0045\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0097 - val_loss: 0.0041\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0094 - val_loss: 0.0038\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0090 - val_loss: 0.0038\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0090 - val_loss: 0.0040\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0090 - val_loss: 0.0039\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0091 - val_loss: 0.0040\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0091 - val_loss: 0.0040\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0090 - val_loss: 0.0038\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0089 - val_loss: 0.0037\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0087 - val_loss: 0.0036\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0086 - val_loss: 0.0035\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0084 - val_loss: 0.0035\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0083 - val_loss: 0.0035\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0035\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0081 - val_loss: 0.0035\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0035\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0081 - val_loss: 0.0035\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0035\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0082 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0081 - val_loss: 0.0036\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0081 - val_loss: 0.0035\n",
      "第50个数，还剩4073个没有训练\n",
      "inv_hat [1.49911786 1.46927885 1.47504806 1.47120166 1.43568461 1.43376803\n",
      " 1.43568461 1.45006967 1.43472623 1.44335431 1.47312468 1.47408627\n",
      " 1.4702402  1.45102937 1.45486886 1.44623185 1.45486886 1.46159129\n",
      " 1.47120166 1.45102937 1.45294896 1.44335431 1.43280982 1.43089377\n",
      " 1.42227565 1.42802027 1.42514751 1.42131845 1.41749074 1.42227565]\n",
      "Test RMSE: 0.013\n",
      "Train on 1068 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1068/1068 [==============================] - 0s 81us/sample - loss: 0.0119 - val_loss: 0.0046\n",
      "Epoch 2/50\n",
      "1068/1068 [==============================] - 0s 76us/sample - loss: 0.0117 - val_loss: 0.0034\n",
      "Epoch 3/50\n",
      "1068/1068 [==============================] - 0s 77us/sample - loss: 0.0114 - val_loss: 0.0036\n",
      "Epoch 4/50\n",
      "1068/1068 [==============================] - 0s 76us/sample - loss: 0.0115 - val_loss: 0.0037\n",
      "Epoch 5/50\n",
      "1068/1068 [==============================] - 0s 81us/sample - loss: 0.0125 - val_loss: 0.0061\n",
      "Epoch 6/50\n",
      "1068/1068 [==============================] - 0s 78us/sample - loss: 0.0127 - val_loss: 0.0079\n",
      "Epoch 7/50\n",
      "1068/1068 [==============================] - 0s 83us/sample - loss: 0.0129 - val_loss: 0.0101\n",
      "Epoch 8/50\n",
      "1068/1068 [==============================] - 0s 82us/sample - loss: 0.0134 - val_loss: 0.0120\n",
      "Epoch 9/50\n",
      "1068/1068 [==============================] - 0s 82us/sample - loss: 0.0131 - val_loss: 0.0106\n",
      "Epoch 10/50\n",
      "1068/1068 [==============================] - 0s 83us/sample - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 11/50\n",
      "1068/1068 [==============================] - 0s 81us/sample - loss: 0.0130 - val_loss: 0.0098\n",
      "Epoch 12/50\n",
      "1068/1068 [==============================] - 0s 79us/sample - loss: 0.0129 - val_loss: 0.0099\n",
      "Epoch 13/50\n",
      "1068/1068 [==============================] - 0s 78us/sample - loss: 0.0128 - val_loss: 0.0102\n",
      "Epoch 14/50\n",
      "1068/1068 [==============================] - 0s 83us/sample - loss: 0.0127 - val_loss: 0.0095\n",
      "Epoch 15/50\n",
      "1068/1068 [==============================] - 0s 80us/sample - loss: 0.0126 - val_loss: 0.0093\n",
      "Epoch 16/50\n",
      "1068/1068 [==============================] - 0s 80us/sample - loss: 0.0127 - val_loss: 0.0094\n",
      "Epoch 17/50\n",
      "1068/1068 [==============================] - 0s 80us/sample - loss: 0.0126 - val_loss: 0.0087\n",
      "Epoch 18/50\n",
      "1068/1068 [==============================] - 0s 82us/sample - loss: 0.0127 - val_loss: 0.0096\n",
      "Epoch 19/50\n",
      "1068/1068 [==============================] - 0s 81us/sample - loss: 0.0126 - val_loss: 0.0095\n",
      "Epoch 20/50\n",
      "1068/1068 [==============================] - 0s 85us/sample - loss: 0.0125 - val_loss: 0.0090\n",
      "Epoch 21/50\n",
      "1068/1068 [==============================] - 0s 87us/sample - loss: 0.0123 - val_loss: 0.0087\n",
      "Epoch 22/50\n",
      "1068/1068 [==============================] - 0s 82us/sample - loss: 0.0120 - val_loss: 0.0082\n",
      "Epoch 23/50\n",
      "1068/1068 [==============================] - 0s 80us/sample - loss: 0.0115 - val_loss: 0.0082\n",
      "Epoch 24/50\n",
      "1068/1068 [==============================] - 0s 77us/sample - loss: 0.0117 - val_loss: 0.0124\n",
      "Epoch 25/50\n",
      "1068/1068 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0123\n",
      "Epoch 26/50\n",
      "1068/1068 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0063\n",
      "Epoch 27/50\n",
      "1068/1068 [==============================] - 0s 79us/sample - loss: 0.0115 - val_loss: 0.0069\n",
      "Epoch 28/50\n",
      "1068/1068 [==============================] - 0s 80us/sample - loss: 0.0114 - val_loss: 0.0062\n",
      "Epoch 29/50\n",
      "1068/1068 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0076\n",
      "Epoch 30/50\n",
      "1068/1068 [==============================] - 0s 82us/sample - loss: 0.0115 - val_loss: 0.0076\n",
      "Epoch 31/50\n",
      "1068/1068 [==============================] - 0s 83us/sample - loss: 0.0114 - val_loss: 0.0062\n",
      "Epoch 32/50\n",
      "1068/1068 [==============================] - 0s 79us/sample - loss: 0.0113 - val_loss: 0.0063\n",
      "Epoch 33/50\n",
      "1068/1068 [==============================] - 0s 82us/sample - loss: 0.0114 - val_loss: 0.0073\n",
      "Epoch 34/50\n",
      "1068/1068 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0059\n",
      "Epoch 35/50\n",
      "1068/1068 [==============================] - 0s 75us/sample - loss: 0.0114 - val_loss: 0.0063\n",
      "Epoch 36/50\n",
      "1068/1068 [==============================] - 0s 79us/sample - loss: 0.0113 - val_loss: 0.0053\n",
      "Epoch 37/50\n",
      "1068/1068 [==============================] - 0s 78us/sample - loss: 0.0115 - val_loss: 0.0069\n",
      "Epoch 38/50\n",
      "1068/1068 [==============================] - 0s 82us/sample - loss: 0.0113 - val_loss: 0.0057\n",
      "Epoch 39/50\n",
      "1068/1068 [==============================] - 0s 84us/sample - loss: 0.0114 - val_loss: 0.0073\n",
      "Epoch 40/50\n",
      "1068/1068 [==============================] - 0s 79us/sample - loss: 0.0115 - val_loss: 0.0073\n",
      "Epoch 41/50\n",
      "1068/1068 [==============================] - 0s 80us/sample - loss: 0.0116 - val_loss: 0.0088\n",
      "Epoch 42/50\n",
      "1068/1068 [==============================] - 0s 80us/sample - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 43/50\n",
      "1068/1068 [==============================] - 0s 78us/sample - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 44/50\n",
      "1068/1068 [==============================] - 0s 81us/sample - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 45/50\n",
      "1068/1068 [==============================] - 0s 80us/sample - loss: 0.0120 - val_loss: 0.0098\n",
      "Epoch 46/50\n",
      "1068/1068 [==============================] - 0s 83us/sample - loss: 0.0119 - val_loss: 0.0108\n",
      "Epoch 47/50\n",
      "1068/1068 [==============================] - 0s 77us/sample - loss: 0.0121 - val_loss: 0.0091\n",
      "Epoch 48/50\n",
      "1068/1068 [==============================] - 0s 82us/sample - loss: 0.0119 - val_loss: 0.0093\n",
      "Epoch 49/50\n",
      "1068/1068 [==============================] - 0s 79us/sample - loss: 0.0119 - val_loss: 0.0093\n",
      "Epoch 50/50\n",
      "1068/1068 [==============================] - 0s 77us/sample - loss: 0.0120 - val_loss: 0.0102\n",
      "第51个数，还剩4072个没有训练\n",
      "inv_hat [1.09985526 1.09985526 1.09985526 1.10083946 1.10083946 1.10182297\n",
      " 1.10083946 1.10083946 1.10083946 1.10182297 1.10182297 1.10280565\n",
      " 1.1037877  1.1037877  1.1037877  1.1025055  1.1025055  1.10347001\n",
      " 1.10347001 1.10347001 1.10347001 1.10347001 1.10347001 1.10347001\n",
      " 1.10347001 1.10476897 1.10280565 1.10182297 1.10182297 1.10280565]\n",
      "Test RMSE: 0.002\n",
      "Train on 559 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "559/559 [==============================] - 0s 85us/sample - loss: 0.0197 - val_loss: 0.0080\n",
      "Epoch 2/50\n",
      "559/559 [==============================] - 0s 85us/sample - loss: 0.0196 - val_loss: 0.0089\n",
      "Epoch 3/50\n",
      "559/559 [==============================] - 0s 80us/sample - loss: 0.0191 - val_loss: 0.0074\n",
      "Epoch 4/50\n",
      "559/559 [==============================] - 0s 78us/sample - loss: 0.0189 - val_loss: 0.0093\n",
      "Epoch 5/50\n",
      "559/559 [==============================] - 0s 82us/sample - loss: 0.0192 - val_loss: 0.0081\n",
      "Epoch 6/50\n",
      "559/559 [==============================] - 0s 82us/sample - loss: 0.0191 - val_loss: 0.0101\n",
      "Epoch 7/50\n",
      "559/559 [==============================] - 0s 84us/sample - loss: 0.0196 - val_loss: 0.0077\n",
      "Epoch 8/50\n",
      "559/559 [==============================] - 0s 81us/sample - loss: 0.0193 - val_loss: 0.0095\n",
      "Epoch 9/50\n",
      "559/559 [==============================] - 0s 83us/sample - loss: 0.0193 - val_loss: 0.0072\n",
      "Epoch 10/50\n",
      "559/559 [==============================] - 0s 80us/sample - loss: 0.0190 - val_loss: 0.0095\n",
      "Epoch 11/50\n",
      "559/559 [==============================] - 0s 80us/sample - loss: 0.0192 - val_loss: 0.0081\n",
      "Epoch 12/50\n",
      "559/559 [==============================] - 0s 87us/sample - loss: 0.0191 - val_loss: 0.0101\n",
      "Epoch 13/50\n",
      "559/559 [==============================] - 0s 86us/sample - loss: 0.0195 - val_loss: 0.0075\n",
      "Epoch 14/50\n",
      "559/559 [==============================] - 0s 83us/sample - loss: 0.0191 - val_loss: 0.0097\n",
      "Epoch 15/50\n",
      "559/559 [==============================] - 0s 82us/sample - loss: 0.0193 - val_loss: 0.0072\n",
      "Epoch 16/50\n",
      "559/559 [==============================] - 0s 81us/sample - loss: 0.0190 - val_loss: 0.0092\n",
      "Epoch 17/50\n",
      "559/559 [==============================] - 0s 80us/sample - loss: 0.0191 - val_loss: 0.0083\n",
      "Epoch 18/50\n",
      "559/559 [==============================] - 0s 83us/sample - loss: 0.0191 - val_loss: 0.0104\n",
      "Epoch 19/50\n",
      "559/559 [==============================] - 0s 83us/sample - loss: 0.0195 - val_loss: 0.0073\n",
      "Epoch 20/50\n",
      "559/559 [==============================] - 0s 81us/sample - loss: 0.0190 - val_loss: 0.0096\n",
      "Epoch 21/50\n",
      "559/559 [==============================] - 0s 82us/sample - loss: 0.0191 - val_loss: 0.0072\n",
      "Epoch 22/50\n",
      "559/559 [==============================] - 0s 81us/sample - loss: 0.0189 - val_loss: 0.0102\n",
      "Epoch 23/50\n",
      "559/559 [==============================] - 0s 84us/sample - loss: 0.0193 - val_loss: 0.0076\n",
      "Epoch 24/50\n",
      "559/559 [==============================] - 0s 83us/sample - loss: 0.0190 - val_loss: 0.0097\n",
      "Epoch 25/50\n",
      "559/559 [==============================] - 0s 79us/sample - loss: 0.0192 - val_loss: 0.0079\n",
      "Epoch 26/50\n",
      "559/559 [==============================] - 0s 81us/sample - loss: 0.0189 - val_loss: 0.0102\n",
      "Epoch 27/50\n",
      "559/559 [==============================] - 0s 87us/sample - loss: 0.0194 - val_loss: 0.0076\n",
      "Epoch 28/50\n",
      "559/559 [==============================] - 0s 87us/sample - loss: 0.0190 - val_loss: 0.0094\n",
      "Epoch 29/50\n",
      "559/559 [==============================] - 0s 86us/sample - loss: 0.0191 - val_loss: 0.0078\n",
      "Epoch 30/50\n",
      "559/559 [==============================] - 0s 86us/sample - loss: 0.0189 - val_loss: 0.0103\n",
      "Epoch 31/50\n",
      "559/559 [==============================] - 0s 85us/sample - loss: 0.0193 - val_loss: 0.0076\n",
      "Epoch 32/50\n",
      "559/559 [==============================] - 0s 87us/sample - loss: 0.0189 - val_loss: 0.0098\n",
      "Epoch 33/50\n",
      "559/559 [==============================] - 0s 86us/sample - loss: 0.0192 - val_loss: 0.0080\n",
      "Epoch 34/50\n",
      "559/559 [==============================] - 0s 87us/sample - loss: 0.0190 - val_loss: 0.0102\n",
      "Epoch 35/50\n",
      "559/559 [==============================] - 0s 88us/sample - loss: 0.0193 - val_loss: 0.0075\n",
      "Epoch 36/50\n",
      "559/559 [==============================] - 0s 83us/sample - loss: 0.0190 - val_loss: 0.0093\n",
      "Epoch 37/50\n",
      "559/559 [==============================] - 0s 86us/sample - loss: 0.0191 - val_loss: 0.0079\n",
      "Epoch 38/50\n",
      "559/559 [==============================] - 0s 85us/sample - loss: 0.0189 - val_loss: 0.0103\n",
      "Epoch 39/50\n",
      "559/559 [==============================] - 0s 78us/sample - loss: 0.0194 - val_loss: 0.0079\n",
      "Epoch 40/50\n",
      "559/559 [==============================] - 0s 79us/sample - loss: 0.0190 - val_loss: 0.0099\n",
      "Epoch 41/50\n",
      "559/559 [==============================] - 0s 79us/sample - loss: 0.0192 - val_loss: 0.0078\n",
      "Epoch 42/50\n",
      "559/559 [==============================] - 0s 81us/sample - loss: 0.0189 - val_loss: 0.0104\n",
      "Epoch 43/50\n",
      "559/559 [==============================] - 0s 82us/sample - loss: 0.0193 - val_loss: 0.0074\n",
      "Epoch 44/50\n",
      "559/559 [==============================] - 0s 81us/sample - loss: 0.0190 - val_loss: 0.0094\n",
      "Epoch 45/50\n",
      "559/559 [==============================] - 0s 81us/sample - loss: 0.0191 - val_loss: 0.0078\n",
      "Epoch 46/50\n",
      "559/559 [==============================] - 0s 85us/sample - loss: 0.0189 - val_loss: 0.0104\n",
      "Epoch 47/50\n",
      "559/559 [==============================] - 0s 82us/sample - loss: 0.0193 - val_loss: 0.0079\n",
      "Epoch 48/50\n",
      "559/559 [==============================] - 0s 80us/sample - loss: 0.0190 - val_loss: 0.0099\n",
      "Epoch 49/50\n",
      "559/559 [==============================] - 0s 80us/sample - loss: 0.0192 - val_loss: 0.0076\n",
      "Epoch 50/50\n",
      "559/559 [==============================] - 0s 83us/sample - loss: 0.0189 - val_loss: 0.0107\n",
      "第52个数，还剩4071个没有训练\n",
      "inv_hat [0.98551553 0.98352639 0.98352639 0.98352639 0.98253259 0.98253259\n",
      " 0.98253259 0.98253259 0.98352639 0.98352639 0.98551553 0.98551553\n",
      " 0.98552686 0.98552686 0.98552686 0.98552686 0.98552686 0.98552686\n",
      " 0.98552686 0.98451834 0.98351031 0.98351031 0.9845207  0.98551553\n",
      " 0.98551553 0.9845207  0.9865108  0.9865108  0.98949881 0.99049531]\n",
      "Test RMSE: 0.001\n",
      "Train on 1118 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1118/1118 [==============================] - 0s 84us/sample - loss: 0.0122 - val_loss: 0.0161\n",
      "Epoch 2/50\n",
      "1118/1118 [==============================] - 0s 81us/sample - loss: 0.0122 - val_loss: 0.0132\n",
      "Epoch 3/50\n",
      "1118/1118 [==============================] - 0s 82us/sample - loss: 0.0118 - val_loss: 0.0150\n",
      "Epoch 4/50\n",
      "1118/1118 [==============================] - 0s 83us/sample - loss: 0.0118 - val_loss: 0.0134\n",
      "Epoch 5/50\n",
      "1118/1118 [==============================] - 0s 85us/sample - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 6/50\n",
      "1118/1118 [==============================] - 0s 81us/sample - loss: 0.0118 - val_loss: 0.0134\n",
      "Epoch 7/50\n",
      "1118/1118 [==============================] - 0s 80us/sample - loss: 0.0119 - val_loss: 0.0149\n",
      "Epoch 8/50\n",
      "1118/1118 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0133\n",
      "Epoch 9/50\n",
      "1118/1118 [==============================] - 0s 77us/sample - loss: 0.0119 - val_loss: 0.0155\n",
      "Epoch 10/50\n",
      "1118/1118 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0133\n",
      "Epoch 11/50\n",
      "1118/1118 [==============================] - 0s 80us/sample - loss: 0.0119 - val_loss: 0.0147\n",
      "Epoch 12/50\n",
      "1118/1118 [==============================] - 0s 81us/sample - loss: 0.0116 - val_loss: 0.0132\n",
      "Epoch 13/50\n",
      "1118/1118 [==============================] - 0s 83us/sample - loss: 0.0118 - val_loss: 0.0148\n",
      "Epoch 14/50\n",
      "1118/1118 [==============================] - 0s 86us/sample - loss: 0.0116 - val_loss: 0.0132\n",
      "Epoch 15/50\n",
      "1118/1118 [==============================] - 0s 84us/sample - loss: 0.0119 - val_loss: 0.0151\n",
      "Epoch 16/50\n",
      "1118/1118 [==============================] - 0s 82us/sample - loss: 0.0116 - val_loss: 0.0133\n",
      "Epoch 17/50\n",
      "1118/1118 [==============================] - 0s 80us/sample - loss: 0.0119 - val_loss: 0.0145\n",
      "Epoch 18/50\n",
      "1118/1118 [==============================] - 0s 83us/sample - loss: 0.0116 - val_loss: 0.0132\n",
      "Epoch 19/50\n",
      "1118/1118 [==============================] - 0s 82us/sample - loss: 0.0119 - val_loss: 0.0153\n",
      "Epoch 20/50\n",
      "1118/1118 [==============================] - 0s 82us/sample - loss: 0.0116 - val_loss: 0.0132\n",
      "Epoch 21/50\n",
      "1118/1118 [==============================] - 0s 81us/sample - loss: 0.0119 - val_loss: 0.0149\n",
      "Epoch 22/50\n",
      "1118/1118 [==============================] - 0s 78us/sample - loss: 0.0116 - val_loss: 0.0132\n",
      "Epoch 23/50\n",
      "1118/1118 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0147\n",
      "Epoch 24/50\n",
      "1118/1118 [==============================] - 0s 79us/sample - loss: 0.0116 - val_loss: 0.0132\n",
      "Epoch 25/50\n",
      "1118/1118 [==============================] - 0s 77us/sample - loss: 0.0118 - val_loss: 0.0145\n",
      "Epoch 26/50\n",
      "1118/1118 [==============================] - 0s 80us/sample - loss: 0.0115 - val_loss: 0.0131\n",
      "Epoch 27/50\n",
      "1118/1118 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0144\n",
      "Epoch 28/50\n",
      "1118/1118 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0129\n",
      "Epoch 29/50\n",
      "1118/1118 [==============================] - 0s 76us/sample - loss: 0.0116 - val_loss: 0.0141\n",
      "Epoch 30/50\n",
      "1118/1118 [==============================] - 0s 80us/sample - loss: 0.0113 - val_loss: 0.0129\n",
      "Epoch 31/50\n",
      "1118/1118 [==============================] - 0s 84us/sample - loss: 0.0115 - val_loss: 0.0140\n",
      "Epoch 32/50\n",
      "1118/1118 [==============================] - 0s 84us/sample - loss: 0.0112 - val_loss: 0.0129\n",
      "Epoch 33/50\n",
      "1118/1118 [==============================] - 0s 80us/sample - loss: 0.0115 - val_loss: 0.0140\n",
      "Epoch 34/50\n",
      "1118/1118 [==============================] - 0s 82us/sample - loss: 0.0112 - val_loss: 0.0129\n",
      "Epoch 35/50\n",
      "1118/1118 [==============================] - 0s 78us/sample - loss: 0.0115 - val_loss: 0.0141\n",
      "Epoch 36/50\n",
      "1118/1118 [==============================] - 0s 77us/sample - loss: 0.0112 - val_loss: 0.0129\n",
      "Epoch 37/50\n",
      "1118/1118 [==============================] - 0s 79us/sample - loss: 0.0115 - val_loss: 0.0141\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1118/1118 [==============================] - 0s 80us/sample - loss: 0.0113 - val_loss: 0.0129\n",
      "Epoch 39/50\n",
      "1118/1118 [==============================] - 0s 85us/sample - loss: 0.0115 - val_loss: 0.0142\n",
      "Epoch 40/50\n",
      "1118/1118 [==============================] - 0s 83us/sample - loss: 0.0113 - val_loss: 0.0129\n",
      "Epoch 41/50\n",
      "1118/1118 [==============================] - 0s 79us/sample - loss: 0.0115 - val_loss: 0.0142\n",
      "Epoch 42/50\n",
      "1118/1118 [==============================] - 0s 80us/sample - loss: 0.0113 - val_loss: 0.0129\n",
      "Epoch 43/50\n",
      "1118/1118 [==============================] - 0s 82us/sample - loss: 0.0115 - val_loss: 0.0142\n",
      "Epoch 44/50\n",
      "1118/1118 [==============================] - 0s 83us/sample - loss: 0.0113 - val_loss: 0.0129\n",
      "Epoch 45/50\n",
      "1118/1118 [==============================] - 0s 79us/sample - loss: 0.0115 - val_loss: 0.0143\n",
      "Epoch 46/50\n",
      "1118/1118 [==============================] - 0s 82us/sample - loss: 0.0113 - val_loss: 0.0129\n",
      "Epoch 47/50\n",
      "1118/1118 [==============================] - 0s 82us/sample - loss: 0.0119 - val_loss: 0.0153\n",
      "Epoch 48/50\n",
      "1118/1118 [==============================] - 0s 84us/sample - loss: 0.0115 - val_loss: 0.0133\n",
      "Epoch 49/50\n",
      "1118/1118 [==============================] - 0s 81us/sample - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 50/50\n",
      "1118/1118 [==============================] - 0s 87us/sample - loss: 0.0117 - val_loss: 0.0130\n",
      "第53个数，还剩4070个没有训练\n",
      "inv_hat [1.93192233 1.89862758 1.91174708 1.90771073 1.86328606 1.84914303\n",
      " 1.86126598 1.87742584 1.85217403 1.87641584 1.93797255 1.95913972\n",
      " 1.96820674 1.90468317 1.87843555 1.86530641 1.87237634 1.87338615\n",
      " 1.89660862 1.8501534  1.83398659 1.81983764 1.78344683 1.78344683\n",
      " 1.76828204 1.80063252 1.81074095 1.804676   1.79759995 1.80669765]\n",
      "Test RMSE: 0.026\n",
      "Train on 598 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "598/598 [==============================] - 0s 89us/sample - loss: 0.0233 - val_loss: 0.0238\n",
      "Epoch 2/50\n",
      "598/598 [==============================] - 0s 85us/sample - loss: 0.0225 - val_loss: 0.0209\n",
      "Epoch 3/50\n",
      "598/598 [==============================] - 0s 84us/sample - loss: 0.0226 - val_loss: 0.0246\n",
      "Epoch 4/50\n",
      "598/598 [==============================] - 0s 96us/sample - loss: 0.0226 - val_loss: 0.0219\n",
      "Epoch 5/50\n",
      "598/598 [==============================] - 0s 89us/sample - loss: 0.0224 - val_loss: 0.0246\n",
      "Epoch 6/50\n",
      "598/598 [==============================] - 0s 86us/sample - loss: 0.0226 - val_loss: 0.0218\n",
      "Epoch 7/50\n",
      "598/598 [==============================] - 0s 87us/sample - loss: 0.0224 - val_loss: 0.0243\n",
      "Epoch 8/50\n",
      "598/598 [==============================] - 0s 86us/sample - loss: 0.0225 - val_loss: 0.0220\n",
      "Epoch 9/50\n",
      "598/598 [==============================] - 0s 82us/sample - loss: 0.0224 - val_loss: 0.0242\n",
      "Epoch 10/50\n",
      "598/598 [==============================] - 0s 82us/sample - loss: 0.0224 - val_loss: 0.0225\n",
      "Epoch 11/50\n",
      "598/598 [==============================] - 0s 89us/sample - loss: 0.0223 - val_loss: 0.0241\n",
      "Epoch 12/50\n",
      "598/598 [==============================] - 0s 85us/sample - loss: 0.0224 - val_loss: 0.0228\n",
      "Epoch 13/50\n",
      "598/598 [==============================] - 0s 86us/sample - loss: 0.0223 - val_loss: 0.0239\n",
      "Epoch 14/50\n",
      "598/598 [==============================] - 0s 84us/sample - loss: 0.0224 - val_loss: 0.0228\n",
      "Epoch 15/50\n",
      "598/598 [==============================] - 0s 87us/sample - loss: 0.0223 - val_loss: 0.0238\n",
      "Epoch 16/50\n",
      "598/598 [==============================] - 0s 89us/sample - loss: 0.0223 - val_loss: 0.0229\n",
      "Epoch 17/50\n",
      "598/598 [==============================] - 0s 84us/sample - loss: 0.0223 - val_loss: 0.0235\n",
      "Epoch 18/50\n",
      "598/598 [==============================] - 0s 87us/sample - loss: 0.0223 - val_loss: 0.0232\n",
      "Epoch 19/50\n",
      "598/598 [==============================] - 0s 85us/sample - loss: 0.0223 - val_loss: 0.0231\n",
      "Epoch 20/50\n",
      "598/598 [==============================] - 0s 83us/sample - loss: 0.0223 - val_loss: 0.0232\n",
      "Epoch 21/50\n",
      "598/598 [==============================] - 0s 85us/sample - loss: 0.0223 - val_loss: 0.0227\n",
      "Epoch 22/50\n",
      "598/598 [==============================] - 0s 83us/sample - loss: 0.0223 - val_loss: 0.0236\n",
      "Epoch 23/50\n",
      "598/598 [==============================] - 0s 80us/sample - loss: 0.0223 - val_loss: 0.0231\n",
      "Epoch 24/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.012 - 0s 83us/sample - loss: 0.0223 - val_loss: 0.0232\n",
      "Epoch 25/50\n",
      "598/598 [==============================] - 0s 92us/sample - loss: 0.0223 - val_loss: 0.0229\n",
      "Epoch 26/50\n",
      "598/598 [==============================] - 0s 90us/sample - loss: 0.0223 - val_loss: 0.0236\n",
      "Epoch 27/50\n",
      "598/598 [==============================] - 0s 88us/sample - loss: 0.0223 - val_loss: 0.0234\n",
      "Epoch 28/50\n",
      "598/598 [==============================] - 0s 86us/sample - loss: 0.0223 - val_loss: 0.0230\n",
      "Epoch 29/50\n",
      "598/598 [==============================] - 0s 89us/sample - loss: 0.0223 - val_loss: 0.0237\n",
      "Epoch 30/50\n",
      "598/598 [==============================] - 0s 88us/sample - loss: 0.0223 - val_loss: 0.0232\n",
      "Epoch 31/50\n",
      "598/598 [==============================] - 0s 92us/sample - loss: 0.0223 - val_loss: 0.0234\n",
      "Epoch 32/50\n",
      "598/598 [==============================] - 0s 87us/sample - loss: 0.0223 - val_loss: 0.0233\n",
      "Epoch 33/50\n",
      "598/598 [==============================] - 0s 89us/sample - loss: 0.0223 - val_loss: 0.0228\n",
      "Epoch 34/50\n",
      "598/598 [==============================] - 0s 90us/sample - loss: 0.0223 - val_loss: 0.0236\n",
      "Epoch 35/50\n",
      "598/598 [==============================] - 0s 89us/sample - loss: 0.0223 - val_loss: 0.0235\n",
      "Epoch 36/50\n",
      "598/598 [==============================] - 0s 88us/sample - loss: 0.0223 - val_loss: 0.0231\n",
      "Epoch 37/50\n",
      "598/598 [==============================] - 0s 82us/sample - loss: 0.0223 - val_loss: 0.0233\n",
      "Epoch 38/50\n",
      "598/598 [==============================] - 0s 84us/sample - loss: 0.0223 - val_loss: 0.0233\n",
      "Epoch 39/50\n",
      "598/598 [==============================] - 0s 81us/sample - loss: 0.0223 - val_loss: 0.0232\n",
      "Epoch 40/50\n",
      "598/598 [==============================] - 0s 81us/sample - loss: 0.0223 - val_loss: 0.0231\n",
      "Epoch 41/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.012 - 0s 81us/sample - loss: 0.0222 - val_loss: 0.0230\n",
      "Epoch 42/50\n",
      "598/598 [==============================] - 0s 82us/sample - loss: 0.0222 - val_loss: 0.0235\n",
      "Epoch 43/50\n",
      "598/598 [==============================] - 0s 88us/sample - loss: 0.0223 - val_loss: 0.0236\n",
      "Epoch 44/50\n",
      "598/598 [==============================] - 0s 89us/sample - loss: 0.0223 - val_loss: 0.0232\n",
      "Epoch 45/50\n",
      "598/598 [==============================] - 0s 88us/sample - loss: 0.0222 - val_loss: 0.0236\n",
      "Epoch 46/50\n",
      "598/598 [==============================] - 0s 88us/sample - loss: 0.0223 - val_loss: 0.0237\n",
      "Epoch 47/50\n",
      "598/598 [==============================] - 0s 88us/sample - loss: 0.0223 - val_loss: 0.0231\n",
      "Epoch 48/50\n",
      "598/598 [==============================] - 0s 90us/sample - loss: 0.0222 - val_loss: 0.0237\n",
      "Epoch 49/50\n",
      "598/598 [==============================] - 0s 86us/sample - loss: 0.0223 - val_loss: 0.0236\n",
      "Epoch 50/50\n",
      "598/598 [==============================] - 0s 86us/sample - loss: 0.0223 - val_loss: 0.0231\n",
      "第54个数，还剩4069个没有训练\n",
      "inv_hat [1.0125828  0.99407793 1.00282612 0.997962   0.97861006 0.97187943\n",
      " 0.97957345 0.98632998 0.97668463 0.98536338 1.00965192 1.00867563\n",
      " 1.00769983 0.98923223 0.98729697 0.9815016  0.98246642 0.98343162\n",
      " 0.99699039 0.9815016  0.97861006 0.97572266 0.96612925 0.96326088\n",
      " 0.95944361 0.96708636 0.96135124 0.96039719 0.95753814 0.96517263]\n",
      "Test RMSE: 0.011\n",
      "Train on 581 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "581/581 [==============================] - 0s 86us/sample - loss: 0.0080 - val_loss: 0.0245\n",
      "Epoch 2/50\n",
      "581/581 [==============================] - 0s 88us/sample - loss: 0.0117 - val_loss: 0.0185\n",
      "Epoch 3/50\n",
      "581/581 [==============================] - 0s 86us/sample - loss: 0.0108 - val_loss: 0.0193\n",
      "Epoch 4/50\n",
      "581/581 [==============================] - 0s 87us/sample - loss: 0.0128 - val_loss: 0.0255\n",
      "Epoch 5/50\n",
      "581/581 [==============================] - 0s 83us/sample - loss: 0.0234 - val_loss: 0.0292\n",
      "Epoch 6/50\n",
      "581/581 [==============================] - 0s 82us/sample - loss: 0.0073 - val_loss: 0.0237\n",
      "Epoch 7/50\n",
      "581/581 [==============================] - 0s 86us/sample - loss: 0.0072 - val_loss: 0.0226\n",
      "Epoch 8/50\n",
      "581/581 [==============================] - 0s 87us/sample - loss: 0.0083 - val_loss: 0.0196\n",
      "Epoch 9/50\n",
      "581/581 [==============================] - 0s 85us/sample - loss: 0.0069 - val_loss: 0.0184\n",
      "Epoch 10/50\n",
      "581/581 [==============================] - 0s 85us/sample - loss: 0.0070 - val_loss: 0.0177\n",
      "Epoch 11/50\n",
      "581/581 [==============================] - 0s 85us/sample - loss: 0.0101 - val_loss: 0.0198\n",
      "Epoch 12/50\n",
      "581/581 [==============================] - 0s 88us/sample - loss: 0.0179 - val_loss: 0.0214\n",
      "Epoch 13/50\n",
      "581/581 [==============================] - 0s 87us/sample - loss: 0.0150 - val_loss: 0.0309\n",
      "Epoch 14/50\n",
      "581/581 [==============================] - 0s 86us/sample - loss: 0.0089 - val_loss: 0.0207\n",
      "Epoch 15/50\n",
      "581/581 [==============================] - 0s 88us/sample - loss: 0.0127 - val_loss: 0.0206\n",
      "Epoch 16/50\n",
      "581/581 [==============================] - 0s 87us/sample - loss: 0.0149 - val_loss: 0.0371\n",
      "Epoch 17/50\n",
      "581/581 [==============================] - 0s 88us/sample - loss: 0.0092 - val_loss: 0.0191\n",
      "Epoch 18/50\n",
      "581/581 [==============================] - 0s 92us/sample - loss: 0.0087 - val_loss: 0.0180\n",
      "Epoch 19/50\n",
      "581/581 [==============================] - 0s 91us/sample - loss: 0.0105 - val_loss: 0.0252\n",
      "Epoch 20/50\n",
      "581/581 [==============================] - 0s 94us/sample - loss: 0.0094 - val_loss: 0.0232\n",
      "Epoch 21/50\n",
      "581/581 [==============================] - 0s 94us/sample - loss: 0.0128 - val_loss: 0.0213\n",
      "Epoch 22/50\n",
      "581/581 [==============================] - 0s 93us/sample - loss: 0.0073 - val_loss: 0.0187\n",
      "Epoch 23/50\n",
      "581/581 [==============================] - 0s 96us/sample - loss: 0.0121 - val_loss: 0.0252\n",
      "Epoch 24/50\n",
      "581/581 [==============================] - 0s 90us/sample - loss: 0.0096 - val_loss: 0.0178\n",
      "Epoch 25/50\n",
      "581/581 [==============================] - 0s 92us/sample - loss: 0.0137 - val_loss: 0.0192\n",
      "Epoch 26/50\n",
      "581/581 [==============================] - 0s 95us/sample - loss: 0.0095 - val_loss: 0.0248\n",
      "Epoch 27/50\n",
      "581/581 [==============================] - 0s 91us/sample - loss: 0.0076 - val_loss: 0.0192\n",
      "Epoch 28/50\n",
      "581/581 [==============================] - 0s 88us/sample - loss: 0.0113 - val_loss: 0.0185\n",
      "Epoch 29/50\n",
      "581/581 [==============================] - 0s 89us/sample - loss: 0.0068 - val_loss: 0.0195\n",
      "Epoch 30/50\n",
      "581/581 [==============================] - 0s 92us/sample - loss: 0.0115 - val_loss: 0.0261\n",
      "Epoch 31/50\n",
      "581/581 [==============================] - 0s 86us/sample - loss: 0.0093 - val_loss: 0.0177\n",
      "Epoch 32/50\n",
      "581/581 [==============================] - 0s 86us/sample - loss: 0.0120 - val_loss: 0.0201\n",
      "Epoch 33/50\n",
      "581/581 [==============================] - 0s 86us/sample - loss: 0.0095 - val_loss: 0.0256\n",
      "Epoch 34/50\n",
      "581/581 [==============================] - 0s 96us/sample - loss: 0.0088 - val_loss: 0.0189\n",
      "Epoch 35/50\n",
      "581/581 [==============================] - 0s 92us/sample - loss: 0.0107 - val_loss: 0.0181\n",
      "Epoch 36/50\n",
      "581/581 [==============================] - 0s 92us/sample - loss: 0.0103 - val_loss: 0.0261\n",
      "Epoch 37/50\n",
      "581/581 [==============================] - 0s 94us/sample - loss: 0.0082 - val_loss: 0.0184\n",
      "Epoch 38/50\n",
      "581/581 [==============================] - 0s 92us/sample - loss: 0.0092 - val_loss: 0.0198\n",
      "Epoch 39/50\n",
      "581/581 [==============================] - 0s 88us/sample - loss: 0.0117 - val_loss: 0.0226\n",
      "Epoch 40/50\n",
      "581/581 [==============================] - 0s 85us/sample - loss: 0.0067 - val_loss: 0.0183\n",
      "Epoch 41/50\n",
      "581/581 [==============================] - 0s 92us/sample - loss: 0.0074 - val_loss: 0.0188\n",
      "Epoch 42/50\n",
      "581/581 [==============================] - 0s 88us/sample - loss: 0.0065 - val_loss: 0.0206\n",
      "Epoch 43/50\n",
      "581/581 [==============================] - 0s 89us/sample - loss: 0.0071 - val_loss: 0.0193\n",
      "Epoch 44/50\n",
      "581/581 [==============================] - 0s 87us/sample - loss: 0.0080 - val_loss: 0.0189\n",
      "Epoch 45/50\n",
      "581/581 [==============================] - 0s 86us/sample - loss: 0.0122 - val_loss: 0.0195\n",
      "Epoch 46/50\n",
      "581/581 [==============================] - 0s 86us/sample - loss: 0.0109 - val_loss: 0.0258\n",
      "Epoch 47/50\n",
      "581/581 [==============================] - 0s 87us/sample - loss: 0.0074 - val_loss: 0.0174\n",
      "Epoch 48/50\n",
      "581/581 [==============================] - 0s 87us/sample - loss: 0.0060 - val_loss: 0.0190\n",
      "Epoch 49/50\n",
      "581/581 [==============================] - 0s 89us/sample - loss: 0.0064 - val_loss: 0.0187\n",
      "Epoch 50/50\n",
      "581/581 [==============================] - 0s 85us/sample - loss: 0.0077 - val_loss: 0.0197\n",
      "第55个数，还剩4068个没有训练\n",
      "inv_hat [1.07493961 1.07493961 1.07493961 1.07493961 1.07493961 1.07591688\n",
      " 1.07591688 1.07493961 1.07591688 1.07591688 1.07591688 1.07591688\n",
      " 1.07786684 1.07786684 1.07883946 1.07981066 1.07981066 1.08078027\n",
      " 1.07925385 1.07981066 1.03902024 1.03800948 1.03800948 1.03902024\n",
      " 1.04003071 1.04003071 1.04003071 1.04003071 1.04104074 1.04205051]\n",
      "Test RMSE: 0.008\n",
      "Train on 796 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "796/796 [==============================] - 0s 85us/sample - loss: 0.0178 - val_loss: 0.0189\n",
      "Epoch 2/50\n",
      "796/796 [==============================] - ETA: 0s - loss: 0.018 - 0s 84us/sample - loss: 0.0181 - val_loss: 0.0256\n",
      "Epoch 3/50\n",
      "796/796 [==============================] - 0s 84us/sample - loss: 0.0178 - val_loss: 0.0214\n",
      "Epoch 4/50\n",
      "796/796 [==============================] - 0s 89us/sample - loss: 0.0175 - val_loss: 0.0183\n",
      "Epoch 5/50\n",
      "796/796 [==============================] - 0s 86us/sample - loss: 0.0178 - val_loss: 0.0228\n",
      "Epoch 6/50\n",
      "796/796 [==============================] - 0s 88us/sample - loss: 0.0176 - val_loss: 0.0201\n",
      "Epoch 7/50\n",
      "796/796 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0218\n",
      "Epoch 8/50\n",
      "796/796 [==============================] - 0s 88us/sample - loss: 0.0175 - val_loss: 0.0212\n",
      "Epoch 9/50\n",
      "796/796 [==============================] - 0s 89us/sample - loss: 0.0174 - val_loss: 0.0207\n",
      "Epoch 10/50\n",
      "796/796 [==============================] - 0s 84us/sample - loss: 0.0175 - val_loss: 0.0217\n",
      "Epoch 11/50\n",
      "796/796 [==============================] - 0s 81us/sample - loss: 0.0175 - val_loss: 0.0216\n",
      "Epoch 12/50\n",
      "796/796 [==============================] - 0s 85us/sample - loss: 0.0175 - val_loss: 0.0213\n",
      "Epoch 13/50\n",
      "796/796 [==============================] - 0s 87us/sample - loss: 0.0174 - val_loss: 0.0210\n",
      "Epoch 14/50\n",
      "796/796 [==============================] - 0s 90us/sample - loss: 0.0174 - val_loss: 0.0212\n",
      "Epoch 15/50\n",
      "796/796 [==============================] - 0s 90us/sample - loss: 0.0175 - val_loss: 0.0224\n",
      "Epoch 16/50\n",
      "796/796 [==============================] - 0s 84us/sample - loss: 0.0175 - val_loss: 0.0211\n",
      "Epoch 17/50\n",
      "796/796 [==============================] - 0s 92us/sample - loss: 0.0174 - val_loss: 0.0211\n",
      "Epoch 18/50\n",
      "796/796 [==============================] - 0s 87us/sample - loss: 0.0175 - val_loss: 0.0221\n",
      "Epoch 19/50\n",
      "796/796 [==============================] - 0s 89us/sample - loss: 0.0175 - val_loss: 0.0216\n",
      "Epoch 20/50\n",
      "796/796 [==============================] - 0s 86us/sample - loss: 0.0174 - val_loss: 0.0211\n",
      "Epoch 21/50\n",
      "796/796 [==============================] - 0s 85us/sample - loss: 0.0174 - val_loss: 0.0211\n",
      "Epoch 22/50\n",
      "796/796 [==============================] - 0s 82us/sample - loss: 0.0175 - val_loss: 0.0223\n",
      "Epoch 23/50\n",
      "796/796 [==============================] - 0s 85us/sample - loss: 0.0175 - val_loss: 0.0216\n",
      "Epoch 24/50\n",
      "796/796 [==============================] - 0s 89us/sample - loss: 0.0175 - val_loss: 0.0217\n",
      "Epoch 25/50\n",
      "796/796 [==============================] - 0s 82us/sample - loss: 0.0175 - val_loss: 0.0215\n",
      "Epoch 26/50\n",
      "796/796 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0215\n",
      "Epoch 27/50\n",
      "796/796 [==============================] - 0s 86us/sample - loss: 0.0175 - val_loss: 0.0225\n",
      "Epoch 28/50\n",
      "796/796 [==============================] - 0s 84us/sample - loss: 0.0175 - val_loss: 0.0218\n",
      "Epoch 29/50\n",
      "796/796 [==============================] - 0s 87us/sample - loss: 0.0175 - val_loss: 0.0215\n",
      "Epoch 30/50\n",
      "796/796 [==============================] - 0s 85us/sample - loss: 0.0174 - val_loss: 0.0215\n",
      "Epoch 31/50\n",
      "796/796 [==============================] - 0s 86us/sample - loss: 0.0175 - val_loss: 0.0223\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "796/796 [==============================] - 0s 84us/sample - loss: 0.0175 - val_loss: 0.0222\n",
      "Epoch 33/50\n",
      "796/796 [==============================] - 0s 84us/sample - loss: 0.0175 - val_loss: 0.0215\n",
      "Epoch 34/50\n",
      "796/796 [==============================] - 0s 83us/sample - loss: 0.0174 - val_loss: 0.0210\n",
      "Epoch 35/50\n",
      "796/796 [==============================] - 0s 84us/sample - loss: 0.0174 - val_loss: 0.0213\n",
      "Epoch 36/50\n",
      "796/796 [==============================] - 0s 81us/sample - loss: 0.0175 - val_loss: 0.0228\n",
      "Epoch 37/50\n",
      "796/796 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0220\n",
      "Epoch 38/50\n",
      "796/796 [==============================] - 0s 84us/sample - loss: 0.0175 - val_loss: 0.0210\n",
      "Epoch 39/50\n",
      "796/796 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0217\n",
      "Epoch 40/50\n",
      "796/796 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0224\n",
      "Epoch 41/50\n",
      "796/796 [==============================] - 0s 82us/sample - loss: 0.0175 - val_loss: 0.0222\n",
      "Epoch 42/50\n",
      "796/796 [==============================] - 0s 80us/sample - loss: 0.0175 - val_loss: 0.0215\n",
      "Epoch 43/50\n",
      "796/796 [==============================] - 0s 82us/sample - loss: 0.0174 - val_loss: 0.0213\n",
      "Epoch 44/50\n",
      "796/796 [==============================] - 0s 85us/sample - loss: 0.0175 - val_loss: 0.0219\n",
      "Epoch 45/50\n",
      "796/796 [==============================] - 0s 87us/sample - loss: 0.0176 - val_loss: 0.0231\n",
      "Epoch 46/50\n",
      "796/796 [==============================] - 0s 90us/sample - loss: 0.0175 - val_loss: 0.0217\n",
      "Epoch 47/50\n",
      "796/796 [==============================] - 0s 89us/sample - loss: 0.0174 - val_loss: 0.0207\n",
      "Epoch 48/50\n",
      "796/796 [==============================] - 0s 89us/sample - loss: 0.0175 - val_loss: 0.0221\n",
      "Epoch 49/50\n",
      "796/796 [==============================] - 0s 91us/sample - loss: 0.0175 - val_loss: 0.0223\n",
      "Epoch 50/50\n",
      "796/796 [==============================] - 0s 92us/sample - loss: 0.0175 - val_loss: 0.0218\n",
      "第56个数，还剩4067个没有训练\n",
      "inv_hat [1.10160471 1.08627462 1.08792187 1.08075568 1.05085413 1.04729864\n",
      " 1.05527857 1.07456649 0.96603893 0.9838433  0.99965324 0.9913133\n",
      " 0.99813542 0.98866388 0.98630001 0.97337514 0.98403223 0.98885303\n",
      " 0.9955756  0.97572997 0.97582421 0.96989305 0.95900059 0.95722001\n",
      " 0.93491012 0.93379431 0.92683031 0.91673944 0.9087114  0.91009387]\n",
      "Test RMSE: 0.027\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 88us/sample - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0049 - val_loss: 0.0063\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0085 - val_loss: 0.0023\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0065 - val_loss: 0.0082\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0078 - val_loss: 0.0070\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0120 - val_loss: 0.0051\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0093 - val_loss: 0.0028\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0073 - val_loss: 0.0037\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0074 - val_loss: 0.0056\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0086 - val_loss: 0.0033\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0073 - val_loss: 0.0038\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0071 - val_loss: 0.0046\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0087 - val_loss: 0.0028\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0066 - val_loss: 0.0036\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0062 - val_loss: 0.0033\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0048 - val_loss: 0.0070\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0041 - val_loss: 0.0054\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0051 - val_loss: 0.0033\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0043 - val_loss: 0.0038\n",
      "第57个数，还剩4066个没有训练\n",
      "inv_hat [1.21387359 1.21485933 1.21485933 1.21485933 1.2158445  1.2158445\n",
      " 1.21485933 1.21485933 1.21485933 1.21485933 1.21485933 1.2158445\n",
      " 1.21682882 1.21682882 1.21781258 1.21781258 1.21781258 1.21879563\n",
      " 1.21781258 1.21781258 1.21682882 1.2158445  1.2158445  1.21682882\n",
      " 1.2158445  1.21682882 1.21682882 1.21682882 1.21682882 1.21781258]\n",
      "Test RMSE: 0.001\n",
      "Train on 513 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "513/513 [==============================] - 0s 97us/sample - loss: 0.0194 - val_loss: 0.0233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "513/513 [==============================] - 0s 92us/sample - loss: 0.0187 - val_loss: 0.0234\n",
      "Epoch 3/50\n",
      "513/513 [==============================] - 0s 87us/sample - loss: 0.0184 - val_loss: 0.0235\n",
      "Epoch 4/50\n",
      "513/513 [==============================] - 0s 88us/sample - loss: 0.0184 - val_loss: 0.0233\n",
      "Epoch 5/50\n",
      "513/513 [==============================] - 0s 89us/sample - loss: 0.0184 - val_loss: 0.0233\n",
      "Epoch 6/50\n",
      "513/513 [==============================] - 0s 88us/sample - loss: 0.0184 - val_loss: 0.0233\n",
      "Epoch 7/50\n",
      "513/513 [==============================] - 0s 85us/sample - loss: 0.0184 - val_loss: 0.0233\n",
      "Epoch 8/50\n",
      "513/513 [==============================] - 0s 96us/sample - loss: 0.0184 - val_loss: 0.0233\n",
      "Epoch 9/50\n",
      "513/513 [==============================] - 0s 93us/sample - loss: 0.0184 - val_loss: 0.0233\n",
      "Epoch 10/50\n",
      "513/513 [==============================] - 0s 94us/sample - loss: 0.0184 - val_loss: 0.0233\n",
      "Epoch 11/50\n",
      "513/513 [==============================] - 0s 96us/sample - loss: 0.0184 - val_loss: 0.0233\n",
      "Epoch 12/50\n",
      "513/513 [==============================] - 0s 94us/sample - loss: 0.0184 - val_loss: 0.0233\n",
      "Epoch 13/50\n",
      "513/513 [==============================] - 0s 93us/sample - loss: 0.0184 - val_loss: 0.0233\n",
      "Epoch 14/50\n",
      "513/513 [==============================] - 0s 95us/sample - loss: 0.0184 - val_loss: 0.0234\n",
      "Epoch 15/50\n",
      "513/513 [==============================] - 0s 91us/sample - loss: 0.0183 - val_loss: 0.0234\n",
      "Epoch 16/50\n",
      "513/513 [==============================] - 0s 90us/sample - loss: 0.0183 - val_loss: 0.0234\n",
      "Epoch 17/50\n",
      "513/513 [==============================] - 0s 89us/sample - loss: 0.0183 - val_loss: 0.0235\n",
      "Epoch 18/50\n",
      "513/513 [==============================] - 0s 87us/sample - loss: 0.0183 - val_loss: 0.0236\n",
      "Epoch 19/50\n",
      "513/513 [==============================] - 0s 95us/sample - loss: 0.0183 - val_loss: 0.0235\n",
      "Epoch 20/50\n",
      "513/513 [==============================] - 0s 95us/sample - loss: 0.0183 - val_loss: 0.0236\n",
      "Epoch 21/50\n",
      "513/513 [==============================] - 0s 96us/sample - loss: 0.0183 - val_loss: 0.0237\n",
      "Epoch 22/50\n",
      "513/513 [==============================] - 0s 93us/sample - loss: 0.0183 - val_loss: 0.0236\n",
      "Epoch 23/50\n",
      "513/513 [==============================] - 0s 89us/sample - loss: 0.0183 - val_loss: 0.0237\n",
      "Epoch 24/50\n",
      "513/513 [==============================] - 0s 92us/sample - loss: 0.0183 - val_loss: 0.0238\n",
      "Epoch 25/50\n",
      "513/513 [==============================] - 0s 90us/sample - loss: 0.0183 - val_loss: 0.0238\n",
      "Epoch 26/50\n",
      "513/513 [==============================] - 0s 93us/sample - loss: 0.0183 - val_loss: 0.0238\n",
      "Epoch 27/50\n",
      "513/513 [==============================] - 0s 90us/sample - loss: 0.0183 - val_loss: 0.0239\n",
      "Epoch 28/50\n",
      "513/513 [==============================] - 0s 88us/sample - loss: 0.0183 - val_loss: 0.0240\n",
      "Epoch 29/50\n",
      "513/513 [==============================] - 0s 91us/sample - loss: 0.0183 - val_loss: 0.0239\n",
      "Epoch 30/50\n",
      "513/513 [==============================] - 0s 89us/sample - loss: 0.0183 - val_loss: 0.0242\n",
      "Epoch 31/50\n",
      "513/513 [==============================] - 0s 88us/sample - loss: 0.0183 - val_loss: 0.0241\n",
      "Epoch 32/50\n",
      "513/513 [==============================] - 0s 93us/sample - loss: 0.0183 - val_loss: 0.0240\n",
      "Epoch 33/50\n",
      "513/513 [==============================] - 0s 86us/sample - loss: 0.0183 - val_loss: 0.0243\n",
      "Epoch 34/50\n",
      "513/513 [==============================] - 0s 92us/sample - loss: 0.0183 - val_loss: 0.0244\n",
      "Epoch 35/50\n",
      "513/513 [==============================] - 0s 93us/sample - loss: 0.0182 - val_loss: 0.0243\n",
      "Epoch 36/50\n",
      "513/513 [==============================] - 0s 93us/sample - loss: 0.0183 - val_loss: 0.0244\n",
      "Epoch 37/50\n",
      "513/513 [==============================] - 0s 98us/sample - loss: 0.0183 - val_loss: 0.0246\n",
      "Epoch 38/50\n",
      "513/513 [==============================] - 0s 102us/sample - loss: 0.0182 - val_loss: 0.0247\n",
      "Epoch 39/50\n",
      "513/513 [==============================] - 0s 90us/sample - loss: 0.0183 - val_loss: 0.0247\n",
      "Epoch 40/50\n",
      "513/513 [==============================] - 0s 86us/sample - loss: 0.0182 - val_loss: 0.0252\n",
      "Epoch 41/50\n",
      "513/513 [==============================] - 0s 89us/sample - loss: 0.0182 - val_loss: 0.0248\n",
      "Epoch 42/50\n",
      "513/513 [==============================] - 0s 95us/sample - loss: 0.0182 - val_loss: 0.0254\n",
      "Epoch 43/50\n",
      "513/513 [==============================] - 0s 93us/sample - loss: 0.0183 - val_loss: 0.0255\n",
      "Epoch 44/50\n",
      "513/513 [==============================] - 0s 88us/sample - loss: 0.0182 - val_loss: 0.0254\n",
      "Epoch 45/50\n",
      "513/513 [==============================] - 0s 87us/sample - loss: 0.0183 - val_loss: 0.0255\n",
      "Epoch 46/50\n",
      "513/513 [==============================] - 0s 90us/sample - loss: 0.0182 - val_loss: 0.0257\n",
      "Epoch 47/50\n",
      "513/513 [==============================] - 0s 89us/sample - loss: 0.0182 - val_loss: 0.0256\n",
      "Epoch 48/50\n",
      "513/513 [==============================] - 0s 87us/sample - loss: 0.0182 - val_loss: 0.0260\n",
      "Epoch 49/50\n",
      "513/513 [==============================] - 0s 96us/sample - loss: 0.0183 - val_loss: 0.0260\n",
      "Epoch 50/50\n",
      "513/513 [==============================] - 0s 94us/sample - loss: 0.0182 - val_loss: 0.0263\n",
      "第58个数，还剩4065个没有训练\n",
      "inv_hat [1.09831571 1.09233028 1.09532525 1.09931152 1.08131403 1.08532559\n",
      " 1.08332056 1.08833019 1.09233028 1.10030664 1.11909652 1.13082771\n",
      " 1.12985474 1.12301974 1.13082771 1.13179996 1.13179996 1.13277124\n",
      " 1.13471135 1.12301974 1.12204016 1.12204016 1.12007852 1.12204016\n",
      " 1.12497675 1.12497675 1.12497675 1.12790595 1.12985474 1.13374173]\n",
      "Test RMSE: 0.007\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0079 - val_loss: 0.0027\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 88us/sample - loss: 0.0098 - val_loss: 0.0043\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0075\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0051\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0171 - val_loss: 0.0067\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0125 - val_loss: 0.0027\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0141 - val_loss: 0.0026\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0108 - val_loss: 0.0037\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0101 - val_loss: 0.0050\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0137 - val_loss: 0.0031\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0121 - val_loss: 0.0087\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0140 - val_loss: 0.0051\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0048\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0166 - val_loss: 0.0065\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0119 - val_loss: 0.0040\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0117 - val_loss: 0.0058\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0157 - val_loss: 0.0067\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0041\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0026\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0157 - val_loss: 0.0067\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0094 - val_loss: 0.0027\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0107 - val_loss: 0.0058\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0155 - val_loss: 0.0207\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0134 - val_loss: 0.0036\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0139 - val_loss: 0.0045\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0105 - val_loss: 0.0046\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0069\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0050\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0027\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0164 - val_loss: 0.0075\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0088 - val_loss: 0.0027\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0099 - val_loss: 0.0041\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0135 - val_loss: 0.0146\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0134 - val_loss: 0.0034\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0136 - val_loss: 0.0070\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0113 - val_loss: 0.0061\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0153 - val_loss: 0.0056\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0048\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0108 - val_loss: 0.0035\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0159 - val_loss: 0.0062\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0086 - val_loss: 0.0029\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0098 - val_loss: 0.0054\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0147 - val_loss: 0.0162\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0115 - val_loss: 0.0029\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0138 - val_loss: 0.0051\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0102 - val_loss: 0.0045\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0145 - val_loss: 0.0069\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0058\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0028\n",
      "第59个数，还剩4064个没有训练\n",
      "inv_hat [1.17132288 1.16049864 1.16148216 1.15754865 1.15066901 1.14968669\n",
      " 1.14968669 1.15558257 1.14968669 1.15165155 1.16443335 1.16541723\n",
      " 1.16738546 1.16049864 1.15754865 1.15361682 1.15361682 1.15558257\n",
      " 1.16344951 1.15558257 1.14968669 1.14281269 1.13496304 1.13006045\n",
      " 1.12418093 1.12810015 1.12810015 1.12614032 1.12614032 1.12810015]\n",
      "Test RMSE: 0.006\n",
      "Train on 736 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "736/736 [==============================] - 0s 82us/sample - loss: 0.0170 - val_loss: 0.0042\n",
      "Epoch 2/50\n",
      "736/736 [==============================] - 0s 89us/sample - loss: 0.0139 - val_loss: 0.0032\n",
      "Epoch 3/50\n",
      "736/736 [==============================] - 0s 83us/sample - loss: 0.0147 - val_loss: 0.0045\n",
      "Epoch 4/50\n",
      "736/736 [==============================] - 0s 83us/sample - loss: 0.0144 - val_loss: 0.0035\n",
      "Epoch 5/50\n",
      "736/736 [==============================] - 0s 92us/sample - loss: 0.0144 - val_loss: 0.0036\n",
      "Epoch 6/50\n",
      "736/736 [==============================] - 0s 93us/sample - loss: 0.0139 - val_loss: 0.0035\n",
      "Epoch 7/50\n",
      "736/736 [==============================] - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0045\n",
      "Epoch 8/50\n",
      "736/736 [==============================] - 0s 85us/sample - loss: 0.0140 - val_loss: 0.0040\n",
      "Epoch 9/50\n",
      "736/736 [==============================] - 0s 87us/sample - loss: 0.0140 - val_loss: 0.0046\n",
      "Epoch 10/50\n",
      "736/736 [==============================] - 0s 88us/sample - loss: 0.0139 - val_loss: 0.0039\n",
      "Epoch 11/50\n",
      "736/736 [==============================] - 0s 91us/sample - loss: 0.0140 - val_loss: 0.0043\n",
      "Epoch 12/50\n",
      "736/736 [==============================] - 0s 84us/sample - loss: 0.0141 - val_loss: 0.0038\n",
      "Epoch 13/50\n",
      "736/736 [==============================] - 0s 86us/sample - loss: 0.0140 - val_loss: 0.0044\n",
      "Epoch 14/50\n",
      "736/736 [==============================] - 0s 92us/sample - loss: 0.0140 - val_loss: 0.0041\n",
      "Epoch 15/50\n",
      "736/736 [==============================] - 0s 89us/sample - loss: 0.0139 - val_loss: 0.0036\n",
      "Epoch 16/50\n",
      "736/736 [==============================] - 0s 83us/sample - loss: 0.0140 - val_loss: 0.0044\n",
      "Epoch 17/50\n",
      "736/736 [==============================] - 0s 83us/sample - loss: 0.0141 - val_loss: 0.0038\n",
      "Epoch 18/50\n",
      "736/736 [==============================] - 0s 80us/sample - loss: 0.0140 - val_loss: 0.0047\n",
      "Epoch 19/50\n",
      "736/736 [==============================] - 0s 82us/sample - loss: 0.0140 - val_loss: 0.0037\n",
      "Epoch 20/50\n",
      "736/736 [==============================] - 0s 87us/sample - loss: 0.0140 - val_loss: 0.0046\n",
      "Epoch 21/50\n",
      "736/736 [==============================] - 0s 83us/sample - loss: 0.0139 - val_loss: 0.0037\n",
      "Epoch 22/50\n",
      "736/736 [==============================] - 0s 89us/sample - loss: 0.0140 - val_loss: 0.0044\n",
      "Epoch 23/50\n",
      "736/736 [==============================] - 0s 85us/sample - loss: 0.0138 - val_loss: 0.0037\n",
      "Epoch 24/50\n",
      "736/736 [==============================] - 0s 89us/sample - loss: 0.0141 - val_loss: 0.0047\n",
      "Epoch 25/50\n",
      "736/736 [==============================] - 0s 82us/sample - loss: 0.0140 - val_loss: 0.0036\n",
      "Epoch 26/50\n",
      "736/736 [==============================] - 0s 82us/sample - loss: 0.0140 - val_loss: 0.0044\n",
      "Epoch 27/50\n",
      "736/736 [==============================] - 0s 78us/sample - loss: 0.0138 - val_loss: 0.0038\n",
      "Epoch 28/50\n",
      "736/736 [==============================] - 0s 82us/sample - loss: 0.0141 - val_loss: 0.0046\n",
      "Epoch 29/50\n",
      "736/736 [==============================] - 0s 85us/sample - loss: 0.0140 - val_loss: 0.0038\n",
      "Epoch 30/50\n",
      "736/736 [==============================] - 0s 85us/sample - loss: 0.0140 - val_loss: 0.0043\n",
      "Epoch 31/50\n",
      "736/736 [==============================] - 0s 89us/sample - loss: 0.0138 - val_loss: 0.0038\n",
      "Epoch 32/50\n",
      "736/736 [==============================] - 0s 86us/sample - loss: 0.0140 - val_loss: 0.0045\n",
      "Epoch 33/50\n",
      "736/736 [==============================] - 0s 86us/sample - loss: 0.0141 - val_loss: 0.0036\n",
      "Epoch 34/50\n",
      "736/736 [==============================] - 0s 84us/sample - loss: 0.0139 - val_loss: 0.0045\n",
      "Epoch 35/50\n",
      "736/736 [==============================] - 0s 87us/sample - loss: 0.0140 - val_loss: 0.0036\n",
      "Epoch 36/50\n",
      "736/736 [==============================] - 0s 80us/sample - loss: 0.0140 - val_loss: 0.0047\n",
      "Epoch 37/50\n",
      "736/736 [==============================] - 0s 87us/sample - loss: 0.0139 - val_loss: 0.0036\n",
      "Epoch 38/50\n",
      "736/736 [==============================] - 0s 84us/sample - loss: 0.0140 - val_loss: 0.0042\n",
      "Epoch 39/50\n",
      "736/736 [==============================] - 0s 83us/sample - loss: 0.0138 - val_loss: 0.0038\n",
      "Epoch 40/50\n",
      "736/736 [==============================] - 0s 82us/sample - loss: 0.0139 - val_loss: 0.0041\n",
      "Epoch 41/50\n",
      "736/736 [==============================] - 0s 82us/sample - loss: 0.0141 - val_loss: 0.0034\n",
      "Epoch 42/50\n",
      "736/736 [==============================] - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0045\n",
      "Epoch 43/50\n",
      "736/736 [==============================] - 0s 85us/sample - loss: 0.0140 - val_loss: 0.0037\n",
      "Epoch 44/50\n",
      "736/736 [==============================] - 0s 81us/sample - loss: 0.0139 - val_loss: 0.0044\n",
      "Epoch 45/50\n",
      "736/736 [==============================] - 0s 81us/sample - loss: 0.0138 - val_loss: 0.0039\n",
      "Epoch 46/50\n",
      "736/736 [==============================] - 0s 82us/sample - loss: 0.0139 - val_loss: 0.0044\n",
      "Epoch 47/50\n",
      "736/736 [==============================] - 0s 84us/sample - loss: 0.0141 - val_loss: 0.0038\n",
      "Epoch 48/50\n",
      "736/736 [==============================] - 0s 79us/sample - loss: 0.0139 - val_loss: 0.0043\n",
      "Epoch 49/50\n",
      "736/736 [==============================] - 0s 82us/sample - loss: 0.0140 - val_loss: 0.0045\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736/736 [==============================] - 0s 83us/sample - loss: 0.0139 - val_loss: 0.0037\n",
      "第60个数，还剩4063个没有训练\n",
      "inv_hat [1.23128489 1.23128489 1.23128489 1.23128489 1.23128489 1.23128489\n",
      " 1.23128489 1.23028714 1.23128489 1.23128489 1.23128489 1.23128489\n",
      " 1.23028714 1.23128489 1.23128489 1.23228221 1.23228221 1.23228221\n",
      " 1.23128489 1.23128489 1.23028714 1.23028714 1.23128489 1.23128489\n",
      " 1.23228221 1.23327897 1.23427502 1.23527058 1.23527058 1.23626543]\n",
      "Test RMSE: 0.001\n",
      "Train on 692 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "692/692 [==============================] - 0s 83us/sample - loss: 0.0154 - val_loss: 0.0051\n",
      "Epoch 2/50\n",
      "692/692 [==============================] - 0s 82us/sample - loss: 0.0159 - val_loss: 0.0058\n",
      "Epoch 3/50\n",
      "692/692 [==============================] - 0s 80us/sample - loss: 0.0185 - val_loss: 0.0069\n",
      "Epoch 4/50\n",
      "692/692 [==============================] - 0s 83us/sample - loss: 0.0150 - val_loss: 0.0081\n",
      "Epoch 5/50\n",
      "692/692 [==============================] - 0s 87us/sample - loss: 0.0180 - val_loss: 0.0116\n",
      "Epoch 6/50\n",
      "692/692 [==============================] - 0s 89us/sample - loss: 0.0157 - val_loss: 0.0057\n",
      "Epoch 7/50\n",
      "692/692 [==============================] - 0s 88us/sample - loss: 0.0169 - val_loss: 0.0079\n",
      "Epoch 8/50\n",
      "692/692 [==============================] - 0s 83us/sample - loss: 0.0189 - val_loss: 0.0060\n",
      "Epoch 9/50\n",
      "692/692 [==============================] - 0s 89us/sample - loss: 0.0192 - val_loss: 0.0163\n",
      "Epoch 10/50\n",
      "692/692 [==============================] - 0s 83us/sample - loss: 0.0182 - val_loss: 0.0118\n",
      "Epoch 11/50\n",
      "692/692 [==============================] - 0s 84us/sample - loss: 0.0160 - val_loss: 0.0059\n",
      "Epoch 12/50\n",
      "692/692 [==============================] - 0s 84us/sample - loss: 0.0174 - val_loss: 0.0057\n",
      "Epoch 13/50\n",
      "692/692 [==============================] - 0s 84us/sample - loss: 0.0175 - val_loss: 0.0132\n",
      "Epoch 14/50\n",
      "692/692 [==============================] - 0s 87us/sample - loss: 0.0169 - val_loss: 0.0092\n",
      "Epoch 15/50\n",
      "692/692 [==============================] - 0s 84us/sample - loss: 0.0159 - val_loss: 0.0059\n",
      "Epoch 16/50\n",
      "692/692 [==============================] - 0s 85us/sample - loss: 0.0171 - val_loss: 0.0055\n",
      "Epoch 17/50\n",
      "692/692 [==============================] - 0s 79us/sample - loss: 0.0180 - val_loss: 0.0152\n",
      "Epoch 18/50\n",
      "692/692 [==============================] - 0s 81us/sample - loss: 0.0160 - val_loss: 0.0080\n",
      "Epoch 19/50\n",
      "692/692 [==============================] - 0s 84us/sample - loss: 0.0154 - val_loss: 0.0061\n",
      "Epoch 20/50\n",
      "692/692 [==============================] - 0s 78us/sample - loss: 0.0161 - val_loss: 0.0052\n",
      "Epoch 21/50\n",
      "692/692 [==============================] - 0s 78us/sample - loss: 0.0169 - val_loss: 0.0132\n",
      "Epoch 22/50\n",
      "692/692 [==============================] - 0s 81us/sample - loss: 0.0155 - val_loss: 0.0067\n",
      "Epoch 23/50\n",
      "692/692 [==============================] - 0s 84us/sample - loss: 0.0154 - val_loss: 0.0061\n",
      "Epoch 24/50\n",
      "692/692 [==============================] - 0s 79us/sample - loss: 0.0158 - val_loss: 0.0051\n",
      "Epoch 25/50\n",
      "692/692 [==============================] - 0s 80us/sample - loss: 0.0166 - val_loss: 0.0127\n",
      "Epoch 26/50\n",
      "692/692 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0071\n",
      "Epoch 27/50\n",
      "692/692 [==============================] - 0s 87us/sample - loss: 0.0151 - val_loss: 0.0058\n",
      "Epoch 28/50\n",
      "692/692 [==============================] - 0s 87us/sample - loss: 0.0165 - val_loss: 0.0056\n",
      "Epoch 29/50\n",
      "692/692 [==============================] - 0s 86us/sample - loss: 0.0170 - val_loss: 0.0129\n",
      "Epoch 30/50\n",
      "692/692 [==============================] - 0s 85us/sample - loss: 0.0156 - val_loss: 0.0073\n",
      "Epoch 31/50\n",
      "692/692 [==============================] - 0s 83us/sample - loss: 0.0153 - val_loss: 0.0060\n",
      "Epoch 32/50\n",
      "692/692 [==============================] - 0s 79us/sample - loss: 0.0157 - val_loss: 0.0051\n",
      "Epoch 33/50\n",
      "692/692 [==============================] - 0s 77us/sample - loss: 0.0163 - val_loss: 0.0117\n",
      "Epoch 34/50\n",
      "692/692 [==============================] - 0s 80us/sample - loss: 0.0155 - val_loss: 0.0067\n",
      "Epoch 35/50\n",
      "692/692 [==============================] - 0s 83us/sample - loss: 0.0154 - val_loss: 0.0061\n",
      "Epoch 36/50\n",
      "692/692 [==============================] - 0s 84us/sample - loss: 0.0156 - val_loss: 0.0053\n",
      "Epoch 37/50\n",
      "692/692 [==============================] - 0s 82us/sample - loss: 0.0161 - val_loss: 0.0113\n",
      "Epoch 38/50\n",
      "692/692 [==============================] - 0s 80us/sample - loss: 0.0155 - val_loss: 0.0066\n",
      "Epoch 39/50\n",
      "692/692 [==============================] - 0s 84us/sample - loss: 0.0157 - val_loss: 0.0066\n",
      "Epoch 40/50\n",
      "692/692 [==============================] - 0s 84us/sample - loss: 0.0152 - val_loss: 0.0056\n",
      "Epoch 41/50\n",
      "692/692 [==============================] - 0s 84us/sample - loss: 0.0157 - val_loss: 0.0103\n",
      "Epoch 42/50\n",
      "692/692 [==============================] - 0s 85us/sample - loss: 0.0150 - val_loss: 0.0052\n",
      "Epoch 43/50\n",
      "692/692 [==============================] - 0s 86us/sample - loss: 0.0152 - val_loss: 0.0061\n",
      "Epoch 44/50\n",
      "692/692 [==============================] - 0s 82us/sample - loss: 0.0165 - val_loss: 0.0058\n",
      "Epoch 45/50\n",
      "692/692 [==============================] - 0s 82us/sample - loss: 0.0167 - val_loss: 0.0123\n",
      "Epoch 46/50\n",
      "692/692 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0075\n",
      "Epoch 47/50\n",
      "692/692 [==============================] - 0s 84us/sample - loss: 0.0152 - val_loss: 0.0060\n",
      "Epoch 48/50\n",
      "692/692 [==============================] - 0s 85us/sample - loss: 0.0154 - val_loss: 0.0053\n",
      "Epoch 49/50\n",
      "692/692 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0101\n",
      "Epoch 50/50\n",
      "692/692 [==============================] - 0s 82us/sample - loss: 0.0158 - val_loss: 0.0071\n",
      "第61个数，还剩4062个没有训练\n",
      "inv_hat [0.84921412 0.84237812 0.84237812 0.84335218 0.84043251 0.84043251\n",
      " 0.83849044 0.83849044 0.83365078 0.83268559 0.8365519  0.84043251\n",
      " 0.83752072 0.83268559 0.83268559 0.83268559 0.83268559 0.83268559\n",
      " 0.83268559 0.83075794 0.82979525 0.82979525 0.82979525 0.82979525\n",
      " 0.82979525 0.82979525 0.82979525 0.82882747 0.82882747 0.82882747]\n",
      "Test RMSE: 0.003\n",
      "Train on 994 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "994/994 [==============================] - 0s 81us/sample - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 2/50\n",
      "994/994 [==============================] - 0s 78us/sample - loss: 0.0082 - val_loss: 0.0053\n",
      "Epoch 3/50\n",
      "994/994 [==============================] - 0s 77us/sample - loss: 0.0112 - val_loss: 0.0023\n",
      "Epoch 4/50\n",
      "994/994 [==============================] - 0s 80us/sample - loss: 0.0119 - val_loss: 0.0032\n",
      "Epoch 5/50\n",
      "994/994 [==============================] - 0s 76us/sample - loss: 0.0164 - val_loss: 0.0290\n",
      "Epoch 6/50\n",
      "994/994 [==============================] - 0s 81us/sample - loss: 0.0103 - val_loss: 0.0041\n",
      "Epoch 7/50\n",
      "994/994 [==============================] - 0s 82us/sample - loss: 0.0058 - val_loss: 0.0102\n",
      "Epoch 8/50\n",
      "994/994 [==============================] - 0s 81us/sample - loss: 0.0061 - val_loss: 0.0014\n",
      "Epoch 9/50\n",
      "994/994 [==============================] - 0s 77us/sample - loss: 0.0124 - val_loss: 0.0038\n",
      "Epoch 10/50\n",
      "994/994 [==============================] - 0s 76us/sample - loss: 0.0124 - val_loss: 0.0215\n",
      "Epoch 11/50\n",
      "994/994 [==============================] - 0s 77us/sample - loss: 0.0096 - val_loss: 0.0024\n",
      "Epoch 12/50\n",
      "994/994 [==============================] - 0s 75us/sample - loss: 0.0049 - val_loss: 0.0023\n",
      "Epoch 13/50\n",
      "994/994 [==============================] - 0s 75us/sample - loss: 0.0052 - val_loss: 0.0022\n",
      "Epoch 14/50\n",
      "994/994 [==============================] - 0s 76us/sample - loss: 0.0070 - val_loss: 0.0015\n",
      "Epoch 15/50\n",
      "994/994 [==============================] - 0s 75us/sample - loss: 0.0124 - val_loss: 0.0026\n",
      "Epoch 16/50\n",
      "994/994 [==============================] - 0s 77us/sample - loss: 0.0197 - val_loss: 0.0022\n",
      "Epoch 17/50\n",
      "994/994 [==============================] - 0s 85us/sample - loss: 0.0076 - val_loss: 0.0124\n",
      "Epoch 18/50\n",
      "994/994 [==============================] - 0s 86us/sample - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 19/50\n",
      "994/994 [==============================] - 0s 83us/sample - loss: 0.0178 - val_loss: 0.0152\n",
      "Epoch 20/50\n",
      "994/994 [==============================] - 0s 83us/sample - loss: 0.0119 - val_loss: 0.0028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50\n",
      "994/994 [==============================] - 0s 81us/sample - loss: 0.0115 - val_loss: 0.0167\n",
      "Epoch 22/50\n",
      "994/994 [==============================] - 0s 79us/sample - loss: 0.0102 - val_loss: 0.0010\n",
      "Epoch 23/50\n",
      "994/994 [==============================] - 0s 85us/sample - loss: 0.0058 - val_loss: 0.0094\n",
      "Epoch 24/50\n",
      "994/994 [==============================] - 0s 76us/sample - loss: 0.0089 - val_loss: 0.0019\n",
      "Epoch 25/50\n",
      "994/994 [==============================] - 0s 82us/sample - loss: 0.0199 - val_loss: 0.0215\n",
      "Epoch 26/50\n",
      "994/994 [==============================] - 0s 83us/sample - loss: 0.0048 - val_loss: 0.0015\n",
      "Epoch 27/50\n",
      "994/994 [==============================] - 0s 79us/sample - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 28/50\n",
      "994/994 [==============================] - 0s 79us/sample - loss: 0.0123 - val_loss: 0.0096\n",
      "Epoch 29/50\n",
      "994/994 [==============================] - 0s 80us/sample - loss: 0.0069 - val_loss: 0.0053\n",
      "Epoch 30/50\n",
      "994/994 [==============================] - 0s 76us/sample - loss: 0.0055 - val_loss: 0.0022\n",
      "Epoch 31/50\n",
      "994/994 [==============================] - 0s 81us/sample - loss: 0.0173 - val_loss: 0.0016\n",
      "Epoch 32/50\n",
      "994/994 [==============================] - 0s 86us/sample - loss: 0.0079 - val_loss: 0.0051\n",
      "Epoch 33/50\n",
      "994/994 [==============================] - 0s 83us/sample - loss: 0.0167 - val_loss: 0.0202\n",
      "Epoch 34/50\n",
      "994/994 [==============================] - 0s 80us/sample - loss: 0.0119 - val_loss: 0.0053\n",
      "Epoch 35/50\n",
      "994/994 [==============================] - 0s 80us/sample - loss: 0.0154 - val_loss: 0.0152\n",
      "Epoch 36/50\n",
      "994/994 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0035\n",
      "Epoch 37/50\n",
      "994/994 [==============================] - 0s 77us/sample - loss: 0.0103 - val_loss: 0.0123\n",
      "Epoch 38/50\n",
      "994/994 [==============================] - 0s 80us/sample - loss: 0.0044 - val_loss: 0.0017\n",
      "Epoch 39/50\n",
      "994/994 [==============================] - 0s 79us/sample - loss: 0.0079 - val_loss: 0.0015\n",
      "Epoch 40/50\n",
      "994/994 [==============================] - 0s 79us/sample - loss: 0.0163 - val_loss: 0.0042\n",
      "Epoch 41/50\n",
      "994/994 [==============================] - 0s 79us/sample - loss: 0.0065 - val_loss: 0.0142\n",
      "Epoch 42/50\n",
      "994/994 [==============================] - 0s 80us/sample - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 43/50\n",
      "994/994 [==============================] - 0s 83us/sample - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 44/50\n",
      "994/994 [==============================] - 0s 84us/sample - loss: 0.0127 - val_loss: 0.0066\n",
      "Epoch 45/50\n",
      "994/994 [==============================] - 0s 80us/sample - loss: 0.0105 - val_loss: 0.0138\n",
      "Epoch 46/50\n",
      "994/994 [==============================] - 0s 82us/sample - loss: 0.0109 - val_loss: 0.0038\n",
      "Epoch 47/50\n",
      "994/994 [==============================] - 0s 80us/sample - loss: 0.0091 - val_loss: 0.0131\n",
      "Epoch 48/50\n",
      "994/994 [==============================] - 0s 82us/sample - loss: 0.0050 - val_loss: 0.0011\n",
      "Epoch 49/50\n",
      "994/994 [==============================] - 0s 81us/sample - loss: 0.0071 - val_loss: 0.0117\n",
      "Epoch 50/50\n",
      "994/994 [==============================] - 0s 79us/sample - loss: 0.0168 - val_loss: 0.0089\n",
      "第62个数，还剩4061个没有训练\n",
      "inv_hat [0.80694572 0.80694572 0.80598934 0.80598934 0.80598934 0.80598934\n",
      " 0.80598934 0.80503338 0.80598934 0.80598934 0.80503338 0.80503338\n",
      " 0.80503338 0.80503338 0.80503338 0.80503338 0.80503338 0.80503338\n",
      " 0.80407786 0.80407786 0.80216805 0.80312277 0.80312277 0.80312277\n",
      " 0.80312277 0.80312277 0.80312277 0.80407786 0.80407786 0.80598934]\n",
      "Test RMSE: 0.005\n",
      "Train on 575 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "575/575 [==============================] - 0s 79us/sample - loss: 0.0121 - val_loss: 0.0072\n",
      "Epoch 2/50\n",
      "575/575 [==============================] - 0s 78us/sample - loss: 0.0176 - val_loss: 0.0149\n",
      "Epoch 3/50\n",
      "575/575 [==============================] - 0s 82us/sample - loss: 0.0100 - val_loss: 0.0072\n",
      "Epoch 4/50\n",
      "575/575 [==============================] - 0s 81us/sample - loss: 0.0103 - val_loss: 0.0072\n",
      "Epoch 5/50\n",
      "575/575 [==============================] - 0s 84us/sample - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 6/50\n",
      "575/575 [==============================] - 0s 83us/sample - loss: 0.0109 - val_loss: 0.0073\n",
      "Epoch 7/50\n",
      "575/575 [==============================] - 0s 82us/sample - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 8/50\n",
      "575/575 [==============================] - 0s 86us/sample - loss: 0.0092 - val_loss: 0.0071\n",
      "Epoch 9/50\n",
      "575/575 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0081\n",
      "Epoch 10/50\n",
      "575/575 [==============================] - 0s 76us/sample - loss: 0.0095 - val_loss: 0.0083\n",
      "Epoch 11/50\n",
      "575/575 [==============================] - 0s 78us/sample - loss: 0.0092 - val_loss: 0.0072\n",
      "Epoch 12/50\n",
      "575/575 [==============================] - 0s 80us/sample - loss: 0.0106 - val_loss: 0.0073\n",
      "Epoch 13/50\n",
      "575/575 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0081\n",
      "Epoch 14/50\n",
      "575/575 [==============================] - 0s 80us/sample - loss: 0.0090 - val_loss: 0.0090\n",
      "Epoch 15/50\n",
      "575/575 [==============================] - 0s 81us/sample - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 16/50\n",
      "575/575 [==============================] - 0s 80us/sample - loss: 0.0105 - val_loss: 0.0072\n",
      "Epoch 17/50\n",
      "575/575 [==============================] - 0s 81us/sample - loss: 0.0094 - val_loss: 0.0093\n",
      "Epoch 18/50\n",
      "575/575 [==============================] - 0s 84us/sample - loss: 0.0098 - val_loss: 0.0072\n",
      "Epoch 19/50\n",
      "575/575 [==============================] - 0s 83us/sample - loss: 0.0100 - val_loss: 0.0073\n",
      "Epoch 20/50\n",
      "575/575 [==============================] - 0s 79us/sample - loss: 0.0101 - val_loss: 0.0093\n",
      "Epoch 21/50\n",
      "575/575 [==============================] - 0s 76us/sample - loss: 0.0101 - val_loss: 0.0073\n",
      "Epoch 22/50\n",
      "575/575 [==============================] - 0s 78us/sample - loss: 0.0100 - val_loss: 0.0078\n",
      "Epoch 23/50\n",
      "575/575 [==============================] - 0s 81us/sample - loss: 0.0093 - val_loss: 0.0071\n",
      "Epoch 24/50\n",
      "575/575 [==============================] - 0s 78us/sample - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 25/50\n",
      "575/575 [==============================] - 0s 89us/sample - loss: 0.0112 - val_loss: 0.0074\n",
      "Epoch 26/50\n",
      "575/575 [==============================] - 0s 86us/sample - loss: 0.0096 - val_loss: 0.0073\n",
      "Epoch 27/50\n",
      "575/575 [==============================] - 0s 82us/sample - loss: 0.0088 - val_loss: 0.0074\n",
      "Epoch 28/50\n",
      "575/575 [==============================] - 0s 81us/sample - loss: 0.0091 - val_loss: 0.0084\n",
      "Epoch 29/50\n",
      "575/575 [==============================] - 0s 77us/sample - loss: 0.0096 - val_loss: 0.0074\n",
      "Epoch 30/50\n",
      "575/575 [==============================] - 0s 80us/sample - loss: 0.0106 - val_loss: 0.0088\n",
      "Epoch 31/50\n",
      "575/575 [==============================] - 0s 77us/sample - loss: 0.0090 - val_loss: 0.0087\n",
      "Epoch 32/50\n",
      "575/575 [==============================] - 0s 77us/sample - loss: 0.0091 - val_loss: 0.0074\n",
      "Epoch 33/50\n",
      "575/575 [==============================] - 0s 78us/sample - loss: 0.0101 - val_loss: 0.0073\n",
      "Epoch 34/50\n",
      "575/575 [==============================] - 0s 76us/sample - loss: 0.0102 - val_loss: 0.0073\n",
      "Epoch 35/50\n",
      "575/575 [==============================] - 0s 79us/sample - loss: 0.0087 - val_loss: 0.0089\n",
      "Epoch 36/50\n",
      "575/575 [==============================] - 0s 77us/sample - loss: 0.0100 - val_loss: 0.0072\n",
      "Epoch 37/50\n",
      "575/575 [==============================] - 0s 76us/sample - loss: 0.0096 - val_loss: 0.0072\n",
      "Epoch 38/50\n",
      "575/575 [==============================] - 0s 75us/sample - loss: 0.0094 - val_loss: 0.0073\n",
      "Epoch 39/50\n",
      "575/575 [==============================] - 0s 76us/sample - loss: 0.0088 - val_loss: 0.0073\n",
      "Epoch 40/50\n",
      "575/575 [==============================] - 0s 80us/sample - loss: 0.0092 - val_loss: 0.0078\n",
      "Epoch 41/50\n",
      "575/575 [==============================] - 0s 80us/sample - loss: 0.0096 - val_loss: 0.0073\n",
      "Epoch 42/50\n",
      "575/575 [==============================] - 0s 78us/sample - loss: 0.0099 - val_loss: 0.0077\n",
      "Epoch 43/50\n",
      "575/575 [==============================] - 0s 81us/sample - loss: 0.0090 - val_loss: 0.0072\n",
      "Epoch 44/50\n",
      "575/575 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0073\n",
      "Epoch 45/50\n",
      "575/575 [==============================] - 0s 77us/sample - loss: 0.0099 - val_loss: 0.0088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "575/575 [==============================] - 0s 80us/sample - loss: 0.0102 - val_loss: 0.0074\n",
      "Epoch 47/50\n",
      "575/575 [==============================] - 0s 79us/sample - loss: 0.0100 - val_loss: 0.0082\n",
      "Epoch 48/50\n",
      "575/575 [==============================] - 0s 79us/sample - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 49/50\n",
      "575/575 [==============================] - 0s 87us/sample - loss: 0.0092 - val_loss: 0.0091\n",
      "Epoch 50/50\n",
      "575/575 [==============================] - 0s 85us/sample - loss: 0.0099 - val_loss: 0.0072\n",
      "第63个数，还剩4060个没有训练\n",
      "inv_hat [1.10743875 1.1084044  1.1084044  1.1084044  1.10936829 1.10936829\n",
      " 1.1084044  1.1084044  1.10936829 1.10936829 1.10936829 1.11033062\n",
      " 1.11033062 1.11225003 1.11225003 1.1132072  1.1132072  1.11416249\n",
      " 1.11225003 1.11129114 1.1084044  1.10936829 1.11033062 1.11225003\n",
      " 1.11129114 1.11129114 1.11225003 1.1132072  1.11416249 1.11606788]\n",
      "Test RMSE: 0.001\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0100 - val_loss: 0.0128\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0101 - val_loss: 0.0132\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0110\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0099 - val_loss: 0.0111\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0099 - val_loss: 0.0118\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0098 - val_loss: 0.0121\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0098 - val_loss: 0.0115\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0098 - val_loss: 0.0116\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0098 - val_loss: 0.0116\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0098 - val_loss: 0.0119\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0098 - val_loss: 0.0119\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0098 - val_loss: 0.0119\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0098 - val_loss: 0.0118\n",
      "第64个数，还剩4059个没有训练\n",
      "inv_hat [1.94859592 1.91368527 1.92181711 1.9099696  1.87096148 1.8683568\n",
      " 1.87206349 1.89731123 1.87036062 1.8853825  1.9344592  1.92944346\n",
      " 1.92593178 1.88618338 1.8824789  1.86975938 1.88768504 1.88848573\n",
      " 1.91278161 1.87166282 1.85603073 1.83587543 1.80747274 1.79913765\n",
      " 1.78145641 1.80084497 1.79943887 1.78969528 1.77683366 1.78627936]\n",
      "Test RMSE: 0.023\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0091 - val_loss: 0.0057\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0097 - val_loss: 0.0052\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0102 - val_loss: 0.0052\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0053\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0095 - val_loss: 0.0055\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0095 - val_loss: 0.0054\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0052\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0098 - val_loss: 0.0053\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0095 - val_loss: 0.0055\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0095 - val_loss: 0.0054\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0100 - val_loss: 0.0052\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - ETA: 0s - loss: 0.013 - 0s 84us/sample - loss: 0.0098 - val_loss: 0.0053\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0096 - val_loss: 0.0053\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0097 - val_loss: 0.0052\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0099 - val_loss: 0.0052\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0099 - val_loss: 0.0053\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0097 - val_loss: 0.0054\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0096 - val_loss: 0.0053\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0097 - val_loss: 0.0052\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0097 - val_loss: 0.0052\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0097 - val_loss: 0.0052\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0098 - val_loss: 0.0052\n",
      "第65个数，还剩4058个没有训练\n",
      "inv_hat [0.8281356  0.81069959 0.82043723 0.82569888 0.80456899 0.80252619\n",
      " 0.8040826  0.80943431 0.7992196  0.806223   0.82803812 0.83671683\n",
      " 0.84061931 0.81702815 0.79513621 0.78483716 0.78988839 0.78716818\n",
      " 0.79455301 0.77561486 0.76795167 0.76387977 0.74760751 0.74567196\n",
      " 0.73812687 0.74886577 0.74751071 0.74509139 0.7383203  0.74006103]\n",
      "Test RMSE: 0.011\n",
      "Train on 673 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "673/673 [==============================] - 0s 86us/sample - loss: 0.0151 - val_loss: 0.0107\n",
      "Epoch 2/50\n",
      "673/673 [==============================] - 0s 84us/sample - loss: 0.0161 - val_loss: 0.0104\n",
      "Epoch 3/50\n",
      "673/673 [==============================] - 0s 88us/sample - loss: 0.0168 - val_loss: 0.0104\n",
      "Epoch 4/50\n",
      "673/673 [==============================] - 0s 92us/sample - loss: 0.0156 - val_loss: 0.0105\n",
      "Epoch 5/50\n",
      "673/673 [==============================] - 0s 87us/sample - loss: 0.0153 - val_loss: 0.0104\n",
      "Epoch 6/50\n",
      "673/673 [==============================] - 0s 81us/sample - loss: 0.0154 - val_loss: 0.0103\n",
      "Epoch 7/50\n",
      "673/673 [==============================] - 0s 84us/sample - loss: 0.0160 - val_loss: 0.0103\n",
      "Epoch 8/50\n",
      "673/673 [==============================] - 0s 89us/sample - loss: 0.0162 - val_loss: 0.0103\n",
      "Epoch 9/50\n",
      "673/673 [==============================] - 0s 84us/sample - loss: 0.0157 - val_loss: 0.0104\n",
      "Epoch 10/50\n",
      "673/673 [==============================] - 0s 87us/sample - loss: 0.0153 - val_loss: 0.0104\n",
      "Epoch 11/50\n",
      "673/673 [==============================] - 0s 87us/sample - loss: 0.0153 - val_loss: 0.0103\n",
      "Epoch 12/50\n",
      "673/673 [==============================] - 0s 88us/sample - loss: 0.0160 - val_loss: 0.0103\n",
      "Epoch 13/50\n",
      "673/673 [==============================] - 0s 84us/sample - loss: 0.0162 - val_loss: 0.0103\n",
      "Epoch 14/50\n",
      "673/673 [==============================] - 0s 83us/sample - loss: 0.0157 - val_loss: 0.0103\n",
      "Epoch 15/50\n",
      "673/673 [==============================] - 0s 87us/sample - loss: 0.0152 - val_loss: 0.0104\n",
      "Epoch 16/50\n",
      "673/673 [==============================] - 0s 82us/sample - loss: 0.0154 - val_loss: 0.0103\n",
      "Epoch 17/50\n",
      "673/673 [==============================] - 0s 85us/sample - loss: 0.0159 - val_loss: 0.0103\n",
      "Epoch 18/50\n",
      "673/673 [==============================] - 0s 86us/sample - loss: 0.0162 - val_loss: 0.0103\n",
      "Epoch 19/50\n",
      "673/673 [==============================] - 0s 88us/sample - loss: 0.0155 - val_loss: 0.0103\n",
      "Epoch 20/50\n",
      "673/673 [==============================] - 0s 88us/sample - loss: 0.0152 - val_loss: 0.0103\n",
      "Epoch 21/50\n",
      "673/673 [==============================] - 0s 86us/sample - loss: 0.0153 - val_loss: 0.0103\n",
      "Epoch 22/50\n",
      "673/673 [==============================] - 0s 85us/sample - loss: 0.0159 - val_loss: 0.0103\n",
      "Epoch 23/50\n",
      "673/673 [==============================] - 0s 100us/sample - loss: 0.0162 - val_loss: 0.0103\n",
      "Epoch 24/50\n",
      "673/673 [==============================] - 0s 87us/sample - loss: 0.0155 - val_loss: 0.0103\n",
      "Epoch 25/50\n",
      "673/673 [==============================] - 0s 86us/sample - loss: 0.0152 - val_loss: 0.0103\n",
      "Epoch 26/50\n",
      "673/673 [==============================] - 0s 85us/sample - loss: 0.0153 - val_loss: 0.0103\n",
      "Epoch 27/50\n",
      "673/673 [==============================] - 0s 87us/sample - loss: 0.0158 - val_loss: 0.0103\n",
      "Epoch 28/50\n",
      "673/673 [==============================] - 0s 86us/sample - loss: 0.0168 - val_loss: 0.0104\n",
      "Epoch 29/50\n",
      "673/673 [==============================] - 0s 88us/sample - loss: 0.0155 - val_loss: 0.0103\n",
      "Epoch 30/50\n",
      "673/673 [==============================] - 0s 86us/sample - loss: 0.0152 - val_loss: 0.0103\n",
      "Epoch 31/50\n",
      "673/673 [==============================] - 0s 86us/sample - loss: 0.0153 - val_loss: 0.0103\n",
      "Epoch 32/50\n",
      "673/673 [==============================] - 0s 83us/sample - loss: 0.0157 - val_loss: 0.0102\n",
      "Epoch 33/50\n",
      "673/673 [==============================] - 0s 83us/sample - loss: 0.0168 - val_loss: 0.0105\n",
      "Epoch 34/50\n",
      "673/673 [==============================] - 0s 81us/sample - loss: 0.0153 - val_loss: 0.0103\n",
      "Epoch 35/50\n",
      "673/673 [==============================] - 0s 83us/sample - loss: 0.0152 - val_loss: 0.0103\n",
      "Epoch 36/50\n",
      "673/673 [==============================] - 0s 85us/sample - loss: 0.0153 - val_loss: 0.0103\n",
      "Epoch 37/50\n",
      "673/673 [==============================] - 0s 92us/sample - loss: 0.0159 - val_loss: 0.0103\n",
      "Epoch 38/50\n",
      "673/673 [==============================] - 0s 90us/sample - loss: 0.0161 - val_loss: 0.0105\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673/673 [==============================] - 0s 88us/sample - loss: 0.0153 - val_loss: 0.0103\n",
      "Epoch 40/50\n",
      "673/673 [==============================] - 0s 82us/sample - loss: 0.0152 - val_loss: 0.0103\n",
      "Epoch 41/50\n",
      "673/673 [==============================] - 0s 83us/sample - loss: 0.0153 - val_loss: 0.0103\n",
      "Epoch 42/50\n",
      "673/673 [==============================] - 0s 81us/sample - loss: 0.0158 - val_loss: 0.0104\n",
      "Epoch 43/50\n",
      "673/673 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0104\n",
      "Epoch 44/50\n",
      "673/673 [==============================] - 0s 87us/sample - loss: 0.0152 - val_loss: 0.0103\n",
      "Epoch 45/50\n",
      "673/673 [==============================] - 0s 87us/sample - loss: 0.0152 - val_loss: 0.0103\n",
      "Epoch 46/50\n",
      "673/673 [==============================] - 0s 93us/sample - loss: 0.0155 - val_loss: 0.0103\n",
      "Epoch 47/50\n",
      "673/673 [==============================] - 0s 87us/sample - loss: 0.0161 - val_loss: 0.0104\n",
      "Epoch 48/50\n",
      "673/673 [==============================] - 0s 86us/sample - loss: 0.0153 - val_loss: 0.0103\n",
      "Epoch 49/50\n",
      "673/673 [==============================] - 0s 89us/sample - loss: 0.0152 - val_loss: 0.0103\n",
      "Epoch 50/50\n",
      "673/673 [==============================] - 0s 87us/sample - loss: 0.0153 - val_loss: 0.0103\n",
      "第66个数，还剩4057个没有训练\n",
      "inv_hat [0.54965235 0.53612842 0.53612842 0.53805574 0.53131704 0.52843506\n",
      " 0.53324037 0.53805574 0.52747524 0.53227851 0.54771582 0.54674804\n",
      " 0.54481376 0.530356   0.53516536 0.53516536 0.53902004 0.53324037\n",
      " 0.54094971 0.52939529 0.52172499 0.51981157 0.51122271 0.51217532\n",
      " 0.51122271 0.52076809 0.5226823  0.51789992 0.51217532 0.51217532]\n",
      "Test RMSE: 0.007\n",
      "Train on 740 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "740/740 [==============================] - 0s 91us/sample - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 2/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0071 - val_loss: 0.0042\n",
      "Epoch 3/50\n",
      "740/740 [==============================] - 0s 86us/sample - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 4/50\n",
      "740/740 [==============================] - 0s 90us/sample - loss: 0.0063 - val_loss: 0.0040\n",
      "Epoch 5/50\n",
      "740/740 [==============================] - 0s 89us/sample - loss: 0.0070 - val_loss: 0.0040\n",
      "Epoch 6/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0087 - val_loss: 0.0041\n",
      "Epoch 7/50\n",
      "740/740 [==============================] - 0s 83us/sample - loss: 0.0100 - val_loss: 0.0040\n",
      "Epoch 8/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0073 - val_loss: 0.0113\n",
      "Epoch 9/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0070 - val_loss: 0.0040\n",
      "Epoch 10/50\n",
      "740/740 [==============================] - 0s 82us/sample - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 11/50\n",
      "740/740 [==============================] - 0s 82us/sample - loss: 0.0078 - val_loss: 0.0046\n",
      "Epoch 12/50\n",
      "740/740 [==============================] - 0s 81us/sample - loss: 0.0085 - val_loss: 0.0043\n",
      "Epoch 13/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0086 - val_loss: 0.0041\n",
      "Epoch 14/50\n",
      "740/740 [==============================] - 0s 90us/sample - loss: 0.0068 - val_loss: 0.0089\n",
      "Epoch 15/50\n",
      "740/740 [==============================] - 0s 90us/sample - loss: 0.0067 - val_loss: 0.0043\n",
      "Epoch 16/50\n",
      "740/740 [==============================] - 0s 90us/sample - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 17/50\n",
      "740/740 [==============================] - 0s 89us/sample - loss: 0.0075 - val_loss: 0.0043\n",
      "Epoch 18/50\n",
      "740/740 [==============================] - 0s 90us/sample - loss: 0.0080 - val_loss: 0.0042\n",
      "Epoch 19/50\n",
      "740/740 [==============================] - 0s 83us/sample - loss: 0.0077 - val_loss: 0.0040\n",
      "Epoch 20/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0062 - val_loss: 0.0042\n",
      "Epoch 21/50\n",
      "740/740 [==============================] - 0s 94us/sample - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 22/50\n",
      "740/740 [==============================] - 0s 83us/sample - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 23/50\n",
      "740/740 [==============================] - 0s 88us/sample - loss: 0.0063 - val_loss: 0.0042\n",
      "Epoch 24/50\n",
      "740/740 [==============================] - 0s 87us/sample - loss: 0.0072 - val_loss: 0.0040\n",
      "Epoch 25/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0062 - val_loss: 0.0040\n",
      "Epoch 26/50\n",
      "740/740 [==============================] - 0s 90us/sample - loss: 0.0074 - val_loss: 0.0040\n",
      "Epoch 27/50\n",
      "740/740 [==============================] - 0s 89us/sample - loss: 0.0061 - val_loss: 0.0040\n",
      "Epoch 28/50\n",
      "740/740 [==============================] - 0s 86us/sample - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 29/50\n",
      "740/740 [==============================] - 0s 82us/sample - loss: 0.0071 - val_loss: 0.0040\n",
      "Epoch 30/50\n",
      "740/740 [==============================] - 0s 89us/sample - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 31/50\n",
      "740/740 [==============================] - 0s 82us/sample - loss: 0.0066 - val_loss: 0.0049\n",
      "Epoch 32/50\n",
      "740/740 [==============================] - 0s 79us/sample - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 33/50\n",
      "740/740 [==============================] - 0s 83us/sample - loss: 0.0067 - val_loss: 0.0041\n",
      "Epoch 34/50\n",
      "740/740 [==============================] - 0s 90us/sample - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 35/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0070 - val_loss: 0.0041\n",
      "Epoch 36/50\n",
      "740/740 [==============================] - 0s 91us/sample - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 37/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0068 - val_loss: 0.0042\n",
      "Epoch 38/50\n",
      "740/740 [==============================] - 0s 83us/sample - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 39/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0065 - val_loss: 0.0045\n",
      "Epoch 40/50\n",
      "740/740 [==============================] - 0s 87us/sample - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 41/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0065 - val_loss: 0.0043\n",
      "Epoch 42/50\n",
      "740/740 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 43/50\n",
      "740/740 [==============================] - 0s 89us/sample - loss: 0.0069 - val_loss: 0.0040\n",
      "Epoch 44/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0062 - val_loss: 0.0042\n",
      "Epoch 45/50\n",
      "740/740 [==============================] - 0s 83us/sample - loss: 0.0070 - val_loss: 0.0040\n",
      "Epoch 46/50\n",
      "740/740 [==============================] - 0s 82us/sample - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 47/50\n",
      "740/740 [==============================] - 0s 87us/sample - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 48/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0063 - val_loss: 0.0044\n",
      "Epoch 49/50\n",
      "740/740 [==============================] - 0s 88us/sample - loss: 0.0069 - val_loss: 0.0041\n",
      "Epoch 50/50\n",
      "740/740 [==============================] - 0s 92us/sample - loss: 0.0060 - val_loss: 0.0042\n",
      "第67个数，还剩4056个没有训练\n",
      "inv_hat [2.33768405 2.31641881 2.32047019 2.31641881 2.28703515 2.28804864\n",
      " 2.29007572 2.29919598 2.28804864 2.29615624 2.31844455 2.32148295\n",
      " 2.31743168 2.3042624  2.31135394 2.30324922 2.30831471 2.30831471\n",
      " 2.31236691 2.30122265 2.29412926 2.28804864 2.28196709 2.2809535\n",
      " 2.27487122 2.2809535  2.27689872 2.27182983 2.26980213 2.26980213]\n",
      "Test RMSE: 0.010\n",
      "Train on 666 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "666/666 [==============================] - 0s 87us/sample - loss: 0.0234 - val_loss: 0.0256\n",
      "Epoch 2/50\n",
      "666/666 [==============================] - 0s 90us/sample - loss: 0.0236 - val_loss: 0.0279\n",
      "Epoch 3/50\n",
      "666/666 [==============================] - 0s 88us/sample - loss: 0.0230 - val_loss: 0.0223\n",
      "Epoch 4/50\n",
      "666/666 [==============================] - 0s 88us/sample - loss: 0.0224 - val_loss: 0.0226\n",
      "Epoch 5/50\n",
      "666/666 [==============================] - 0s 88us/sample - loss: 0.0222 - val_loss: 0.0274\n",
      "Epoch 6/50\n",
      "666/666 [==============================] - 0s 94us/sample - loss: 0.0236 - val_loss: 0.0248\n",
      "Epoch 7/50\n",
      "666/666 [==============================] - 0s 91us/sample - loss: 0.0218 - val_loss: 0.0228\n",
      "Epoch 8/50\n",
      "666/666 [==============================] - 0s 86us/sample - loss: 0.0218 - val_loss: 0.0241\n",
      "Epoch 9/50\n",
      "666/666 [==============================] - 0s 90us/sample - loss: 0.0222 - val_loss: 0.0259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "666/666 [==============================] - 0s 92us/sample - loss: 0.0224 - val_loss: 0.0240\n",
      "Epoch 11/50\n",
      "666/666 [==============================] - 0s 86us/sample - loss: 0.0217 - val_loss: 0.0229\n",
      "Epoch 12/50\n",
      "666/666 [==============================] - 0s 83us/sample - loss: 0.0218 - val_loss: 0.0248\n",
      "Epoch 13/50\n",
      "666/666 [==============================] - 0s 83us/sample - loss: 0.0226 - val_loss: 0.0262\n",
      "Epoch 14/50\n",
      "666/666 [==============================] - 0s 83us/sample - loss: 0.0223 - val_loss: 0.0228\n",
      "Epoch 15/50\n",
      "666/666 [==============================] - 0s 81us/sample - loss: 0.0220 - val_loss: 0.0227\n",
      "Epoch 16/50\n",
      "666/666 [==============================] - 0s 82us/sample - loss: 0.0221 - val_loss: 0.0269\n",
      "Epoch 17/50\n",
      "666/666 [==============================] - 0s 85us/sample - loss: 0.0234 - val_loss: 0.0248\n",
      "Epoch 18/50\n",
      "666/666 [==============================] - 0s 83us/sample - loss: 0.0217 - val_loss: 0.0225\n",
      "Epoch 19/50\n",
      "666/666 [==============================] - 0s 83us/sample - loss: 0.0219 - val_loss: 0.0240\n",
      "Epoch 20/50\n",
      "666/666 [==============================] - 0s 92us/sample - loss: 0.0223 - val_loss: 0.0267\n",
      "Epoch 21/50\n",
      "666/666 [==============================] - 0s 86us/sample - loss: 0.0226 - val_loss: 0.0235\n",
      "Epoch 22/50\n",
      "666/666 [==============================] - 0s 84us/sample - loss: 0.0217 - val_loss: 0.0228\n",
      "Epoch 23/50\n",
      "666/666 [==============================] - 0s 87us/sample - loss: 0.0218 - val_loss: 0.0246\n",
      "Epoch 24/50\n",
      "666/666 [==============================] - 0s 89us/sample - loss: 0.0225 - val_loss: 0.0267\n",
      "Epoch 25/50\n",
      "666/666 [==============================] - 0s 87us/sample - loss: 0.0225 - val_loss: 0.0227\n",
      "Epoch 26/50\n",
      "666/666 [==============================] - 0s 89us/sample - loss: 0.0220 - val_loss: 0.0226\n",
      "Epoch 27/50\n",
      "666/666 [==============================] - 0s 84us/sample - loss: 0.0221 - val_loss: 0.0269\n",
      "Epoch 28/50\n",
      "666/666 [==============================] - 0s 88us/sample - loss: 0.0233 - val_loss: 0.0244\n",
      "Epoch 29/50\n",
      "666/666 [==============================] - 0s 89us/sample - loss: 0.0217 - val_loss: 0.0229\n",
      "Epoch 30/50\n",
      "666/666 [==============================] - 0s 83us/sample - loss: 0.0217 - val_loss: 0.0241\n",
      "Epoch 31/50\n",
      "666/666 [==============================] - 0s 82us/sample - loss: 0.0222 - val_loss: 0.0259\n",
      "Epoch 32/50\n",
      "666/666 [==============================] - 0s 86us/sample - loss: 0.0222 - val_loss: 0.0231\n",
      "Epoch 33/50\n",
      "666/666 [==============================] - 0s 89us/sample - loss: 0.0218 - val_loss: 0.0232\n",
      "Epoch 34/50\n",
      "666/666 [==============================] - 0s 90us/sample - loss: 0.0219 - val_loss: 0.0252\n",
      "Epoch 35/50\n",
      "666/666 [==============================] - 0s 84us/sample - loss: 0.0223 - val_loss: 0.0246\n",
      "Epoch 36/50\n",
      "666/666 [==============================] - 0s 86us/sample - loss: 0.0217 - val_loss: 0.0228\n",
      "Epoch 37/50\n",
      "666/666 [==============================] - 0s 83us/sample - loss: 0.0218 - val_loss: 0.0243\n",
      "Epoch 38/50\n",
      "666/666 [==============================] - 0s 86us/sample - loss: 0.0224 - val_loss: 0.0262\n",
      "Epoch 39/50\n",
      "666/666 [==============================] - 0s 91us/sample - loss: 0.0223 - val_loss: 0.0230\n",
      "Epoch 40/50\n",
      "666/666 [==============================] - 0s 93us/sample - loss: 0.0218 - val_loss: 0.0228\n",
      "Epoch 41/50\n",
      "666/666 [==============================] - 0s 90us/sample - loss: 0.0220 - val_loss: 0.0266\n",
      "Epoch 42/50\n",
      "666/666 [==============================] - 0s 91us/sample - loss: 0.0232 - val_loss: 0.0242\n",
      "Epoch 43/50\n",
      "666/666 [==============================] - 0s 90us/sample - loss: 0.0216 - val_loss: 0.0226\n",
      "Epoch 44/50\n",
      "666/666 [==============================] - 0s 85us/sample - loss: 0.0218 - val_loss: 0.0244\n",
      "Epoch 45/50\n",
      "666/666 [==============================] - 0s 85us/sample - loss: 0.0223 - val_loss: 0.0263\n",
      "Epoch 46/50\n",
      "666/666 [==============================] - 0s 84us/sample - loss: 0.0223 - val_loss: 0.0228\n",
      "Epoch 47/50\n",
      "666/666 [==============================] - 0s 85us/sample - loss: 0.0219 - val_loss: 0.0227\n",
      "Epoch 48/50\n",
      "666/666 [==============================] - 0s 86us/sample - loss: 0.0220 - val_loss: 0.0268\n",
      "Epoch 49/50\n",
      "666/666 [==============================] - 0s 82us/sample - loss: 0.0233 - val_loss: 0.0241\n",
      "Epoch 50/50\n",
      "666/666 [==============================] - 0s 88us/sample - loss: 0.0217 - val_loss: 0.0230\n",
      "第68个数，还剩4055个没有训练\n",
      "inv_hat [1.04522945 1.0225722  1.02649726 1.02355288 1.00596907 1.00014124\n",
      " 0.99529828 1.01278976 1.00014124 1.00694199 1.03436731 1.03732517\n",
      " 1.03929896 1.01571984 1.00596907 0.99529828 1.00305297 1.00111137\n",
      " 1.01083869 0.98950349 0.97797099 0.97318914 0.9579845  0.96651852\n",
      " 0.9617714  0.97797099 0.9770135  0.97032682 0.96746976 0.96842153]\n",
      "Test RMSE: 0.012\n",
      "Train on 850 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "850/850 [==============================] - 0s 80us/sample - loss: 0.0094 - val_loss: 0.0159\n",
      "Epoch 2/50\n",
      "850/850 [==============================] - 0s 81us/sample - loss: 0.0091 - val_loss: 0.0155\n",
      "Epoch 3/50\n",
      "850/850 [==============================] - 0s 79us/sample - loss: 0.0094 - val_loss: 0.0163\n",
      "Epoch 4/50\n",
      "850/850 [==============================] - 0s 78us/sample - loss: 0.0093 - val_loss: 0.0168\n",
      "Epoch 5/50\n",
      "850/850 [==============================] - 0s 82us/sample - loss: 0.0091 - val_loss: 0.0160\n",
      "Epoch 6/50\n",
      "850/850 [==============================] - 0s 81us/sample - loss: 0.0096 - val_loss: 0.0169\n",
      "Epoch 7/50\n",
      "850/850 [==============================] - 0s 81us/sample - loss: 0.0092 - val_loss: 0.0160\n",
      "Epoch 8/50\n",
      "850/850 [==============================] - 0s 83us/sample - loss: 0.0094 - val_loss: 0.0161\n",
      "Epoch 9/50\n",
      "850/850 [==============================] - 0s 83us/sample - loss: 0.0091 - val_loss: 0.0156\n",
      "Epoch 10/50\n",
      "850/850 [==============================] - 0s 76us/sample - loss: 0.0093 - val_loss: 0.0160\n",
      "Epoch 11/50\n",
      "850/850 [==============================] - 0s 76us/sample - loss: 0.0096 - val_loss: 0.0172\n",
      "Epoch 12/50\n",
      "850/850 [==============================] - 0s 77us/sample - loss: 0.0091 - val_loss: 0.0150\n",
      "Epoch 13/50\n",
      "850/850 [==============================] - 0s 78us/sample - loss: 0.0099 - val_loss: 0.0155\n",
      "Epoch 14/50\n",
      "850/850 [==============================] - 0s 76us/sample - loss: 0.0095 - val_loss: 0.0165\n",
      "Epoch 15/50\n",
      "850/850 [==============================] - 0s 77us/sample - loss: 0.0092 - val_loss: 0.0161\n",
      "Epoch 16/50\n",
      "850/850 [==============================] - 0s 84us/sample - loss: 0.0095 - val_loss: 0.0160\n",
      "Epoch 17/50\n",
      "850/850 [==============================] - 0s 88us/sample - loss: 0.0097 - val_loss: 0.0162\n",
      "Epoch 18/50\n",
      "850/850 [==============================] - 0s 82us/sample - loss: 0.0092 - val_loss: 0.0166\n",
      "Epoch 19/50\n",
      "850/850 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0166\n",
      "Epoch 20/50\n",
      "850/850 [==============================] - 0s 82us/sample - loss: 0.0092 - val_loss: 0.0163\n",
      "Epoch 21/50\n",
      "850/850 [==============================] - 0s 84us/sample - loss: 0.0092 - val_loss: 0.0162\n",
      "Epoch 22/50\n",
      "850/850 [==============================] - 0s 80us/sample - loss: 0.0092 - val_loss: 0.0165\n",
      "Epoch 23/50\n",
      "850/850 [==============================] - 0s 82us/sample - loss: 0.0092 - val_loss: 0.0159\n",
      "Epoch 24/50\n",
      "850/850 [==============================] - 0s 82us/sample - loss: 0.0093 - val_loss: 0.0159\n",
      "Epoch 25/50\n",
      "850/850 [==============================] - 0s 84us/sample - loss: 0.0097 - val_loss: 0.0158\n",
      "Epoch 26/50\n",
      "850/850 [==============================] - 0s 82us/sample - loss: 0.0096 - val_loss: 0.0167\n",
      "Epoch 27/50\n",
      "850/850 [==============================] - 0s 82us/sample - loss: 0.0091 - val_loss: 0.0161\n",
      "Epoch 28/50\n",
      "850/850 [==============================] - 0s 85us/sample - loss: 0.0092 - val_loss: 0.0162\n",
      "Epoch 29/50\n",
      "850/850 [==============================] - 0s 82us/sample - loss: 0.0092 - val_loss: 0.0162\n",
      "Epoch 30/50\n",
      "850/850 [==============================] - 0s 86us/sample - loss: 0.0096 - val_loss: 0.0167\n",
      "Epoch 31/50\n",
      "850/850 [==============================] - 0s 87us/sample - loss: 0.0090 - val_loss: 0.0157\n",
      "Epoch 32/50\n",
      "850/850 [==============================] - 0s 86us/sample - loss: 0.0093 - val_loss: 0.0156\n",
      "Epoch 33/50\n",
      "850/850 [==============================] - 0s 80us/sample - loss: 0.0097 - val_loss: 0.0162\n",
      "Epoch 34/50\n",
      "850/850 [==============================] - 0s 80us/sample - loss: 0.0092 - val_loss: 0.0168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "850/850 [==============================] - 0s 87us/sample - loss: 0.0092 - val_loss: 0.0154\n",
      "Epoch 36/50\n",
      "850/850 [==============================] - 0s 83us/sample - loss: 0.0102 - val_loss: 0.0154\n",
      "Epoch 37/50\n",
      "850/850 [==============================] - 0s 79us/sample - loss: 0.0098 - val_loss: 0.0161\n",
      "Epoch 38/50\n",
      "850/850 [==============================] - 0s 78us/sample - loss: 0.0092 - val_loss: 0.0163\n",
      "Epoch 39/50\n",
      "850/850 [==============================] - 0s 82us/sample - loss: 0.0090 - val_loss: 0.0156\n",
      "Epoch 40/50\n",
      "850/850 [==============================] - 0s 77us/sample - loss: 0.0095 - val_loss: 0.0157\n",
      "Epoch 41/50\n",
      "850/850 [==============================] - 0s 77us/sample - loss: 0.0096 - val_loss: 0.0163\n",
      "Epoch 42/50\n",
      "850/850 [==============================] - 0s 76us/sample - loss: 0.0093 - val_loss: 0.0169\n",
      "Epoch 43/50\n",
      "850/850 [==============================] - 0s 85us/sample - loss: 0.0092 - val_loss: 0.0165\n",
      "Epoch 44/50\n",
      "850/850 [==============================] - 0s 80us/sample - loss: 0.0090 - val_loss: 0.0153\n",
      "Epoch 45/50\n",
      "850/850 [==============================] - 0s 80us/sample - loss: 0.0096 - val_loss: 0.0157\n",
      "Epoch 46/50\n",
      "850/850 [==============================] - 0s 80us/sample - loss: 0.0096 - val_loss: 0.0163\n",
      "Epoch 47/50\n",
      "850/850 [==============================] - 0s 81us/sample - loss: 0.0092 - val_loss: 0.0164\n",
      "Epoch 48/50\n",
      "850/850 [==============================] - 0s 82us/sample - loss: 0.0096 - val_loss: 0.0160\n",
      "Epoch 49/50\n",
      "850/850 [==============================] - 0s 93us/sample - loss: 0.0099 - val_loss: 0.0155\n",
      "Epoch 50/50\n",
      "850/850 [==============================] - 0s 83us/sample - loss: 0.0100 - val_loss: 0.0159\n",
      "第69个数，还剩4054个没有训练\n",
      "inv_hat [0.90877446 0.89050491 0.89319982 0.89127441 0.87385625 0.87090873\n",
      " 0.87100368 0.87766804 0.86806187 0.87414179 0.8897357  0.8925257\n",
      " 0.89031254 0.88148925 0.88139359 0.874237   0.87766804 0.88062864\n",
      " 0.88791024 0.87738183 0.87661884 0.87071875 0.86399117 0.86078075\n",
      " 0.85400711 0.85616722 0.8517569  0.84960413 0.84792185 0.85119497]\n",
      "Test RMSE: 0.008\n",
      "Train on 973 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "973/973 [==============================] - 0s 82us/sample - loss: 0.0168 - val_loss: 0.0073\n",
      "Epoch 2/50\n",
      "973/973 [==============================] - 0s 85us/sample - loss: 0.0168 - val_loss: 0.0069\n",
      "Epoch 3/50\n",
      "973/973 [==============================] - 0s 78us/sample - loss: 0.0165 - val_loss: 0.0087\n",
      "Epoch 4/50\n",
      "973/973 [==============================] - 0s 78us/sample - loss: 0.0163 - val_loss: 0.0067\n",
      "Epoch 5/50\n",
      "973/973 [==============================] - 0s 78us/sample - loss: 0.0164 - val_loss: 0.0071\n",
      "Epoch 6/50\n",
      "973/973 [==============================] - 0s 78us/sample - loss: 0.0165 - val_loss: 0.0062\n",
      "Epoch 7/50\n",
      "973/973 [==============================] - 0s 79us/sample - loss: 0.0165 - val_loss: 0.0066\n",
      "Epoch 8/50\n",
      "973/973 [==============================] - 0s 81us/sample - loss: 0.0163 - val_loss: 0.0074\n",
      "Epoch 9/50\n",
      "973/973 [==============================] - 0s 85us/sample - loss: 0.0166 - val_loss: 0.0065\n",
      "Epoch 10/50\n",
      "973/973 [==============================] - 0s 78us/sample - loss: 0.0163 - val_loss: 0.0063\n",
      "Epoch 11/50\n",
      "973/973 [==============================] - 0s 82us/sample - loss: 0.0165 - val_loss: 0.0064\n",
      "Epoch 12/50\n",
      "973/973 [==============================] - 0s 78us/sample - loss: 0.0163 - val_loss: 0.0070\n",
      "Epoch 13/50\n",
      "973/973 [==============================] - 0s 78us/sample - loss: 0.0167 - val_loss: 0.0067\n",
      "Epoch 14/50\n",
      "973/973 [==============================] - 0s 81us/sample - loss: 0.0168 - val_loss: 0.0066\n",
      "Epoch 15/50\n",
      "973/973 [==============================] - 0s 82us/sample - loss: 0.0168 - val_loss: 0.0071\n",
      "Epoch 16/50\n",
      "973/973 [==============================] - 0s 83us/sample - loss: 0.0167 - val_loss: 0.0075\n",
      "Epoch 17/50\n",
      "973/973 [==============================] - 0s 81us/sample - loss: 0.0166 - val_loss: 0.0064\n",
      "Epoch 18/50\n",
      "973/973 [==============================] - 0s 82us/sample - loss: 0.0166 - val_loss: 0.0068\n",
      "Epoch 19/50\n",
      "973/973 [==============================] - 0s 83us/sample - loss: 0.0168 - val_loss: 0.0062\n",
      "Epoch 20/50\n",
      "973/973 [==============================] - 0s 82us/sample - loss: 0.0167 - val_loss: 0.0072\n",
      "Epoch 21/50\n",
      "973/973 [==============================] - 0s 82us/sample - loss: 0.0168 - val_loss: 0.0077\n",
      "Epoch 22/50\n",
      "973/973 [==============================] - 0s 81us/sample - loss: 0.0166 - val_loss: 0.0064\n",
      "Epoch 23/50\n",
      "973/973 [==============================] - 0s 82us/sample - loss: 0.0167 - val_loss: 0.0066\n",
      "Epoch 24/50\n",
      "973/973 [==============================] - 0s 88us/sample - loss: 0.0168 - val_loss: 0.0062\n",
      "Epoch 25/50\n",
      "973/973 [==============================] - 0s 80us/sample - loss: 0.0167 - val_loss: 0.0066\n",
      "Epoch 26/50\n",
      "973/973 [==============================] - 0s 78us/sample - loss: 0.0170 - val_loss: 0.0095\n",
      "Epoch 27/50\n",
      "973/973 [==============================] - 0s 80us/sample - loss: 0.0170 - val_loss: 0.0099\n",
      "Epoch 28/50\n",
      "973/973 [==============================] - 0s 81us/sample - loss: 0.0166 - val_loss: 0.0065\n",
      "Epoch 29/50\n",
      "973/973 [==============================] - 0s 82us/sample - loss: 0.0164 - val_loss: 0.0063\n",
      "Epoch 30/50\n",
      "973/973 [==============================] - 0s 81us/sample - loss: 0.0162 - val_loss: 0.0066\n",
      "Epoch 31/50\n",
      "973/973 [==============================] - 0s 79us/sample - loss: 0.0166 - val_loss: 0.0062\n",
      "Epoch 32/50\n",
      "973/973 [==============================] - 0s 81us/sample - loss: 0.0165 - val_loss: 0.0100\n",
      "Epoch 33/50\n",
      "973/973 [==============================] - 0s 85us/sample - loss: 0.0165 - val_loss: 0.0074\n",
      "Epoch 34/50\n",
      "973/973 [==============================] - 0s 83us/sample - loss: 0.0166 - val_loss: 0.0062\n",
      "Epoch 35/50\n",
      "973/973 [==============================] - 0s 82us/sample - loss: 0.0163 - val_loss: 0.0068\n",
      "Epoch 36/50\n",
      "973/973 [==============================] - 0s 81us/sample - loss: 0.0164 - val_loss: 0.0065\n",
      "Epoch 37/50\n",
      "973/973 [==============================] - 0s 83us/sample - loss: 0.0162 - val_loss: 0.0063\n",
      "Epoch 38/50\n",
      "973/973 [==============================] - 0s 80us/sample - loss: 0.0166 - val_loss: 0.0064\n",
      "Epoch 39/50\n",
      "973/973 [==============================] - 0s 85us/sample - loss: 0.0163 - val_loss: 0.0074\n",
      "Epoch 40/50\n",
      "973/973 [==============================] - 0s 82us/sample - loss: 0.0167 - val_loss: 0.0067\n",
      "Epoch 41/50\n",
      "973/973 [==============================] - 0s 83us/sample - loss: 0.0165 - val_loss: 0.0066\n",
      "Epoch 42/50\n",
      "973/973 [==============================] - 0s 85us/sample - loss: 0.0164 - val_loss: 0.0071\n",
      "Epoch 43/50\n",
      "973/973 [==============================] - 0s 82us/sample - loss: 0.0164 - val_loss: 0.0065\n",
      "Epoch 44/50\n",
      "973/973 [==============================] - 0s 82us/sample - loss: 0.0165 - val_loss: 0.0064\n",
      "Epoch 45/50\n",
      "973/973 [==============================] - 0s 81us/sample - loss: 0.0165 - val_loss: 0.0098\n",
      "Epoch 46/50\n",
      "973/973 [==============================] - 0s 83us/sample - loss: 0.0163 - val_loss: 0.0062\n",
      "Epoch 47/50\n",
      "973/973 [==============================] - 0s 84us/sample - loss: 0.0164 - val_loss: 0.0087\n",
      "Epoch 48/50\n",
      "973/973 [==============================] - 0s 84us/sample - loss: 0.0164 - val_loss: 0.0067\n",
      "Epoch 49/50\n",
      "973/973 [==============================] - 0s 84us/sample - loss: 0.0164 - val_loss: 0.0065\n",
      "Epoch 50/50\n",
      "973/973 [==============================] - 0s 82us/sample - loss: 0.0164 - val_loss: 0.0065\n",
      "第70个数，还剩4053个没有训练\n",
      "inv_hat [1.030051   1.02806055 1.02806055 1.0270651  1.0260697  1.02507418\n",
      " 1.02507418 1.0260697  1.0260697  1.0260697  1.02905589 1.030051\n",
      " 1.030051   1.02905589 1.02905589 1.02905589 1.030051   1.02905589\n",
      " 1.02905589 1.0270651  1.0260697  1.02507418 1.02507418 1.02507418\n",
      " 1.02407878 1.02407878 1.02407878 1.02407878 1.02507418 1.02806055]\n",
      "Test RMSE: 0.001\n",
      "Train on 895 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "895/895 [==============================] - 0s 80us/sample - loss: 0.0138 - val_loss: 0.0104\n",
      "Epoch 2/50\n",
      "895/895 [==============================] - 0s 82us/sample - loss: 0.0134 - val_loss: 0.0070\n",
      "Epoch 3/50\n",
      "895/895 [==============================] - 0s 86us/sample - loss: 0.0137 - val_loss: 0.0069\n",
      "Epoch 4/50\n",
      "895/895 [==============================] - 0s 86us/sample - loss: 0.0144 - val_loss: 0.0061\n",
      "Epoch 5/50\n",
      "895/895 [==============================] - 0s 82us/sample - loss: 0.0148 - val_loss: 0.0083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "895/895 [==============================] - 0s 80us/sample - loss: 0.0143 - val_loss: 0.0124\n",
      "Epoch 7/50\n",
      "895/895 [==============================] - 0s 82us/sample - loss: 0.0144 - val_loss: 0.0135\n",
      "Epoch 8/50\n",
      "895/895 [==============================] - 0s 81us/sample - loss: 0.0152 - val_loss: 0.0084\n",
      "Epoch 9/50\n",
      "895/895 [==============================] - 0s 83us/sample - loss: 0.0151 - val_loss: 0.0115\n",
      "Epoch 10/50\n",
      "895/895 [==============================] - 0s 85us/sample - loss: 0.0147 - val_loss: 0.0163\n",
      "Epoch 11/50\n",
      "895/895 [==============================] - 0s 83us/sample - loss: 0.0151 - val_loss: 0.0104\n",
      "Epoch 12/50\n",
      "895/895 [==============================] - 0s 81us/sample - loss: 0.0145 - val_loss: 0.0090\n",
      "Epoch 13/50\n",
      "895/895 [==============================] - 0s 85us/sample - loss: 0.0133 - val_loss: 0.0083\n",
      "Epoch 14/50\n",
      "895/895 [==============================] - 0s 85us/sample - loss: 0.0132 - val_loss: 0.0066\n",
      "Epoch 15/50\n",
      "895/895 [==============================] - 0s 84us/sample - loss: 0.0131 - val_loss: 0.0062\n",
      "Epoch 16/50\n",
      "895/895 [==============================] - 0s 82us/sample - loss: 0.0131 - val_loss: 0.0063\n",
      "Epoch 17/50\n",
      "895/895 [==============================] - 0s 81us/sample - loss: 0.0132 - val_loss: 0.0063\n",
      "Epoch 18/50\n",
      "895/895 [==============================] - 0s 84us/sample - loss: 0.0132 - val_loss: 0.0069\n",
      "Epoch 19/50\n",
      "895/895 [==============================] - 0s 86us/sample - loss: 0.0134 - val_loss: 0.0064\n",
      "Epoch 20/50\n",
      "895/895 [==============================] - 0s 88us/sample - loss: 0.0132 - val_loss: 0.0071\n",
      "Epoch 21/50\n",
      "895/895 [==============================] - 0s 81us/sample - loss: 0.0134 - val_loss: 0.0061\n",
      "Epoch 22/50\n",
      "895/895 [==============================] - 0s 83us/sample - loss: 0.0135 - val_loss: 0.0068\n",
      "Epoch 23/50\n",
      "895/895 [==============================] - 0s 82us/sample - loss: 0.0135 - val_loss: 0.0061\n",
      "Epoch 24/50\n",
      "895/895 [==============================] - 0s 80us/sample - loss: 0.0136 - val_loss: 0.0072\n",
      "Epoch 25/50\n",
      "895/895 [==============================] - 0s 84us/sample - loss: 0.0135 - val_loss: 0.0062\n",
      "Epoch 26/50\n",
      "895/895 [==============================] - 0s 90us/sample - loss: 0.0136 - val_loss: 0.0061\n",
      "Epoch 27/50\n",
      "895/895 [==============================] - 0s 82us/sample - loss: 0.0137 - val_loss: 0.0069\n",
      "Epoch 28/50\n",
      "895/895 [==============================] - 0s 83us/sample - loss: 0.0136 - val_loss: 0.0070\n",
      "Epoch 29/50\n",
      "895/895 [==============================] - 0s 81us/sample - loss: 0.0131 - val_loss: 0.0066\n",
      "Epoch 30/50\n",
      "895/895 [==============================] - 0s 82us/sample - loss: 0.0132 - val_loss: 0.0071\n",
      "Epoch 31/50\n",
      "895/895 [==============================] - 0s 85us/sample - loss: 0.0134 - val_loss: 0.0061\n",
      "Epoch 32/50\n",
      "895/895 [==============================] - 0s 85us/sample - loss: 0.0132 - val_loss: 0.0061\n",
      "Epoch 33/50\n",
      "895/895 [==============================] - 0s 85us/sample - loss: 0.0134 - val_loss: 0.0083\n",
      "Epoch 34/50\n",
      "895/895 [==============================] - 0s 88us/sample - loss: 0.0132 - val_loss: 0.0073\n",
      "Epoch 35/50\n",
      "895/895 [==============================] - 0s 84us/sample - loss: 0.0133 - val_loss: 0.0068\n",
      "Epoch 36/50\n",
      "895/895 [==============================] - 0s 83us/sample - loss: 0.0136 - val_loss: 0.0061\n",
      "Epoch 37/50\n",
      "895/895 [==============================] - 0s 83us/sample - loss: 0.0136 - val_loss: 0.0093\n",
      "Epoch 38/50\n",
      "895/895 [==============================] - 0s 82us/sample - loss: 0.0135 - val_loss: 0.0084\n",
      "Epoch 39/50\n",
      "895/895 [==============================] - 0s 85us/sample - loss: 0.0137 - val_loss: 0.0073\n",
      "Epoch 40/50\n",
      "895/895 [==============================] - 0s 86us/sample - loss: 0.0140 - val_loss: 0.0061\n",
      "Epoch 41/50\n",
      "895/895 [==============================] - 0s 85us/sample - loss: 0.0138 - val_loss: 0.0069\n",
      "Epoch 42/50\n",
      "895/895 [==============================] - 0s 87us/sample - loss: 0.0132 - val_loss: 0.0067\n",
      "Epoch 43/50\n",
      "895/895 [==============================] - 0s 88us/sample - loss: 0.0137 - val_loss: 0.0066\n",
      "Epoch 44/50\n",
      "895/895 [==============================] - 0s 84us/sample - loss: 0.0137 - val_loss: 0.0097\n",
      "Epoch 45/50\n",
      "895/895 [==============================] - 0s 85us/sample - loss: 0.0138 - val_loss: 0.0107\n",
      "Epoch 46/50\n",
      "895/895 [==============================] - 0s 85us/sample - loss: 0.0140 - val_loss: 0.0079\n",
      "Epoch 47/50\n",
      "895/895 [==============================] - 0s 87us/sample - loss: 0.0137 - val_loss: 0.0065\n",
      "Epoch 48/50\n",
      "895/895 [==============================] - 0s 83us/sample - loss: 0.0131 - val_loss: 0.0062\n",
      "Epoch 49/50\n",
      "895/895 [==============================] - 0s 89us/sample - loss: 0.0132 - val_loss: 0.0074\n",
      "Epoch 50/50\n",
      "895/895 [==============================] - 0s 89us/sample - loss: 0.0133 - val_loss: 0.0062\n",
      "第71个数，还剩4052个没有训练\n",
      "inv_hat [0.95885594 0.94124406 0.94027261 0.93930196 0.93930196 0.93833212\n",
      " 0.93930196 0.93930196 0.94027261 0.94027261 0.94027261 0.94124406\n",
      " 0.94124406 0.94124406 0.94513772 0.94611302 0.94611302 0.94611302\n",
      " 0.94416317 0.94416317 0.9422163  0.94318938 0.94513772 0.94611302\n",
      " 0.94513772 0.94513772 0.94513772 0.94611302 0.94611302 0.94806589]\n",
      "Test RMSE: 0.003\n",
      "Train on 830 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "830/830 [==============================] - 0s 82us/sample - loss: 0.0244 - val_loss: 0.0228\n",
      "Epoch 2/50\n",
      "830/830 [==============================] - 0s 82us/sample - loss: 0.0244 - val_loss: 0.0230\n",
      "Epoch 3/50\n",
      "830/830 [==============================] - 0s 83us/sample - loss: 0.0244 - val_loss: 0.0232\n",
      "Epoch 4/50\n",
      "830/830 [==============================] - 0s 89us/sample - loss: 0.0244 - val_loss: 0.0230\n",
      "Epoch 5/50\n",
      "830/830 [==============================] - 0s 87us/sample - loss: 0.0244 - val_loss: 0.0231\n",
      "Epoch 6/50\n",
      "830/830 [==============================] - 0s 82us/sample - loss: 0.0244 - val_loss: 0.0231\n",
      "Epoch 7/50\n",
      "830/830 [==============================] - 0s 89us/sample - loss: 0.0244 - val_loss: 0.0230\n",
      "Epoch 8/50\n",
      "830/830 [==============================] - 0s 87us/sample - loss: 0.0244 - val_loss: 0.0230\n",
      "Epoch 9/50\n",
      "830/830 [==============================] - 0s 83us/sample - loss: 0.0244 - val_loss: 0.0231\n",
      "Epoch 10/50\n",
      "830/830 [==============================] - 0s 84us/sample - loss: 0.0244 - val_loss: 0.0231\n",
      "Epoch 11/50\n",
      "830/830 [==============================] - 0s 84us/sample - loss: 0.0243 - val_loss: 0.0231\n",
      "Epoch 12/50\n",
      "830/830 [==============================] - 0s 83us/sample - loss: 0.0243 - val_loss: 0.0230\n",
      "Epoch 13/50\n",
      "830/830 [==============================] - 0s 83us/sample - loss: 0.0243 - val_loss: 0.0230\n",
      "Epoch 14/50\n",
      "830/830 [==============================] - 0s 87us/sample - loss: 0.0243 - val_loss: 0.0231\n",
      "Epoch 15/50\n",
      "830/830 [==============================] - 0s 88us/sample - loss: 0.0243 - val_loss: 0.0231\n",
      "Epoch 16/50\n",
      "830/830 [==============================] - 0s 83us/sample - loss: 0.0243 - val_loss: 0.0232\n",
      "Epoch 17/50\n",
      "830/830 [==============================] - 0s 81us/sample - loss: 0.0243 - val_loss: 0.0230\n",
      "Epoch 18/50\n",
      "830/830 [==============================] - 0s 85us/sample - loss: 0.0243 - val_loss: 0.0230\n",
      "Epoch 19/50\n",
      "830/830 [==============================] - 0s 84us/sample - loss: 0.0243 - val_loss: 0.0231\n",
      "Epoch 20/50\n",
      "830/830 [==============================] - 0s 86us/sample - loss: 0.0243 - val_loss: 0.0232\n",
      "Epoch 21/50\n",
      "830/830 [==============================] - 0s 84us/sample - loss: 0.0243 - val_loss: 0.0231\n",
      "Epoch 22/50\n",
      "830/830 [==============================] - 0s 86us/sample - loss: 0.0243 - val_loss: 0.0230\n",
      "Epoch 23/50\n",
      "830/830 [==============================] - 0s 86us/sample - loss: 0.0243 - val_loss: 0.0232\n",
      "Epoch 24/50\n",
      "830/830 [==============================] - 0s 83us/sample - loss: 0.0243 - val_loss: 0.0231\n",
      "Epoch 25/50\n",
      "830/830 [==============================] - 0s 87us/sample - loss: 0.0243 - val_loss: 0.0230\n",
      "Epoch 26/50\n",
      "830/830 [==============================] - 0s 82us/sample - loss: 0.0243 - val_loss: 0.0232\n",
      "Epoch 27/50\n",
      "830/830 [==============================] - 0s 87us/sample - loss: 0.0243 - val_loss: 0.0232\n",
      "Epoch 28/50\n",
      "830/830 [==============================] - 0s 87us/sample - loss: 0.0243 - val_loss: 0.0231\n",
      "Epoch 29/50\n",
      "830/830 [==============================] - 0s 84us/sample - loss: 0.0243 - val_loss: 0.0230\n",
      "Epoch 30/50\n",
      "830/830 [==============================] - 0s 87us/sample - loss: 0.0243 - val_loss: 0.0231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "830/830 [==============================] - 0s 89us/sample - loss: 0.0243 - val_loss: 0.0232\n",
      "Epoch 32/50\n",
      "830/830 [==============================] - 0s 92us/sample - loss: 0.0243 - val_loss: 0.0232\n",
      "Epoch 33/50\n",
      "830/830 [==============================] - 0s 84us/sample - loss: 0.0243 - val_loss: 0.0232\n",
      "Epoch 34/50\n",
      "830/830 [==============================] - 0s 86us/sample - loss: 0.0243 - val_loss: 0.0230\n",
      "Epoch 35/50\n",
      "830/830 [==============================] - 0s 85us/sample - loss: 0.0243 - val_loss: 0.0231\n",
      "Epoch 36/50\n",
      "830/830 [==============================] - 0s 85us/sample - loss: 0.0243 - val_loss: 0.0233\n",
      "Epoch 37/50\n",
      "830/830 [==============================] - 0s 86us/sample - loss: 0.0243 - val_loss: 0.0232\n",
      "Epoch 38/50\n",
      "830/830 [==============================] - 0s 87us/sample - loss: 0.0243 - val_loss: 0.0232\n",
      "Epoch 39/50\n",
      "830/830 [==============================] - 0s 87us/sample - loss: 0.0243 - val_loss: 0.0231\n",
      "Epoch 40/50\n",
      "830/830 [==============================] - 0s 85us/sample - loss: 0.0243 - val_loss: 0.0233\n",
      "Epoch 41/50\n",
      "830/830 [==============================] - 0s 84us/sample - loss: 0.0243 - val_loss: 0.0233\n",
      "Epoch 42/50\n",
      "830/830 [==============================] - 0s 83us/sample - loss: 0.0243 - val_loss: 0.0232\n",
      "Epoch 43/50\n",
      "830/830 [==============================] - 0s 85us/sample - loss: 0.0243 - val_loss: 0.0231\n",
      "Epoch 44/50\n",
      "830/830 [==============================] - 0s 83us/sample - loss: 0.0243 - val_loss: 0.0231\n",
      "Epoch 45/50\n",
      "830/830 [==============================] - 0s 84us/sample - loss: 0.0243 - val_loss: 0.0233\n",
      "Epoch 46/50\n",
      "830/830 [==============================] - 0s 84us/sample - loss: 0.0243 - val_loss: 0.0237\n",
      "Epoch 47/50\n",
      "830/830 [==============================] - 0s 87us/sample - loss: 0.0244 - val_loss: 0.0235\n",
      "Epoch 48/50\n",
      "830/830 [==============================] - 0s 84us/sample - loss: 0.0243 - val_loss: 0.0231\n",
      "Epoch 49/50\n",
      "830/830 [==============================] - 0s 83us/sample - loss: 0.0243 - val_loss: 0.0227\n",
      "Epoch 50/50\n",
      "830/830 [==============================] - 0s 87us/sample - loss: 0.0244 - val_loss: 0.0232\n",
      "第72个数，还剩4051个没有训练\n",
      "inv_hat [0.73389038 0.72192246 0.73161333 0.73507885 0.71688739 0.71629544\n",
      " 0.71935482 0.72686432 0.71984849 0.72548011 0.74667834 0.75983098\n",
      " 0.77050535 0.74062805 0.71511174 0.7110702  0.71373123 0.71087313\n",
      " 0.7171834  0.6973034  0.68457255 0.68359559 0.66772203 0.6641331\n",
      " 0.65629626 0.66752791 0.66830451 0.66539347 0.65987261 0.66529648]\n",
      "Test RMSE: 0.012\n",
      "Train on 1193 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0098 - val_loss: 0.0077\n",
      "Epoch 2/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0076 - val_loss: 0.0048\n",
      "Epoch 3/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0088 - val_loss: 0.0061\n",
      "Epoch 4/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0085 - val_loss: 0.0056\n",
      "Epoch 5/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0091 - val_loss: 0.0058\n",
      "Epoch 6/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0079 - val_loss: 0.0040\n",
      "Epoch 7/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0077 - val_loss: 0.0054\n",
      "Epoch 8/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 9/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0086 - val_loss: 0.0035\n",
      "Epoch 10/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0072 - val_loss: 0.0048\n",
      "Epoch 11/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0080 - val_loss: 0.0050\n",
      "Epoch 12/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0077 - val_loss: 0.0037\n",
      "Epoch 13/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0075 - val_loss: 0.0038\n",
      "Epoch 14/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0074 - val_loss: 0.0040\n",
      "Epoch 15/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0075 - val_loss: 0.0041\n",
      "Epoch 16/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 17/50\n",
      "1193/1193 [==============================] - ETA: 0s - loss: 0.008 - 0s 83us/sample - loss: 0.0084 - val_loss: 0.0048\n",
      "Epoch 18/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0083 - val_loss: 0.0034\n",
      "Epoch 19/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0073 - val_loss: 0.0034\n",
      "Epoch 20/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0085 - val_loss: 0.0038\n",
      "Epoch 21/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0074 - val_loss: 0.0053\n",
      "Epoch 22/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0082 - val_loss: 0.0036\n",
      "Epoch 23/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0079 - val_loss: 0.0041\n",
      "Epoch 24/50\n",
      "1193/1193 [==============================] - 0s 84us/sample - loss: 0.0074 - val_loss: 0.0051\n",
      "Epoch 25/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0075 - val_loss: 0.0051\n",
      "Epoch 26/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0077 - val_loss: 0.0042\n",
      "Epoch 27/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 28/50\n",
      "1193/1193 [==============================] - 0s 87us/sample - loss: 0.0075 - val_loss: 0.0046\n",
      "Epoch 29/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0075 - val_loss: 0.0040\n",
      "Epoch 30/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0072 - val_loss: 0.0033\n",
      "Epoch 31/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0078 - val_loss: 0.0067\n",
      "Epoch 32/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0078 - val_loss: 0.0038\n",
      "Epoch 33/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0078 - val_loss: 0.0051\n",
      "Epoch 34/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0074 - val_loss: 0.0056\n",
      "Epoch 35/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0082 - val_loss: 0.0051\n",
      "Epoch 36/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0083 - val_loss: 0.0057\n",
      "Epoch 37/50\n",
      "1193/1193 [==============================] - 0s 84us/sample - loss: 0.0084 - val_loss: 0.0069\n",
      "Epoch 38/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0075 - val_loss: 0.0044\n",
      "Epoch 39/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0074 - val_loss: 0.0039\n",
      "Epoch 40/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0070 - val_loss: 0.0035\n",
      "Epoch 41/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0073 - val_loss: 0.0033\n",
      "Epoch 42/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0071 - val_loss: 0.0032\n",
      "Epoch 43/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0071 - val_loss: 0.0033\n",
      "Epoch 44/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0080 - val_loss: 0.0082\n",
      "Epoch 45/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0079 - val_loss: 0.0046\n",
      "Epoch 46/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0073 - val_loss: 0.0049\n",
      "Epoch 47/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 48/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0078 - val_loss: 0.0036\n",
      "Epoch 49/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0073 - val_loss: 0.0046\n",
      "Epoch 50/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0078 - val_loss: 0.0040\n",
      "第73个数，还剩4050个没有训练\n",
      "inv_hat [1.04409318 1.04409318 1.04409318 1.0450966  1.0450966  1.0450966\n",
      " 1.0450966  1.0450966  1.04609849 1.04609849 1.04609849 1.04609849\n",
      " 1.04609849 1.04609849 1.04709864 1.04709864 1.04709864 1.04709864\n",
      " 1.04709864 1.04809682 1.04809682 1.04809682 1.04809682 1.04809682\n",
      " 1.04909318 1.04909318 1.04909318 1.04909318 1.04909318 1.05008738]\n",
      "Test RMSE: 0.000\n",
      "Train on 848 samples, validate on 30 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0070 - val_loss: 0.0036\n",
      "Epoch 2/50\n",
      "848/848 [==============================] - 0s 76us/sample - loss: 0.0072 - val_loss: 0.0034\n",
      "Epoch 3/50\n",
      "848/848 [==============================] - 0s 78us/sample - loss: 0.0070 - val_loss: 0.0025\n",
      "Epoch 4/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0070 - val_loss: 0.0041\n",
      "Epoch 5/50\n",
      "848/848 [==============================] - 0s 90us/sample - loss: 0.0071 - val_loss: 0.0029\n",
      "Epoch 6/50\n",
      "848/848 [==============================] - 0s 84us/sample - loss: 0.0069 - val_loss: 0.0029\n",
      "Epoch 7/50\n",
      "848/848 [==============================] - 0s 84us/sample - loss: 0.0071 - val_loss: 0.0037\n",
      "Epoch 8/50\n",
      "848/848 [==============================] - 0s 84us/sample - loss: 0.0070 - val_loss: 0.0027\n",
      "Epoch 9/50\n",
      "848/848 [==============================] - 0s 81us/sample - loss: 0.0070 - val_loss: 0.0037\n",
      "Epoch 10/50\n",
      "848/848 [==============================] - 0s 77us/sample - loss: 0.0071 - val_loss: 0.0029\n",
      "Epoch 11/50\n",
      "848/848 [==============================] - 0s 78us/sample - loss: 0.0069 - val_loss: 0.0032\n",
      "Epoch 12/50\n",
      "848/848 [==============================] - 0s 76us/sample - loss: 0.0071 - val_loss: 0.0031\n",
      "Epoch 13/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0069 - val_loss: 0.0029\n",
      "Epoch 14/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0070 - val_loss: 0.0033\n",
      "Epoch 15/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0069 - val_loss: 0.0027\n",
      "Epoch 16/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0069 - val_loss: 0.0035\n",
      "Epoch 17/50\n",
      "848/848 [==============================] - 0s 77us/sample - loss: 0.0069 - val_loss: 0.0027\n",
      "Epoch 18/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0069 - val_loss: 0.0035\n",
      "Epoch 19/50\n",
      "848/848 [==============================] - 0s 78us/sample - loss: 0.0069 - val_loss: 0.0026\n",
      "Epoch 20/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0069 - val_loss: 0.0034\n",
      "Epoch 21/50\n",
      "848/848 [==============================] - 0s 77us/sample - loss: 0.0069 - val_loss: 0.0026\n",
      "Epoch 22/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0069 - val_loss: 0.0030\n",
      "Epoch 23/50\n",
      "848/848 [==============================] - 0s 90us/sample - loss: 0.0069 - val_loss: 0.0029\n",
      "Epoch 24/50\n",
      "848/848 [==============================] - 0s 83us/sample - loss: 0.0068 - val_loss: 0.0028\n",
      "Epoch 25/50\n",
      "848/848 [==============================] - 0s 78us/sample - loss: 0.0069 - val_loss: 0.0032\n",
      "Epoch 26/50\n",
      "848/848 [==============================] - 0s 81us/sample - loss: 0.0069 - val_loss: 0.0025\n",
      "Epoch 27/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0068 - val_loss: 0.0029\n",
      "Epoch 28/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0069 - val_loss: 0.0027\n",
      "Epoch 29/50\n",
      "848/848 [==============================] - 0s 81us/sample - loss: 0.0068 - val_loss: 0.0026\n",
      "Epoch 30/50\n",
      "848/848 [==============================] - 0s 81us/sample - loss: 0.0069 - val_loss: 0.0032\n",
      "Epoch 31/50\n",
      "848/848 [==============================] - 0s 82us/sample - loss: 0.0068 - val_loss: 0.0026\n",
      "Epoch 32/50\n",
      "848/848 [==============================] - 0s 84us/sample - loss: 0.0067 - val_loss: 0.0029\n",
      "Epoch 33/50\n",
      "848/848 [==============================] - 0s 83us/sample - loss: 0.0070 - val_loss: 0.0032\n",
      "Epoch 34/50\n",
      "848/848 [==============================] - 0s 85us/sample - loss: 0.0068 - val_loss: 0.0027\n",
      "Epoch 35/50\n",
      "848/848 [==============================] - 0s 84us/sample - loss: 0.0067 - val_loss: 0.0027\n",
      "Epoch 36/50\n",
      "848/848 [==============================] - 0s 88us/sample - loss: 0.0067 - val_loss: 0.0034\n",
      "Epoch 37/50\n",
      "848/848 [==============================] - 0s 85us/sample - loss: 0.0069 - val_loss: 0.0031\n",
      "Epoch 38/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0066 - val_loss: 0.0019\n",
      "Epoch 39/50\n",
      "848/848 [==============================] - 0s 81us/sample - loss: 0.0062 - val_loss: 0.0021\n",
      "Epoch 40/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0062 - val_loss: 0.0028\n",
      "Epoch 41/50\n",
      "848/848 [==============================] - 0s 78us/sample - loss: 0.0067 - val_loss: 0.0032\n",
      "Epoch 42/50\n",
      "848/848 [==============================] - 0s 76us/sample - loss: 0.0067 - val_loss: 0.0025\n",
      "Epoch 43/50\n",
      "848/848 [==============================] - 0s 77us/sample - loss: 0.0067 - val_loss: 0.0029\n",
      "Epoch 44/50\n",
      "848/848 [==============================] - 0s 78us/sample - loss: 0.0070 - val_loss: 0.0036\n",
      "Epoch 45/50\n",
      "848/848 [==============================] - 0s 90us/sample - loss: 0.0068 - val_loss: 0.0021\n",
      "Epoch 46/50\n",
      "848/848 [==============================] - 0s 90us/sample - loss: 0.0065 - val_loss: 0.0019\n",
      "Epoch 47/50\n",
      "848/848 [==============================] - 0s 82us/sample - loss: 0.0062 - val_loss: 0.0016\n",
      "Epoch 48/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0060 - val_loss: 0.0024\n",
      "Epoch 49/50\n",
      "848/848 [==============================] - 0s 81us/sample - loss: 0.0062 - val_loss: 0.0016\n",
      "Epoch 50/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0061 - val_loss: 0.0023\n",
      "第74个数，还剩4049个没有训练\n",
      "inv_hat [1.01796437 1.01806443 1.0181645  1.01826456 1.01846455 1.01876471\n",
      " 1.01896479 1.01906483 1.01916475 1.01926478 1.01966488 1.0197649\n",
      " 1.01986479 1.0200648  1.0201648  1.02056465 1.02066462 1.0207646\n",
      " 1.02086457 1.02106449 1.02136423 1.02156411 1.02166404 1.02176396\n",
      " 1.02186388 1.02226339 1.02236329 1.02246317 1.02266292 1.02276267]\n",
      "Test RMSE: 0.000\n",
      "Train on 477 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "477/477 [==============================] - 0s 90us/sample - loss: 0.0217 - val_loss: 0.0211\n",
      "Epoch 2/50\n",
      "477/477 [==============================] - 0s 87us/sample - loss: 0.0217 - val_loss: 0.0181\n",
      "Epoch 3/50\n",
      "477/477 [==============================] - 0s 90us/sample - loss: 0.0218 - val_loss: 0.0209\n",
      "Epoch 4/50\n",
      "477/477 [==============================] - 0s 84us/sample - loss: 0.0218 - val_loss: 0.0178\n",
      "Epoch 5/50\n",
      "477/477 [==============================] - 0s 86us/sample - loss: 0.0219 - val_loss: 0.0201\n",
      "Epoch 6/50\n",
      "477/477 [==============================] - 0s 87us/sample - loss: 0.0216 - val_loss: 0.0178\n",
      "Epoch 7/50\n",
      "477/477 [==============================] - 0s 86us/sample - loss: 0.0219 - val_loss: 0.0205\n",
      "Epoch 8/50\n",
      "477/477 [==============================] - 0s 86us/sample - loss: 0.0216 - val_loss: 0.0177\n",
      "Epoch 9/50\n",
      "477/477 [==============================] - 0s 81us/sample - loss: 0.0221 - val_loss: 0.0218\n",
      "Epoch 10/50\n",
      "477/477 [==============================] - 0s 83us/sample - loss: 0.0219 - val_loss: 0.0179\n",
      "Epoch 11/50\n",
      "477/477 [==============================] - 0s 81us/sample - loss: 0.0225 - val_loss: 0.0228\n",
      "Epoch 12/50\n",
      "477/477 [==============================] - 0s 85us/sample - loss: 0.0220 - val_loss: 0.0181\n",
      "Epoch 13/50\n",
      "477/477 [==============================] - 0s 84us/sample - loss: 0.0227 - val_loss: 0.0237\n",
      "Epoch 14/50\n",
      "477/477 [==============================] - 0s 87us/sample - loss: 0.0222 - val_loss: 0.0188\n",
      "Epoch 15/50\n",
      "477/477 [==============================] - 0s 83us/sample - loss: 0.0234 - val_loss: 0.0251\n",
      "Epoch 16/50\n",
      "477/477 [==============================] - 0s 81us/sample - loss: 0.0225 - val_loss: 0.0189\n",
      "Epoch 17/50\n",
      "477/477 [==============================] - 0s 89us/sample - loss: 0.0234 - val_loss: 0.0238\n",
      "Epoch 18/50\n",
      "477/477 [==============================] - 0s 83us/sample - loss: 0.0221 - val_loss: 0.0186\n",
      "Epoch 19/50\n",
      "477/477 [==============================] - 0s 86us/sample - loss: 0.0231 - val_loss: 0.0237\n",
      "Epoch 20/50\n",
      "477/477 [==============================] - 0s 87us/sample - loss: 0.0222 - val_loss: 0.0190\n",
      "Epoch 21/50\n",
      "477/477 [==============================] - 0s 97us/sample - loss: 0.0233 - val_loss: 0.0229\n",
      "Epoch 22/50\n",
      "477/477 [==============================] - 0s 93us/sample - loss: 0.0220 - val_loss: 0.0186\n",
      "Epoch 23/50\n",
      "477/477 [==============================] - 0s 87us/sample - loss: 0.0229 - val_loss: 0.0229\n",
      "Epoch 24/50\n",
      "477/477 [==============================] - 0s 86us/sample - loss: 0.0220 - val_loss: 0.0185\n",
      "Epoch 25/50\n",
      "477/477 [==============================] - 0s 84us/sample - loss: 0.0229 - val_loss: 0.0229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "477/477 [==============================] - 0s 83us/sample - loss: 0.0220 - val_loss: 0.0186\n",
      "Epoch 27/50\n",
      "477/477 [==============================] - 0s 90us/sample - loss: 0.0230 - val_loss: 0.0228\n",
      "Epoch 28/50\n",
      "477/477 [==============================] - 0s 92us/sample - loss: 0.0220 - val_loss: 0.0184\n",
      "Epoch 29/50\n",
      "477/477 [==============================] - 0s 87us/sample - loss: 0.0228 - val_loss: 0.0226\n",
      "Epoch 30/50\n",
      "477/477 [==============================] - 0s 87us/sample - loss: 0.0219 - val_loss: 0.0183\n",
      "Epoch 31/50\n",
      "477/477 [==============================] - 0s 87us/sample - loss: 0.0226 - val_loss: 0.0221\n",
      "Epoch 32/50\n",
      "477/477 [==============================] - 0s 86us/sample - loss: 0.0218 - val_loss: 0.0182\n",
      "Epoch 33/50\n",
      "477/477 [==============================] - 0s 84us/sample - loss: 0.0226 - val_loss: 0.0223\n",
      "Epoch 34/50\n",
      "477/477 [==============================] - 0s 84us/sample - loss: 0.0218 - val_loss: 0.0181\n",
      "Epoch 35/50\n",
      "477/477 [==============================] - 0s 91us/sample - loss: 0.0225 - val_loss: 0.0221\n",
      "Epoch 36/50\n",
      "477/477 [==============================] - 0s 100us/sample - loss: 0.0217 - val_loss: 0.0181\n",
      "Epoch 37/50\n",
      "477/477 [==============================] - 0s 87us/sample - loss: 0.0225 - val_loss: 0.0218\n",
      "Epoch 38/50\n",
      "477/477 [==============================] - 0s 86us/sample - loss: 0.0217 - val_loss: 0.0180\n",
      "Epoch 39/50\n",
      "477/477 [==============================] - 0s 86us/sample - loss: 0.0224 - val_loss: 0.0217\n",
      "Epoch 40/50\n",
      "477/477 [==============================] - 0s 87us/sample - loss: 0.0216 - val_loss: 0.0180\n",
      "Epoch 41/50\n",
      "477/477 [==============================] - 0s 85us/sample - loss: 0.0223 - val_loss: 0.0215\n",
      "Epoch 42/50\n",
      "477/477 [==============================] - 0s 85us/sample - loss: 0.0216 - val_loss: 0.0179\n",
      "Epoch 43/50\n",
      "477/477 [==============================] - 0s 83us/sample - loss: 0.0223 - val_loss: 0.0216\n",
      "Epoch 44/50\n",
      "477/477 [==============================] - 0s 85us/sample - loss: 0.0216 - val_loss: 0.0179\n",
      "Epoch 45/50\n",
      "477/477 [==============================] - 0s 86us/sample - loss: 0.0223 - val_loss: 0.0215\n",
      "Epoch 46/50\n",
      "477/477 [==============================] - 0s 82us/sample - loss: 0.0216 - val_loss: 0.0178\n",
      "Epoch 47/50\n",
      "477/477 [==============================] - 0s 87us/sample - loss: 0.0221 - val_loss: 0.0210\n",
      "Epoch 48/50\n",
      "477/477 [==============================] - 0s 87us/sample - loss: 0.0215 - val_loss: 0.0178\n",
      "Epoch 49/50\n",
      "477/477 [==============================] - 0s 86us/sample - loss: 0.0220 - val_loss: 0.0209\n",
      "Epoch 50/50\n",
      "477/477 [==============================] - 0s 87us/sample - loss: 0.0215 - val_loss: 0.0178\n",
      "第75个数，还剩4048个没有训练\n",
      "inv_hat [0.89075577 0.86744568 0.86648054 0.86744568 0.84441615 0.8434628\n",
      " 0.85110363 0.86069976 0.84632427 0.85685543 0.88197609 0.88197609\n",
      " 0.88197609 0.86744568 0.86841124 0.86069976 0.86166203 0.86166203\n",
      " 0.87518283 0.85397733 0.8434628  0.84155781 0.82262674 0.82450979\n",
      " 0.81980644 0.8320647  0.83111835 0.83111835 0.82262674 0.82356798]\n",
      "Test RMSE: 0.011\n",
      "Train on 613 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "613/613 [==============================] - 0s 84us/sample - loss: 0.0140 - val_loss: 0.0181\n",
      "Epoch 2/50\n",
      "613/613 [==============================] - 0s 85us/sample - loss: 0.0137 - val_loss: 0.0187\n",
      "Epoch 3/50\n",
      "613/613 [==============================] - 0s 81us/sample - loss: 0.0148 - val_loss: 0.0222\n",
      "Epoch 4/50\n",
      "613/613 [==============================] - 0s 86us/sample - loss: 0.0151 - val_loss: 0.0241\n",
      "Epoch 5/50\n",
      "613/613 [==============================] - 0s 84us/sample - loss: 0.0147 - val_loss: 0.0191\n",
      "Epoch 6/50\n",
      "613/613 [==============================] - 0s 83us/sample - loss: 0.0134 - val_loss: 0.0177\n",
      "Epoch 7/50\n",
      "613/613 [==============================] - 0s 82us/sample - loss: 0.0138 - val_loss: 0.0181\n",
      "Epoch 8/50\n",
      "613/613 [==============================] - 0s 84us/sample - loss: 0.0141 - val_loss: 0.0179\n",
      "Epoch 9/50\n",
      "613/613 [==============================] - 0s 84us/sample - loss: 0.0144 - val_loss: 0.0183\n",
      "Epoch 10/50\n",
      "613/613 [==============================] - 0s 88us/sample - loss: 0.0146 - val_loss: 0.0218\n",
      "Epoch 11/50\n",
      "613/613 [==============================] - 0s 81us/sample - loss: 0.0150 - val_loss: 0.0243\n",
      "Epoch 12/50\n",
      "613/613 [==============================] - 0s 80us/sample - loss: 0.0149 - val_loss: 0.0194\n",
      "Epoch 13/50\n",
      "613/613 [==============================] - 0s 87us/sample - loss: 0.0137 - val_loss: 0.0178\n",
      "Epoch 14/50\n",
      "613/613 [==============================] - 0s 84us/sample - loss: 0.0139 - val_loss: 0.0177\n",
      "Epoch 15/50\n",
      "613/613 [==============================] - 0s 85us/sample - loss: 0.0136 - val_loss: 0.0182\n",
      "Epoch 16/50\n",
      "613/613 [==============================] - 0s 86us/sample - loss: 0.0138 - val_loss: 0.0182\n",
      "Epoch 17/50\n",
      "613/613 [==============================] - 0s 87us/sample - loss: 0.0141 - val_loss: 0.0189\n",
      "Epoch 18/50\n",
      "613/613 [==============================] - 0s 88us/sample - loss: 0.0155 - val_loss: 0.0251\n",
      "Epoch 19/50\n",
      "613/613 [==============================] - 0s 84us/sample - loss: 0.0150 - val_loss: 0.0201\n",
      "Epoch 20/50\n",
      "613/613 [==============================] - 0s 82us/sample - loss: 0.0138 - val_loss: 0.0178\n",
      "Epoch 21/50\n",
      "613/613 [==============================] - 0s 79us/sample - loss: 0.0137 - val_loss: 0.0178\n",
      "Epoch 22/50\n",
      "613/613 [==============================] - 0s 81us/sample - loss: 0.0136 - val_loss: 0.0188\n",
      "Epoch 23/50\n",
      "613/613 [==============================] - 0s 85us/sample - loss: 0.0134 - val_loss: 0.0180\n",
      "Epoch 24/50\n",
      "613/613 [==============================] - 0s 85us/sample - loss: 0.0137 - val_loss: 0.0179\n",
      "Epoch 25/50\n",
      "613/613 [==============================] - 0s 84us/sample - loss: 0.0137 - val_loss: 0.0180\n",
      "Epoch 26/50\n",
      "613/613 [==============================] - 0s 86us/sample - loss: 0.0142 - val_loss: 0.0183\n",
      "Epoch 27/50\n",
      "613/613 [==============================] - 0s 83us/sample - loss: 0.0159 - val_loss: 0.0248\n",
      "Epoch 28/50\n",
      "613/613 [==============================] - 0s 91us/sample - loss: 0.0148 - val_loss: 0.0185\n",
      "Epoch 29/50\n",
      "613/613 [==============================] - 0s 83us/sample - loss: 0.0135 - val_loss: 0.0188\n",
      "Epoch 30/50\n",
      "613/613 [==============================] - 0s 84us/sample - loss: 0.0135 - val_loss: 0.0187\n",
      "Epoch 31/50\n",
      "613/613 [==============================] - 0s 86us/sample - loss: 0.0135 - val_loss: 0.0188\n",
      "Epoch 32/50\n",
      "613/613 [==============================] - 0s 84us/sample - loss: 0.0134 - val_loss: 0.0189\n",
      "Epoch 33/50\n",
      "613/613 [==============================] - 0s 86us/sample - loss: 0.0133 - val_loss: 0.0187\n",
      "Epoch 34/50\n",
      "613/613 [==============================] - 0s 83us/sample - loss: 0.0133 - val_loss: 0.0183\n",
      "Epoch 35/50\n",
      "613/613 [==============================] - 0s 82us/sample - loss: 0.0134 - val_loss: 0.0181\n",
      "Epoch 36/50\n",
      "613/613 [==============================] - 0s 84us/sample - loss: 0.0135 - val_loss: 0.0185\n",
      "Epoch 37/50\n",
      "613/613 [==============================] - 0s 84us/sample - loss: 0.0136 - val_loss: 0.0186\n",
      "Epoch 38/50\n",
      "613/613 [==============================] - 0s 81us/sample - loss: 0.0157 - val_loss: 0.0250\n",
      "Epoch 39/50\n",
      "613/613 [==============================] - 0s 82us/sample - loss: 0.0145 - val_loss: 0.0191\n",
      "Epoch 40/50\n",
      "613/613 [==============================] - 0s 83us/sample - loss: 0.0134 - val_loss: 0.0184\n",
      "Epoch 41/50\n",
      "613/613 [==============================] - 0s 85us/sample - loss: 0.0136 - val_loss: 0.0181\n",
      "Epoch 42/50\n",
      "613/613 [==============================] - 0s 84us/sample - loss: 0.0145 - val_loss: 0.0202\n",
      "Epoch 43/50\n",
      "613/613 [==============================] - 0s 79us/sample - loss: 0.0146 - val_loss: 0.0224\n",
      "Epoch 44/50\n",
      "613/613 [==============================] - 0s 79us/sample - loss: 0.0141 - val_loss: 0.0188\n",
      "Epoch 45/50\n",
      "613/613 [==============================] - 0s 79us/sample - loss: 0.0135 - val_loss: 0.0181\n",
      "Epoch 46/50\n",
      "613/613 [==============================] - 0s 79us/sample - loss: 0.0136 - val_loss: 0.0180\n",
      "Epoch 47/50\n",
      "613/613 [==============================] - 0s 78us/sample - loss: 0.0135 - val_loss: 0.0184\n",
      "Epoch 48/50\n",
      "613/613 [==============================] - 0s 86us/sample - loss: 0.0134 - val_loss: 0.0184\n",
      "Epoch 49/50\n",
      "613/613 [==============================] - 0s 81us/sample - loss: 0.0134 - val_loss: 0.0182\n",
      "Epoch 50/50\n",
      "613/613 [==============================] - 0s 88us/sample - loss: 0.0134 - val_loss: 0.0184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第76个数，还剩4047个没有训练\n",
      "inv_hat [0.98802919 0.98319961 0.98416095 0.98319961 0.97937945 0.97937945\n",
      " 0.97937945 0.98224076 0.98033065 0.98224076 0.98802919 0.98802919\n",
      " 0.98705879 0.98416095 0.98512461 0.98512461 0.98512461 0.97748532\n",
      " 0.97937945 0.97748532 0.97843101 0.97654244 0.97654244 0.9756087\n",
      " 0.97654244 0.97748532 0.97748532 0.97748532 0.97748532 0.97748532]\n",
      "Test RMSE: 0.003\n",
      "Train on 865 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "865/865 [==============================] - 0s 89us/sample - loss: 0.0200 - val_loss: 0.0128\n",
      "Epoch 2/50\n",
      "865/865 [==============================] - 0s 87us/sample - loss: 0.0196 - val_loss: 0.0132\n",
      "Epoch 3/50\n",
      "865/865 [==============================] - 0s 88us/sample - loss: 0.0200 - val_loss: 0.0127\n",
      "Epoch 4/50\n",
      "865/865 [==============================] - 0s 87us/sample - loss: 0.0214 - val_loss: 0.0156\n",
      "Epoch 5/50\n",
      "865/865 [==============================] - 0s 82us/sample - loss: 0.0200 - val_loss: 0.0127\n",
      "Epoch 6/50\n",
      "865/865 [==============================] - 0s 87us/sample - loss: 0.0222 - val_loss: 0.0165\n",
      "Epoch 7/50\n",
      "865/865 [==============================] - 0s 85us/sample - loss: 0.0207 - val_loss: 0.0131\n",
      "Epoch 8/50\n",
      "865/865 [==============================] - 0s 85us/sample - loss: 0.0234 - val_loss: 0.0176\n",
      "Epoch 9/50\n",
      "865/865 [==============================] - 0s 89us/sample - loss: 0.0211 - val_loss: 0.0130\n",
      "Epoch 10/50\n",
      "865/865 [==============================] - 0s 83us/sample - loss: 0.0232 - val_loss: 0.0174\n",
      "Epoch 11/50\n",
      "865/865 [==============================] - 0s 86us/sample - loss: 0.0211 - val_loss: 0.0130\n",
      "Epoch 12/50\n",
      "865/865 [==============================] - 0s 84us/sample - loss: 0.0231 - val_loss: 0.0174\n",
      "Epoch 13/50\n",
      "865/865 [==============================] - 0s 88us/sample - loss: 0.0212 - val_loss: 0.0128\n",
      "Epoch 14/50\n",
      "865/865 [==============================] - 0s 85us/sample - loss: 0.0227 - val_loss: 0.0175\n",
      "Epoch 15/50\n",
      "865/865 [==============================] - 0s 81us/sample - loss: 0.0212 - val_loss: 0.0128\n",
      "Epoch 16/50\n",
      "865/865 [==============================] - 0s 84us/sample - loss: 0.0227 - val_loss: 0.0169\n",
      "Epoch 17/50\n",
      "865/865 [==============================] - 0s 83us/sample - loss: 0.0208 - val_loss: 0.0129\n",
      "Epoch 18/50\n",
      "865/865 [==============================] - 0s 85us/sample - loss: 0.0231 - val_loss: 0.0174\n",
      "Epoch 19/50\n",
      "865/865 [==============================] - 0s 87us/sample - loss: 0.0210 - val_loss: 0.0129\n",
      "Epoch 20/50\n",
      "865/865 [==============================] - 0s 84us/sample - loss: 0.0230 - val_loss: 0.0174\n",
      "Epoch 21/50\n",
      "865/865 [==============================] - 0s 84us/sample - loss: 0.0210 - val_loss: 0.0128\n",
      "Epoch 22/50\n",
      "865/865 [==============================] - 0s 88us/sample - loss: 0.0229 - val_loss: 0.0173\n",
      "Epoch 23/50\n",
      "865/865 [==============================] - 0s 82us/sample - loss: 0.0210 - val_loss: 0.0128\n",
      "Epoch 24/50\n",
      "865/865 [==============================] - 0s 85us/sample - loss: 0.0228 - val_loss: 0.0170\n",
      "Epoch 25/50\n",
      "865/865 [==============================] - 0s 84us/sample - loss: 0.0209 - val_loss: 0.0128\n",
      "Epoch 26/50\n",
      "865/865 [==============================] - 0s 83us/sample - loss: 0.0228 - val_loss: 0.0171\n",
      "Epoch 27/50\n",
      "865/865 [==============================] - 0s 88us/sample - loss: 0.0209 - val_loss: 0.0128\n",
      "Epoch 28/50\n",
      "865/865 [==============================] - 0s 86us/sample - loss: 0.0229 - val_loss: 0.0173\n",
      "Epoch 29/50\n",
      "865/865 [==============================] - 0s 84us/sample - loss: 0.0210 - val_loss: 0.0129\n",
      "Epoch 30/50\n",
      "865/865 [==============================] - 0s 85us/sample - loss: 0.0229 - val_loss: 0.0173\n",
      "Epoch 31/50\n",
      "865/865 [==============================] - 0s 88us/sample - loss: 0.0210 - val_loss: 0.0128\n",
      "Epoch 32/50\n",
      "865/865 [==============================] - 0s 83us/sample - loss: 0.0227 - val_loss: 0.0174\n",
      "Epoch 33/50\n",
      "865/865 [==============================] - 0s 83us/sample - loss: 0.0211 - val_loss: 0.0127\n",
      "Epoch 34/50\n",
      "865/865 [==============================] - 0s 80us/sample - loss: 0.0226 - val_loss: 0.0170\n",
      "Epoch 35/50\n",
      "865/865 [==============================] - 0s 81us/sample - loss: 0.0208 - val_loss: 0.0128\n",
      "Epoch 36/50\n",
      "865/865 [==============================] - 0s 84us/sample - loss: 0.0229 - val_loss: 0.0172\n",
      "Epoch 37/50\n",
      "865/865 [==============================] - 0s 85us/sample - loss: 0.0209 - val_loss: 0.0128\n",
      "Epoch 38/50\n",
      "865/865 [==============================] - 0s 81us/sample - loss: 0.0229 - val_loss: 0.0174\n",
      "Epoch 39/50\n",
      "865/865 [==============================] - 0s 80us/sample - loss: 0.0210 - val_loss: 0.0128\n",
      "Epoch 40/50\n",
      "865/865 [==============================] - 0s 81us/sample - loss: 0.0228 - val_loss: 0.0171\n",
      "Epoch 41/50\n",
      "865/865 [==============================] - 0s 83us/sample - loss: 0.0209 - val_loss: 0.0128\n",
      "Epoch 42/50\n",
      "865/865 [==============================] - 0s 84us/sample - loss: 0.0228 - val_loss: 0.0172\n",
      "Epoch 43/50\n",
      "865/865 [==============================] - 0s 81us/sample - loss: 0.0209 - val_loss: 0.0128\n",
      "Epoch 44/50\n",
      "865/865 [==============================] - 0s 91us/sample - loss: 0.0227 - val_loss: 0.0170\n",
      "Epoch 45/50\n",
      "865/865 [==============================] - 0s 87us/sample - loss: 0.0208 - val_loss: 0.0128\n",
      "Epoch 46/50\n",
      "865/865 [==============================] - 0s 84us/sample - loss: 0.0228 - val_loss: 0.0171\n",
      "Epoch 47/50\n",
      "865/865 [==============================] - 0s 84us/sample - loss: 0.0208 - val_loss: 0.0128\n",
      "Epoch 48/50\n",
      "865/865 [==============================] - 0s 82us/sample - loss: 0.0228 - val_loss: 0.0173\n",
      "Epoch 49/50\n",
      "865/865 [==============================] - 0s 82us/sample - loss: 0.0209 - val_loss: 0.0127\n",
      "Epoch 50/50\n",
      "865/865 [==============================] - 0s 86us/sample - loss: 0.0227 - val_loss: 0.0170\n",
      "第77个数，还剩4046个没有训练\n",
      "inv_hat [1.0229099  1.01799557 1.01996311 1.01897961 1.01701112 1.01799557\n",
      " 1.01799557 1.01799557 1.01701112 1.01799557 1.01897961 1.01799557\n",
      " 1.01701112 1.01701112 1.01701112 1.01602606 1.01701112 1.01602606\n",
      " 1.01701112 1.01602606 1.01602606 1.01602606 1.01504063 1.01602606\n",
      " 1.01701112 1.01602606 1.01504063 1.01602606 1.01504063 1.01701112]\n",
      "Test RMSE: 0.002\n",
      "Train on 827 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "827/827 [==============================] - 0s 81us/sample - loss: 0.0250 - val_loss: 0.0165\n",
      "Epoch 2/50\n",
      "827/827 [==============================] - 0s 85us/sample - loss: 0.0244 - val_loss: 0.0164\n",
      "Epoch 3/50\n",
      "827/827 [==============================] - 0s 85us/sample - loss: 0.0244 - val_loss: 0.0177\n",
      "Epoch 4/50\n",
      "827/827 [==============================] - 0s 82us/sample - loss: 0.0243 - val_loss: 0.0164\n",
      "Epoch 5/50\n",
      "827/827 [==============================] - 0s 84us/sample - loss: 0.0242 - val_loss: 0.0165\n",
      "Epoch 6/50\n",
      "827/827 [==============================] - 0s 87us/sample - loss: 0.0242 - val_loss: 0.0169\n",
      "Epoch 7/50\n",
      "827/827 [==============================] - 0s 83us/sample - loss: 0.0243 - val_loss: 0.0168\n",
      "Epoch 8/50\n",
      "827/827 [==============================] - 0s 85us/sample - loss: 0.0242 - val_loss: 0.0165\n",
      "Epoch 9/50\n",
      "827/827 [==============================] - 0s 83us/sample - loss: 0.0242 - val_loss: 0.0164\n",
      "Epoch 10/50\n",
      "827/827 [==============================] - 0s 86us/sample - loss: 0.0242 - val_loss: 0.0169\n",
      "Epoch 11/50\n",
      "827/827 [==============================] - 0s 82us/sample - loss: 0.0242 - val_loss: 0.0167\n",
      "Epoch 12/50\n",
      "827/827 [==============================] - 0s 82us/sample - loss: 0.0242 - val_loss: 0.0166\n",
      "Epoch 13/50\n",
      "827/827 [==============================] - 0s 83us/sample - loss: 0.0242 - val_loss: 0.0166\n",
      "Epoch 14/50\n",
      "827/827 [==============================] - 0s 86us/sample - loss: 0.0242 - val_loss: 0.0169\n",
      "Epoch 15/50\n",
      "827/827 [==============================] - 0s 87us/sample - loss: 0.0242 - val_loss: 0.0167\n",
      "Epoch 16/50\n",
      "827/827 [==============================] - 0s 85us/sample - loss: 0.0242 - val_loss: 0.0166\n",
      "Epoch 17/50\n",
      "827/827 [==============================] - 0s 83us/sample - loss: 0.0242 - val_loss: 0.0166\n",
      "Epoch 18/50\n",
      "827/827 [==============================] - 0s 83us/sample - loss: 0.0242 - val_loss: 0.0168\n",
      "Epoch 19/50\n",
      "827/827 [==============================] - 0s 82us/sample - loss: 0.0242 - val_loss: 0.0166\n",
      "Epoch 20/50\n",
      "827/827 [==============================] - 0s 83us/sample - loss: 0.0242 - val_loss: 0.0167\n",
      "Epoch 21/50\n",
      "827/827 [==============================] - 0s 85us/sample - loss: 0.0242 - val_loss: 0.0167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "827/827 [==============================] - 0s 87us/sample - loss: 0.0242 - val_loss: 0.0167\n",
      "Epoch 23/50\n",
      "827/827 [==============================] - 0s 80us/sample - loss: 0.0242 - val_loss: 0.0168\n",
      "Epoch 24/50\n",
      "827/827 [==============================] - 0s 84us/sample - loss: 0.0242 - val_loss: 0.0168\n",
      "Epoch 25/50\n",
      "827/827 [==============================] - 0s 84us/sample - loss: 0.0242 - val_loss: 0.0167\n",
      "Epoch 26/50\n",
      "827/827 [==============================] - 0s 81us/sample - loss: 0.0242 - val_loss: 0.0166\n",
      "Epoch 27/50\n",
      "827/827 [==============================] - 0s 79us/sample - loss: 0.0242 - val_loss: 0.0168\n",
      "Epoch 28/50\n",
      "827/827 [==============================] - 0s 79us/sample - loss: 0.0242 - val_loss: 0.0167\n",
      "Epoch 29/50\n",
      "827/827 [==============================] - 0s 83us/sample - loss: 0.0242 - val_loss: 0.0168\n",
      "Epoch 30/50\n",
      "827/827 [==============================] - 0s 82us/sample - loss: 0.0242 - val_loss: 0.0168\n",
      "Epoch 31/50\n",
      "827/827 [==============================] - 0s 79us/sample - loss: 0.0242 - val_loss: 0.0167\n",
      "Epoch 32/50\n",
      "827/827 [==============================] - 0s 81us/sample - loss: 0.0242 - val_loss: 0.0166\n",
      "Epoch 33/50\n",
      "827/827 [==============================] - 0s 79us/sample - loss: 0.0242 - val_loss: 0.0169\n",
      "Epoch 34/50\n",
      "827/827 [==============================] - 0s 87us/sample - loss: 0.0242 - val_loss: 0.0167\n",
      "Epoch 35/50\n",
      "827/827 [==============================] - 0s 84us/sample - loss: 0.0242 - val_loss: 0.0168\n",
      "Epoch 36/50\n",
      "827/827 [==============================] - 0s 84us/sample - loss: 0.0242 - val_loss: 0.0167\n",
      "Epoch 37/50\n",
      "827/827 [==============================] - 0s 85us/sample - loss: 0.0242 - val_loss: 0.0168\n",
      "Epoch 38/50\n",
      "827/827 [==============================] - 0s 85us/sample - loss: 0.0242 - val_loss: 0.0167\n",
      "Epoch 39/50\n",
      "827/827 [==============================] - 0s 85us/sample - loss: 0.0242 - val_loss: 0.0167\n",
      "Epoch 40/50\n",
      "827/827 [==============================] - 0s 82us/sample - loss: 0.0242 - val_loss: 0.0168\n",
      "Epoch 41/50\n",
      "827/827 [==============================] - 0s 83us/sample - loss: 0.0242 - val_loss: 0.0168\n",
      "Epoch 42/50\n",
      "827/827 [==============================] - 0s 85us/sample - loss: 0.0242 - val_loss: 0.0167\n",
      "Epoch 43/50\n",
      "827/827 [==============================] - 0s 79us/sample - loss: 0.0242 - val_loss: 0.0168\n",
      "Epoch 44/50\n",
      "827/827 [==============================] - 0s 86us/sample - loss: 0.0242 - val_loss: 0.0167\n",
      "Epoch 45/50\n",
      "827/827 [==============================] - 0s 85us/sample - loss: 0.0242 - val_loss: 0.0169\n",
      "Epoch 46/50\n",
      "827/827 [==============================] - 0s 82us/sample - loss: 0.0243 - val_loss: 0.0167\n",
      "Epoch 47/50\n",
      "827/827 [==============================] - 0s 81us/sample - loss: 0.0242 - val_loss: 0.0166\n",
      "Epoch 48/50\n",
      "827/827 [==============================] - 0s 79us/sample - loss: 0.0242 - val_loss: 0.0167\n",
      "Epoch 49/50\n",
      "827/827 [==============================] - 0s 84us/sample - loss: 0.0242 - val_loss: 0.0169\n",
      "Epoch 50/50\n",
      "827/827 [==============================] - 0s 86us/sample - loss: 0.0242 - val_loss: 0.0168\n",
      "第78个数，还剩4045个没有训练\n",
      "inv_hat [1.01514633 0.99913485 1.001135   1.001135   0.98414882 0.98215307\n",
      " 0.98115546 0.9921377  0.98514694 0.99413627 1.01714904 1.01815043\n",
      " 1.01714904 0.99913485 1.001135   0.99413627 1.00013488 1.00313555\n",
      " 1.01815043 1.00613714 0.99913485 0.99413627 0.98215307 0.97616977\n",
      " 0.96820207 0.97318044 0.97118853 0.97019282 0.97118853 0.97816352]\n",
      "Test RMSE: 0.009\n",
      "Train on 797 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "797/797 [==============================] - 0s 87us/sample - loss: 0.0129 - val_loss: 0.0066\n",
      "Epoch 2/50\n",
      "797/797 [==============================] - 0s 82us/sample - loss: 0.0125 - val_loss: 0.0051\n",
      "Epoch 3/50\n",
      "797/797 [==============================] - 0s 84us/sample - loss: 0.0125 - val_loss: 0.0066\n",
      "Epoch 4/50\n",
      "797/797 [==============================] - 0s 85us/sample - loss: 0.0124 - val_loss: 0.0067\n",
      "Epoch 5/50\n",
      "797/797 [==============================] - 0s 83us/sample - loss: 0.0126 - val_loss: 0.0065\n",
      "Epoch 6/50\n",
      "797/797 [==============================] - 0s 84us/sample - loss: 0.0126 - val_loss: 0.0074\n",
      "Epoch 7/50\n",
      "797/797 [==============================] - 0s 83us/sample - loss: 0.0128 - val_loss: 0.0080\n",
      "Epoch 8/50\n",
      "797/797 [==============================] - 0s 87us/sample - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 9/50\n",
      "797/797 [==============================] - 0s 86us/sample - loss: 0.0129 - val_loss: 0.0076\n",
      "Epoch 10/50\n",
      "797/797 [==============================] - 0s 81us/sample - loss: 0.0130 - val_loss: 0.0077\n",
      "Epoch 11/50\n",
      "797/797 [==============================] - 0s 83us/sample - loss: 0.0128 - val_loss: 0.0080\n",
      "Epoch 12/50\n",
      "797/797 [==============================] - 0s 83us/sample - loss: 0.0128 - val_loss: 0.0079\n",
      "Epoch 13/50\n",
      "797/797 [==============================] - 0s 85us/sample - loss: 0.0130 - val_loss: 0.0081\n",
      "Epoch 14/50\n",
      "797/797 [==============================] - 0s 85us/sample - loss: 0.0129 - val_loss: 0.0084\n",
      "Epoch 15/50\n",
      "797/797 [==============================] - ETA: 0s - loss: 0.012 - 0s 86us/sample - loss: 0.0128 - val_loss: 0.0072\n",
      "Epoch 16/50\n",
      "797/797 [==============================] - 0s 89us/sample - loss: 0.0126 - val_loss: 0.0056\n",
      "Epoch 17/50\n",
      "797/797 [==============================] - 0s 88us/sample - loss: 0.0125 - val_loss: 0.0052\n",
      "Epoch 18/50\n",
      "797/797 [==============================] - 0s 85us/sample - loss: 0.0125 - val_loss: 0.0070\n",
      "Epoch 19/50\n",
      "797/797 [==============================] - 0s 85us/sample - loss: 0.0126 - val_loss: 0.0080\n",
      "Epoch 20/50\n",
      "797/797 [==============================] - 0s 87us/sample - loss: 0.0127 - val_loss: 0.0078\n",
      "Epoch 21/50\n",
      "797/797 [==============================] - 0s 85us/sample - loss: 0.0127 - val_loss: 0.0070\n",
      "Epoch 22/50\n",
      "797/797 [==============================] - 0s 85us/sample - loss: 0.0126 - val_loss: 0.0057\n",
      "Epoch 23/50\n",
      "797/797 [==============================] - 0s 82us/sample - loss: 0.0125 - val_loss: 0.0055\n",
      "Epoch 24/50\n",
      "797/797 [==============================] - 0s 84us/sample - loss: 0.0125 - val_loss: 0.0070\n",
      "Epoch 25/50\n",
      "797/797 [==============================] - 0s 87us/sample - loss: 0.0126 - val_loss: 0.0077\n",
      "Epoch 26/50\n",
      "797/797 [==============================] - 0s 84us/sample - loss: 0.0127 - val_loss: 0.0078\n",
      "Epoch 27/50\n",
      "797/797 [==============================] - 0s 85us/sample - loss: 0.0130 - val_loss: 0.0066\n",
      "Epoch 28/50\n",
      "797/797 [==============================] - 0s 87us/sample - loss: 0.0127 - val_loss: 0.0052\n",
      "Epoch 29/50\n",
      "797/797 [==============================] - 0s 87us/sample - loss: 0.0125 - val_loss: 0.0044\n",
      "Epoch 30/50\n",
      "797/797 [==============================] - 0s 84us/sample - loss: 0.0125 - val_loss: 0.0046\n",
      "Epoch 31/50\n",
      "797/797 [==============================] - 0s 89us/sample - loss: 0.0125 - val_loss: 0.0073\n",
      "Epoch 32/50\n",
      "797/797 [==============================] - 0s 92us/sample - loss: 0.0126 - val_loss: 0.0072\n",
      "Epoch 33/50\n",
      "797/797 [==============================] - 0s 85us/sample - loss: 0.0126 - val_loss: 0.0072\n",
      "Epoch 34/50\n",
      "797/797 [==============================] - 0s 85us/sample - loss: 0.0126 - val_loss: 0.0067\n",
      "Epoch 35/50\n",
      "797/797 [==============================] - 0s 88us/sample - loss: 0.0125 - val_loss: 0.0054\n",
      "Epoch 36/50\n",
      "797/797 [==============================] - 0s 86us/sample - loss: 0.0124 - val_loss: 0.0055\n",
      "Epoch 37/50\n",
      "797/797 [==============================] - 0s 88us/sample - loss: 0.0125 - val_loss: 0.0055\n",
      "Epoch 38/50\n",
      "797/797 [==============================] - 0s 88us/sample - loss: 0.0125 - val_loss: 0.0054\n",
      "Epoch 39/50\n",
      "797/797 [==============================] - 0s 86us/sample - loss: 0.0125 - val_loss: 0.0061\n",
      "Epoch 40/50\n",
      "797/797 [==============================] - 0s 85us/sample - loss: 0.0126 - val_loss: 0.0068\n",
      "Epoch 41/50\n",
      "797/797 [==============================] - 0s 92us/sample - loss: 0.0125 - val_loss: 0.0059\n",
      "Epoch 42/50\n",
      "797/797 [==============================] - 0s 85us/sample - loss: 0.0125 - val_loss: 0.0053\n",
      "Epoch 43/50\n",
      "797/797 [==============================] - 0s 87us/sample - loss: 0.0124 - val_loss: 0.0054\n",
      "Epoch 44/50\n",
      "797/797 [==============================] - 0s 89us/sample - loss: 0.0125 - val_loss: 0.0054\n",
      "Epoch 45/50\n",
      "797/797 [==============================] - 0s 89us/sample - loss: 0.0125 - val_loss: 0.0054\n",
      "Epoch 46/50\n",
      "797/797 [==============================] - 0s 90us/sample - loss: 0.0125 - val_loss: 0.0064\n",
      "Epoch 47/50\n",
      "797/797 [==============================] - 0s 88us/sample - loss: 0.0126 - val_loss: 0.0073\n",
      "Epoch 48/50\n",
      "797/797 [==============================] - 0s 88us/sample - loss: 0.0127 - val_loss: 0.0069\n",
      "Epoch 49/50\n",
      "797/797 [==============================] - 0s 89us/sample - loss: 0.0126 - val_loss: 0.0064\n",
      "Epoch 50/50\n",
      "797/797 [==============================] - 0s 85us/sample - loss: 0.0125 - val_loss: 0.0057\n",
      "第79个数，还剩4044个没有训练\n",
      "inv_hat [1.02235852 1.01979124 1.01751847 1.02847142 1.02837294 1.02827441\n",
      " 1.02817594 1.02817594 1.02788039 1.02768346 1.02768346 1.0274864\n",
      " 1.02738786 1.02699381 1.02689525 1.02679669 1.02669814 1.02659957\n",
      " 1.02620539 1.02664836 1.02645129 1.02635275 1.02625431 1.02586009\n",
      " 1.02576151 1.02566296 1.02556437 1.0254659  1.02497295 1.02477586]\n",
      "Test RMSE: 0.002\n",
      "Train on 523 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "523/523 [==============================] - 0s 91us/sample - loss: 0.0044 - val_loss: 0.0070\n",
      "Epoch 2/50\n",
      "523/523 [==============================] - 0s 86us/sample - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 3/50\n",
      "523/523 [==============================] - 0s 85us/sample - loss: 0.0102 - val_loss: 0.0118\n",
      "Epoch 4/50\n",
      "523/523 [==============================] - 0s 83us/sample - loss: 0.0046 - val_loss: 0.0026\n",
      "Epoch 5/50\n",
      "523/523 [==============================] - 0s 85us/sample - loss: 0.0057 - val_loss: 0.0035\n",
      "Epoch 6/50\n",
      "523/523 [==============================] - 0s 92us/sample - loss: 0.0061 - val_loss: 0.0030\n",
      "Epoch 7/50\n",
      "523/523 [==============================] - 0s 91us/sample - loss: 0.0100 - val_loss: 0.0057\n",
      "Epoch 8/50\n",
      "523/523 [==============================] - 0s 97us/sample - loss: 0.0107 - val_loss: 0.0027\n",
      "Epoch 9/50\n",
      "523/523 [==============================] - 0s 94us/sample - loss: 0.0121 - val_loss: 0.0074\n",
      "Epoch 10/50\n",
      "523/523 [==============================] - 0s 89us/sample - loss: 0.0075 - val_loss: 0.0044\n",
      "Epoch 11/50\n",
      "523/523 [==============================] - 0s 95us/sample - loss: 0.0083 - val_loss: 0.0052\n",
      "Epoch 12/50\n",
      "523/523 [==============================] - 0s 96us/sample - loss: 0.0134 - val_loss: 0.0057\n",
      "Epoch 13/50\n",
      "523/523 [==============================] - 0s 91us/sample - loss: 0.0089 - val_loss: 0.0023\n",
      "Epoch 14/50\n",
      "523/523 [==============================] - 0s 89us/sample - loss: 0.0081 - val_loss: 0.0024\n",
      "Epoch 15/50\n",
      "523/523 [==============================] - 0s 92us/sample - loss: 0.0110 - val_loss: 0.0022\n",
      "Epoch 16/50\n",
      "523/523 [==============================] - 0s 89us/sample - loss: 0.0089 - val_loss: 0.0024\n",
      "Epoch 17/50\n",
      "523/523 [==============================] - 0s 88us/sample - loss: 0.0097 - val_loss: 0.0022\n",
      "Epoch 18/50\n",
      "523/523 [==============================] - 0s 90us/sample - loss: 0.0091 - val_loss: 0.0022\n",
      "Epoch 19/50\n",
      "523/523 [==============================] - 0s 85us/sample - loss: 0.0096 - val_loss: 0.0025\n",
      "Epoch 20/50\n",
      "523/523 [==============================] - 0s 88us/sample - loss: 0.0086 - val_loss: 0.0022\n",
      "Epoch 21/50\n",
      "523/523 [==============================] - 0s 86us/sample - loss: 0.0095 - val_loss: 0.0025\n",
      "Epoch 22/50\n",
      "523/523 [==============================] - 0s 87us/sample - loss: 0.0086 - val_loss: 0.0022\n",
      "Epoch 23/50\n",
      "523/523 [==============================] - 0s 88us/sample - loss: 0.0093 - val_loss: 0.0025\n",
      "Epoch 24/50\n",
      "523/523 [==============================] - 0s 87us/sample - loss: 0.0085 - val_loss: 0.0022\n",
      "Epoch 25/50\n",
      "523/523 [==============================] - 0s 87us/sample - loss: 0.0091 - val_loss: 0.0025\n",
      "Epoch 26/50\n",
      "523/523 [==============================] - 0s 87us/sample - loss: 0.0084 - val_loss: 0.0022\n",
      "Epoch 27/50\n",
      "523/523 [==============================] - 0s 88us/sample - loss: 0.0090 - val_loss: 0.0025\n",
      "Epoch 28/50\n",
      "523/523 [==============================] - 0s 87us/sample - loss: 0.0083 - val_loss: 0.0022\n",
      "Epoch 29/50\n",
      "523/523 [==============================] - 0s 88us/sample - loss: 0.0088 - val_loss: 0.0024\n",
      "Epoch 30/50\n",
      "523/523 [==============================] - 0s 89us/sample - loss: 0.0083 - val_loss: 0.0022\n",
      "Epoch 31/50\n",
      "523/523 [==============================] - 0s 91us/sample - loss: 0.0087 - val_loss: 0.0026\n",
      "Epoch 32/50\n",
      "523/523 [==============================] - 0s 92us/sample - loss: 0.0080 - val_loss: 0.0022\n",
      "Epoch 33/50\n",
      "523/523 [==============================] - 0s 90us/sample - loss: 0.0084 - val_loss: 0.0022\n",
      "Epoch 34/50\n",
      "523/523 [==============================] - 0s 89us/sample - loss: 0.0085 - val_loss: 0.0023\n",
      "Epoch 35/50\n",
      "523/523 [==============================] - 0s 87us/sample - loss: 0.0085 - val_loss: 0.0026\n",
      "Epoch 36/50\n",
      "523/523 [==============================] - 0s 90us/sample - loss: 0.0077 - val_loss: 0.0022\n",
      "Epoch 37/50\n",
      "523/523 [==============================] - 0s 92us/sample - loss: 0.0081 - val_loss: 0.0022\n",
      "Epoch 38/50\n",
      "523/523 [==============================] - 0s 92us/sample - loss: 0.0084 - val_loss: 0.0023\n",
      "Epoch 39/50\n",
      "523/523 [==============================] - 0s 92us/sample - loss: 0.0082 - val_loss: 0.0026\n",
      "Epoch 40/50\n",
      "523/523 [==============================] - 0s 89us/sample - loss: 0.0077 - val_loss: 0.0022\n",
      "Epoch 41/50\n",
      "523/523 [==============================] - 0s 90us/sample - loss: 0.0083 - val_loss: 0.0025\n",
      "Epoch 42/50\n",
      "523/523 [==============================] - 0s 91us/sample - loss: 0.0078 - val_loss: 0.0022\n",
      "Epoch 43/50\n",
      "523/523 [==============================] - 0s 86us/sample - loss: 0.0081 - val_loss: 0.0025\n",
      "Epoch 44/50\n",
      "523/523 [==============================] - 0s 86us/sample - loss: 0.0077 - val_loss: 0.0022\n",
      "Epoch 45/50\n",
      "523/523 [==============================] - 0s 87us/sample - loss: 0.0079 - val_loss: 0.0025\n",
      "Epoch 46/50\n",
      "523/523 [==============================] - 0s 86us/sample - loss: 0.0077 - val_loss: 0.0023\n",
      "Epoch 47/50\n",
      "523/523 [==============================] - 0s 84us/sample - loss: 0.0079 - val_loss: 0.0026\n",
      "Epoch 48/50\n",
      "523/523 [==============================] - 0s 85us/sample - loss: 0.0077 - val_loss: 0.0023\n",
      "Epoch 49/50\n",
      "523/523 [==============================] - 0s 88us/sample - loss: 0.0075 - val_loss: 0.0024\n",
      "Epoch 50/50\n",
      "523/523 [==============================] - 0s 96us/sample - loss: 0.0078 - val_loss: 0.0023\n",
      "第80个数，还剩4043个没有训练\n",
      "inv_hat [1.07890289 1.0790948  1.07919073 1.0793825  1.0793825  1.07957409\n",
      " 1.07947825 1.07947825 1.07957409 1.07976568 1.08005292 1.08014863\n",
      " 1.08081779 1.0809132  1.08132114 1.08179775 1.08189303 1.08198828\n",
      " 1.08179775 1.08141653 1.08160725 1.08113028 1.08113028 1.08141653\n",
      " 1.08189303 1.08217873 1.08217873 1.08217873 1.08236906 1.08312927]\n",
      "Test RMSE: 0.000\n",
      "Train on 704 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "704/704 [==============================] - 0s 86us/sample - loss: 0.0268 - val_loss: 0.0223\n",
      "Epoch 2/50\n",
      "704/704 [==============================] - 0s 87us/sample - loss: 0.0255 - val_loss: 0.0270\n",
      "Epoch 3/50\n",
      "704/704 [==============================] - 0s 86us/sample - loss: 0.0248 - val_loss: 0.0244\n",
      "Epoch 4/50\n",
      "704/704 [==============================] - 0s 85us/sample - loss: 0.0250 - val_loss: 0.0267\n",
      "Epoch 5/50\n",
      "704/704 [==============================] - 0s 82us/sample - loss: 0.0249 - val_loss: 0.0263\n",
      "Epoch 6/50\n",
      "704/704 [==============================] - 0s 82us/sample - loss: 0.0248 - val_loss: 0.0265\n",
      "Epoch 7/50\n",
      "704/704 [==============================] - 0s 79us/sample - loss: 0.0248 - val_loss: 0.0271\n",
      "Epoch 8/50\n",
      "704/704 [==============================] - 0s 82us/sample - loss: 0.0248 - val_loss: 0.0270\n",
      "Epoch 9/50\n",
      "704/704 [==============================] - 0s 82us/sample - loss: 0.0248 - val_loss: 0.0275\n",
      "Epoch 10/50\n",
      "704/704 [==============================] - 0s 81us/sample - loss: 0.0248 - val_loss: 0.0275\n",
      "Epoch 11/50\n",
      "704/704 [==============================] - 0s 77us/sample - loss: 0.0248 - val_loss: 0.0278\n",
      "Epoch 12/50\n",
      "704/704 [==============================] - 0s 79us/sample - loss: 0.0248 - val_loss: 0.0277\n",
      "Epoch 13/50\n",
      "704/704 [==============================] - 0s 78us/sample - loss: 0.0248 - val_loss: 0.0277\n",
      "Epoch 14/50\n",
      "704/704 [==============================] - 0s 78us/sample - loss: 0.0247 - val_loss: 0.0277\n",
      "Epoch 15/50\n",
      "704/704 [==============================] - 0s 75us/sample - loss: 0.0248 - val_loss: 0.0277\n",
      "Epoch 16/50\n",
      "704/704 [==============================] - 0s 75us/sample - loss: 0.0248 - val_loss: 0.0278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "704/704 [==============================] - 0s 79us/sample - loss: 0.0247 - val_loss: 0.0277\n",
      "Epoch 18/50\n",
      "704/704 [==============================] - 0s 78us/sample - loss: 0.0248 - val_loss: 0.0278\n",
      "Epoch 19/50\n",
      "704/704 [==============================] - 0s 80us/sample - loss: 0.0248 - val_loss: 0.0279\n",
      "Epoch 20/50\n",
      "704/704 [==============================] - 0s 80us/sample - loss: 0.0247 - val_loss: 0.0278\n",
      "Epoch 21/50\n",
      "704/704 [==============================] - 0s 77us/sample - loss: 0.0247 - val_loss: 0.0278\n",
      "Epoch 22/50\n",
      "704/704 [==============================] - 0s 78us/sample - loss: 0.0248 - val_loss: 0.0279\n",
      "Epoch 23/50\n",
      "704/704 [==============================] - 0s 86us/sample - loss: 0.0247 - val_loss: 0.0279\n",
      "Epoch 24/50\n",
      "704/704 [==============================] - 0s 86us/sample - loss: 0.0247 - val_loss: 0.0279\n",
      "Epoch 25/50\n",
      "704/704 [==============================] - 0s 85us/sample - loss: 0.0247 - val_loss: 0.0279\n",
      "Epoch 26/50\n",
      "704/704 [==============================] - 0s 81us/sample - loss: 0.0247 - val_loss: 0.0278\n",
      "Epoch 27/50\n",
      "704/704 [==============================] - 0s 87us/sample - loss: 0.0247 - val_loss: 0.0280\n",
      "Epoch 28/50\n",
      "704/704 [==============================] - 0s 79us/sample - loss: 0.0247 - val_loss: 0.0279\n",
      "Epoch 29/50\n",
      "704/704 [==============================] - 0s 85us/sample - loss: 0.0247 - val_loss: 0.0280\n",
      "Epoch 30/50\n",
      "704/704 [==============================] - 0s 87us/sample - loss: 0.0247 - val_loss: 0.0279\n",
      "Epoch 31/50\n",
      "704/704 [==============================] - 0s 77us/sample - loss: 0.0247 - val_loss: 0.0282\n",
      "Epoch 32/50\n",
      "704/704 [==============================] - 0s 79us/sample - loss: 0.0247 - val_loss: 0.0280\n",
      "Epoch 33/50\n",
      "704/704 [==============================] - 0s 85us/sample - loss: 0.0247 - val_loss: 0.0282\n",
      "Epoch 34/50\n",
      "704/704 [==============================] - 0s 77us/sample - loss: 0.0247 - val_loss: 0.0280\n",
      "Epoch 35/50\n",
      "704/704 [==============================] - 0s 84us/sample - loss: 0.0247 - val_loss: 0.0283\n",
      "Epoch 36/50\n",
      "704/704 [==============================] - 0s 85us/sample - loss: 0.0247 - val_loss: 0.0280\n",
      "Epoch 37/50\n",
      "704/704 [==============================] - 0s 78us/sample - loss: 0.0247 - val_loss: 0.0282\n",
      "Epoch 38/50\n",
      "704/704 [==============================] - 0s 81us/sample - loss: 0.0247 - val_loss: 0.0281\n",
      "Epoch 39/50\n",
      "704/704 [==============================] - 0s 82us/sample - loss: 0.0247 - val_loss: 0.0285\n",
      "Epoch 40/50\n",
      "704/704 [==============================] - 0s 82us/sample - loss: 0.0247 - val_loss: 0.0282\n",
      "Epoch 41/50\n",
      "704/704 [==============================] - 0s 85us/sample - loss: 0.0248 - val_loss: 0.0286\n",
      "Epoch 42/50\n",
      "704/704 [==============================] - 0s 79us/sample - loss: 0.0247 - val_loss: 0.0283\n",
      "Epoch 43/50\n",
      "704/704 [==============================] - 0s 79us/sample - loss: 0.0247 - val_loss: 0.0287\n",
      "Epoch 44/50\n",
      "704/704 [==============================] - 0s 79us/sample - loss: 0.0247 - val_loss: 0.0283\n",
      "Epoch 45/50\n",
      "704/704 [==============================] - 0s 80us/sample - loss: 0.0247 - val_loss: 0.0287\n",
      "Epoch 46/50\n",
      "704/704 [==============================] - 0s 83us/sample - loss: 0.0247 - val_loss: 0.0284\n",
      "Epoch 47/50\n",
      "704/704 [==============================] - 0s 79us/sample - loss: 0.0247 - val_loss: 0.0288\n",
      "Epoch 48/50\n",
      "704/704 [==============================] - 0s 81us/sample - loss: 0.0247 - val_loss: 0.0284\n",
      "Epoch 49/50\n",
      "704/704 [==============================] - 0s 77us/sample - loss: 0.0247 - val_loss: 0.0288\n",
      "Epoch 50/50\n",
      "704/704 [==============================] - 0s 84us/sample - loss: 0.0247 - val_loss: 0.0285\n",
      "第81个数，还剩4042个没有训练\n",
      "inv_hat [0.92147646 0.93267275 0.91935848 0.93557588 0.94323456 0.93683479\n",
      " 0.93731915 0.93151231 0.92793754 0.93596313 0.95334555 0.97345694\n",
      " 0.97159787 0.96514616 0.96133862 0.96133862 0.95821731 0.94469089\n",
      " 0.92928962 0.91801163 0.89866517 0.92398182 0.91628106 0.92986925\n",
      " 0.93073898 0.93189908 0.92996589 0.91052159 0.89942814 0.88630744]\n",
      "Test RMSE: 0.014\n",
      "Train on 541 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "541/541 [==============================] - 0s 85us/sample - loss: 0.0202 - val_loss: 0.0082\n",
      "Epoch 2/50\n",
      "541/541 [==============================] - 0s 88us/sample - loss: 0.0152 - val_loss: 0.0066\n",
      "Epoch 3/50\n",
      "541/541 [==============================] - 0s 86us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 4/50\n",
      "541/541 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0070\n",
      "Epoch 5/50\n",
      "541/541 [==============================] - 0s 85us/sample - loss: 0.0151 - val_loss: 0.0057\n",
      "Epoch 6/50\n",
      "541/541 [==============================] - 0s 87us/sample - loss: 0.0156 - val_loss: 0.0061\n",
      "Epoch 7/50\n",
      "541/541 [==============================] - 0s 92us/sample - loss: 0.0162 - val_loss: 0.0080\n",
      "Epoch 8/50\n",
      "541/541 [==============================] - 0s 89us/sample - loss: 0.0151 - val_loss: 0.0061\n",
      "Epoch 9/50\n",
      "541/541 [==============================] - 0s 87us/sample - loss: 0.0151 - val_loss: 0.0051\n",
      "Epoch 10/50\n",
      "541/541 [==============================] - 0s 90us/sample - loss: 0.0158 - val_loss: 0.0054\n",
      "Epoch 11/50\n",
      "541/541 [==============================] - 0s 89us/sample - loss: 0.0166 - val_loss: 0.0073\n",
      "Epoch 12/50\n",
      "541/541 [==============================] - 0s 83us/sample - loss: 0.0162 - val_loss: 0.0054\n",
      "Epoch 13/50\n",
      "541/541 [==============================] - 0s 82us/sample - loss: 0.0157 - val_loss: 0.0066\n",
      "Epoch 14/50\n",
      "541/541 [==============================] - 0s 91us/sample - loss: 0.0146 - val_loss: 0.0062\n",
      "Epoch 15/50\n",
      "541/541 [==============================] - 0s 89us/sample - loss: 0.0150 - val_loss: 0.0052\n",
      "Epoch 16/50\n",
      "541/541 [==============================] - 0s 89us/sample - loss: 0.0155 - val_loss: 0.0055\n",
      "Epoch 17/50\n",
      "541/541 [==============================] - 0s 85us/sample - loss: 0.0162 - val_loss: 0.0062\n",
      "Epoch 18/50\n",
      "541/541 [==============================] - 0s 85us/sample - loss: 0.0155 - val_loss: 0.0062\n",
      "Epoch 19/50\n",
      "541/541 [==============================] - 0s 85us/sample - loss: 0.0149 - val_loss: 0.0052\n",
      "Epoch 20/50\n",
      "541/541 [==============================] - 0s 81us/sample - loss: 0.0166 - val_loss: 0.0067\n",
      "Epoch 21/50\n",
      "541/541 [==============================] - 0s 85us/sample - loss: 0.0172 - val_loss: 0.0101\n",
      "Epoch 22/50\n",
      "541/541 [==============================] - 0s 82us/sample - loss: 0.0171 - val_loss: 0.0071\n",
      "Epoch 23/50\n",
      "541/541 [==============================] - 0s 93us/sample - loss: 0.0189 - val_loss: 0.0169\n",
      "Epoch 24/50\n",
      "541/541 [==============================] - 0s 88us/sample - loss: 0.0178 - val_loss: 0.0126\n",
      "Epoch 25/50\n",
      "541/541 [==============================] - 0s 85us/sample - loss: 0.0175 - val_loss: 0.0120\n",
      "Epoch 26/50\n",
      "541/541 [==============================] - 0s 83us/sample - loss: 0.0173 - val_loss: 0.0085\n",
      "Epoch 27/50\n",
      "541/541 [==============================] - 0s 85us/sample - loss: 0.0152 - val_loss: 0.0070\n",
      "Epoch 28/50\n",
      "541/541 [==============================] - 0s 89us/sample - loss: 0.0153 - val_loss: 0.0067\n",
      "Epoch 29/50\n",
      "541/541 [==============================] - 0s 90us/sample - loss: 0.0172 - val_loss: 0.0106\n",
      "Epoch 30/50\n",
      "541/541 [==============================] - 0s 88us/sample - loss: 0.0173 - val_loss: 0.0095\n",
      "Epoch 31/50\n",
      "541/541 [==============================] - 0s 87us/sample - loss: 0.0153 - val_loss: 0.0083\n",
      "Epoch 32/50\n",
      "541/541 [==============================] - 0s 88us/sample - loss: 0.0154 - val_loss: 0.0066\n",
      "Epoch 33/50\n",
      "541/541 [==============================] - 0s 88us/sample - loss: 0.0170 - val_loss: 0.0100\n",
      "Epoch 34/50\n",
      "541/541 [==============================] - 0s 91us/sample - loss: 0.0174 - val_loss: 0.0099\n",
      "Epoch 35/50\n",
      "541/541 [==============================] - 0s 84us/sample - loss: 0.0154 - val_loss: 0.0092\n",
      "Epoch 36/50\n",
      "541/541 [==============================] - 0s 83us/sample - loss: 0.0153 - val_loss: 0.0064\n",
      "Epoch 37/50\n",
      "541/541 [==============================] - 0s 84us/sample - loss: 0.0163 - val_loss: 0.0081\n",
      "Epoch 38/50\n",
      "541/541 [==============================] - 0s 82us/sample - loss: 0.0167 - val_loss: 0.0075\n",
      "Epoch 39/50\n",
      "541/541 [==============================] - 0s 81us/sample - loss: 0.0158 - val_loss: 0.0075\n",
      "Epoch 40/50\n",
      "541/541 [==============================] - 0s 85us/sample - loss: 0.0160 - val_loss: 0.0066\n",
      "Epoch 41/50\n",
      "541/541 [==============================] - 0s 84us/sample - loss: 0.0183 - val_loss: 0.0155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "541/541 [==============================] - 0s 83us/sample - loss: 0.0177 - val_loss: 0.0126\n",
      "Epoch 43/50\n",
      "541/541 [==============================] - 0s 88us/sample - loss: 0.0169 - val_loss: 0.0102\n",
      "Epoch 44/50\n",
      "541/541 [==============================] - 0s 84us/sample - loss: 0.0170 - val_loss: 0.0083\n",
      "Epoch 45/50\n",
      "541/541 [==============================] - 0s 87us/sample - loss: 0.0152 - val_loss: 0.0075\n",
      "Epoch 46/50\n",
      "541/541 [==============================] - 0s 89us/sample - loss: 0.0153 - val_loss: 0.0069\n",
      "Epoch 47/50\n",
      "541/541 [==============================] - 0s 90us/sample - loss: 0.0170 - val_loss: 0.0094\n",
      "Epoch 48/50\n",
      "541/541 [==============================] - 0s 85us/sample - loss: 0.0170 - val_loss: 0.0092\n",
      "Epoch 49/50\n",
      "541/541 [==============================] - 0s 84us/sample - loss: 0.0155 - val_loss: 0.0079\n",
      "Epoch 50/50\n",
      "541/541 [==============================] - 0s 82us/sample - loss: 0.0157 - val_loss: 0.0067\n",
      "第82个数，还剩4041个没有训练\n",
      "inv_hat [1.07734215 1.07637987 1.07637987 1.07637987 1.07541545 1.07541545\n",
      " 1.07541545 1.07637987 1.07541545 1.07541545 1.07734215 1.07734215\n",
      " 1.07734215 1.07637987 1.07637987 1.07637987 1.07637987 1.07734215\n",
      " 1.07734215 1.07637987 1.07541545 1.07541545 1.07444922 1.07348093\n",
      " 1.07251076 1.07348093 1.07348093 1.07251076 1.07251076 1.07251076]\n",
      "Test RMSE: 0.001\n",
      "Train on 873 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "873/873 [==============================] - 0s 82us/sample - loss: 0.0285 - val_loss: 0.0394\n",
      "Epoch 2/50\n",
      "873/873 [==============================] - 0s 81us/sample - loss: 0.0281 - val_loss: 0.0387\n",
      "Epoch 3/50\n",
      "873/873 [==============================] - 0s 84us/sample - loss: 0.0277 - val_loss: 0.0394\n",
      "Epoch 4/50\n",
      "873/873 [==============================] - 0s 81us/sample - loss: 0.0273 - val_loss: 0.0389\n",
      "Epoch 5/50\n",
      "873/873 [==============================] - 0s 83us/sample - loss: 0.0273 - val_loss: 0.0391\n",
      "Epoch 6/50\n",
      "873/873 [==============================] - 0s 82us/sample - loss: 0.0272 - val_loss: 0.0389\n",
      "Epoch 7/50\n",
      "873/873 [==============================] - 0s 85us/sample - loss: 0.0272 - val_loss: 0.0389\n",
      "Epoch 8/50\n",
      "873/873 [==============================] - 0s 82us/sample - loss: 0.0272 - val_loss: 0.0389\n",
      "Epoch 9/50\n",
      "873/873 [==============================] - 0s 83us/sample - loss: 0.0272 - val_loss: 0.0388\n",
      "Epoch 10/50\n",
      "873/873 [==============================] - 0s 83us/sample - loss: 0.0272 - val_loss: 0.0388\n",
      "Epoch 11/50\n",
      "873/873 [==============================] - 0s 86us/sample - loss: 0.0272 - val_loss: 0.0388\n",
      "Epoch 12/50\n",
      "873/873 [==============================] - 0s 82us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 13/50\n",
      "873/873 [==============================] - 0s 83us/sample - loss: 0.0272 - val_loss: 0.0388\n",
      "Epoch 14/50\n",
      "873/873 [==============================] - 0s 90us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 15/50\n",
      "873/873 [==============================] - 0s 87us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 16/50\n",
      "873/873 [==============================] - 0s 87us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 17/50\n",
      "873/873 [==============================] - 0s 89us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 18/50\n",
      "873/873 [==============================] - 0s 83us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 19/50\n",
      "873/873 [==============================] - 0s 88us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 20/50\n",
      "873/873 [==============================] - 0s 82us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 21/50\n",
      "873/873 [==============================] - 0s 84us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 22/50\n",
      "873/873 [==============================] - 0s 86us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 23/50\n",
      "873/873 [==============================] - 0s 88us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 24/50\n",
      "873/873 [==============================] - 0s 86us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 25/50\n",
      "873/873 [==============================] - 0s 87us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 26/50\n",
      "873/873 [==============================] - 0s 83us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 27/50\n",
      "873/873 [==============================] - 0s 90us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 28/50\n",
      "873/873 [==============================] - 0s 85us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 29/50\n",
      "873/873 [==============================] - 0s 84us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 30/50\n",
      "873/873 [==============================] - 0s 86us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 31/50\n",
      "873/873 [==============================] - 0s 89us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 32/50\n",
      "873/873 [==============================] - 0s 84us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 33/50\n",
      "873/873 [==============================] - 0s 84us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 34/50\n",
      "873/873 [==============================] - 0s 86us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 35/50\n",
      "873/873 [==============================] - 0s 83us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 36/50\n",
      "873/873 [==============================] - 0s 83us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 37/50\n",
      "873/873 [==============================] - 0s 88us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 38/50\n",
      "873/873 [==============================] - 0s 85us/sample - loss: 0.0272 - val_loss: 0.0388\n",
      "Epoch 39/50\n",
      "873/873 [==============================] - 0s 81us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 40/50\n",
      "873/873 [==============================] - 0s 84us/sample - loss: 0.0272 - val_loss: 0.0388\n",
      "Epoch 41/50\n",
      "873/873 [==============================] - 0s 83us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 42/50\n",
      "873/873 [==============================] - 0s 81us/sample - loss: 0.0272 - val_loss: 0.0388\n",
      "Epoch 43/50\n",
      "873/873 [==============================] - 0s 84us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 44/50\n",
      "873/873 [==============================] - 0s 83us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 45/50\n",
      "873/873 [==============================] - 0s 89us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 46/50\n",
      "873/873 [==============================] - 0s 86us/sample - loss: 0.0272 - val_loss: 0.0388\n",
      "Epoch 47/50\n",
      "873/873 [==============================] - 0s 82us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 48/50\n",
      "873/873 [==============================] - 0s 85us/sample - loss: 0.0272 - val_loss: 0.0388\n",
      "Epoch 49/50\n",
      "873/873 [==============================] - 0s 83us/sample - loss: 0.0272 - val_loss: 0.0387\n",
      "Epoch 50/50\n",
      "873/873 [==============================] - 0s 85us/sample - loss: 0.0271 - val_loss: 0.0388\n",
      "第83个数，还剩4040个没有训练\n",
      "inv_hat [0.95222707 0.97206119 0.97898976 0.95719001 0.95222707 0.96115846\n",
      " 0.96314196 0.97997889 0.9780005  1.0046395  1.00070348 1.01544178\n",
      " 1.02913854 0.98689739 0.98590963 0.95619755 0.96016645 0.96611633\n",
      " 0.97898976 0.96115846 0.94328845 0.92937552 0.91148607 0.89361442\n",
      " 0.87875032 0.84326197 0.83542415 0.88172037 0.88271074 0.8777606 ]\n",
      "Test RMSE: 0.019\n",
      "Train on 478 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "478/478 [==============================] - 0s 86us/sample - loss: 0.0223 - val_loss: 0.0247\n",
      "Epoch 2/50\n",
      "478/478 [==============================] - 0s 85us/sample - loss: 0.0221 - val_loss: 0.0231\n",
      "Epoch 3/50\n",
      "478/478 [==============================] - 0s 87us/sample - loss: 0.0220 - val_loss: 0.0223\n",
      "Epoch 4/50\n",
      "478/478 [==============================] - 0s 91us/sample - loss: 0.0219 - val_loss: 0.0218\n",
      "Epoch 5/50\n",
      "478/478 [==============================] - 0s 89us/sample - loss: 0.0219 - val_loss: 0.0214\n",
      "Epoch 6/50\n",
      "478/478 [==============================] - 0s 85us/sample - loss: 0.0219 - val_loss: 0.0214\n",
      "Epoch 7/50\n",
      "478/478 [==============================] - 0s 99us/sample - loss: 0.0219 - val_loss: 0.0215\n",
      "Epoch 8/50\n",
      "478/478 [==============================] - 0s 86us/sample - loss: 0.0219 - val_loss: 0.0216\n",
      "Epoch 9/50\n",
      "478/478 [==============================] - 0s 82us/sample - loss: 0.0219 - val_loss: 0.0216\n",
      "Epoch 10/50\n",
      "478/478 [==============================] - 0s 81us/sample - loss: 0.0219 - val_loss: 0.0217\n",
      "Epoch 11/50\n",
      "478/478 [==============================] - 0s 83us/sample - loss: 0.0219 - val_loss: 0.0219\n",
      "Epoch 12/50\n",
      "478/478 [==============================] - 0s 84us/sample - loss: 0.0218 - val_loss: 0.0216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "478/478 [==============================] - 0s 85us/sample - loss: 0.0219 - val_loss: 0.0220\n",
      "Epoch 14/50\n",
      "478/478 [==============================] - 0s 85us/sample - loss: 0.0218 - val_loss: 0.0218\n",
      "Epoch 15/50\n",
      "478/478 [==============================] - 0s 88us/sample - loss: 0.0218 - val_loss: 0.0217\n",
      "Epoch 16/50\n",
      "478/478 [==============================] - 0s 86us/sample - loss: 0.0218 - val_loss: 0.0218\n",
      "Epoch 17/50\n",
      "478/478 [==============================] - 0s 88us/sample - loss: 0.0218 - val_loss: 0.0216\n",
      "Epoch 18/50\n",
      "478/478 [==============================] - 0s 86us/sample - loss: 0.0218 - val_loss: 0.0219\n",
      "Epoch 19/50\n",
      "478/478 [==============================] - 0s 93us/sample - loss: 0.0218 - val_loss: 0.0218\n",
      "Epoch 20/50\n",
      "478/478 [==============================] - 0s 85us/sample - loss: 0.0218 - val_loss: 0.0216\n",
      "Epoch 21/50\n",
      "478/478 [==============================] - 0s 86us/sample - loss: 0.0218 - val_loss: 0.0218\n",
      "Epoch 22/50\n",
      "478/478 [==============================] - 0s 84us/sample - loss: 0.0218 - val_loss: 0.0215\n",
      "Epoch 23/50\n",
      "478/478 [==============================] - 0s 85us/sample - loss: 0.0218 - val_loss: 0.0219\n",
      "Epoch 24/50\n",
      "478/478 [==============================] - 0s 83us/sample - loss: 0.0218 - val_loss: 0.0218\n",
      "Epoch 25/50\n",
      "478/478 [==============================] - 0s 88us/sample - loss: 0.0218 - val_loss: 0.0218\n",
      "Epoch 26/50\n",
      "478/478 [==============================] - 0s 88us/sample - loss: 0.0218 - val_loss: 0.0216\n",
      "Epoch 27/50\n",
      "478/478 [==============================] - 0s 92us/sample - loss: 0.0218 - val_loss: 0.0221\n",
      "Epoch 28/50\n",
      "478/478 [==============================] - 0s 91us/sample - loss: 0.0218 - val_loss: 0.0218\n",
      "Epoch 29/50\n",
      "478/478 [==============================] - 0s 94us/sample - loss: 0.0218 - val_loss: 0.0217\n",
      "Epoch 30/50\n",
      "478/478 [==============================] - 0s 91us/sample - loss: 0.0218 - val_loss: 0.0219\n",
      "Epoch 31/50\n",
      "478/478 [==============================] - 0s 92us/sample - loss: 0.0218 - val_loss: 0.0218\n",
      "Epoch 32/50\n",
      "478/478 [==============================] - 0s 86us/sample - loss: 0.0218 - val_loss: 0.0216\n",
      "Epoch 33/50\n",
      "478/478 [==============================] - 0s 85us/sample - loss: 0.0218 - val_loss: 0.0220\n",
      "Epoch 34/50\n",
      "478/478 [==============================] - 0s 93us/sample - loss: 0.0218 - val_loss: 0.0219\n",
      "Epoch 35/50\n",
      "478/478 [==============================] - 0s 90us/sample - loss: 0.0218 - val_loss: 0.0216\n",
      "Epoch 36/50\n",
      "478/478 [==============================] - 0s 86us/sample - loss: 0.0218 - val_loss: 0.0220\n",
      "Epoch 37/50\n",
      "478/478 [==============================] - 0s 93us/sample - loss: 0.0218 - val_loss: 0.0220\n",
      "Epoch 38/50\n",
      "478/478 [==============================] - 0s 91us/sample - loss: 0.0217 - val_loss: 0.0215\n",
      "Epoch 39/50\n",
      "478/478 [==============================] - 0s 87us/sample - loss: 0.0218 - val_loss: 0.0220\n",
      "Epoch 40/50\n",
      "478/478 [==============================] - 0s 85us/sample - loss: 0.0218 - val_loss: 0.0220\n",
      "Epoch 41/50\n",
      "478/478 [==============================] - 0s 89us/sample - loss: 0.0217 - val_loss: 0.0215\n",
      "Epoch 42/50\n",
      "478/478 [==============================] - 0s 88us/sample - loss: 0.0218 - val_loss: 0.0219\n",
      "Epoch 43/50\n",
      "478/478 [==============================] - 0s 84us/sample - loss: 0.0218 - val_loss: 0.0219\n",
      "Epoch 44/50\n",
      "478/478 [==============================] - 0s 84us/sample - loss: 0.0217 - val_loss: 0.0215\n",
      "Epoch 45/50\n",
      "478/478 [==============================] - 0s 91us/sample - loss: 0.0218 - val_loss: 0.0220\n",
      "Epoch 46/50\n",
      "478/478 [==============================] - 0s 87us/sample - loss: 0.0218 - val_loss: 0.0218\n",
      "Epoch 47/50\n",
      "478/478 [==============================] - 0s 89us/sample - loss: 0.0218 - val_loss: 0.0216\n",
      "Epoch 48/50\n",
      "478/478 [==============================] - 0s 85us/sample - loss: 0.0218 - val_loss: 0.0220\n",
      "Epoch 49/50\n",
      "478/478 [==============================] - 0s 93us/sample - loss: 0.0218 - val_loss: 0.0219\n",
      "Epoch 50/50\n",
      "478/478 [==============================] - 0s 92us/sample - loss: 0.0218 - val_loss: 0.0215\n",
      "第84个数，还剩4039个没有训练\n",
      "inv_hat [0.9997219  0.97163781 0.97368704 0.9691037  0.95629261 0.95638932\n",
      " 0.96055265 0.9711502  0.95011547 0.96307481 0.99104218 0.99360332\n",
      " 0.98622333 0.9655034  0.96589228 0.96589228 0.97280855 0.97163781\n",
      " 0.97994559 0.96220136 0.95890543 0.95088629 0.93965696 0.94045069\n",
      " 0.93321676 0.93341466 0.92009033 0.91497814 0.91232842 0.91664817]\n",
      "Test RMSE: 0.012\n",
      "Train on 773 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "773/773 [==============================] - 0s 88us/sample - loss: 0.0232 - val_loss: 0.0161\n",
      "Epoch 2/50\n",
      "773/773 [==============================] - 0s 80us/sample - loss: 0.0239 - val_loss: 0.0183\n",
      "Epoch 3/50\n",
      "773/773 [==============================] - 0s 76us/sample - loss: 0.0231 - val_loss: 0.0164\n",
      "Epoch 4/50\n",
      "773/773 [==============================] - 0s 84us/sample - loss: 0.0237 - val_loss: 0.0175\n",
      "Epoch 5/50\n",
      "773/773 [==============================] - 0s 81us/sample - loss: 0.0233 - val_loss: 0.0168\n",
      "Epoch 6/50\n",
      "773/773 [==============================] - 0s 79us/sample - loss: 0.0234 - val_loss: 0.0168\n",
      "Epoch 7/50\n",
      "773/773 [==============================] - 0s 81us/sample - loss: 0.0234 - val_loss: 0.0167\n",
      "Epoch 8/50\n",
      "773/773 [==============================] - 0s 81us/sample - loss: 0.0234 - val_loss: 0.0167\n",
      "Epoch 9/50\n",
      "773/773 [==============================] - 0s 81us/sample - loss: 0.0234 - val_loss: 0.0167\n",
      "Epoch 10/50\n",
      "773/773 [==============================] - 0s 80us/sample - loss: 0.0233 - val_loss: 0.0166\n",
      "Epoch 11/50\n",
      "773/773 [==============================] - 0s 77us/sample - loss: 0.0234 - val_loss: 0.0166\n",
      "Epoch 12/50\n",
      "773/773 [==============================] - 0s 81us/sample - loss: 0.0234 - val_loss: 0.0167\n",
      "Epoch 13/50\n",
      "773/773 [==============================] - 0s 83us/sample - loss: 0.0234 - val_loss: 0.0166\n",
      "Epoch 14/50\n",
      "773/773 [==============================] - 0s 80us/sample - loss: 0.0233 - val_loss: 0.0165\n",
      "Epoch 15/50\n",
      "773/773 [==============================] - 0s 87us/sample - loss: 0.0234 - val_loss: 0.0166\n",
      "Epoch 16/50\n",
      "773/773 [==============================] - 0s 86us/sample - loss: 0.0234 - val_loss: 0.0166\n",
      "Epoch 17/50\n",
      "773/773 [==============================] - 0s 84us/sample - loss: 0.0234 - val_loss: 0.0166\n",
      "Epoch 18/50\n",
      "773/773 [==============================] - 0s 84us/sample - loss: 0.0233 - val_loss: 0.0166\n",
      "Epoch 19/50\n",
      "773/773 [==============================] - 0s 82us/sample - loss: 0.0234 - val_loss: 0.0168\n",
      "Epoch 20/50\n",
      "773/773 [==============================] - 0s 80us/sample - loss: 0.0233 - val_loss: 0.0167\n",
      "Epoch 21/50\n",
      "773/773 [==============================] - 0s 79us/sample - loss: 0.0233 - val_loss: 0.0166\n",
      "Epoch 22/50\n",
      "773/773 [==============================] - 0s 81us/sample - loss: 0.0234 - val_loss: 0.0168\n",
      "Epoch 23/50\n",
      "773/773 [==============================] - 0s 85us/sample - loss: 0.0233 - val_loss: 0.0167\n",
      "Epoch 24/50\n",
      "773/773 [==============================] - 0s 84us/sample - loss: 0.0234 - val_loss: 0.0167\n",
      "Epoch 25/50\n",
      "773/773 [==============================] - 0s 81us/sample - loss: 0.0234 - val_loss: 0.0167\n",
      "Epoch 26/50\n",
      "773/773 [==============================] - 0s 83us/sample - loss: 0.0234 - val_loss: 0.0166\n",
      "Epoch 27/50\n",
      "773/773 [==============================] - 0s 88us/sample - loss: 0.0234 - val_loss: 0.0166\n",
      "Epoch 28/50\n",
      "773/773 [==============================] - 0s 82us/sample - loss: 0.0234 - val_loss: 0.0166\n",
      "Epoch 29/50\n",
      "773/773 [==============================] - 0s 82us/sample - loss: 0.0234 - val_loss: 0.0165\n",
      "Epoch 30/50\n",
      "773/773 [==============================] - 0s 81us/sample - loss: 0.0234 - val_loss: 0.0166\n",
      "Epoch 31/50\n",
      "773/773 [==============================] - 0s 82us/sample - loss: 0.0234 - val_loss: 0.0166\n",
      "Epoch 32/50\n",
      "773/773 [==============================] - 0s 84us/sample - loss: 0.0233 - val_loss: 0.0166\n",
      "Epoch 33/50\n",
      "773/773 [==============================] - 0s 80us/sample - loss: 0.0234 - val_loss: 0.0167\n",
      "Epoch 34/50\n",
      "773/773 [==============================] - 0s 83us/sample - loss: 0.0234 - val_loss: 0.0167\n",
      "Epoch 35/50\n",
      "773/773 [==============================] - 0s 85us/sample - loss: 0.0234 - val_loss: 0.0167\n",
      "Epoch 36/50\n",
      "773/773 [==============================] - 0s 79us/sample - loss: 0.0234 - val_loss: 0.0166\n",
      "Epoch 37/50\n",
      "773/773 [==============================] - 0s 82us/sample - loss: 0.0234 - val_loss: 0.0167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "773/773 [==============================] - 0s 86us/sample - loss: 0.0233 - val_loss: 0.0166\n",
      "Epoch 39/50\n",
      "773/773 [==============================] - 0s 85us/sample - loss: 0.0234 - val_loss: 0.0168\n",
      "Epoch 40/50\n",
      "773/773 [==============================] - 0s 84us/sample - loss: 0.0234 - val_loss: 0.0166\n",
      "Epoch 41/50\n",
      "773/773 [==============================] - 0s 81us/sample - loss: 0.0234 - val_loss: 0.0167\n",
      "Epoch 42/50\n",
      "773/773 [==============================] - 0s 78us/sample - loss: 0.0233 - val_loss: 0.0166\n",
      "Epoch 43/50\n",
      "773/773 [==============================] - 0s 79us/sample - loss: 0.0234 - val_loss: 0.0166\n",
      "Epoch 44/50\n",
      "773/773 [==============================] - 0s 81us/sample - loss: 0.0234 - val_loss: 0.0167\n",
      "Epoch 45/50\n",
      "773/773 [==============================] - 0s 82us/sample - loss: 0.0233 - val_loss: 0.0167\n",
      "Epoch 46/50\n",
      "773/773 [==============================] - 0s 82us/sample - loss: 0.0234 - val_loss: 0.0167\n",
      "Epoch 47/50\n",
      "773/773 [==============================] - 0s 81us/sample - loss: 0.0234 - val_loss: 0.0167\n",
      "Epoch 48/50\n",
      "773/773 [==============================] - 0s 83us/sample - loss: 0.0233 - val_loss: 0.0166\n",
      "Epoch 49/50\n",
      "773/773 [==============================] - 0s 83us/sample - loss: 0.0234 - val_loss: 0.0167\n",
      "Epoch 50/50\n",
      "773/773 [==============================] - 0s 81us/sample - loss: 0.0234 - val_loss: 0.0167\n",
      "第85个数，还剩4038个没有训练\n",
      "inv_hat [0.90641289 0.88888924 0.88985858 0.885017   0.86865594 0.87057245\n",
      " 0.87345146 0.88211836 0.87057245 0.87633544 0.90250531 0.9015296\n",
      " 0.90055436 0.88018854 0.87826093 0.87441223 0.87922446 0.87729789\n",
      " 0.885017   0.86865594 0.85910858 0.85517232 0.84043455 0.83847646\n",
      " 0.83847646 0.85024982 0.85123359 0.8492665  0.84631891 0.84631891]\n",
      "Test RMSE: 0.010\n",
      "Train on 1021 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1021/1021 [==============================] - 0s 85us/sample - loss: 0.0139 - val_loss: 0.0055\n",
      "Epoch 2/50\n",
      "1021/1021 [==============================] - 0s 84us/sample - loss: 0.0097 - val_loss: 0.0043\n",
      "Epoch 3/50\n",
      "1021/1021 [==============================] - 0s 81us/sample - loss: 0.0099 - val_loss: 0.0065\n",
      "Epoch 4/50\n",
      "1021/1021 [==============================] - 0s 81us/sample - loss: 0.0103 - val_loss: 0.0063\n",
      "Epoch 5/50\n",
      "1021/1021 [==============================] - 0s 82us/sample - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 6/50\n",
      "1021/1021 [==============================] - 0s 81us/sample - loss: 0.0146 - val_loss: 0.0101\n",
      "Epoch 7/50\n",
      "1021/1021 [==============================] - 0s 81us/sample - loss: 0.0131 - val_loss: 0.0080\n",
      "Epoch 8/50\n",
      "1021/1021 [==============================] - 0s 83us/sample - loss: 0.0103 - val_loss: 0.0060\n",
      "Epoch 9/50\n",
      "1021/1021 [==============================] - 0s 84us/sample - loss: 0.0088 - val_loss: 0.0043\n",
      "Epoch 10/50\n",
      "1021/1021 [==============================] - ETA: 0s - loss: 0.009 - 0s 85us/sample - loss: 0.0091 - val_loss: 0.0044\n",
      "Epoch 11/50\n",
      "1021/1021 [==============================] - 0s 89us/sample - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 12/50\n",
      "1021/1021 [==============================] - 0s 82us/sample - loss: 0.0105 - val_loss: 0.0072\n",
      "Epoch 13/50\n",
      "1021/1021 [==============================] - 0s 79us/sample - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 14/50\n",
      "1021/1021 [==============================] - 0s 81us/sample - loss: 0.0165 - val_loss: 0.0087\n",
      "Epoch 15/50\n",
      "1021/1021 [==============================] - 0s 86us/sample - loss: 0.0120 - val_loss: 0.0067\n",
      "Epoch 16/50\n",
      "1021/1021 [==============================] - 0s 83us/sample - loss: 0.0096 - val_loss: 0.0051\n",
      "Epoch 17/50\n",
      "1021/1021 [==============================] - 0s 83us/sample - loss: 0.0095 - val_loss: 0.0057\n",
      "Epoch 18/50\n",
      "1021/1021 [==============================] - 0s 86us/sample - loss: 0.0106 - val_loss: 0.0136\n",
      "Epoch 19/50\n",
      "1021/1021 [==============================] - 0s 84us/sample - loss: 0.0106 - val_loss: 0.0099\n",
      "Epoch 20/50\n",
      "1021/1021 [==============================] - 0s 86us/sample - loss: 0.0091 - val_loss: 0.0067\n",
      "Epoch 21/50\n",
      "1021/1021 [==============================] - 0s 82us/sample - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 22/50\n",
      "1021/1021 [==============================] - 0s 81us/sample - loss: 0.0119 - val_loss: 0.0059\n",
      "Epoch 23/50\n",
      "1021/1021 [==============================] - 0s 80us/sample - loss: 0.0140 - val_loss: 0.0145\n",
      "Epoch 24/50\n",
      "1021/1021 [==============================] - 0s 85us/sample - loss: 0.0123 - val_loss: 0.0061\n",
      "Epoch 25/50\n",
      "1021/1021 [==============================] - 0s 88us/sample - loss: 0.0088 - val_loss: 0.0061\n",
      "Epoch 26/50\n",
      "1021/1021 [==============================] - 0s 87us/sample - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 27/50\n",
      "1021/1021 [==============================] - 0s 88us/sample - loss: 0.0102 - val_loss: 0.0086\n",
      "Epoch 28/50\n",
      "1021/1021 [==============================] - 0s 87us/sample - loss: 0.0118 - val_loss: 0.0046\n",
      "Epoch 29/50\n",
      "1021/1021 [==============================] - 0s 89us/sample - loss: 0.0131 - val_loss: 0.0142\n",
      "Epoch 30/50\n",
      "1021/1021 [==============================] - 0s 81us/sample - loss: 0.0116 - val_loss: 0.0070\n",
      "Epoch 31/50\n",
      "1021/1021 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0046\n",
      "Epoch 32/50\n",
      "1021/1021 [==============================] - 0s 79us/sample - loss: 0.0101 - val_loss: 0.0088\n",
      "Epoch 33/50\n",
      "1021/1021 [==============================] - 0s 83us/sample - loss: 0.0110 - val_loss: 0.0046\n",
      "Epoch 34/50\n",
      "1021/1021 [==============================] - 0s 87us/sample - loss: 0.0109 - val_loss: 0.0089\n",
      "Epoch 35/50\n",
      "1021/1021 [==============================] - 0s 88us/sample - loss: 0.0135 - val_loss: 0.0140\n",
      "Epoch 36/50\n",
      "1021/1021 [==============================] - 0s 83us/sample - loss: 0.0133 - val_loss: 0.0043\n",
      "Epoch 37/50\n",
      "1021/1021 [==============================] - 0s 80us/sample - loss: 0.0128 - val_loss: 0.0080\n",
      "Epoch 38/50\n",
      "1021/1021 [==============================] - 0s 82us/sample - loss: 0.0106 - val_loss: 0.0045\n",
      "Epoch 39/50\n",
      "1021/1021 [==============================] - 0s 84us/sample - loss: 0.0102 - val_loss: 0.0044\n",
      "Epoch 40/50\n",
      "1021/1021 [==============================] - 0s 82us/sample - loss: 0.0087 - val_loss: 0.0058\n",
      "Epoch 41/50\n",
      "1021/1021 [==============================] - 0s 82us/sample - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 42/50\n",
      "1021/1021 [==============================] - 0s 84us/sample - loss: 0.0109 - val_loss: 0.0047\n",
      "Epoch 43/50\n",
      "1021/1021 [==============================] - 0s 83us/sample - loss: 0.0118 - val_loss: 0.0053\n",
      "Epoch 44/50\n",
      "1021/1021 [==============================] - 0s 86us/sample - loss: 0.0094 - val_loss: 0.0045\n",
      "Epoch 45/50\n",
      "1021/1021 [==============================] - 0s 88us/sample - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 46/50\n",
      "1021/1021 [==============================] - 0s 81us/sample - loss: 0.0100 - val_loss: 0.0069\n",
      "Epoch 47/50\n",
      "1021/1021 [==============================] - 0s 81us/sample - loss: 0.0093 - val_loss: 0.0071\n",
      "Epoch 48/50\n",
      "1021/1021 [==============================] - 0s 79us/sample - loss: 0.0085 - val_loss: 0.0046\n",
      "Epoch 49/50\n",
      "1021/1021 [==============================] - 0s 79us/sample - loss: 0.0094 - val_loss: 0.0077\n",
      "Epoch 50/50\n",
      "1021/1021 [==============================] - 0s 80us/sample - loss: 0.0086 - val_loss: 0.0059\n",
      "第86个数，还剩4037个没有训练\n",
      "inv_hat [1.03996455 1.03996455 1.03996455 1.03996455 1.03996455 1.0409422\n",
      " 1.0409422  1.0409422  1.0409422  1.0409422  1.0419157  1.0419157\n",
      " 1.0419157  1.0419157  1.0419157  1.0419157  1.0428848  1.0428848\n",
      " 1.0428848  1.0428848  1.0428848  1.0428848  1.04384953 1.04384953\n",
      " 1.04384953 1.04384953 1.04384953 1.04384953 1.04480955 1.04480955]\n",
      "Test RMSE: 0.000\n",
      "Train on 679 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "679/679 [==============================] - 0s 82us/sample - loss: 0.0152 - val_loss: 0.0103\n",
      "Epoch 2/50\n",
      "679/679 [==============================] - 0s 84us/sample - loss: 0.0112 - val_loss: 0.0076\n",
      "Epoch 3/50\n",
      "679/679 [==============================] - 0s 85us/sample - loss: 0.0105 - val_loss: 0.0064\n",
      "Epoch 4/50\n",
      "679/679 [==============================] - 0s 91us/sample - loss: 0.0094 - val_loss: 0.0044\n",
      "Epoch 5/50\n",
      "679/679 [==============================] - 0s 88us/sample - loss: 0.0096 - val_loss: 0.0064\n",
      "Epoch 6/50\n",
      "679/679 [==============================] - 0s 87us/sample - loss: 0.0098 - val_loss: 0.0045\n",
      "Epoch 7/50\n",
      "679/679 [==============================] - 0s 92us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 8/50\n",
      "679/679 [==============================] - 0s 89us/sample - loss: 0.0098 - val_loss: 0.0047\n",
      "Epoch 9/50\n",
      "679/679 [==============================] - 0s 87us/sample - loss: 0.0093 - val_loss: 0.0048\n",
      "Epoch 10/50\n",
      "679/679 [==============================] - 0s 87us/sample - loss: 0.0099 - val_loss: 0.0087\n",
      "Epoch 11/50\n",
      "679/679 [==============================] - 0s 82us/sample - loss: 0.0094 - val_loss: 0.0060\n",
      "Epoch 12/50\n",
      "679/679 [==============================] - 0s 88us/sample - loss: 0.0095 - val_loss: 0.0049\n",
      "Epoch 13/50\n",
      "679/679 [==============================] - 0s 88us/sample - loss: 0.0097 - val_loss: 0.0045\n",
      "Epoch 14/50\n",
      "679/679 [==============================] - 0s 89us/sample - loss: 0.0098 - val_loss: 0.0048\n",
      "Epoch 15/50\n",
      "679/679 [==============================] - 0s 84us/sample - loss: 0.0097 - val_loss: 0.0045\n",
      "Epoch 16/50\n",
      "679/679 [==============================] - 0s 83us/sample - loss: 0.0093 - val_loss: 0.0052\n",
      "Epoch 17/50\n",
      "679/679 [==============================] - 0s 82us/sample - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 18/50\n",
      "679/679 [==============================] - 0s 89us/sample - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 19/50\n",
      "679/679 [==============================] - 0s 84us/sample - loss: 0.0094 - val_loss: 0.0046\n",
      "Epoch 20/50\n",
      "679/679 [==============================] - 0s 88us/sample - loss: 0.0095 - val_loss: 0.0045\n",
      "Epoch 21/50\n",
      "679/679 [==============================] - 0s 89us/sample - loss: 0.0097 - val_loss: 0.0046\n",
      "Epoch 22/50\n",
      "679/679 [==============================] - 0s 86us/sample - loss: 0.0096 - val_loss: 0.0044\n",
      "Epoch 23/50\n",
      "679/679 [==============================] - 0s 88us/sample - loss: 0.0098 - val_loss: 0.0081\n",
      "Epoch 24/50\n",
      "679/679 [==============================] - 0s 86us/sample - loss: 0.0101 - val_loss: 0.0085\n",
      "Epoch 25/50\n",
      "679/679 [==============================] - 0s 85us/sample - loss: 0.0096 - val_loss: 0.0064\n",
      "Epoch 26/50\n",
      "679/679 [==============================] - 0s 88us/sample - loss: 0.0096 - val_loss: 0.0065\n",
      "Epoch 27/50\n",
      "679/679 [==============================] - 0s 86us/sample - loss: 0.0095 - val_loss: 0.0049\n",
      "Epoch 28/50\n",
      "679/679 [==============================] - 0s 88us/sample - loss: 0.0095 - val_loss: 0.0046\n",
      "Epoch 29/50\n",
      "679/679 [==============================] - 0s 87us/sample - loss: 0.0095 - val_loss: 0.0044\n",
      "Epoch 30/50\n",
      "679/679 [==============================] - 0s 83us/sample - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 31/50\n",
      "679/679 [==============================] - 0s 86us/sample - loss: 0.0101 - val_loss: 0.0087\n",
      "Epoch 32/50\n",
      "679/679 [==============================] - 0s 84us/sample - loss: 0.0096 - val_loss: 0.0063\n",
      "Epoch 33/50\n",
      "679/679 [==============================] - 0s 84us/sample - loss: 0.0095 - val_loss: 0.0055\n",
      "Epoch 34/50\n",
      "679/679 [==============================] - 0s 82us/sample - loss: 0.0094 - val_loss: 0.0046\n",
      "Epoch 35/50\n",
      "679/679 [==============================] - 0s 88us/sample - loss: 0.0096 - val_loss: 0.0047\n",
      "Epoch 36/50\n",
      "679/679 [==============================] - 0s 84us/sample - loss: 0.0095 - val_loss: 0.0044\n",
      "Epoch 37/50\n",
      "679/679 [==============================] - 0s 82us/sample - loss: 0.0098 - val_loss: 0.0088\n",
      "Epoch 38/50\n",
      "679/679 [==============================] - 0s 89us/sample - loss: 0.0100 - val_loss: 0.0089\n",
      "Epoch 39/50\n",
      "679/679 [==============================] - 0s 88us/sample - loss: 0.0095 - val_loss: 0.0067\n",
      "Epoch 40/50\n",
      "679/679 [==============================] - 0s 84us/sample - loss: 0.0096 - val_loss: 0.0058\n",
      "Epoch 41/50\n",
      "679/679 [==============================] - 0s 86us/sample - loss: 0.0098 - val_loss: 0.0050\n",
      "Epoch 42/50\n",
      "679/679 [==============================] - 0s 86us/sample - loss: 0.0095 - val_loss: 0.0045\n",
      "Epoch 43/50\n",
      "679/679 [==============================] - 0s 88us/sample - loss: 0.0096 - val_loss: 0.0077\n",
      "Epoch 44/50\n",
      "679/679 [==============================] - 0s 87us/sample - loss: 0.0096 - val_loss: 0.0069\n",
      "Epoch 45/50\n",
      "679/679 [==============================] - 0s 83us/sample - loss: 0.0098 - val_loss: 0.0074\n",
      "Epoch 46/50\n",
      "679/679 [==============================] - 0s 82us/sample - loss: 0.0093 - val_loss: 0.0045\n",
      "Epoch 47/50\n",
      "679/679 [==============================] - 0s 80us/sample - loss: 0.0097 - val_loss: 0.0060\n",
      "Epoch 48/50\n",
      "679/679 [==============================] - 0s 80us/sample - loss: 0.0096 - val_loss: 0.0047\n",
      "Epoch 49/50\n",
      "679/679 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0051\n",
      "Epoch 50/50\n",
      "679/679 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0059\n",
      "第87个数，还剩4036个没有训练\n",
      "inv_hat [1.09587129 1.09606329 1.09625521 1.09615924 1.09606329 1.09596729\n",
      " 1.09587129 1.09596729 1.09587129 1.09577525 1.09558327 1.0948143\n",
      " 1.0948143  1.0947181  1.09452563 1.09433309 1.09442937 1.09433309\n",
      " 1.09433309 1.09462187 1.09442937 1.0947181  1.09500656 1.09510272\n",
      " 1.09558327 1.09539111 1.09558327 1.09683046 1.10039445 1.10200575]\n",
      "Test RMSE: 0.001\n",
      "Train on 845 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "845/845 [==============================] - 0s 79us/sample - loss: 0.0133 - val_loss: 0.0213\n",
      "Epoch 2/50\n",
      "845/845 [==============================] - 0s 77us/sample - loss: 0.0131 - val_loss: 0.0227\n",
      "Epoch 3/50\n",
      "845/845 [==============================] - 0s 77us/sample - loss: 0.0168 - val_loss: 0.0359\n",
      "Epoch 4/50\n",
      "845/845 [==============================] - 0s 83us/sample - loss: 0.0232 - val_loss: 0.0257\n",
      "Epoch 5/50\n",
      "845/845 [==============================] - 0s 81us/sample - loss: 0.0206 - val_loss: 0.0225\n",
      "Epoch 6/50\n",
      "845/845 [==============================] - 0s 78us/sample - loss: 0.0169 - val_loss: 0.0270\n",
      "Epoch 7/50\n",
      "845/845 [==============================] - 0s 83us/sample - loss: 0.0217 - val_loss: 0.0256\n",
      "Epoch 8/50\n",
      "845/845 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0215\n",
      "Epoch 9/50\n",
      "845/845 [==============================] - 0s 79us/sample - loss: 0.0145 - val_loss: 0.0271\n",
      "Epoch 10/50\n",
      "845/845 [==============================] - 0s 76us/sample - loss: 0.0212 - val_loss: 0.0269\n",
      "Epoch 11/50\n",
      "845/845 [==============================] - 0s 82us/sample - loss: 0.0185 - val_loss: 0.0252\n",
      "Epoch 12/50\n",
      "845/845 [==============================] - 0s 80us/sample - loss: 0.0158 - val_loss: 0.0216\n",
      "Epoch 13/50\n",
      "845/845 [==============================] - 0s 76us/sample - loss: 0.0160 - val_loss: 0.0265\n",
      "Epoch 14/50\n",
      "845/845 [==============================] - 0s 80us/sample - loss: 0.0202 - val_loss: 0.0271\n",
      "Epoch 15/50\n",
      "845/845 [==============================] - 0s 82us/sample - loss: 0.0191 - val_loss: 0.0235\n",
      "Epoch 16/50\n",
      "845/845 [==============================] - 0s 79us/sample - loss: 0.0144 - val_loss: 0.0217\n",
      "Epoch 17/50\n",
      "845/845 [==============================] - 0s 81us/sample - loss: 0.0145 - val_loss: 0.0265\n",
      "Epoch 18/50\n",
      "845/845 [==============================] - 0s 84us/sample - loss: 0.0202 - val_loss: 0.0265\n",
      "Epoch 19/50\n",
      "845/845 [==============================] - 0s 81us/sample - loss: 0.0178 - val_loss: 0.0239\n",
      "Epoch 20/50\n",
      "845/845 [==============================] - 0s 80us/sample - loss: 0.0144 - val_loss: 0.0215\n",
      "Epoch 21/50\n",
      "845/845 [==============================] - 0s 79us/sample - loss: 0.0154 - val_loss: 0.0243\n",
      "Epoch 22/50\n",
      "845/845 [==============================] - 0s 79us/sample - loss: 0.0181 - val_loss: 0.0266\n",
      "Epoch 23/50\n",
      "845/845 [==============================] - 0s 84us/sample - loss: 0.0188 - val_loss: 0.0234\n",
      "Epoch 24/50\n",
      "845/845 [==============================] - 0s 80us/sample - loss: 0.0143 - val_loss: 0.0217\n",
      "Epoch 25/50\n",
      "845/845 [==============================] - 0s 78us/sample - loss: 0.0146 - val_loss: 0.0248\n",
      "Epoch 26/50\n",
      "845/845 [==============================] - 0s 79us/sample - loss: 0.0190 - val_loss: 0.0264\n",
      "Epoch 27/50\n",
      "845/845 [==============================] - 0s 75us/sample - loss: 0.0180 - val_loss: 0.0229\n",
      "Epoch 28/50\n",
      "845/845 [==============================] - 0s 81us/sample - loss: 0.0139 - val_loss: 0.0216\n",
      "Epoch 29/50\n",
      "845/845 [==============================] - 0s 82us/sample - loss: 0.0153 - val_loss: 0.0228\n",
      "Epoch 30/50\n",
      "845/845 [==============================] - 0s 84us/sample - loss: 0.0166 - val_loss: 0.0258\n",
      "Epoch 31/50\n",
      "845/845 [==============================] - 0s 81us/sample - loss: 0.0185 - val_loss: 0.0236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "845/845 [==============================] - 0s 79us/sample - loss: 0.0145 - val_loss: 0.0215\n",
      "Epoch 33/50\n",
      "845/845 [==============================] - 0s 81us/sample - loss: 0.0147 - val_loss: 0.0235\n",
      "Epoch 34/50\n",
      "845/845 [==============================] - 0s 85us/sample - loss: 0.0173 - val_loss: 0.0260\n",
      "Epoch 35/50\n",
      "845/845 [==============================] - 0s 83us/sample - loss: 0.0182 - val_loss: 0.0232\n",
      "Epoch 36/50\n",
      "845/845 [==============================] - 0s 85us/sample - loss: 0.0140 - val_loss: 0.0216\n",
      "Epoch 37/50\n",
      "845/845 [==============================] - 0s 86us/sample - loss: 0.0150 - val_loss: 0.0231\n",
      "Epoch 38/50\n",
      "845/845 [==============================] - 0s 83us/sample - loss: 0.0171 - val_loss: 0.0260\n",
      "Epoch 39/50\n",
      "845/845 [==============================] - 0s 81us/sample - loss: 0.0182 - val_loss: 0.0229\n",
      "Epoch 40/50\n",
      "845/845 [==============================] - 0s 78us/sample - loss: 0.0138 - val_loss: 0.0218\n",
      "Epoch 41/50\n",
      "845/845 [==============================] - 0s 81us/sample - loss: 0.0146 - val_loss: 0.0240\n",
      "Epoch 42/50\n",
      "845/845 [==============================] - 0s 83us/sample - loss: 0.0182 - val_loss: 0.0259\n",
      "Epoch 43/50\n",
      "845/845 [==============================] - 0s 82us/sample - loss: 0.0173 - val_loss: 0.0229\n",
      "Epoch 44/50\n",
      "845/845 [==============================] - 0s 90us/sample - loss: 0.0136 - val_loss: 0.0215\n",
      "Epoch 45/50\n",
      "845/845 [==============================] - 0s 89us/sample - loss: 0.0154 - val_loss: 0.0220\n",
      "Epoch 46/50\n",
      "845/845 [==============================] - 0s 81us/sample - loss: 0.0159 - val_loss: 0.0260\n",
      "Epoch 47/50\n",
      "845/845 [==============================] - 0s 83us/sample - loss: 0.0182 - val_loss: 0.0231\n",
      "Epoch 48/50\n",
      "845/845 [==============================] - 0s 83us/sample - loss: 0.0140 - val_loss: 0.0218\n",
      "Epoch 49/50\n",
      "845/845 [==============================] - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0239\n",
      "Epoch 50/50\n",
      "845/845 [==============================] - 0s 80us/sample - loss: 0.0181 - val_loss: 0.0258\n",
      "第88个数，还剩4035个没有训练\n",
      "inv_hat [1.06635431 1.0485239  1.05237702 1.04615588 1.03200635 1.0351414\n",
      " 1.03063661 1.04280572 1.03220215 1.0408376  1.05643436 1.05395961\n",
      " 1.05000517 1.03690725 1.03926448 1.02838877 1.03543553 1.03936277\n",
      " 1.04862264 1.03906791 1.03906791 1.03720178 1.0362203  1.03523937\n",
      " 1.03347518 1.03308341 1.03278957 1.03093007 1.02917028 1.03327924]\n",
      "Test RMSE: 0.009\n",
      "Train on 863 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "863/863 [==============================] - 0s 78us/sample - loss: 0.0129 - val_loss: 0.0087\n",
      "Epoch 2/50\n",
      "863/863 [==============================] - 0s 77us/sample - loss: 0.0123 - val_loss: 0.0111\n",
      "Epoch 3/50\n",
      "863/863 [==============================] - 0s 76us/sample - loss: 0.0122 - val_loss: 0.0127\n",
      "Epoch 4/50\n",
      "863/863 [==============================] - 0s 77us/sample - loss: 0.0118 - val_loss: 0.0084\n",
      "Epoch 5/50\n",
      "863/863 [==============================] - 0s 77us/sample - loss: 0.0118 - val_loss: 0.0087\n",
      "Epoch 6/50\n",
      "863/863 [==============================] - 0s 79us/sample - loss: 0.0117 - val_loss: 0.0079\n",
      "Epoch 7/50\n",
      "863/863 [==============================] - 0s 78us/sample - loss: 0.0117 - val_loss: 0.0071\n",
      "Epoch 8/50\n",
      "863/863 [==============================] - 0s 79us/sample - loss: 0.0117 - val_loss: 0.0071\n",
      "Epoch 9/50\n",
      "863/863 [==============================] - 0s 84us/sample - loss: 0.0117 - val_loss: 0.0068\n",
      "Epoch 10/50\n",
      "863/863 [==============================] - 0s 80us/sample - loss: 0.0117 - val_loss: 0.0066\n",
      "Epoch 11/50\n",
      "863/863 [==============================] - 0s 83us/sample - loss: 0.0117 - val_loss: 0.0068\n",
      "Epoch 12/50\n",
      "863/863 [==============================] - 0s 81us/sample - loss: 0.0117 - val_loss: 0.0065\n",
      "Epoch 13/50\n",
      "863/863 [==============================] - 0s 78us/sample - loss: 0.0117 - val_loss: 0.0068\n",
      "Epoch 14/50\n",
      "863/863 [==============================] - 0s 77us/sample - loss: 0.0117 - val_loss: 0.0065\n",
      "Epoch 15/50\n",
      "863/863 [==============================] - 0s 77us/sample - loss: 0.0117 - val_loss: 0.0065\n",
      "Epoch 16/50\n",
      "863/863 [==============================] - 0s 80us/sample - loss: 0.0117 - val_loss: 0.0067\n",
      "Epoch 17/50\n",
      "863/863 [==============================] - 0s 78us/sample - loss: 0.0117 - val_loss: 0.0064\n",
      "Epoch 18/50\n",
      "863/863 [==============================] - 0s 78us/sample - loss: 0.0117 - val_loss: 0.0067\n",
      "Epoch 19/50\n",
      "863/863 [==============================] - 0s 79us/sample - loss: 0.0117 - val_loss: 0.0065\n",
      "Epoch 20/50\n",
      "863/863 [==============================] - 0s 76us/sample - loss: 0.0117 - val_loss: 0.0064\n",
      "Epoch 21/50\n",
      "863/863 [==============================] - 0s 75us/sample - loss: 0.0117 - val_loss: 0.0066\n",
      "Epoch 22/50\n",
      "863/863 [==============================] - 0s 75us/sample - loss: 0.0117 - val_loss: 0.0064\n",
      "Epoch 23/50\n",
      "863/863 [==============================] - 0s 74us/sample - loss: 0.0117 - val_loss: 0.0063\n",
      "Epoch 24/50\n",
      "863/863 [==============================] - 0s 74us/sample - loss: 0.0117 - val_loss: 0.0065\n",
      "Epoch 25/50\n",
      "863/863 [==============================] - 0s 76us/sample - loss: 0.0117 - val_loss: 0.0064\n",
      "Epoch 26/50\n",
      "863/863 [==============================] - 0s 78us/sample - loss: 0.0117 - val_loss: 0.0066\n",
      "Epoch 27/50\n",
      "863/863 [==============================] - 0s 76us/sample - loss: 0.0117 - val_loss: 0.0062\n",
      "Epoch 28/50\n",
      "863/863 [==============================] - 0s 77us/sample - loss: 0.0116 - val_loss: 0.0060\n",
      "Epoch 29/50\n",
      "863/863 [==============================] - 0s 80us/sample - loss: 0.0117 - val_loss: 0.0066\n",
      "Epoch 30/50\n",
      "863/863 [==============================] - 0s 84us/sample - loss: 0.0117 - val_loss: 0.0065\n",
      "Epoch 31/50\n",
      "863/863 [==============================] - 0s 81us/sample - loss: 0.0117 - val_loss: 0.0065\n",
      "Epoch 32/50\n",
      "863/863 [==============================] - 0s 76us/sample - loss: 0.0117 - val_loss: 0.0066\n",
      "Epoch 33/50\n",
      "863/863 [==============================] - 0s 79us/sample - loss: 0.0117 - val_loss: 0.0064\n",
      "Epoch 34/50\n",
      "863/863 [==============================] - 0s 79us/sample - loss: 0.0117 - val_loss: 0.0066\n",
      "Epoch 35/50\n",
      "863/863 [==============================] - 0s 77us/sample - loss: 0.0116 - val_loss: 0.0063\n",
      "Epoch 36/50\n",
      "863/863 [==============================] - 0s 81us/sample - loss: 0.0117 - val_loss: 0.0065\n",
      "Epoch 37/50\n",
      "863/863 [==============================] - 0s 80us/sample - loss: 0.0117 - val_loss: 0.0064\n",
      "Epoch 38/50\n",
      "863/863 [==============================] - 0s 78us/sample - loss: 0.0117 - val_loss: 0.0065\n",
      "Epoch 39/50\n",
      "863/863 [==============================] - 0s 78us/sample - loss: 0.0116 - val_loss: 0.0063\n",
      "Epoch 40/50\n",
      "863/863 [==============================] - 0s 78us/sample - loss: 0.0117 - val_loss: 0.0065\n",
      "Epoch 41/50\n",
      "863/863 [==============================] - 0s 78us/sample - loss: 0.0117 - val_loss: 0.0063\n",
      "Epoch 42/50\n",
      "863/863 [==============================] - 0s 77us/sample - loss: 0.0116 - val_loss: 0.0062\n",
      "Epoch 43/50\n",
      "863/863 [==============================] - 0s 77us/sample - loss: 0.0117 - val_loss: 0.0065\n",
      "Epoch 44/50\n",
      "863/863 [==============================] - 0s 79us/sample - loss: 0.0116 - val_loss: 0.0063\n",
      "Epoch 45/50\n",
      "863/863 [==============================] - 0s 79us/sample - loss: 0.0116 - val_loss: 0.0062\n",
      "Epoch 46/50\n",
      "863/863 [==============================] - 0s 77us/sample - loss: 0.0117 - val_loss: 0.0064\n",
      "Epoch 47/50\n",
      "863/863 [==============================] - 0s 83us/sample - loss: 0.0117 - val_loss: 0.0063\n",
      "Epoch 48/50\n",
      "863/863 [==============================] - 0s 87us/sample - loss: 0.0116 - val_loss: 0.0062\n",
      "Epoch 49/50\n",
      "863/863 [==============================] - 0s 79us/sample - loss: 0.0117 - val_loss: 0.0063\n",
      "Epoch 50/50\n",
      "863/863 [==============================] - 0s 81us/sample - loss: 0.0117 - val_loss: 0.0063\n",
      "第89个数，还剩4034个没有训练\n",
      "inv_hat [0.51161045 0.4957377  0.49672834 0.4957377  0.48485318 0.48090107\n",
      " 0.47892622 0.48485318 0.47892622 0.48584172 0.50069285 0.50069285\n",
      " 0.49871022 0.48188881 0.47991356 0.47399269 0.47596549 0.47793912\n",
      " 0.48485318 0.47596549 0.47202072 0.47004961 0.46315728 0.46118997\n",
      " 0.45725796 0.46118997 0.45922352 0.45627551 0.45431127 0.45627551]\n",
      "Test RMSE: 0.007\n",
      "Train on 800 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.0075 - val_loss: 0.0049\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 0.0097 - val_loss: 0.0050\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 0.0102 - val_loss: 0.0114\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 0.0116 - val_loss: 0.0048\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 0.0087 - val_loss: 0.0058\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.0107 - val_loss: 0.0066\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 0.0088 - val_loss: 0.0039\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 83us/sample - loss: 0.0086 - val_loss: 0.0037\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.0105 - val_loss: 0.0075\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 83us/sample - loss: 0.0094 - val_loss: 0.0054\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 81us/sample - loss: 0.0115 - val_loss: 0.0171\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 82us/sample - loss: 0.0152 - val_loss: 0.0049\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0147\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.0159 - val_loss: 0.0080\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 0.0178 - val_loss: 0.0090\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 0.0125 - val_loss: 0.0046\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 0.0116 - val_loss: 0.0102\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.0132 - val_loss: 0.0070\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.0180 - val_loss: 0.0090\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 0.0122 - val_loss: 0.0034\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 83us/sample - loss: 0.0109 - val_loss: 0.0072\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 83us/sample - loss: 0.0106 - val_loss: 0.0025\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 0.0152 - val_loss: 0.0130\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.0151 - val_loss: 0.0037\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 0.0120 - val_loss: 0.0151\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.0177 - val_loss: 0.0081\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.0136 - val_loss: 0.0094\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 0.0126 - val_loss: 0.0057\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.0093 - val_loss: 0.0043\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 81us/sample - loss: 0.0090 - val_loss: 0.0038\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 0.0090 - val_loss: 0.0101\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 0.0103 - val_loss: 0.0039\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.0079 - val_loss: 0.0030\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 0.0074 - val_loss: 0.0032\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 0.0078 - val_loss: 0.0028\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 0.0110 - val_loss: 0.0141\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 0.0132 - val_loss: 0.0027\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 0.0121 - val_loss: 0.0140\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.0160 - val_loss: 0.0082\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.0151 - val_loss: 0.0067\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 0.0105 - val_loss: 0.0037\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 82us/sample - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.0136 - val_loss: 0.0069\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 82us/sample - loss: 0.0145 - val_loss: 0.0076\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 83us/sample - loss: 0.0106 - val_loss: 0.0037\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 0.0119 - val_loss: 0.0106\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.0137 - val_loss: 0.0068\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 0.0142 - val_loss: 0.0075\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 0.0101 - val_loss: 0.0032\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 0.0100 - val_loss: 0.0053\n",
      "第90个数，还剩4033个没有训练\n",
      "inv_hat [1.14828723 1.14828723 1.14728309 1.14728309 1.14728309 1.14728309\n",
      " 1.14627902 1.14627902 1.14627902 1.14627902 1.14527519 1.14527519\n",
      " 1.14527519 1.14527519 1.14527519 1.14427175 1.14427175 1.14427175\n",
      " 1.14427175 1.14427175 1.14326837 1.14326837 1.14326837 1.14326837\n",
      " 1.14326837 1.14226539 1.14226539 1.14226539 1.16740618 1.16740618]\n",
      "Test RMSE: 0.005\n",
      "Train on 1193 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0075 - val_loss: 0.0069\n",
      "Epoch 2/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0088 - val_loss: 0.0032\n",
      "Epoch 3/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0078 - val_loss: 0.0054\n",
      "Epoch 4/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0071 - val_loss: 0.0041\n",
      "Epoch 5/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0068 - val_loss: 0.0031\n",
      "Epoch 6/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0077 - val_loss: 0.0044\n",
      "Epoch 7/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0078 - val_loss: 0.0059\n",
      "Epoch 8/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0072 - val_loss: 0.0052\n",
      "Epoch 9/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0069 - val_loss: 0.0035\n",
      "Epoch 10/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0070 - val_loss: 0.0030\n",
      "Epoch 11/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0078 - val_loss: 0.0039\n",
      "Epoch 12/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0069 - val_loss: 0.0034\n",
      "Epoch 13/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0079 - val_loss: 0.0045\n",
      "Epoch 14/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0070 - val_loss: 0.0030\n",
      "Epoch 15/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0071 - val_loss: 0.0041\n",
      "Epoch 16/50\n",
      "1193/1193 [==============================] - 0s 75us/sample - loss: 0.0074 - val_loss: 0.0050\n",
      "Epoch 17/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0043\n",
      "Epoch 18/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0083 - val_loss: 0.0068\n",
      "Epoch 19/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0074 - val_loss: 0.0029\n",
      "Epoch 20/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0067 - val_loss: 0.0033\n",
      "Epoch 21/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0068 - val_loss: 0.0035\n",
      "Epoch 22/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0078 - val_loss: 0.0040\n",
      "Epoch 23/50\n",
      "1193/1193 [==============================] - 0s 75us/sample - loss: 0.0070 - val_loss: 0.0034\n",
      "Epoch 24/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0068 - val_loss: 0.0044\n",
      "Epoch 25/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0087 - val_loss: 0.0042\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1193/1193 [==============================] - 0s 75us/sample - loss: 0.0087 - val_loss: 0.0065\n",
      "Epoch 27/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0085 - val_loss: 0.0046\n",
      "Epoch 28/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0077 - val_loss: 0.0054\n",
      "Epoch 29/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0070 - val_loss: 0.0035\n",
      "Epoch 30/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0068 - val_loss: 0.0035\n",
      "Epoch 31/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0071 - val_loss: 0.0029\n",
      "Epoch 32/50\n",
      "1193/1193 [==============================] - 0s 85us/sample - loss: 0.0069 - val_loss: 0.0028\n",
      "Epoch 33/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0076 - val_loss: 0.0051\n",
      "Epoch 34/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0070 - val_loss: 0.0040\n",
      "Epoch 35/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0068 - val_loss: 0.0033\n",
      "Epoch 36/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0072 - val_loss: 0.0030\n",
      "Epoch 37/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0069 - val_loss: 0.0037\n",
      "Epoch 38/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0032\n",
      "Epoch 39/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0075 - val_loss: 0.0063\n",
      "Epoch 40/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0075 - val_loss: 0.0030\n",
      "Epoch 41/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0068 - val_loss: 0.0031\n",
      "Epoch 42/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0074 - val_loss: 0.0057\n",
      "Epoch 43/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0068 - val_loss: 0.0031\n",
      "Epoch 44/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0067 - val_loss: 0.0037\n",
      "Epoch 45/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0076 - val_loss: 0.0037\n",
      "Epoch 46/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0068 - val_loss: 0.0030\n",
      "Epoch 47/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0076 - val_loss: 0.0046\n",
      "Epoch 48/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0072 - val_loss: 0.0037\n",
      "Epoch 49/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0070 - val_loss: 0.0040\n",
      "Epoch 50/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0071 - val_loss: 0.0041\n",
      "第91个数，还剩4032个没有训练\n",
      "inv_hat [1.03990603 1.03990603 1.03990603 1.03990603 1.03990603 1.04091171\n",
      " 1.04091171 1.04091171 1.04091171 1.04091171 1.04091171 1.04191886\n",
      " 1.04191886 1.04191886 1.04191886 1.04191886 1.04191886 1.04292407\n",
      " 1.04292407 1.04292407 1.04292407 1.04292407 1.04292407 1.04392749\n",
      " 1.04392749 1.04392749 1.04392749 1.04392749 1.04392749 1.04492874]\n",
      "Test RMSE: 0.000\n",
      "Train on 526 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "526/526 [==============================] - 0s 88us/sample - loss: 0.0080 - val_loss: 0.0121\n",
      "Epoch 2/50\n",
      "526/526 [==============================] - 0s 85us/sample - loss: 0.0126 - val_loss: 0.0070\n",
      "Epoch 3/50\n",
      "526/526 [==============================] - 0s 87us/sample - loss: 0.0073 - val_loss: 0.0034\n",
      "Epoch 4/50\n",
      "526/526 [==============================] - 0s 84us/sample - loss: 0.0065 - val_loss: 0.0043\n",
      "Epoch 5/50\n",
      "526/526 [==============================] - 0s 84us/sample - loss: 0.0068 - val_loss: 0.0041\n",
      "Epoch 6/50\n",
      "526/526 [==============================] - 0s 86us/sample - loss: 0.0068 - val_loss: 0.0050\n",
      "Epoch 7/50\n",
      "526/526 [==============================] - 0s 87us/sample - loss: 0.0073 - val_loss: 0.0037\n",
      "Epoch 8/50\n",
      "526/526 [==============================] - 0s 85us/sample - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 9/50\n",
      "526/526 [==============================] - 0s 88us/sample - loss: 0.0082 - val_loss: 0.0040\n",
      "Epoch 10/50\n",
      "526/526 [==============================] - 0s 86us/sample - loss: 0.0076 - val_loss: 0.0075\n",
      "Epoch 11/50\n",
      "526/526 [==============================] - 0s 95us/sample - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 12/50\n",
      "526/526 [==============================] - 0s 90us/sample - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 13/50\n",
      "526/526 [==============================] - 0s 87us/sample - loss: 0.0080 - val_loss: 0.0037\n",
      "Epoch 14/50\n",
      "526/526 [==============================] - 0s 86us/sample - loss: 0.0070 - val_loss: 0.0057\n",
      "Epoch 15/50\n",
      "526/526 [==============================] - 0s 86us/sample - loss: 0.0077 - val_loss: 0.0042\n",
      "Epoch 16/50\n",
      "526/526 [==============================] - 0s 88us/sample - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 17/50\n",
      "526/526 [==============================] - 0s 83us/sample - loss: 0.0084 - val_loss: 0.0045\n",
      "Epoch 18/50\n",
      "526/526 [==============================] - 0s 84us/sample - loss: 0.0074 - val_loss: 0.0042\n",
      "Epoch 19/50\n",
      "526/526 [==============================] - 0s 86us/sample - loss: 0.0069 - val_loss: 0.0039\n",
      "Epoch 20/50\n",
      "526/526 [==============================] - 0s 84us/sample - loss: 0.0067 - val_loss: 0.0057\n",
      "Epoch 21/50\n",
      "526/526 [==============================] - 0s 90us/sample - loss: 0.0078 - val_loss: 0.0036\n",
      "Epoch 22/50\n",
      "526/526 [==============================] - 0s 92us/sample - loss: 0.0073 - val_loss: 0.0061\n",
      "Epoch 23/50\n",
      "526/526 [==============================] - 0s 85us/sample - loss: 0.0084 - val_loss: 0.0050\n",
      "Epoch 24/50\n",
      "526/526 [==============================] - 0s 92us/sample - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 25/50\n",
      "526/526 [==============================] - 0s 84us/sample - loss: 0.0077 - val_loss: 0.0038\n",
      "Epoch 26/50\n",
      "526/526 [==============================] - 0s 86us/sample - loss: 0.0072 - val_loss: 0.0043\n",
      "Epoch 27/50\n",
      "526/526 [==============================] - 0s 85us/sample - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 28/50\n",
      "526/526 [==============================] - 0s 86us/sample - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 29/50\n",
      "526/526 [==============================] - 0s 86us/sample - loss: 0.0074 - val_loss: 0.0037\n",
      "Epoch 30/50\n",
      "526/526 [==============================] - 0s 84us/sample - loss: 0.0072 - val_loss: 0.0052\n",
      "Epoch 31/50\n",
      "526/526 [==============================] - 0s 85us/sample - loss: 0.0076 - val_loss: 0.0041\n",
      "Epoch 32/50\n",
      "526/526 [==============================] - 0s 84us/sample - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 33/50\n",
      "526/526 [==============================] - 0s 88us/sample - loss: 0.0083 - val_loss: 0.0038\n",
      "Epoch 34/50\n",
      "526/526 [==============================] - 0s 87us/sample - loss: 0.0071 - val_loss: 0.0050\n",
      "Epoch 35/50\n",
      "526/526 [==============================] - 0s 84us/sample - loss: 0.0076 - val_loss: 0.0041\n",
      "Epoch 36/50\n",
      "526/526 [==============================] - 0s 88us/sample - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 37/50\n",
      "526/526 [==============================] - 0s 89us/sample - loss: 0.0080 - val_loss: 0.0037\n",
      "Epoch 38/50\n",
      "526/526 [==============================] - 0s 87us/sample - loss: 0.0070 - val_loss: 0.0052\n",
      "Epoch 39/50\n",
      "526/526 [==============================] - 0s 88us/sample - loss: 0.0077 - val_loss: 0.0044\n",
      "Epoch 40/50\n",
      "526/526 [==============================] - 0s 90us/sample - loss: 0.0070 - val_loss: 0.0057\n",
      "Epoch 41/50\n",
      "526/526 [==============================] - 0s 93us/sample - loss: 0.0078 - val_loss: 0.0039\n",
      "Epoch 42/50\n",
      "526/526 [==============================] - 0s 98us/sample - loss: 0.0073 - val_loss: 0.0038\n",
      "Epoch 43/50\n",
      "526/526 [==============================] - 0s 88us/sample - loss: 0.0068 - val_loss: 0.0041\n",
      "Epoch 44/50\n",
      "526/526 [==============================] - 0s 88us/sample - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 45/50\n",
      "526/526 [==============================] - 0s 89us/sample - loss: 0.0073 - val_loss: 0.0036\n",
      "Epoch 46/50\n",
      "526/526 [==============================] - 0s 88us/sample - loss: 0.0071 - val_loss: 0.0049\n",
      "Epoch 47/50\n",
      "526/526 [==============================] - 0s 91us/sample - loss: 0.0075 - val_loss: 0.0043\n",
      "Epoch 48/50\n",
      "526/526 [==============================] - 0s 88us/sample - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 49/50\n",
      "526/526 [==============================] - 0s 87us/sample - loss: 0.0080 - val_loss: 0.0040\n",
      "Epoch 50/50\n",
      "526/526 [==============================] - 0s 88us/sample - loss: 0.0073 - val_loss: 0.0037\n",
      "第92个数，还剩4031个没有训练\n",
      "inv_hat [1.0170109  1.01711175 1.01741441 1.01741441 1.01721262 1.01731351\n",
      " 1.01741441 1.01731351 1.01751532 1.01751532 1.01781806 1.01822208\n",
      " 1.01882845 1.01842406 1.01862623 1.01923295 1.01943534 1.01953656\n",
      " 1.01953656 1.01903073 1.01903073 1.01852514 1.01852514 1.01923295\n",
      " 1.01984017 1.01994144 1.01994144 1.02004272 1.02024533 1.0209547 ]\n",
      "Test RMSE: 0.000\n",
      "Train on 825 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "825/825 [==============================] - 0s 87us/sample - loss: 0.0160 - val_loss: 0.0088\n",
      "Epoch 2/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0159 - val_loss: 0.0085\n",
      "Epoch 3/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0158 - val_loss: 0.0093\n",
      "Epoch 4/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0157 - val_loss: 0.0087\n",
      "Epoch 5/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0086\n",
      "Epoch 6/50\n",
      "825/825 [==============================] - 0s 81us/sample - loss: 0.0157 - val_loss: 0.0086\n",
      "Epoch 7/50\n",
      "825/825 [==============================] - 0s 87us/sample - loss: 0.0156 - val_loss: 0.0086\n",
      "Epoch 8/50\n",
      "825/825 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0086\n",
      "Epoch 9/50\n",
      "825/825 [==============================] - 0s 80us/sample - loss: 0.0156 - val_loss: 0.0086\n",
      "Epoch 10/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0086\n",
      "Epoch 11/50\n",
      "825/825 [==============================] - 0s 80us/sample - loss: 0.0156 - val_loss: 0.0086\n",
      "Epoch 12/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0086\n",
      "Epoch 13/50\n",
      "825/825 [==============================] - 0s 85us/sample - loss: 0.0156 - val_loss: 0.0086\n",
      "Epoch 14/50\n",
      "825/825 [==============================] - 0s 90us/sample - loss: 0.0156 - val_loss: 0.0086\n",
      "Epoch 15/50\n",
      "825/825 [==============================] - 0s 90us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 16/50\n",
      "825/825 [==============================] - 0s 85us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 17/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0156 - val_loss: 0.0086\n",
      "Epoch 18/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0086\n",
      "Epoch 19/50\n",
      "825/825 [==============================] - 0s 78us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 20/50\n",
      "825/825 [==============================] - 0s 80us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 21/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0086\n",
      "Epoch 22/50\n",
      "825/825 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 23/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 24/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 25/50\n",
      "825/825 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 26/50\n",
      "825/825 [==============================] - 0s 79us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 27/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 28/50\n",
      "825/825 [==============================] - 0s 86us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 29/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 30/50\n",
      "825/825 [==============================] - 0s 89us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 31/50\n",
      "825/825 [==============================] - 0s 86us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 32/50\n",
      "825/825 [==============================] - 0s 85us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 33/50\n",
      "825/825 [==============================] - 0s 86us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 34/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 35/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 36/50\n",
      "825/825 [==============================] - 0s 96us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 37/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 38/50\n",
      "825/825 [==============================] - 0s 86us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 39/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 40/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 41/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 42/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 43/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 44/50\n",
      "825/825 [==============================] - 0s 88us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 45/50\n",
      "825/825 [==============================] - 0s 87us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 46/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 47/50\n",
      "825/825 [==============================] - 0s 86us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 48/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 49/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 50/50\n",
      "825/825 [==============================] - 0s 80us/sample - loss: 0.0156 - val_loss: 0.0085\n",
      "第93个数，还剩4030个没有训练\n",
      "inv_hat [0.56055588 0.54554813 0.54842639 0.54505205 0.52832094 0.52664189\n",
      " 0.53059381 0.54019386 0.52980309 0.53633127 0.55279707 0.5549841\n",
      " 0.556078   0.54247349 0.54078842 0.53544039 0.53950031 0.53959934\n",
      " 0.5434651  0.52901253 0.52447008 0.52239818 0.51274479 0.51618944\n",
      " 0.51363027 0.51953889 0.51638641 0.5132367  0.50763326 0.50891043]\n",
      "Test RMSE: 0.008\n",
      "Train on 733 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "733/733 [==============================] - 0s 88us/sample - loss: 0.0108 - val_loss: 0.0172\n",
      "Epoch 2/50\n",
      "733/733 [==============================] - 0s 87us/sample - loss: 0.0113 - val_loss: 0.0167\n",
      "Epoch 3/50\n",
      "733/733 [==============================] - 0s 94us/sample - loss: 0.0133 - val_loss: 0.0167\n",
      "Epoch 4/50\n",
      "733/733 [==============================] - 0s 83us/sample - loss: 0.0129 - val_loss: 0.0171\n",
      "Epoch 5/50\n",
      "733/733 [==============================] - 0s 85us/sample - loss: 0.0142 - val_loss: 0.0171\n",
      "Epoch 6/50\n",
      "733/733 [==============================] - 0s 89us/sample - loss: 0.0128 - val_loss: 0.0166\n",
      "Epoch 7/50\n",
      "733/733 [==============================] - 0s 83us/sample - loss: 0.0133 - val_loss: 0.0166\n",
      "Epoch 8/50\n",
      "733/733 [==============================] - 0s 88us/sample - loss: 0.0137 - val_loss: 0.0170\n",
      "Epoch 9/50\n",
      "733/733 [==============================] - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0171\n",
      "Epoch 10/50\n",
      "733/733 [==============================] - 0s 86us/sample - loss: 0.0131 - val_loss: 0.0167\n",
      "Epoch 11/50\n",
      "733/733 [==============================] - 0s 89us/sample - loss: 0.0135 - val_loss: 0.0166\n",
      "Epoch 12/50\n",
      "733/733 [==============================] - 0s 89us/sample - loss: 0.0129 - val_loss: 0.0170\n",
      "Epoch 13/50\n",
      "733/733 [==============================] - 0s 83us/sample - loss: 0.0131 - val_loss: 0.0170\n",
      "Epoch 14/50\n",
      "733/733 [==============================] - 0s 83us/sample - loss: 0.0128 - val_loss: 0.0167\n",
      "Epoch 15/50\n",
      "733/733 [==============================] - 0s 87us/sample - loss: 0.0132 - val_loss: 0.0166\n",
      "Epoch 16/50\n",
      "733/733 [==============================] - 0s 81us/sample - loss: 0.0118 - val_loss: 0.0171\n",
      "Epoch 17/50\n",
      "733/733 [==============================] - 0s 83us/sample - loss: 0.0116 - val_loss: 0.0169\n",
      "Epoch 18/50\n",
      "733/733 [==============================] - 0s 86us/sample - loss: 0.0141 - val_loss: 0.0168\n",
      "Epoch 19/50\n",
      "733/733 [==============================] - 0s 82us/sample - loss: 0.0140 - val_loss: 0.0168\n",
      "Epoch 20/50\n",
      "733/733 [==============================] - 0s 83us/sample - loss: 0.0115 - val_loss: 0.0171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50\n",
      "733/733 [==============================] - 0s 83us/sample - loss: 0.0108 - val_loss: 0.0168\n",
      "Epoch 22/50\n",
      "733/733 [==============================] - 0s 84us/sample - loss: 0.0145 - val_loss: 0.0168\n",
      "Epoch 23/50\n",
      "733/733 [==============================] - 0s 83us/sample - loss: 0.0144 - val_loss: 0.0169\n",
      "Epoch 24/50\n",
      "733/733 [==============================] - 0s 85us/sample - loss: 0.0117 - val_loss: 0.0170\n",
      "Epoch 25/50\n",
      "733/733 [==============================] - 0s 82us/sample - loss: 0.0108 - val_loss: 0.0168\n",
      "Epoch 26/50\n",
      "733/733 [==============================] - 0s 88us/sample - loss: 0.0146 - val_loss: 0.0168\n",
      "Epoch 27/50\n",
      "733/733 [==============================] - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0172\n",
      "Epoch 28/50\n",
      "733/733 [==============================] - 0s 86us/sample - loss: 0.0112 - val_loss: 0.0169\n",
      "Epoch 29/50\n",
      "733/733 [==============================] - 0s 82us/sample - loss: 0.0105 - val_loss: 0.0168\n",
      "Epoch 30/50\n",
      "733/733 [==============================] - 0s 93us/sample - loss: 0.0134 - val_loss: 0.0168\n",
      "Epoch 31/50\n",
      "733/733 [==============================] - 0s 87us/sample - loss: 0.0125 - val_loss: 0.0167\n",
      "Epoch 32/50\n",
      "733/733 [==============================] - 0s 89us/sample - loss: 0.0113 - val_loss: 0.0170\n",
      "Epoch 33/50\n",
      "733/733 [==============================] - 0s 93us/sample - loss: 0.0109 - val_loss: 0.0168\n",
      "Epoch 34/50\n",
      "733/733 [==============================] - 0s 88us/sample - loss: 0.0149 - val_loss: 0.0169\n",
      "Epoch 35/50\n",
      "733/733 [==============================] - 0s 87us/sample - loss: 0.0134 - val_loss: 0.0168\n",
      "Epoch 36/50\n",
      "733/733 [==============================] - 0s 89us/sample - loss: 0.0115 - val_loss: 0.0169\n",
      "Epoch 37/50\n",
      "733/733 [==============================] - 0s 90us/sample - loss: 0.0123 - val_loss: 0.0168\n",
      "Epoch 38/50\n",
      "733/733 [==============================] - 0s 91us/sample - loss: 0.0122 - val_loss: 0.0167\n",
      "Epoch 39/50\n",
      "733/733 [==============================] - 0s 85us/sample - loss: 0.0126 - val_loss: 0.0168\n",
      "Epoch 40/50\n",
      "733/733 [==============================] - 0s 84us/sample - loss: 0.0111 - val_loss: 0.0169\n",
      "Epoch 41/50\n",
      "733/733 [==============================] - 0s 92us/sample - loss: 0.0104 - val_loss: 0.0169\n",
      "Epoch 42/50\n",
      "733/733 [==============================] - 0s 83us/sample - loss: 0.0138 - val_loss: 0.0169\n",
      "Epoch 43/50\n",
      "733/733 [==============================] - 0s 92us/sample - loss: 0.0119 - val_loss: 0.0166\n",
      "Epoch 44/50\n",
      "733/733 [==============================] - 0s 85us/sample - loss: 0.0118 - val_loss: 0.0169\n",
      "Epoch 45/50\n",
      "733/733 [==============================] - 0s 84us/sample - loss: 0.0114 - val_loss: 0.0169\n",
      "Epoch 46/50\n",
      "733/733 [==============================] - 0s 90us/sample - loss: 0.0129 - val_loss: 0.0168\n",
      "Epoch 47/50\n",
      "733/733 [==============================] - 0s 89us/sample - loss: 0.0115 - val_loss: 0.0167\n",
      "Epoch 48/50\n",
      "733/733 [==============================] - 0s 91us/sample - loss: 0.0116 - val_loss: 0.0169\n",
      "Epoch 49/50\n",
      "733/733 [==============================] - 0s 89us/sample - loss: 0.0113 - val_loss: 0.0168\n",
      "Epoch 50/50\n",
      "733/733 [==============================] - 0s 85us/sample - loss: 0.0138 - val_loss: 0.0167\n",
      "第94个数，还剩4029个没有训练\n",
      "inv_hat [0.90649074 0.90157424 0.90452056 0.90353722 0.90059467 0.90157424\n",
      " 0.90157424 0.90157424 0.89766408 0.90059467 0.90353722 0.90353722\n",
      " 0.90255511 0.8966901  0.89766408 0.89571762 0.89863952 0.8966901\n",
      " 0.89863952 0.89474663 0.89571762 0.89280953 0.89087902 0.89184346\n",
      " 0.89184346 0.89184346 0.89087902 0.88895553 0.8879965  0.89184346]\n",
      "Test RMSE: 0.002\n",
      "Train on 843 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "843/843 [==============================] - 0s 84us/sample - loss: 0.0200 - val_loss: 0.0147\n",
      "Epoch 2/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0200 - val_loss: 0.0148\n",
      "Epoch 3/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0200 - val_loss: 0.0150\n",
      "Epoch 4/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0200 - val_loss: 0.0148\n",
      "Epoch 5/50\n",
      "843/843 [==============================] - 0s 80us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 6/50\n",
      "843/843 [==============================] - 0s 80us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 7/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 8/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 9/50\n",
      "843/843 [==============================] - 0s 82us/sample - loss: 0.0199 - val_loss: 0.0147\n",
      "Epoch 10/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0199 - val_loss: 0.0147\n",
      "Epoch 11/50\n",
      "843/843 [==============================] - 0s 86us/sample - loss: 0.0199 - val_loss: 0.0147\n",
      "Epoch 12/50\n",
      "843/843 [==============================] - 0s 83us/sample - loss: 0.0199 - val_loss: 0.0147\n",
      "Epoch 13/50\n",
      "843/843 [==============================] - 0s 84us/sample - loss: 0.0199 - val_loss: 0.0147\n",
      "Epoch 14/50\n",
      "843/843 [==============================] - 0s 84us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 15/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0199 - val_loss: 0.0147\n",
      "Epoch 16/50\n",
      "843/843 [==============================] - 0s 79us/sample - loss: 0.0199 - val_loss: 0.0147\n",
      "Epoch 17/50\n",
      "843/843 [==============================] - 0s 76us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 18/50\n",
      "843/843 [==============================] - 0s 80us/sample - loss: 0.0199 - val_loss: 0.0147\n",
      "Epoch 19/50\n",
      "843/843 [==============================] - 0s 82us/sample - loss: 0.0199 - val_loss: 0.0147\n",
      "Epoch 20/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0199 - val_loss: 0.0147\n",
      "Epoch 21/50\n",
      "843/843 [==============================] - 0s 86us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 22/50\n",
      "843/843 [==============================] - 0s 89us/sample - loss: 0.0199 - val_loss: 0.0147\n",
      "Epoch 23/50\n",
      "843/843 [==============================] - 0s 84us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 24/50\n",
      "843/843 [==============================] - 0s 83us/sample - loss: 0.0199 - val_loss: 0.0147\n",
      "Epoch 25/50\n",
      "843/843 [==============================] - 0s 84us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 26/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 27/50\n",
      "843/843 [==============================] - 0s 77us/sample - loss: 0.0199 - val_loss: 0.0147\n",
      "Epoch 28/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 29/50\n",
      "843/843 [==============================] - 0s 83us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 30/50\n",
      "843/843 [==============================] - 0s 84us/sample - loss: 0.0199 - val_loss: 0.0147\n",
      "Epoch 31/50\n",
      "843/843 [==============================] - 0s 83us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 32/50\n",
      "843/843 [==============================] - 0s 82us/sample - loss: 0.0199 - val_loss: 0.0147\n",
      "Epoch 33/50\n",
      "843/843 [==============================] - 0s 88us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 34/50\n",
      "843/843 [==============================] - 0s 88us/sample - loss: 0.0199 - val_loss: 0.0147\n",
      "Epoch 35/50\n",
      "843/843 [==============================] - 0s 85us/sample - loss: 0.0199 - val_loss: 0.0147\n",
      "Epoch 36/50\n",
      "843/843 [==============================] - 0s 83us/sample - loss: 0.0199 - val_loss: 0.0147\n",
      "Epoch 37/50\n",
      "843/843 [==============================] - 0s 85us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 38/50\n",
      "843/843 [==============================] - 0s 79us/sample - loss: 0.0199 - val_loss: 0.0147\n",
      "Epoch 39/50\n",
      "843/843 [==============================] - 0s 79us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 40/50\n",
      "843/843 [==============================] - 0s 80us/sample - loss: 0.0199 - val_loss: 0.0147\n",
      "Epoch 41/50\n",
      "843/843 [==============================] - 0s 80us/sample - loss: 0.0199 - val_loss: 0.0147\n",
      "Epoch 42/50\n",
      "843/843 [==============================] - 0s 84us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 43/50\n",
      "843/843 [==============================] - 0s 79us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 44/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 45/50\n",
      "843/843 [==============================] - 0s 82us/sample - loss: 0.0199 - val_loss: 0.0147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "843/843 [==============================] - 0s 79us/sample - loss: 0.0199 - val_loss: 0.0149\n",
      "Epoch 47/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 48/50\n",
      "843/843 [==============================] - 0s 80us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 49/50\n",
      "843/843 [==============================] - 0s 79us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 50/50\n",
      "843/843 [==============================] - 0s 77us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "第95个数，还剩4028个没有训练\n",
      "inv_hat [0.63967808 0.61606226 0.61704614 0.61114298 0.59147056 0.59835487\n",
      " 0.59048711 0.60032207 0.59245389 0.60524037 0.63180587 0.63672601\n",
      " 0.62590176 0.60720779 0.60524037 0.59048711 0.59048711 0.59245389\n",
      " 0.60327295 0.5855707  0.58950378 0.57475747 0.55903755 0.53253904\n",
      " 0.51783701 0.51391922 0.50902365 0.50412996 0.50608722 0.5188167 ]\n",
      "Test RMSE: 0.013\n",
      "Train on 974 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "974/974 [==============================] - 0s 80us/sample - loss: 0.0120 - val_loss: 0.0883\n",
      "Epoch 2/50\n",
      "974/974 [==============================] - 0s 80us/sample - loss: 0.0113 - val_loss: 0.0881\n",
      "Epoch 3/50\n",
      "974/974 [==============================] - 0s 85us/sample - loss: 0.0113 - val_loss: 0.0880\n",
      "Epoch 4/50\n",
      "974/974 [==============================] - 0s 81us/sample - loss: 0.0113 - val_loss: 0.0883\n",
      "Epoch 5/50\n",
      "974/974 [==============================] - 0s 81us/sample - loss: 0.0108 - val_loss: 0.0882\n",
      "Epoch 6/50\n",
      "974/974 [==============================] - 0s 80us/sample - loss: 0.0107 - val_loss: 0.0885\n",
      "Epoch 7/50\n",
      "974/974 [==============================] - 0s 81us/sample - loss: 0.0107 - val_loss: 0.0883\n",
      "Epoch 8/50\n",
      "974/974 [==============================] - 0s 82us/sample - loss: 0.0108 - val_loss: 0.0886\n",
      "Epoch 9/50\n",
      "974/974 [==============================] - 0s 86us/sample - loss: 0.0106 - val_loss: 0.0883\n",
      "Epoch 10/50\n",
      "974/974 [==============================] - 0s 82us/sample - loss: 0.0106 - val_loss: 0.0884\n",
      "Epoch 11/50\n",
      "974/974 [==============================] - 0s 80us/sample - loss: 0.0108 - val_loss: 0.0887\n",
      "Epoch 12/50\n",
      "974/974 [==============================] - 0s 81us/sample - loss: 0.0107 - val_loss: 0.0884\n",
      "Epoch 13/50\n",
      "974/974 [==============================] - 0s 85us/sample - loss: 0.0108 - val_loss: 0.0885\n",
      "Epoch 14/50\n",
      "974/974 [==============================] - 0s 81us/sample - loss: 0.0106 - val_loss: 0.0887\n",
      "Epoch 15/50\n",
      "974/974 [==============================] - 0s 83us/sample - loss: 0.0107 - val_loss: 0.0885\n",
      "Epoch 16/50\n",
      "974/974 [==============================] - 0s 84us/sample - loss: 0.0108 - val_loss: 0.0893\n",
      "Epoch 17/50\n",
      "974/974 [==============================] - 0s 83us/sample - loss: 0.0107 - val_loss: 0.0887\n",
      "Epoch 18/50\n",
      "974/974 [==============================] - 0s 80us/sample - loss: 0.0105 - val_loss: 0.0891\n",
      "Epoch 19/50\n",
      "974/974 [==============================] - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0894\n",
      "Epoch 20/50\n",
      "974/974 [==============================] - 0s 79us/sample - loss: 0.0104 - val_loss: 0.0896\n",
      "Epoch 21/50\n",
      "974/974 [==============================] - 0s 80us/sample - loss: 0.0104 - val_loss: 0.0901\n",
      "Epoch 22/50\n",
      "974/974 [==============================] - 0s 79us/sample - loss: 0.0105 - val_loss: 0.0909\n",
      "Epoch 23/50\n",
      "974/974 [==============================] - 0s 79us/sample - loss: 0.0102 - val_loss: 0.0932\n",
      "Epoch 24/50\n",
      "974/974 [==============================] - 0s 80us/sample - loss: 0.0103 - val_loss: 0.0958\n",
      "Epoch 25/50\n",
      "974/974 [==============================] - 0s 77us/sample - loss: 0.0100 - val_loss: 0.1000\n",
      "Epoch 26/50\n",
      "974/974 [==============================] - 0s 77us/sample - loss: 0.0099 - val_loss: 0.1077\n",
      "Epoch 27/50\n",
      "974/974 [==============================] - 0s 78us/sample - loss: 0.0096 - val_loss: 0.1167\n",
      "Epoch 28/50\n",
      "974/974 [==============================] - 0s 82us/sample - loss: 0.0094 - val_loss: 0.1266\n",
      "Epoch 29/50\n",
      "974/974 [==============================] - 0s 81us/sample - loss: 0.0092 - val_loss: 0.1371\n",
      "Epoch 30/50\n",
      "974/974 [==============================] - 0s 81us/sample - loss: 0.0091 - val_loss: 0.1483\n",
      "Epoch 31/50\n",
      "974/974 [==============================] - 0s 80us/sample - loss: 0.0092 - val_loss: 0.1610\n",
      "Epoch 32/50\n",
      "974/974 [==============================] - 0s 82us/sample - loss: 0.0086 - val_loss: 0.1748\n",
      "Epoch 33/50\n",
      "974/974 [==============================] - 0s 80us/sample - loss: 0.0085 - val_loss: 0.1899\n",
      "Epoch 34/50\n",
      "974/974 [==============================] - 0s 79us/sample - loss: 0.0085 - val_loss: 0.2050\n",
      "Epoch 35/50\n",
      "974/974 [==============================] - 0s 78us/sample - loss: 0.0083 - val_loss: 0.2199\n",
      "Epoch 36/50\n",
      "974/974 [==============================] - 0s 78us/sample - loss: 0.0077 - val_loss: 0.2352\n",
      "Epoch 37/50\n",
      "974/974 [==============================] - 0s 79us/sample - loss: 0.0076 - val_loss: 0.2518\n",
      "Epoch 38/50\n",
      "974/974 [==============================] - 0s 80us/sample - loss: 0.0072 - val_loss: 0.2709\n",
      "Epoch 39/50\n",
      "974/974 [==============================] - 0s 82us/sample - loss: 0.0075 - val_loss: 0.2880\n",
      "Epoch 40/50\n",
      "974/974 [==============================] - 0s 78us/sample - loss: 0.0070 - val_loss: 0.3009\n",
      "Epoch 41/50\n",
      "974/974 [==============================] - 0s 81us/sample - loss: 0.0062 - val_loss: 0.3069\n",
      "Epoch 42/50\n",
      "974/974 [==============================] - 0s 81us/sample - loss: 0.0062 - val_loss: 0.3119\n",
      "Epoch 43/50\n",
      "974/974 [==============================] - 0s 82us/sample - loss: 0.0062 - val_loss: 0.3170\n",
      "Epoch 44/50\n",
      "974/974 [==============================] - 0s 84us/sample - loss: 0.0061 - val_loss: 0.3219\n",
      "Epoch 45/50\n",
      "974/974 [==============================] - 0s 82us/sample - loss: 0.0062 - val_loss: 0.3229\n",
      "Epoch 46/50\n",
      "974/974 [==============================] - 0s 79us/sample - loss: 0.0060 - val_loss: 0.3237\n",
      "Epoch 47/50\n",
      "974/974 [==============================] - 0s 82us/sample - loss: 0.0062 - val_loss: 0.3245\n",
      "Epoch 48/50\n",
      "974/974 [==============================] - 0s 81us/sample - loss: 0.0061 - val_loss: 0.3246\n",
      "Epoch 49/50\n",
      "974/974 [==============================] - 0s 86us/sample - loss: 0.0062 - val_loss: 0.3258\n",
      "Epoch 50/50\n",
      "974/974 [==============================] - 0s 83us/sample - loss: 0.0065 - val_loss: 0.3261\n",
      "第96个数，还剩4027个没有训练\n",
      "inv_hat [1.01394792 1.01394792 1.01494188 1.01494188 1.01494188 1.01494188\n",
      " 1.01494188 1.01494188 1.01494188 1.01494188 1.01593458 1.01593458\n",
      " 1.01593458 1.01593458 1.01593458 0.99893914 0.99662873 0.9912309\n",
      " 0.99739973 0.99739973 0.9950851  0.99585721 0.99431292 0.99893914\n",
      " 0.99970656 1.00350001 1.00789728 1.0064551  1.00931229 1.02783406]\n",
      "Test RMSE: 0.015\n",
      "Train on 594 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "594/594 [==============================] - 0s 86us/sample - loss: 0.0302 - val_loss: 0.0361\n",
      "Epoch 2/50\n",
      "594/594 [==============================] - 0s 83us/sample - loss: 0.0296 - val_loss: 0.0225\n",
      "Epoch 3/50\n",
      "594/594 [==============================] - 0s 85us/sample - loss: 0.0262 - val_loss: 0.0246\n",
      "Epoch 4/50\n",
      "594/594 [==============================] - 0s 89us/sample - loss: 0.0255 - val_loss: 0.0229\n",
      "Epoch 5/50\n",
      "594/594 [==============================] - 0s 92us/sample - loss: 0.0248 - val_loss: 0.0236\n",
      "Epoch 6/50\n",
      "594/594 [==============================] - 0s 92us/sample - loss: 0.0248 - val_loss: 0.0228\n",
      "Epoch 7/50\n",
      "594/594 [==============================] - 0s 94us/sample - loss: 0.0247 - val_loss: 0.0233\n",
      "Epoch 8/50\n",
      "594/594 [==============================] - 0s 90us/sample - loss: 0.0246 - val_loss: 0.0228\n",
      "Epoch 9/50\n",
      "594/594 [==============================] - 0s 92us/sample - loss: 0.0247 - val_loss: 0.0233\n",
      "Epoch 10/50\n",
      "594/594 [==============================] - 0s 86us/sample - loss: 0.0246 - val_loss: 0.0228\n",
      "Epoch 11/50\n",
      "594/594 [==============================] - 0s 89us/sample - loss: 0.0247 - val_loss: 0.0233\n",
      "Epoch 12/50\n",
      "594/594 [==============================] - 0s 90us/sample - loss: 0.0246 - val_loss: 0.0228\n",
      "Epoch 13/50\n",
      "594/594 [==============================] - 0s 84us/sample - loss: 0.0246 - val_loss: 0.0233\n",
      "Epoch 14/50\n",
      "594/594 [==============================] - 0s 86us/sample - loss: 0.0246 - val_loss: 0.0228\n",
      "Epoch 15/50\n",
      "594/594 [==============================] - 0s 85us/sample - loss: 0.0247 - val_loss: 0.0233\n",
      "Epoch 16/50\n",
      "594/594 [==============================] - 0s 87us/sample - loss: 0.0246 - val_loss: 0.0227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "594/594 [==============================] - 0s 84us/sample - loss: 0.0246 - val_loss: 0.0233\n",
      "Epoch 18/50\n",
      "594/594 [==============================] - 0s 85us/sample - loss: 0.0246 - val_loss: 0.0228\n",
      "Epoch 19/50\n",
      "594/594 [==============================] - 0s 84us/sample - loss: 0.0246 - val_loss: 0.0233\n",
      "Epoch 20/50\n",
      "594/594 [==============================] - 0s 84us/sample - loss: 0.0246 - val_loss: 0.0228\n",
      "Epoch 21/50\n",
      "594/594 [==============================] - 0s 84us/sample - loss: 0.0247 - val_loss: 0.0233\n",
      "Epoch 22/50\n",
      "594/594 [==============================] - 0s 87us/sample - loss: 0.0246 - val_loss: 0.0227\n",
      "Epoch 23/50\n",
      "594/594 [==============================] - 0s 88us/sample - loss: 0.0246 - val_loss: 0.0233\n",
      "Epoch 24/50\n",
      "594/594 [==============================] - 0s 87us/sample - loss: 0.0246 - val_loss: 0.0227\n",
      "Epoch 25/50\n",
      "594/594 [==============================] - 0s 85us/sample - loss: 0.0247 - val_loss: 0.0233\n",
      "Epoch 26/50\n",
      "594/594 [==============================] - 0s 88us/sample - loss: 0.0246 - val_loss: 0.0227\n",
      "Epoch 27/50\n",
      "594/594 [==============================] - 0s 86us/sample - loss: 0.0246 - val_loss: 0.0232\n",
      "Epoch 28/50\n",
      "594/594 [==============================] - 0s 86us/sample - loss: 0.0246 - val_loss: 0.0227\n",
      "Epoch 29/50\n",
      "594/594 [==============================] - 0s 88us/sample - loss: 0.0246 - val_loss: 0.0232\n",
      "Epoch 30/50\n",
      "594/594 [==============================] - 0s 93us/sample - loss: 0.0246 - val_loss: 0.0228\n",
      "Epoch 31/50\n",
      "594/594 [==============================] - 0s 92us/sample - loss: 0.0246 - val_loss: 0.0232\n",
      "Epoch 32/50\n",
      "594/594 [==============================] - 0s 93us/sample - loss: 0.0246 - val_loss: 0.0227\n",
      "Epoch 33/50\n",
      "594/594 [==============================] - 0s 89us/sample - loss: 0.0246 - val_loss: 0.0232\n",
      "Epoch 34/50\n",
      "594/594 [==============================] - 0s 88us/sample - loss: 0.0246 - val_loss: 0.0227\n",
      "Epoch 35/50\n",
      "594/594 [==============================] - 0s 91us/sample - loss: 0.0246 - val_loss: 0.0232\n",
      "Epoch 36/50\n",
      "594/594 [==============================] - 0s 88us/sample - loss: 0.0246 - val_loss: 0.0227\n",
      "Epoch 37/50\n",
      "594/594 [==============================] - 0s 87us/sample - loss: 0.0246 - val_loss: 0.0232\n",
      "Epoch 38/50\n",
      "594/594 [==============================] - 0s 86us/sample - loss: 0.0246 - val_loss: 0.0227\n",
      "Epoch 39/50\n",
      "594/594 [==============================] - 0s 87us/sample - loss: 0.0246 - val_loss: 0.0232\n",
      "Epoch 40/50\n",
      "594/594 [==============================] - 0s 84us/sample - loss: 0.0246 - val_loss: 0.0228\n",
      "Epoch 41/50\n",
      "594/594 [==============================] - 0s 89us/sample - loss: 0.0246 - val_loss: 0.0231\n",
      "Epoch 42/50\n",
      "594/594 [==============================] - 0s 86us/sample - loss: 0.0246 - val_loss: 0.0227\n",
      "Epoch 43/50\n",
      "594/594 [==============================] - 0s 82us/sample - loss: 0.0246 - val_loss: 0.0231\n",
      "Epoch 44/50\n",
      "594/594 [==============================] - 0s 85us/sample - loss: 0.0246 - val_loss: 0.0228\n",
      "Epoch 45/50\n",
      "594/594 [==============================] - 0s 82us/sample - loss: 0.0246 - val_loss: 0.0230\n",
      "Epoch 46/50\n",
      "594/594 [==============================] - 0s 93us/sample - loss: 0.0246 - val_loss: 0.0228\n",
      "Epoch 47/50\n",
      "594/594 [==============================] - 0s 90us/sample - loss: 0.0246 - val_loss: 0.0231\n",
      "Epoch 48/50\n",
      "594/594 [==============================] - 0s 85us/sample - loss: 0.0246 - val_loss: 0.0227\n",
      "Epoch 49/50\n",
      "594/594 [==============================] - 0s 87us/sample - loss: 0.0246 - val_loss: 0.0231\n",
      "Epoch 50/50\n",
      "594/594 [==============================] - 0s 84us/sample - loss: 0.0246 - val_loss: 0.0227\n",
      "第97个数，还剩4026个没有训练\n",
      "inv_hat [0.89568795 0.87401036 0.88489392 0.87994351 0.85921659 0.85429915\n",
      " 0.86315573 0.87499863 0.85233429 0.86118561 0.89176281 0.89176281\n",
      " 0.89667013 0.87598712 0.88093315 0.8898024  0.90060192 0.90060192\n",
      " 0.9065093  0.89078243 0.87994351 0.87796484 0.86118561 0.86611297\n",
      " 0.87598712 0.88192302 0.87499863 0.87302225 0.86709923 0.86808576]\n",
      "Test RMSE: 0.012\n",
      "Train on 669 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "669/669 [==============================] - 0s 83us/sample - loss: 0.1160 - val_loss: 0.0158\n",
      "Epoch 2/50\n",
      "669/669 [==============================] - 0s 84us/sample - loss: 0.1053 - val_loss: 0.0136\n",
      "Epoch 3/50\n",
      "669/669 [==============================] - 0s 84us/sample - loss: 0.0960 - val_loss: 0.0129\n",
      "Epoch 4/50\n",
      "669/669 [==============================] - 0s 82us/sample - loss: 0.0879 - val_loss: 0.0122\n",
      "Epoch 5/50\n",
      "669/669 [==============================] - 0s 87us/sample - loss: 0.0797 - val_loss: 0.0124\n",
      "Epoch 6/50\n",
      "669/669 [==============================] - 0s 82us/sample - loss: 0.0716 - val_loss: 0.0122\n",
      "Epoch 7/50\n",
      "669/669 [==============================] - 0s 87us/sample - loss: 0.0637 - val_loss: 0.0125\n",
      "Epoch 8/50\n",
      "669/669 [==============================] - 0s 85us/sample - loss: 0.0556 - val_loss: 0.0128\n",
      "Epoch 9/50\n",
      "669/669 [==============================] - 0s 86us/sample - loss: 0.0467 - val_loss: 0.0130\n",
      "Epoch 10/50\n",
      "669/669 [==============================] - 0s 82us/sample - loss: 0.0385 - val_loss: 0.0127\n",
      "Epoch 11/50\n",
      "669/669 [==============================] - 0s 85us/sample - loss: 0.0291 - val_loss: 0.0125\n",
      "Epoch 12/50\n",
      "669/669 [==============================] - 0s 81us/sample - loss: 0.0240 - val_loss: 0.0163\n",
      "Epoch 13/50\n",
      "669/669 [==============================] - 0s 85us/sample - loss: 0.0254 - val_loss: 0.0126\n",
      "Epoch 14/50\n",
      "669/669 [==============================] - 0s 86us/sample - loss: 0.0235 - val_loss: 0.0130\n",
      "Epoch 15/50\n",
      "669/669 [==============================] - 0s 89us/sample - loss: 0.0241 - val_loss: 0.0126\n",
      "Epoch 16/50\n",
      "669/669 [==============================] - 0s 85us/sample - loss: 0.0241 - val_loss: 0.0157\n",
      "Epoch 17/50\n",
      "669/669 [==============================] - 0s 83us/sample - loss: 0.0240 - val_loss: 0.0132\n",
      "Epoch 18/50\n",
      "669/669 [==============================] - 0s 86us/sample - loss: 0.0241 - val_loss: 0.0171\n",
      "Epoch 19/50\n",
      "669/669 [==============================] - 0s 89us/sample - loss: 0.0242 - val_loss: 0.0134\n",
      "Epoch 20/50\n",
      "669/669 [==============================] - 0s 84us/sample - loss: 0.0244 - val_loss: 0.0170\n",
      "Epoch 21/50\n",
      "669/669 [==============================] - 0s 83us/sample - loss: 0.0244 - val_loss: 0.0135\n",
      "Epoch 22/50\n",
      "669/669 [==============================] - 0s 84us/sample - loss: 0.0246 - val_loss: 0.0174\n",
      "Epoch 23/50\n",
      "669/669 [==============================] - 0s 81us/sample - loss: 0.0245 - val_loss: 0.0133\n",
      "Epoch 24/50\n",
      "669/669 [==============================] - 0s 85us/sample - loss: 0.0247 - val_loss: 0.0161\n",
      "Epoch 25/50\n",
      "669/669 [==============================] - 0s 86us/sample - loss: 0.0244 - val_loss: 0.0130\n",
      "Epoch 26/50\n",
      "669/669 [==============================] - 0s 82us/sample - loss: 0.0245 - val_loss: 0.0156\n",
      "Epoch 27/50\n",
      "669/669 [==============================] - 0s 89us/sample - loss: 0.0242 - val_loss: 0.0131\n",
      "Epoch 28/50\n",
      "669/669 [==============================] - 0s 86us/sample - loss: 0.0244 - val_loss: 0.0158\n",
      "Epoch 29/50\n",
      "669/669 [==============================] - 0s 81us/sample - loss: 0.0243 - val_loss: 0.0131\n",
      "Epoch 30/50\n",
      "669/669 [==============================] - 0s 81us/sample - loss: 0.0245 - val_loss: 0.0158\n",
      "Epoch 31/50\n",
      "669/669 [==============================] - 0s 83us/sample - loss: 0.0243 - val_loss: 0.0130\n",
      "Epoch 32/50\n",
      "669/669 [==============================] - 0s 85us/sample - loss: 0.0245 - val_loss: 0.0155\n",
      "Epoch 33/50\n",
      "669/669 [==============================] - 0s 88us/sample - loss: 0.0242 - val_loss: 0.0131\n",
      "Epoch 34/50\n",
      "669/669 [==============================] - 0s 82us/sample - loss: 0.0244 - val_loss: 0.0157\n",
      "Epoch 35/50\n",
      "669/669 [==============================] - 0s 80us/sample - loss: 0.0242 - val_loss: 0.0129\n",
      "Epoch 36/50\n",
      "669/669 [==============================] - 0s 83us/sample - loss: 0.0244 - val_loss: 0.0154\n",
      "Epoch 37/50\n",
      "669/669 [==============================] - 0s 81us/sample - loss: 0.0241 - val_loss: 0.0131\n",
      "Epoch 38/50\n",
      "669/669 [==============================] - 0s 89us/sample - loss: 0.0244 - val_loss: 0.0157\n",
      "Epoch 39/50\n",
      "669/669 [==============================] - 0s 84us/sample - loss: 0.0242 - val_loss: 0.0130\n",
      "Epoch 40/50\n",
      "669/669 [==============================] - 0s 85us/sample - loss: 0.0245 - val_loss: 0.0154\n",
      "Epoch 41/50\n",
      "669/669 [==============================] - 0s 85us/sample - loss: 0.0241 - val_loss: 0.0131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "669/669 [==============================] - 0s 84us/sample - loss: 0.0244 - val_loss: 0.0157\n",
      "Epoch 43/50\n",
      "669/669 [==============================] - 0s 85us/sample - loss: 0.0242 - val_loss: 0.0130\n",
      "Epoch 44/50\n",
      "669/669 [==============================] - 0s 84us/sample - loss: 0.0244 - val_loss: 0.0155\n",
      "Epoch 45/50\n",
      "669/669 [==============================] - 0s 80us/sample - loss: 0.0241 - val_loss: 0.0131\n",
      "Epoch 46/50\n",
      "669/669 [==============================] - 0s 81us/sample - loss: 0.0244 - val_loss: 0.0156\n",
      "Epoch 47/50\n",
      "669/669 [==============================] - 0s 85us/sample - loss: 0.0242 - val_loss: 0.0130\n",
      "Epoch 48/50\n",
      "669/669 [==============================] - 0s 85us/sample - loss: 0.0244 - val_loss: 0.0155\n",
      "Epoch 49/50\n",
      "669/669 [==============================] - 0s 84us/sample - loss: 0.0241 - val_loss: 0.0130\n",
      "Epoch 50/50\n",
      "669/669 [==============================] - 0s 82us/sample - loss: 0.0244 - val_loss: 0.0157\n",
      "第98个数，还剩4025个没有训练\n",
      "inv_hat [1.05255771 1.04555055 1.04454558 1.04454558 1.0425331  1.0425331\n",
      " 1.0425331  1.04353965 1.04353965 1.04353965 1.04655476 1.04555055\n",
      " 1.04555055 1.04353965 1.04454558 1.0425331  1.04353965 1.04454558\n",
      " 1.04555055 1.04454558 1.04353965 1.0425331  1.04152571 1.04152571\n",
      " 1.04152571 1.04152571 1.04152571 1.04152571 1.04152571 1.04353965]\n",
      "Test RMSE: 0.002\n",
      "Train on 1193 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0608 - val_loss: 0.0384\n",
      "Epoch 2/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0323 - val_loss: 0.0150\n",
      "Epoch 3/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0254 - val_loss: 0.0102\n",
      "Epoch 4/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0219 - val_loss: 0.0081\n",
      "Epoch 5/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0209 - val_loss: 0.0087\n",
      "Epoch 6/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0206 - val_loss: 0.0084\n",
      "Epoch 7/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0208 - val_loss: 0.0092\n",
      "Epoch 8/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0210 - val_loss: 0.0081\n",
      "Epoch 9/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0205 - val_loss: 0.0085\n",
      "Epoch 10/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0213 - val_loss: 0.0095\n",
      "Epoch 11/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0214 - val_loss: 0.0095\n",
      "Epoch 12/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0214 - val_loss: 0.0105\n",
      "Epoch 13/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0219 - val_loss: 0.0082\n",
      "Epoch 14/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0214 - val_loss: 0.0081\n",
      "Epoch 15/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0203 - val_loss: 0.0081\n",
      "Epoch 16/50\n",
      "1193/1193 [==============================] - 0s 86us/sample - loss: 0.0206 - val_loss: 0.0090\n",
      "Epoch 17/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0204 - val_loss: 0.0081\n",
      "Epoch 18/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0208 - val_loss: 0.0089\n",
      "Epoch 19/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0202 - val_loss: 0.0081\n",
      "Epoch 20/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0203 - val_loss: 0.0083\n",
      "Epoch 21/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0203 - val_loss: 0.0082\n",
      "Epoch 22/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0204 - val_loss: 0.0088\n",
      "Epoch 23/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0204 - val_loss: 0.0095\n",
      "Epoch 24/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0206 - val_loss: 0.0088\n",
      "Epoch 25/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0202 - val_loss: 0.0092\n",
      "Epoch 26/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0201 - val_loss: 0.0080\n",
      "Epoch 27/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0203 - val_loss: 0.0101\n",
      "Epoch 28/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0203 - val_loss: 0.0080\n",
      "Epoch 29/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0201 - val_loss: 0.0080\n",
      "Epoch 30/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0200 - val_loss: 0.0084\n",
      "Epoch 31/50\n",
      "1193/1193 [==============================] - 0s 75us/sample - loss: 0.0200 - val_loss: 0.0088\n",
      "Epoch 32/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0204 - val_loss: 0.0094\n",
      "Epoch 33/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0201 - val_loss: 0.0085\n",
      "Epoch 34/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0199 - val_loss: 0.0091\n",
      "Epoch 35/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0206 - val_loss: 0.0086\n",
      "Epoch 36/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0201 - val_loss: 0.0081\n",
      "Epoch 37/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0203 - val_loss: 0.0080\n",
      "Epoch 38/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0200 - val_loss: 0.0090\n",
      "Epoch 39/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0204 - val_loss: 0.0079\n",
      "Epoch 40/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0199 - val_loss: 0.0086\n",
      "Epoch 41/50\n",
      "1193/1193 [==============================] - 0s 87us/sample - loss: 0.0200 - val_loss: 0.0091\n",
      "Epoch 42/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0200 - val_loss: 0.0084\n",
      "Epoch 43/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0199 - val_loss: 0.0080\n",
      "Epoch 44/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0202 - val_loss: 0.0099\n",
      "Epoch 45/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0209 - val_loss: 0.0080\n",
      "Epoch 46/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0202 - val_loss: 0.0080\n",
      "Epoch 47/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0198 - val_loss: 0.0082\n",
      "Epoch 48/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0201 - val_loss: 0.0080\n",
      "Epoch 49/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0196 - val_loss: 0.0082\n",
      "Epoch 50/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0195 - val_loss: 0.0083\n",
      "第99个数，还剩4024个没有训练\n",
      "inv_hat [1.00698964 1.00698964 1.00698964 1.00698964 1.00698964 1.0079898\n",
      " 1.0079898  1.0079898  1.0079898  1.0079898  1.0079898  1.0079898\n",
      " 1.0089931  1.0089931  1.0089931  1.0089931  1.0089931  1.0089931\n",
      " 1.0089931  1.0089931  1.00999331 1.00999331 1.00999331 1.00999331\n",
      " 1.00999331 1.00999331 1.00999331 1.01099296 1.01099296 1.01099296]\n",
      "Test RMSE: 0.000\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0686 - val_loss: 0.0496\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0215 - val_loss: 0.0117\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0112 - val_loss: 0.0071\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0132 - val_loss: 0.0065\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0120 - val_loss: 0.0068\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0068\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0115 - val_loss: 0.0066\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0117 - val_loss: 0.0066\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0116 - val_loss: 0.0066\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0117 - val_loss: 0.0066\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0116 - val_loss: 0.0065\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0115 - val_loss: 0.0066\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0113 - val_loss: 0.0066\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0114 - val_loss: 0.0066\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0113 - val_loss: 0.0065\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0113 - val_loss: 0.0066\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0113 - val_loss: 0.0065\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0113 - val_loss: 0.0065\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0113 - val_loss: 0.0065\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0114 - val_loss: 0.0064\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0115 - val_loss: 0.0064\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0115 - val_loss: 0.0064\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0115 - val_loss: 0.0063\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0115 - val_loss: 0.0063\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0064\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0115 - val_loss: 0.0063\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0115 - val_loss: 0.0063\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0115 - val_loss: 0.0063\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0116 - val_loss: 0.0063\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0116 - val_loss: 0.0063\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0116 - val_loss: 0.0063\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0116 - val_loss: 0.0063\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0115 - val_loss: 0.0064\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0116 - val_loss: 0.0063\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0115 - val_loss: 0.0064\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0115 - val_loss: 0.0064\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0114 - val_loss: 0.0064\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0064\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0064\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0112 - val_loss: 0.0065\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0112 - val_loss: 0.0064\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0064\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0065\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0111 - val_loss: 0.0064\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0064\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0065\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0065\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0065\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0110 - val_loss: 0.0065\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0064\n",
      "第100个数，还剩4023个没有训练\n",
      "inv_hat [3.35482119 3.28338412 3.28612218 3.27556147 3.21312298 3.20257781\n",
      " 3.2031638  3.23441492 3.181691   3.21741958 3.29326194 3.30255468\n",
      " 3.28886058 3.22493986 3.20794795 3.17573921 3.20697122 3.20990053\n",
      " 3.26842422 3.21478288 3.16286203 3.13175888 3.09016199 3.09824419\n",
      " 3.07030405 3.10067881 3.08412547 3.06290848 3.04938622 3.05590339]\n",
      "Test RMSE: 0.036\n",
      "Train on 679 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "679/679 [==============================] - 0s 82us/sample - loss: 0.0622 - val_loss: 0.0680\n",
      "Epoch 2/50\n",
      "679/679 [==============================] - 0s 82us/sample - loss: 0.0424 - val_loss: 0.0880\n",
      "Epoch 3/50\n",
      "679/679 [==============================] - 0s 82us/sample - loss: 0.0252 - val_loss: 0.0656\n",
      "Epoch 4/50\n",
      "679/679 [==============================] - 0s 83us/sample - loss: 0.0221 - val_loss: 0.0964\n",
      "Epoch 5/50\n",
      "679/679 [==============================] - 0s 82us/sample - loss: 0.0193 - val_loss: 0.0779\n",
      "Epoch 6/50\n",
      "679/679 [==============================] - 0s 82us/sample - loss: 0.0208 - val_loss: 0.0992\n",
      "Epoch 7/50\n",
      "679/679 [==============================] - 0s 84us/sample - loss: 0.0181 - val_loss: 0.0856\n",
      "Epoch 8/50\n",
      "679/679 [==============================] - 0s 83us/sample - loss: 0.0172 - val_loss: 0.1042\n",
      "Epoch 9/50\n",
      "679/679 [==============================] - 0s 85us/sample - loss: 0.0168 - val_loss: 0.0965\n",
      "Epoch 10/50\n",
      "679/679 [==============================] - 0s 89us/sample - loss: 0.0155 - val_loss: 0.1081\n",
      "Epoch 11/50\n",
      "679/679 [==============================] - 0s 93us/sample - loss: 0.0140 - val_loss: 0.1061\n",
      "Epoch 12/50\n",
      "679/679 [==============================] - 0s 84us/sample - loss: 0.0139 - val_loss: 0.1111\n",
      "Epoch 13/50\n",
      "679/679 [==============================] - 0s 82us/sample - loss: 0.0130 - val_loss: 0.1173\n",
      "Epoch 14/50\n",
      "679/679 [==============================] - 0s 85us/sample - loss: 0.0148 - val_loss: 0.1182\n",
      "Epoch 15/50\n",
      "679/679 [==============================] - 0s 81us/sample - loss: 0.0133 - val_loss: 0.1276\n",
      "Epoch 16/50\n",
      "679/679 [==============================] - 0s 82us/sample - loss: 0.0129 - val_loss: 0.1284\n",
      "Epoch 17/50\n",
      "679/679 [==============================] - 0s 85us/sample - loss: 0.0143 - val_loss: 0.1310\n",
      "Epoch 18/50\n",
      "679/679 [==============================] - 0s 85us/sample - loss: 0.0131 - val_loss: 0.1361\n",
      "Epoch 19/50\n",
      "679/679 [==============================] - 0s 84us/sample - loss: 0.0120 - val_loss: 0.1375\n",
      "Epoch 20/50\n",
      "679/679 [==============================] - 0s 84us/sample - loss: 0.0131 - val_loss: 0.1367\n",
      "Epoch 21/50\n",
      "679/679 [==============================] - 0s 84us/sample - loss: 0.0130 - val_loss: 0.1425\n",
      "Epoch 22/50\n",
      "679/679 [==============================] - 0s 81us/sample - loss: 0.0114 - val_loss: 0.1426\n",
      "Epoch 23/50\n",
      "679/679 [==============================] - 0s 82us/sample - loss: 0.0130 - val_loss: 0.1409\n",
      "Epoch 24/50\n",
      "679/679 [==============================] - 0s 80us/sample - loss: 0.0128 - val_loss: 0.1428\n",
      "Epoch 25/50\n",
      "679/679 [==============================] - 0s 83us/sample - loss: 0.0130 - val_loss: 0.1444\n",
      "Epoch 26/50\n",
      "679/679 [==============================] - 0s 81us/sample - loss: 0.0113 - val_loss: 0.1433\n",
      "Epoch 27/50\n",
      "679/679 [==============================] - 0s 84us/sample - loss: 0.0123 - val_loss: 0.1440\n",
      "Epoch 28/50\n",
      "679/679 [==============================] - 0s 82us/sample - loss: 0.0125 - val_loss: 0.1408\n",
      "Epoch 29/50\n",
      "679/679 [==============================] - 0s 82us/sample - loss: 0.0137 - val_loss: 0.1459\n",
      "Epoch 30/50\n",
      "679/679 [==============================] - 0s 85us/sample - loss: 0.0114 - val_loss: 0.1427\n",
      "Epoch 31/50\n",
      "679/679 [==============================] - 0s 93us/sample - loss: 0.0118 - val_loss: 0.1445\n",
      "Epoch 32/50\n",
      "679/679 [==============================] - 0s 88us/sample - loss: 0.0118 - val_loss: 0.1408\n",
      "Epoch 33/50\n",
      "679/679 [==============================] - 0s 89us/sample - loss: 0.0137 - val_loss: 0.1462\n",
      "Epoch 34/50\n",
      "679/679 [==============================] - 0s 89us/sample - loss: 0.0114 - val_loss: 0.1417\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679/679 [==============================] - 0s 89us/sample - loss: 0.0121 - val_loss: 0.1427\n",
      "Epoch 36/50\n",
      "679/679 [==============================] - 0s 84us/sample - loss: 0.0118 - val_loss: 0.1402\n",
      "Epoch 37/50\n",
      "679/679 [==============================] - 0s 80us/sample - loss: 0.0131 - val_loss: 0.1416\n",
      "Epoch 38/50\n",
      "679/679 [==============================] - 0s 84us/sample - loss: 0.0124 - val_loss: 0.1427\n",
      "Epoch 39/50\n",
      "679/679 [==============================] - 0s 82us/sample - loss: 0.0120 - val_loss: 0.1403\n",
      "Epoch 40/50\n",
      "679/679 [==============================] - 0s 84us/sample - loss: 0.0120 - val_loss: 0.1393\n",
      "Epoch 41/50\n",
      "679/679 [==============================] - 0s 80us/sample - loss: 0.0126 - val_loss: 0.1413\n",
      "Epoch 42/50\n",
      "679/679 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.1403\n",
      "Epoch 43/50\n",
      "679/679 [==============================] - 0s 80us/sample - loss: 0.0121 - val_loss: 0.1416\n",
      "Epoch 44/50\n",
      "679/679 [==============================] - 0s 80us/sample - loss: 0.0120 - val_loss: 0.1374\n",
      "Epoch 45/50\n",
      "679/679 [==============================] - 0s 86us/sample - loss: 0.0139 - val_loss: 0.1436\n",
      "Epoch 46/50\n",
      "679/679 [==============================] - 0s 86us/sample - loss: 0.0113 - val_loss: 0.1388\n",
      "Epoch 47/50\n",
      "679/679 [==============================] - 0s 82us/sample - loss: 0.0120 - val_loss: 0.1398\n",
      "Epoch 48/50\n",
      "679/679 [==============================] - 0s 86us/sample - loss: 0.0116 - val_loss: 0.1378\n",
      "Epoch 49/50\n",
      "679/679 [==============================] - 0s 80us/sample - loss: 0.0128 - val_loss: 0.1391\n",
      "Epoch 50/50\n",
      "679/679 [==============================] - 0s 87us/sample - loss: 0.0114 - val_loss: 0.1362\n",
      "第101个数，还剩4022个没有训练\n",
      "inv_hat [1.04135226 1.04126022 1.04208848 1.04273249 1.04199645 1.04098404\n",
      " 1.04116816 1.03324863 1.03251205 1.0291994  1.02873915 1.0290154\n",
      " 1.02929138 1.02965933 1.03021126 1.03002723 1.02947535 1.02910743\n",
      " 1.02956734 1.02965933 1.03021126 1.03039518 1.03159158 1.03168353\n",
      " 1.03205179 1.03214386 1.03214386 1.03214386 1.03214386 1.03214386]\n",
      "Test RMSE: 0.016\n",
      "Train on 653 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "653/653 [==============================] - 0s 89us/sample - loss: 0.0150 - val_loss: 0.0175\n",
      "Epoch 2/50\n",
      "653/653 [==============================] - 0s 86us/sample - loss: 0.0176 - val_loss: 0.0169\n",
      "Epoch 3/50\n",
      "653/653 [==============================] - 0s 86us/sample - loss: 0.0162 - val_loss: 0.0163\n",
      "Epoch 4/50\n",
      "653/653 [==============================] - 0s 88us/sample - loss: 0.0150 - val_loss: 0.0170\n",
      "Epoch 5/50\n",
      "653/653 [==============================] - 0s 91us/sample - loss: 0.0158 - val_loss: 0.0162\n",
      "Epoch 6/50\n",
      "653/653 [==============================] - 0s 90us/sample - loss: 0.0155 - val_loss: 0.0161\n",
      "Epoch 7/50\n",
      "653/653 [==============================] - 0s 90us/sample - loss: 0.0151 - val_loss: 0.0172\n",
      "Epoch 8/50\n",
      "653/653 [==============================] - 0s 94us/sample - loss: 0.0154 - val_loss: 0.0183\n",
      "Epoch 9/50\n",
      "653/653 [==============================] - 0s 88us/sample - loss: 0.0163 - val_loss: 0.0161\n",
      "Epoch 10/50\n",
      "653/653 [==============================] - 0s 92us/sample - loss: 0.0153 - val_loss: 0.0162\n",
      "Epoch 11/50\n",
      "653/653 [==============================] - 0s 91us/sample - loss: 0.0162 - val_loss: 0.0179\n",
      "Epoch 12/50\n",
      "653/653 [==============================] - 0s 86us/sample - loss: 0.0163 - val_loss: 0.0170\n",
      "Epoch 13/50\n",
      "653/653 [==============================] - 0s 88us/sample - loss: 0.0151 - val_loss: 0.0183\n",
      "Epoch 14/50\n",
      "653/653 [==============================] - 0s 87us/sample - loss: 0.0161 - val_loss: 0.0161\n",
      "Epoch 15/50\n",
      "653/653 [==============================] - 0s 85us/sample - loss: 0.0159 - val_loss: 0.0169\n",
      "Epoch 16/50\n",
      "653/653 [==============================] - 0s 88us/sample - loss: 0.0150 - val_loss: 0.0194\n",
      "Epoch 17/50\n",
      "653/653 [==============================] - 0s 86us/sample - loss: 0.0163 - val_loss: 0.0165\n",
      "Epoch 18/50\n",
      "653/653 [==============================] - 0s 83us/sample - loss: 0.0145 - val_loss: 0.0169\n",
      "Epoch 19/50\n",
      "653/653 [==============================] - 0s 86us/sample - loss: 0.0154 - val_loss: 0.0164\n",
      "Epoch 20/50\n",
      "653/653 [==============================] - 0s 85us/sample - loss: 0.0145 - val_loss: 0.0162\n",
      "Epoch 21/50\n",
      "653/653 [==============================] - 0s 86us/sample - loss: 0.0148 - val_loss: 0.0164\n",
      "Epoch 22/50\n",
      "653/653 [==============================] - 0s 90us/sample - loss: 0.0150 - val_loss: 0.0197\n",
      "Epoch 23/50\n",
      "653/653 [==============================] - 0s 91us/sample - loss: 0.0160 - val_loss: 0.0179\n",
      "Epoch 24/50\n",
      "653/653 [==============================] - 0s 88us/sample - loss: 0.0155 - val_loss: 0.0171\n",
      "Epoch 25/50\n",
      "653/653 [==============================] - 0s 92us/sample - loss: 0.0153 - val_loss: 0.0163\n",
      "Epoch 26/50\n",
      "653/653 [==============================] - 0s 86us/sample - loss: 0.0145 - val_loss: 0.0161\n",
      "Epoch 27/50\n",
      "653/653 [==============================] - 0s 86us/sample - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 28/50\n",
      "653/653 [==============================] - 0s 85us/sample - loss: 0.0149 - val_loss: 0.0185\n",
      "Epoch 29/50\n",
      "653/653 [==============================] - 0s 81us/sample - loss: 0.0153 - val_loss: 0.0218\n",
      "Epoch 30/50\n",
      "653/653 [==============================] - 0s 89us/sample - loss: 0.0171 - val_loss: 0.0163\n",
      "Epoch 31/50\n",
      "653/653 [==============================] - 0s 90us/sample - loss: 0.0147 - val_loss: 0.0162\n",
      "Epoch 32/50\n",
      "653/653 [==============================] - 0s 88us/sample - loss: 0.0149 - val_loss: 0.0169\n",
      "Epoch 33/50\n",
      "653/653 [==============================] - 0s 82us/sample - loss: 0.0147 - val_loss: 0.0192\n",
      "Epoch 34/50\n",
      "653/653 [==============================] - 0s 84us/sample - loss: 0.0158 - val_loss: 0.0175\n",
      "Epoch 35/50\n",
      "653/653 [==============================] - 0s 82us/sample - loss: 0.0153 - val_loss: 0.0169\n",
      "Epoch 36/50\n",
      "653/653 [==============================] - 0s 86us/sample - loss: 0.0154 - val_loss: 0.0162\n",
      "Epoch 37/50\n",
      "653/653 [==============================] - 0s 88us/sample - loss: 0.0162 - val_loss: 0.0169\n",
      "Epoch 38/50\n",
      "653/653 [==============================] - 0s 86us/sample - loss: 0.0150 - val_loss: 0.0183\n",
      "Epoch 39/50\n",
      "653/653 [==============================] - 0s 93us/sample - loss: 0.0155 - val_loss: 0.0175\n",
      "Epoch 40/50\n",
      "653/653 [==============================] - 0s 88us/sample - loss: 0.0151 - val_loss: 0.0168\n",
      "Epoch 41/50\n",
      "653/653 [==============================] - 0s 84us/sample - loss: 0.0151 - val_loss: 0.0161\n",
      "Epoch 42/50\n",
      "653/653 [==============================] - 0s 88us/sample - loss: 0.0159 - val_loss: 0.0164\n",
      "Epoch 43/50\n",
      "653/653 [==============================] - 0s 88us/sample - loss: 0.0144 - val_loss: 0.0170\n",
      "Epoch 44/50\n",
      "653/653 [==============================] - 0s 86us/sample - loss: 0.0146 - val_loss: 0.0171\n",
      "Epoch 45/50\n",
      "653/653 [==============================] - 0s 92us/sample - loss: 0.0144 - val_loss: 0.0167\n",
      "Epoch 46/50\n",
      "653/653 [==============================] - 0s 89us/sample - loss: 0.0146 - val_loss: 0.0171\n",
      "Epoch 47/50\n",
      "653/653 [==============================] - 0s 90us/sample - loss: 0.0145 - val_loss: 0.0173\n",
      "Epoch 48/50\n",
      "653/653 [==============================] - 0s 89us/sample - loss: 0.0146 - val_loss: 0.0172\n",
      "Epoch 49/50\n",
      "653/653 [==============================] - 0s 94us/sample - loss: 0.0149 - val_loss: 0.0180\n",
      "Epoch 50/50\n",
      "653/653 [==============================] - 0s 92us/sample - loss: 0.0149 - val_loss: 0.0196\n",
      "第102个数，还剩4021个没有训练\n",
      "inv_hat [0.9805868  0.97750183 0.97836755 0.97673355 0.97587071 0.97310159\n",
      " 0.97376841 0.97673355 0.97596651 0.97836755 0.98203912 0.9831066\n",
      " 0.9842734  0.97942773 0.97913838 0.97846385 0.97865646 0.97981381\n",
      " 0.98087696 0.97654165 0.97529641 0.97291128 0.97053939 0.97357781\n",
      " 0.97224579 0.97338729 0.97348251 0.97434082 0.97348251 0.97529641]\n",
      "Test RMSE: 0.003\n",
      "Train on 1081 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1081/1081 [==============================] - 0s 84us/sample - loss: 0.0137 - val_loss: 0.0041\n",
      "Epoch 2/50\n",
      "1081/1081 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0016\n",
      "Epoch 3/50\n",
      "1081/1081 [==============================] - 0s 81us/sample - loss: 0.0114 - val_loss: 0.0018\n",
      "Epoch 4/50\n",
      "1081/1081 [==============================] - 0s 84us/sample - loss: 0.0108 - val_loss: 0.0021\n",
      "Epoch 5/50\n",
      "1081/1081 [==============================] - 0s 84us/sample - loss: 0.0103 - val_loss: 0.0028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "1081/1081 [==============================] - 0s 89us/sample - loss: 0.0120 - val_loss: 0.0032\n",
      "Epoch 7/50\n",
      "1081/1081 [==============================] - 0s 85us/sample - loss: 0.0102 - val_loss: 0.0018\n",
      "Epoch 8/50\n",
      "1081/1081 [==============================] - 0s 85us/sample - loss: 0.0105 - val_loss: 0.0017\n",
      "Epoch 9/50\n",
      "1081/1081 [==============================] - 0s 85us/sample - loss: 0.0109 - val_loss: 0.0024\n",
      "Epoch 10/50\n",
      "1081/1081 [==============================] - 0s 85us/sample - loss: 0.0100 - val_loss: 0.0023\n",
      "Epoch 11/50\n",
      "1081/1081 [==============================] - 0s 84us/sample - loss: 0.0117 - val_loss: 0.0025\n",
      "Epoch 12/50\n",
      "1081/1081 [==============================] - 0s 85us/sample - loss: 0.0100 - val_loss: 0.0019\n",
      "Epoch 13/50\n",
      "1081/1081 [==============================] - 0s 82us/sample - loss: 0.0102 - val_loss: 0.0019\n",
      "Epoch 14/50\n",
      "1081/1081 [==============================] - 0s 82us/sample - loss: 0.0110 - val_loss: 0.0026\n",
      "Epoch 15/50\n",
      "1081/1081 [==============================] - 0s 85us/sample - loss: 0.0099 - val_loss: 0.0030\n",
      "Epoch 16/50\n",
      "1081/1081 [==============================] - 0s 83us/sample - loss: 0.0113 - val_loss: 0.0064\n",
      "Epoch 17/50\n",
      "1081/1081 [==============================] - 0s 83us/sample - loss: 0.0146 - val_loss: 0.0018\n",
      "Epoch 18/50\n",
      "1081/1081 [==============================] - 0s 85us/sample - loss: 0.0165 - val_loss: 0.0088\n",
      "Epoch 19/50\n",
      "1081/1081 [==============================] - 0s 84us/sample - loss: 0.0134 - val_loss: 0.0030\n",
      "Epoch 20/50\n",
      "1081/1081 [==============================] - 0s 86us/sample - loss: 0.0125 - val_loss: 0.0018\n",
      "Epoch 21/50\n",
      "1081/1081 [==============================] - 0s 83us/sample - loss: 0.0140 - val_loss: 0.0052\n",
      "Epoch 22/50\n",
      "1081/1081 [==============================] - 0s 82us/sample - loss: 0.0134 - val_loss: 0.0045\n",
      "Epoch 23/50\n",
      "1081/1081 [==============================] - 0s 83us/sample - loss: 0.0127 - val_loss: 0.0033\n",
      "Epoch 24/50\n",
      "1081/1081 [==============================] - 0s 85us/sample - loss: 0.0126 - val_loss: 0.0033\n",
      "Epoch 25/50\n",
      "1081/1081 [==============================] - 0s 86us/sample - loss: 0.0129 - val_loss: 0.0053\n",
      "Epoch 26/50\n",
      "1081/1081 [==============================] - 0s 83us/sample - loss: 0.0126 - val_loss: 0.0048\n",
      "Epoch 27/50\n",
      "1081/1081 [==============================] - 0s 83us/sample - loss: 0.0116 - val_loss: 0.0026\n",
      "Epoch 28/50\n",
      "1081/1081 [==============================] - 0s 85us/sample - loss: 0.0122 - val_loss: 0.0042\n",
      "Epoch 29/50\n",
      "1081/1081 [==============================] - 0s 82us/sample - loss: 0.0122 - val_loss: 0.0049\n",
      "Epoch 30/50\n",
      "1081/1081 [==============================] - 0s 87us/sample - loss: 0.0119 - val_loss: 0.0048\n",
      "Epoch 31/50\n",
      "1081/1081 [==============================] - 0s 83us/sample - loss: 0.0115 - val_loss: 0.0036\n",
      "Epoch 32/50\n",
      "1081/1081 [==============================] - 0s 86us/sample - loss: 0.0115 - val_loss: 0.0033\n",
      "Epoch 33/50\n",
      "1081/1081 [==============================] - 0s 88us/sample - loss: 0.0119 - val_loss: 0.0049\n",
      "Epoch 34/50\n",
      "1081/1081 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0033\n",
      "Epoch 35/50\n",
      "1081/1081 [==============================] - 0s 83us/sample - loss: 0.0116 - val_loss: 0.0043\n",
      "Epoch 36/50\n",
      "1081/1081 [==============================] - 0s 85us/sample - loss: 0.0113 - val_loss: 0.0032\n",
      "Epoch 37/50\n",
      "1081/1081 [==============================] - 0s 85us/sample - loss: 0.0112 - val_loss: 0.0036\n",
      "Epoch 38/50\n",
      "1081/1081 [==============================] - 0s 83us/sample - loss: 0.0115 - val_loss: 0.0050\n",
      "Epoch 39/50\n",
      "1081/1081 [==============================] - 0s 86us/sample - loss: 0.0109 - val_loss: 0.0038\n",
      "Epoch 40/50\n",
      "1081/1081 [==============================] - 0s 85us/sample - loss: 0.0109 - val_loss: 0.0036\n",
      "Epoch 41/50\n",
      "1081/1081 [==============================] - 0s 87us/sample - loss: 0.0107 - val_loss: 0.0028\n",
      "Epoch 42/50\n",
      "1081/1081 [==============================] - 0s 82us/sample - loss: 0.0113 - val_loss: 0.0040\n",
      "Epoch 43/50\n",
      "1081/1081 [==============================] - 0s 82us/sample - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 44/50\n",
      "1081/1081 [==============================] - 0s 85us/sample - loss: 0.0109 - val_loss: 0.0037\n",
      "Epoch 45/50\n",
      "1081/1081 [==============================] - 0s 85us/sample - loss: 0.0108 - val_loss: 0.0035\n",
      "Epoch 46/50\n",
      "1081/1081 [==============================] - 0s 83us/sample - loss: 0.0107 - val_loss: 0.0030\n",
      "Epoch 47/50\n",
      "1081/1081 [==============================] - 0s 83us/sample - loss: 0.0110 - val_loss: 0.0041\n",
      "Epoch 48/50\n",
      "1081/1081 [==============================] - 0s 86us/sample - loss: 0.0108 - val_loss: 0.0036\n",
      "Epoch 49/50\n",
      "1081/1081 [==============================] - 0s 82us/sample - loss: 0.0108 - val_loss: 0.0033\n",
      "Epoch 50/50\n",
      "1081/1081 [==============================] - 0s 86us/sample - loss: 0.0108 - val_loss: 0.0035\n",
      "第103个数，还剩4020个没有训练\n",
      "inv_hat [1.34675896 1.34675896 1.34675896 1.34675896 1.34573674 1.34471428\n",
      " 1.34573674 1.34675896 1.34675896 1.34675896 1.3477808  1.34982386\n",
      " 1.34982386 1.35084507 1.35084507 1.35186604 1.35186604 1.35288671\n",
      " 1.35288671 1.35084507 1.34880247 1.34880247 1.34982386 1.34982386\n",
      " 1.34880247 1.34982386 1.34982386 1.35084507 1.35186604 1.35390721]\n",
      "Test RMSE: 0.002\n",
      "Train on 710 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "710/710 [==============================] - 0s 78us/sample - loss: 0.0250 - val_loss: 0.0068\n",
      "Epoch 2/50\n",
      "710/710 [==============================] - 0s 76us/sample - loss: 0.0252 - val_loss: 0.0064\n",
      "Epoch 3/50\n",
      "710/710 [==============================] - 0s 75us/sample - loss: 0.0242 - val_loss: 0.0027\n",
      "Epoch 4/50\n",
      "710/710 [==============================] - 0s 76us/sample - loss: 0.0246 - val_loss: 0.0064\n",
      "Epoch 5/50\n",
      "710/710 [==============================] - 0s 77us/sample - loss: 0.0239 - val_loss: 0.0031\n",
      "Epoch 6/50\n",
      "710/710 [==============================] - 0s 78us/sample - loss: 0.0244 - val_loss: 0.0051\n",
      "Epoch 7/50\n",
      "710/710 [==============================] - 0s 76us/sample - loss: 0.0239 - val_loss: 0.0036\n",
      "Epoch 8/50\n",
      "710/710 [==============================] - 0s 78us/sample - loss: 0.0241 - val_loss: 0.0040\n",
      "Epoch 9/50\n",
      "710/710 [==============================] - 0s 79us/sample - loss: 0.0240 - val_loss: 0.0041\n",
      "Epoch 10/50\n",
      "710/710 [==============================] - 0s 76us/sample - loss: 0.0239 - val_loss: 0.0033\n",
      "Epoch 11/50\n",
      "710/710 [==============================] - 0s 82us/sample - loss: 0.0241 - val_loss: 0.0037\n",
      "Epoch 12/50\n",
      "710/710 [==============================] - 0s 82us/sample - loss: 0.0240 - val_loss: 0.0040\n",
      "Epoch 13/50\n",
      "710/710 [==============================] - 0s 85us/sample - loss: 0.0239 - val_loss: 0.0034\n",
      "Epoch 14/50\n",
      "710/710 [==============================] - 0s 78us/sample - loss: 0.0241 - val_loss: 0.0038\n",
      "Epoch 15/50\n",
      "710/710 [==============================] - 0s 81us/sample - loss: 0.0240 - val_loss: 0.0040\n",
      "Epoch 16/50\n",
      "710/710 [==============================] - 0s 86us/sample - loss: 0.0239 - val_loss: 0.0030\n",
      "Epoch 17/50\n",
      "710/710 [==============================] - 0s 84us/sample - loss: 0.0240 - val_loss: 0.0037\n",
      "Epoch 18/50\n",
      "710/710 [==============================] - 0s 84us/sample - loss: 0.0239 - val_loss: 0.0037\n",
      "Epoch 19/50\n",
      "710/710 [==============================] - 0s 81us/sample - loss: 0.0239 - val_loss: 0.0035\n",
      "Epoch 20/50\n",
      "710/710 [==============================] - 0s 82us/sample - loss: 0.0239 - val_loss: 0.0038\n",
      "Epoch 21/50\n",
      "710/710 [==============================] - 0s 85us/sample - loss: 0.0239 - val_loss: 0.0035\n",
      "Epoch 22/50\n",
      "710/710 [==============================] - 0s 87us/sample - loss: 0.0239 - val_loss: 0.0034\n",
      "Epoch 23/50\n",
      "710/710 [==============================] - 0s 85us/sample - loss: 0.0239 - val_loss: 0.0035\n",
      "Epoch 24/50\n",
      "710/710 [==============================] - 0s 79us/sample - loss: 0.0239 - val_loss: 0.0037\n",
      "Epoch 25/50\n",
      "710/710 [==============================] - 0s 81us/sample - loss: 0.0239 - val_loss: 0.0034\n",
      "Epoch 26/50\n",
      "710/710 [==============================] - 0s 82us/sample - loss: 0.0239 - val_loss: 0.0037\n",
      "Epoch 27/50\n",
      "710/710 [==============================] - 0s 82us/sample - loss: 0.0239 - val_loss: 0.0034\n",
      "Epoch 28/50\n",
      "710/710 [==============================] - 0s 81us/sample - loss: 0.0239 - val_loss: 0.0035\n",
      "Epoch 29/50\n",
      "710/710 [==============================] - 0s 82us/sample - loss: 0.0239 - val_loss: 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "710/710 [==============================] - 0s 83us/sample - loss: 0.0239 - val_loss: 0.0033\n",
      "Epoch 31/50\n",
      "710/710 [==============================] - 0s 79us/sample - loss: 0.0239 - val_loss: 0.0036\n",
      "Epoch 32/50\n",
      "710/710 [==============================] - 0s 78us/sample - loss: 0.0239 - val_loss: 0.0034\n",
      "Epoch 33/50\n",
      "710/710 [==============================] - 0s 78us/sample - loss: 0.0239 - val_loss: 0.0035\n",
      "Epoch 34/50\n",
      "710/710 [==============================] - 0s 80us/sample - loss: 0.0239 - val_loss: 0.0037\n",
      "Epoch 35/50\n",
      "710/710 [==============================] - 0s 81us/sample - loss: 0.0238 - val_loss: 0.0032\n",
      "Epoch 36/50\n",
      "710/710 [==============================] - 0s 83us/sample - loss: 0.0239 - val_loss: 0.0039\n",
      "Epoch 37/50\n",
      "710/710 [==============================] - 0s 85us/sample - loss: 0.0238 - val_loss: 0.0032\n",
      "Epoch 38/50\n",
      "710/710 [==============================] - 0s 85us/sample - loss: 0.0239 - val_loss: 0.0038\n",
      "Epoch 39/50\n",
      "710/710 [==============================] - 0s 82us/sample - loss: 0.0238 - val_loss: 0.0031\n",
      "Epoch 40/50\n",
      "710/710 [==============================] - 0s 81us/sample - loss: 0.0239 - val_loss: 0.0039\n",
      "Epoch 41/50\n",
      "710/710 [==============================] - 0s 80us/sample - loss: 0.0238 - val_loss: 0.0032\n",
      "Epoch 42/50\n",
      "710/710 [==============================] - 0s 81us/sample - loss: 0.0239 - val_loss: 0.0037\n",
      "Epoch 43/50\n",
      "710/710 [==============================] - 0s 79us/sample - loss: 0.0238 - val_loss: 0.0034\n",
      "Epoch 44/50\n",
      "710/710 [==============================] - 0s 79us/sample - loss: 0.0238 - val_loss: 0.0033\n",
      "Epoch 45/50\n",
      "710/710 [==============================] - 0s 78us/sample - loss: 0.0239 - val_loss: 0.0039\n",
      "Epoch 46/50\n",
      "710/710 [==============================] - 0s 77us/sample - loss: 0.0238 - val_loss: 0.0031\n",
      "Epoch 47/50\n",
      "710/710 [==============================] - 0s 78us/sample - loss: 0.0239 - val_loss: 0.0035\n",
      "Epoch 48/50\n",
      "710/710 [==============================] - 0s 83us/sample - loss: 0.0238 - val_loss: 0.0035\n",
      "Epoch 49/50\n",
      "710/710 [==============================] - 0s 76us/sample - loss: 0.0238 - val_loss: 0.0032\n",
      "Epoch 50/50\n",
      "710/710 [==============================] - 0s 81us/sample - loss: 0.0239 - val_loss: 0.0038\n",
      "第104个数，还剩4019个没有训练\n",
      "inv_hat [0.97761828 0.97663671 0.97663671 0.97565561 0.97467517 0.97565561\n",
      " 0.97467517 0.97565561 0.97467517 0.97467517 0.97663671 0.97663671\n",
      " 0.97565561 0.97369564 0.97369564 0.971738   0.971738   0.97271658\n",
      " 0.97663671 0.97467517 0.97467517 0.97271658 0.9707599  0.96978221\n",
      " 0.96782843 0.96880507 0.96782843 0.96685227 0.96587655 0.96685227]\n",
      "Test RMSE: 0.002\n",
      "Train on 645 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "645/645 [==============================] - 0s 83us/sample - loss: 0.0788 - val_loss: 0.0327\n",
      "Epoch 2/50\n",
      "645/645 [==============================] - 0s 83us/sample - loss: 0.0306 - val_loss: 0.0106\n",
      "Epoch 3/50\n",
      "645/645 [==============================] - 0s 81us/sample - loss: 0.0165 - val_loss: 0.0057\n",
      "Epoch 4/50\n",
      "645/645 [==============================] - 0s 77us/sample - loss: 0.0128 - val_loss: 0.0112\n",
      "Epoch 5/50\n",
      "645/645 [==============================] - 0s 79us/sample - loss: 0.0141 - val_loss: 0.0059\n",
      "Epoch 6/50\n",
      "645/645 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0063\n",
      "Epoch 7/50\n",
      "645/645 [==============================] - 0s 78us/sample - loss: 0.0137 - val_loss: 0.0128\n",
      "Epoch 8/50\n",
      "645/645 [==============================] - 0s 82us/sample - loss: 0.0180 - val_loss: 0.0046\n",
      "Epoch 9/50\n",
      "645/645 [==============================] - 0s 85us/sample - loss: 0.0077 - val_loss: 0.0052\n",
      "Epoch 10/50\n",
      "645/645 [==============================] - 0s 82us/sample - loss: 0.0140 - val_loss: 0.0128\n",
      "Epoch 11/50\n",
      "645/645 [==============================] - 0s 76us/sample - loss: 0.0126 - val_loss: 0.0069\n",
      "Epoch 12/50\n",
      "645/645 [==============================] - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 13/50\n",
      "645/645 [==============================] - 0s 82us/sample - loss: 0.0213 - val_loss: 0.0160\n",
      "Epoch 14/50\n",
      "645/645 [==============================] - 0s 78us/sample - loss: 0.0066 - val_loss: 0.0082\n",
      "Epoch 15/50\n",
      "645/645 [==============================] - 0s 80us/sample - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 16/50\n",
      "645/645 [==============================] - 0s 78us/sample - loss: 0.0140 - val_loss: 0.0105\n",
      "Epoch 17/50\n",
      "645/645 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0083\n",
      "Epoch 18/50\n",
      "645/645 [==============================] - 0s 83us/sample - loss: 0.0083 - val_loss: 0.0047\n",
      "Epoch 19/50\n",
      "645/645 [==============================] - 0s 86us/sample - loss: 0.0180 - val_loss: 0.0136\n",
      "Epoch 20/50\n",
      "645/645 [==============================] - 0s 83us/sample - loss: 0.0071 - val_loss: 0.0072\n",
      "Epoch 21/50\n",
      "645/645 [==============================] - 0s 81us/sample - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 22/50\n",
      "645/645 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0096\n",
      "Epoch 23/50\n",
      "645/645 [==============================] - 0s 79us/sample - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 24/50\n",
      "645/645 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0047\n",
      "Epoch 25/50\n",
      "645/645 [==============================] - 0s 81us/sample - loss: 0.0149 - val_loss: 0.0102\n",
      "Epoch 26/50\n",
      "645/645 [==============================] - 0s 86us/sample - loss: 0.0078 - val_loss: 0.0067\n",
      "Epoch 27/50\n",
      "645/645 [==============================] - 0s 79us/sample - loss: 0.0076 - val_loss: 0.0059\n",
      "Epoch 28/50\n",
      "645/645 [==============================] - 0s 79us/sample - loss: 0.0150 - val_loss: 0.0163\n",
      "Epoch 29/50\n",
      "645/645 [==============================] - 0s 76us/sample - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 30/50\n",
      "645/645 [==============================] - 0s 79us/sample - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 31/50\n",
      "645/645 [==============================] - 0s 78us/sample - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 32/50\n",
      "645/645 [==============================] - 0s 80us/sample - loss: 0.0078 - val_loss: 0.0116\n",
      "Epoch 33/50\n",
      "645/645 [==============================] - 0s 81us/sample - loss: 0.0067 - val_loss: 0.0058\n",
      "Epoch 34/50\n",
      "645/645 [==============================] - 0s 85us/sample - loss: 0.0156 - val_loss: 0.0165\n",
      "Epoch 35/50\n",
      "645/645 [==============================] - 0s 85us/sample - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 36/50\n",
      "645/645 [==============================] - 0s 86us/sample - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 37/50\n",
      "645/645 [==============================] - 0s 81us/sample - loss: 0.0071 - val_loss: 0.0065\n",
      "Epoch 38/50\n",
      "645/645 [==============================] - 0s 82us/sample - loss: 0.0115 - val_loss: 0.0084\n",
      "Epoch 39/50\n",
      "645/645 [==============================] - 0s 79us/sample - loss: 0.0107 - val_loss: 0.0046\n",
      "Epoch 40/50\n",
      "645/645 [==============================] - 0s 83us/sample - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 41/50\n",
      "645/645 [==============================] - 0s 85us/sample - loss: 0.0079 - val_loss: 0.0078\n",
      "Epoch 42/50\n",
      "645/645 [==============================] - 0s 82us/sample - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 43/50\n",
      "645/645 [==============================] - 0s 84us/sample - loss: 0.0127 - val_loss: 0.0112\n",
      "Epoch 44/50\n",
      "645/645 [==============================] - 0s 86us/sample - loss: 0.0085 - val_loss: 0.0069\n",
      "Epoch 45/50\n",
      "645/645 [==============================] - 0s 86us/sample - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 46/50\n",
      "645/645 [==============================] - 0s 86us/sample - loss: 0.0135 - val_loss: 0.0104\n",
      "Epoch 47/50\n",
      "645/645 [==============================] - 0s 80us/sample - loss: 0.0058 - val_loss: 0.0092\n",
      "Epoch 48/50\n",
      "645/645 [==============================] - 0s 79us/sample - loss: 0.0078 - val_loss: 0.0051\n",
      "Epoch 49/50\n",
      "645/645 [==============================] - 0s 78us/sample - loss: 0.0126 - val_loss: 0.0119\n",
      "Epoch 50/50\n",
      "645/645 [==============================] - 0s 78us/sample - loss: 0.0049 - val_loss: 0.0078\n",
      "第105个数，还剩4018个没有训练\n",
      "inv_hat [1.15487912 1.15487912 1.15587101 1.15587101 1.15388748 1.15388748\n",
      " 1.15388748 1.15388748 1.15388748 1.15388748 1.15587101 1.15686332\n",
      " 1.15785594 1.15785594 1.15884877 1.16182928 1.1628234  1.1648123\n",
      " 1.16182928 1.16083545 1.15984201 1.15984201 1.16083545 1.16182928\n",
      " 1.1628234  1.1628234  1.1648123  1.16381766 1.16680223 1.16978896]\n",
      "Test RMSE: 0.002\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0127 - val_loss: 0.0136\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0130 - val_loss: 0.0126\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0117 - val_loss: 0.0076\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0104 - val_loss: 0.0059\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0103 - val_loss: 0.0084\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0063\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0095 - val_loss: 0.0056\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0094 - val_loss: 0.0056\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0099 - val_loss: 0.0057\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0100 - val_loss: 0.0084\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0105 - val_loss: 0.0125\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0119 - val_loss: 0.0104\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0122 - val_loss: 0.0148\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0143 - val_loss: 0.0103\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0115 - val_loss: 0.0067\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0100 - val_loss: 0.0057\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0096 - val_loss: 0.0074\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0103 - val_loss: 0.0100\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0116 - val_loss: 0.0079\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0108 - val_loss: 0.0070\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0103 - val_loss: 0.0058\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0098 - val_loss: 0.0061\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0104 - val_loss: 0.0095\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0115 - val_loss: 0.0094\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0109 - val_loss: 0.0068\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0103 - val_loss: 0.0066\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0097 - val_loss: 0.0067\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0113 - val_loss: 0.0070\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0103 - val_loss: 0.0065\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0098 - val_loss: 0.0055\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0097 - val_loss: 0.0062\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0116 - val_loss: 0.0082\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0105 - val_loss: 0.0056\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0096 - val_loss: 0.0068\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0102 - val_loss: 0.0098\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0116 - val_loss: 0.0074\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0103 - val_loss: 0.0071\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0100 - val_loss: 0.0063\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0098 - val_loss: 0.0060\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0099 - val_loss: 0.0061\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0096 - val_loss: 0.0063\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0099 - val_loss: 0.0057\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0099 - val_loss: 0.0060\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0073\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0104 - val_loss: 0.0074\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0107 - val_loss: 0.0089\n",
      "第106个数，还剩4017个没有训练\n",
      "inv_hat [1.02761816 1.0286146  1.0286146  1.0286146  1.02960923 1.02960923\n",
      " 1.02960923 1.02960923 1.02960923 1.0306022  1.0306022  1.03159325\n",
      " 1.03267572 1.03258249 1.03258249 1.03356978 1.0306022  1.0306022\n",
      " 1.02960923 1.02960923 1.02960923 1.0286146  1.0286146  1.02960923\n",
      " 1.02960923 1.02960923 1.02960923 1.02960923 1.0306022  1.03159325]\n",
      "Test RMSE: 0.001\n",
      "Train on 576 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 86us/sample - loss: 0.0316 - val_loss: 0.0278\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 81us/sample - loss: 0.0326 - val_loss: 0.0284\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 80us/sample - loss: 0.0316 - val_loss: 0.0277\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 83us/sample - loss: 0.0277 - val_loss: 0.0296\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 80us/sample - loss: 0.0273 - val_loss: 0.0336\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 80us/sample - loss: 0.0269 - val_loss: 0.0326\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 84us/sample - loss: 0.0268 - val_loss: 0.0369\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 77us/sample - loss: 0.0268 - val_loss: 0.0355\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 76us/sample - loss: 0.0267 - val_loss: 0.0362\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 84us/sample - loss: 0.0267 - val_loss: 0.0357\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 80us/sample - loss: 0.0267 - val_loss: 0.0349\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 79us/sample - loss: 0.0266 - val_loss: 0.0353\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 80us/sample - loss: 0.0266 - val_loss: 0.0343\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 83us/sample - loss: 0.0266 - val_loss: 0.0340\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 78us/sample - loss: 0.0266 - val_loss: 0.0342\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 81us/sample - loss: 0.0266 - val_loss: 0.0335\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 77us/sample - loss: 0.0266 - val_loss: 0.0334\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 81us/sample - loss: 0.0265 - val_loss: 0.0335\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 85us/sample - loss: 0.0265 - val_loss: 0.0334\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 80us/sample - loss: 0.0265 - val_loss: 0.0335\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 84us/sample - loss: 0.0265 - val_loss: 0.0334\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 78us/sample - loss: 0.0265 - val_loss: 0.0336\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 81us/sample - loss: 0.0265 - val_loss: 0.0333\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 81us/sample - loss: 0.0265 - val_loss: 0.0336\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 83us/sample - loss: 0.0265 - val_loss: 0.0333\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 81us/sample - loss: 0.0265 - val_loss: 0.0335\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 83us/sample - loss: 0.0265 - val_loss: 0.0332\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 81us/sample - loss: 0.0265 - val_loss: 0.0332\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 85us/sample - loss: 0.0265 - val_loss: 0.0334\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 82us/sample - loss: 0.0265 - val_loss: 0.0330\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 85us/sample - loss: 0.0264 - val_loss: 0.0332\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 87us/sample - loss: 0.0264 - val_loss: 0.0333\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 87us/sample - loss: 0.0264 - val_loss: 0.0332\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 86us/sample - loss: 0.0264 - val_loss: 0.0329\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 83us/sample - loss: 0.0264 - val_loss: 0.0329\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.011 - 0s 83us/sample - loss: 0.0264 - val_loss: 0.0330\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 83us/sample - loss: 0.0264 - val_loss: 0.0328\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 83us/sample - loss: 0.0264 - val_loss: 0.0325\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 81us/sample - loss: 0.0264 - val_loss: 0.0322\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 80us/sample - loss: 0.0264 - val_loss: 0.0322\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 82us/sample - loss: 0.0264 - val_loss: 0.0322\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 80us/sample - loss: 0.0264 - val_loss: 0.0322\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 80us/sample - loss: 0.0264 - val_loss: 0.0321\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 81us/sample - loss: 0.0264 - val_loss: 0.0322\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 80us/sample - loss: 0.0264 - val_loss: 0.0321\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 76us/sample - loss: 0.0264 - val_loss: 0.0321\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 85us/sample - loss: 0.0264 - val_loss: 0.0322\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 80us/sample - loss: 0.0264 - val_loss: 0.0322\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 79us/sample - loss: 0.0264 - val_loss: 0.0322\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 80us/sample - loss: 0.0264 - val_loss: 0.0318\n",
      "第107个数，还剩4016个没有训练\n",
      "inv_hat [0.18921117 0.19037154 0.19056445 0.1901785  0.19258055 0.18736481\n",
      " 0.18482453 0.18668221 0.18853213 0.19123844 0.19133457 0.19123844\n",
      " 0.19085354 0.19056445 0.19037154 0.19238932 0.19305783 0.1937241\n",
      " 0.19410381 0.19429336 0.19429336 0.19410381 0.19400895 0.19410381\n",
      " 0.19362907 0.19467187 0.19419861 0.19457731 0.1937241  0.1938191 ]\n",
      "Test RMSE: 0.002\n",
      "Train on 605 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "605/605 [==============================] - 0s 81us/sample - loss: 0.0172 - val_loss: 0.0234\n",
      "Epoch 2/50\n",
      "605/605 [==============================] - 0s 88us/sample - loss: 0.0152 - val_loss: 0.0169\n",
      "Epoch 3/50\n",
      "605/605 [==============================] - 0s 92us/sample - loss: 0.0126 - val_loss: 0.0069\n",
      "Epoch 4/50\n",
      "605/605 [==============================] - 0s 86us/sample - loss: 0.0153 - val_loss: 0.0125\n",
      "Epoch 5/50\n",
      "605/605 [==============================] - 0s 86us/sample - loss: 0.0121 - val_loss: 0.0074\n",
      "Epoch 6/50\n",
      "605/605 [==============================] - 0s 87us/sample - loss: 0.0148 - val_loss: 0.0133\n",
      "Epoch 7/50\n",
      "605/605 [==============================] - 0s 86us/sample - loss: 0.0111 - val_loss: 0.0083\n",
      "Epoch 8/50\n",
      "605/605 [==============================] - 0s 83us/sample - loss: 0.0145 - val_loss: 0.0169\n",
      "Epoch 9/50\n",
      "605/605 [==============================] - 0s 85us/sample - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 10/50\n",
      "605/605 [==============================] - 0s 94us/sample - loss: 0.0137 - val_loss: 0.0139\n",
      "Epoch 11/50\n",
      "605/605 [==============================] - 0s 87us/sample - loss: 0.0100 - val_loss: 0.0098\n",
      "Epoch 12/50\n",
      "605/605 [==============================] - 0s 90us/sample - loss: 0.0121 - val_loss: 0.0113\n",
      "Epoch 13/50\n",
      "605/605 [==============================] - 0s 84us/sample - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 14/50\n",
      "605/605 [==============================] - 0s 82us/sample - loss: 0.0109 - val_loss: 0.0105\n",
      "Epoch 15/50\n",
      "605/605 [==============================] - 0s 87us/sample - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 16/50\n",
      "605/605 [==============================] - 0s 89us/sample - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 17/50\n",
      "605/605 [==============================] - 0s 92us/sample - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 18/50\n",
      "605/605 [==============================] - 0s 89us/sample - loss: 0.0097 - val_loss: 0.0112\n",
      "Epoch 19/50\n",
      "605/605 [==============================] - 0s 90us/sample - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 20/50\n",
      "605/605 [==============================] - 0s 84us/sample - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 21/50\n",
      "605/605 [==============================] - 0s 87us/sample - loss: 0.0097 - val_loss: 0.0110\n",
      "Epoch 22/50\n",
      "605/605 [==============================] - 0s 90us/sample - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 23/50\n",
      "605/605 [==============================] - 0s 84us/sample - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 24/50\n",
      "605/605 [==============================] - 0s 85us/sample - loss: 0.0097 - val_loss: 0.0109\n",
      "Epoch 25/50\n",
      "605/605 [==============================] - 0s 83us/sample - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 26/50\n",
      "605/605 [==============================] - 0s 83us/sample - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 27/50\n",
      "605/605 [==============================] - 0s 82us/sample - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 28/50\n",
      "605/605 [==============================] - 0s 82us/sample - loss: 0.0096 - val_loss: 0.0087\n",
      "Epoch 29/50\n",
      "605/605 [==============================] - 0s 84us/sample - loss: 0.0106 - val_loss: 0.0100\n",
      "Epoch 30/50\n",
      "605/605 [==============================] - 0s 82us/sample - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 31/50\n",
      "605/605 [==============================] - 0s 82us/sample - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 32/50\n",
      "605/605 [==============================] - 0s 81us/sample - loss: 0.0099 - val_loss: 0.0088\n",
      "Epoch 33/50\n",
      "605/605 [==============================] - 0s 83us/sample - loss: 0.0097 - val_loss: 0.0088\n",
      "Epoch 34/50\n",
      "605/605 [==============================] - 0s 82us/sample - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 35/50\n",
      "605/605 [==============================] - 0s 81us/sample - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 36/50\n",
      "605/605 [==============================] - 0s 83us/sample - loss: 0.0103 - val_loss: 0.0090\n",
      "Epoch 37/50\n",
      "605/605 [==============================] - 0s 85us/sample - loss: 0.0092 - val_loss: 0.0088\n",
      "Epoch 38/50\n",
      "605/605 [==============================] - 0s 81us/sample - loss: 0.0097 - val_loss: 0.0080\n",
      "Epoch 39/50\n",
      "605/605 [==============================] - 0s 79us/sample - loss: 0.0094 - val_loss: 0.0087\n",
      "Epoch 40/50\n",
      "605/605 [==============================] - 0s 82us/sample - loss: 0.0092 - val_loss: 0.0091\n",
      "Epoch 41/50\n",
      "605/605 [==============================] - 0s 84us/sample - loss: 0.0092 - val_loss: 0.0103\n",
      "Epoch 42/50\n",
      "605/605 [==============================] - 0s 86us/sample - loss: 0.0100 - val_loss: 0.0078\n",
      "Epoch 43/50\n",
      "605/605 [==============================] - 0s 83us/sample - loss: 0.0094 - val_loss: 0.0078\n",
      "Epoch 44/50\n",
      "605/605 [==============================] - 0s 84us/sample - loss: 0.0092 - val_loss: 0.0088\n",
      "Epoch 45/50\n",
      "605/605 [==============================] - 0s 83us/sample - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 46/50\n",
      "605/605 [==============================] - 0s 85us/sample - loss: 0.0098 - val_loss: 0.0073\n",
      "Epoch 47/50\n",
      "605/605 [==============================] - 0s 83us/sample - loss: 0.0095 - val_loss: 0.0074\n",
      "Epoch 48/50\n",
      "605/605 [==============================] - 0s 90us/sample - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 49/50\n",
      "605/605 [==============================] - 0s 87us/sample - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 50/50\n",
      "605/605 [==============================] - 0s 83us/sample - loss: 0.0094 - val_loss: 0.0077\n",
      "第108个数，还剩4015个没有训练\n",
      "inv_hat [0.15827433 0.15817611 0.15807795 0.15826848 0.15827433 0.15837261\n",
      " 0.15847094 0.15856931 0.15856931 0.15856931 0.15866774 0.15847094\n",
      " 0.15878477 0.15856931 0.15856931 0.15847094 0.15856931 0.15866774\n",
      " 0.15906184 0.15906184 0.15906184 0.15896325 0.15896325 0.15896325\n",
      " 0.15896325 0.15925911 0.15940313 0.15940313 0.15906184 0.15925911]\n",
      "Test RMSE: 0.000\n",
      "Train on 1075 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1075/1075 [==============================] - 0s 77us/sample - loss: 0.0162 - val_loss: 0.0148\n",
      "Epoch 2/50\n",
      "1075/1075 [==============================] - 0s 78us/sample - loss: 0.0166 - val_loss: 0.0155\n",
      "Epoch 3/50\n",
      "1075/1075 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0113\n",
      "Epoch 4/50\n",
      "1075/1075 [==============================] - 0s 80us/sample - loss: 0.0143 - val_loss: 0.0094\n",
      "Epoch 5/50\n",
      "1075/1075 [==============================] - 0s 79us/sample - loss: 0.0141 - val_loss: 0.0093\n",
      "Epoch 6/50\n",
      "1075/1075 [==============================] - 0s 75us/sample - loss: 0.0144 - val_loss: 0.0100\n",
      "Epoch 7/50\n",
      "1075/1075 [==============================] - 0s 76us/sample - loss: 0.0150 - val_loss: 0.0121\n",
      "Epoch 8/50\n",
      "1075/1075 [==============================] - 0s 76us/sample - loss: 0.0146 - val_loss: 0.0109\n",
      "Epoch 9/50\n",
      "1075/1075 [==============================] - 0s 79us/sample - loss: 0.0142 - val_loss: 0.0098\n",
      "Epoch 10/50\n",
      "1075/1075 [==============================] - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0097\n",
      "Epoch 11/50\n",
      "1075/1075 [==============================] - 0s 76us/sample - loss: 0.0141 - val_loss: 0.0097\n",
      "Epoch 12/50\n",
      "1075/1075 [==============================] - 0s 76us/sample - loss: 0.0142 - val_loss: 0.0106\n",
      "Epoch 13/50\n",
      "1075/1075 [==============================] - 0s 80us/sample - loss: 0.0144 - val_loss: 0.0108\n",
      "Epoch 14/50\n",
      "1075/1075 [==============================] - 0s 79us/sample - loss: 0.0142 - val_loss: 0.0102\n",
      "Epoch 15/50\n",
      "1075/1075 [==============================] - 0s 83us/sample - loss: 0.0140 - val_loss: 0.0101\n",
      "Epoch 16/50\n",
      "1075/1075 [==============================] - 0s 82us/sample - loss: 0.0141 - val_loss: 0.0105\n",
      "Epoch 17/50\n",
      "1075/1075 [==============================] - 0s 80us/sample - loss: 0.0141 - val_loss: 0.0100\n",
      "Epoch 18/50\n",
      "1075/1075 [==============================] - 0s 82us/sample - loss: 0.0140 - val_loss: 0.0101\n",
      "Epoch 19/50\n",
      "1075/1075 [==============================] - 0s 81us/sample - loss: 0.0141 - val_loss: 0.0105\n",
      "Epoch 20/50\n",
      "1075/1075 [==============================] - 0s 79us/sample - loss: 0.0141 - val_loss: 0.0104\n",
      "Epoch 21/50\n",
      "1075/1075 [==============================] - 0s 76us/sample - loss: 0.0140 - val_loss: 0.0102\n",
      "Epoch 22/50\n",
      "1075/1075 [==============================] - 0s 77us/sample - loss: 0.0140 - val_loss: 0.0102\n",
      "Epoch 23/50\n",
      "1075/1075 [==============================] - 0s 77us/sample - loss: 0.0140 - val_loss: 0.0101\n",
      "Epoch 24/50\n",
      "1075/1075 [==============================] - 0s 76us/sample - loss: 0.0140 - val_loss: 0.0102\n",
      "Epoch 25/50\n",
      "1075/1075 [==============================] - 0s 79us/sample - loss: 0.0140 - val_loss: 0.0104\n",
      "Epoch 26/50\n",
      "1075/1075 [==============================] - 0s 78us/sample - loss: 0.0141 - val_loss: 0.0102\n",
      "Epoch 27/50\n",
      "1075/1075 [==============================] - 0s 80us/sample - loss: 0.0140 - val_loss: 0.0106\n",
      "Epoch 28/50\n",
      "1075/1075 [==============================] - 0s 81us/sample - loss: 0.0141 - val_loss: 0.0105\n",
      "Epoch 29/50\n",
      "1075/1075 [==============================] - 0s 79us/sample - loss: 0.0140 - val_loss: 0.0107\n",
      "Epoch 30/50\n",
      "1075/1075 [==============================] - 0s 78us/sample - loss: 0.0141 - val_loss: 0.0107\n",
      "Epoch 31/50\n",
      "1075/1075 [==============================] - 0s 79us/sample - loss: 0.0140 - val_loss: 0.0104\n",
      "Epoch 32/50\n",
      "1075/1075 [==============================] - 0s 82us/sample - loss: 0.0140 - val_loss: 0.0101\n",
      "Epoch 33/50\n",
      "1075/1075 [==============================] - 0s 82us/sample - loss: 0.0140 - val_loss: 0.0106\n",
      "Epoch 34/50\n",
      "1075/1075 [==============================] - 0s 80us/sample - loss: 0.0141 - val_loss: 0.0106\n",
      "Epoch 35/50\n",
      "1075/1075 [==============================] - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0106\n",
      "Epoch 36/50\n",
      "1075/1075 [==============================] - 0s 80us/sample - loss: 0.0140 - val_loss: 0.0103\n",
      "Epoch 37/50\n",
      "1075/1075 [==============================] - 0s 82us/sample - loss: 0.0140 - val_loss: 0.0104\n",
      "Epoch 38/50\n",
      "1075/1075 [==============================] - 0s 79us/sample - loss: 0.0141 - val_loss: 0.0107\n",
      "Epoch 39/50\n",
      "1075/1075 [==============================] - 0s 78us/sample - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 40/50\n",
      "1075/1075 [==============================] - 0s 77us/sample - loss: 0.0140 - val_loss: 0.0104\n",
      "Epoch 41/50\n",
      "1075/1075 [==============================] - 0s 76us/sample - loss: 0.0140 - val_loss: 0.0103\n",
      "Epoch 42/50\n",
      "1075/1075 [==============================] - 0s 79us/sample - loss: 0.0140 - val_loss: 0.0103\n",
      "Epoch 43/50\n",
      "1075/1075 [==============================] - 0s 74us/sample - loss: 0.0140 - val_loss: 0.0105\n",
      "Epoch 44/50\n",
      "1075/1075 [==============================] - 0s 76us/sample - loss: 0.0140 - val_loss: 0.0107\n",
      "Epoch 45/50\n",
      "1075/1075 [==============================] - 0s 75us/sample - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 46/50\n",
      "1075/1075 [==============================] - 0s 84us/sample - loss: 0.0140 - val_loss: 0.0103\n",
      "Epoch 47/50\n",
      "1075/1075 [==============================] - 0s 84us/sample - loss: 0.0140 - val_loss: 0.0106\n",
      "Epoch 48/50\n",
      "1075/1075 [==============================] - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0107\n",
      "Epoch 49/50\n",
      "1075/1075 [==============================] - 0s 78us/sample - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 50/50\n",
      "1075/1075 [==============================] - 0s 75us/sample - loss: 0.0140 - val_loss: 0.0109\n",
      "第109个数，还剩4014个没有训练\n",
      "inv_hat [1.73760892 1.69132568 1.69132568 1.67952804 1.64026893 1.63438937\n",
      " 1.6334099  1.64811223 1.61057306 1.63145076 1.67658004 1.67952804\n",
      " 1.6687214  1.61761597 1.61962799 1.61761597 1.62361753 1.62164001\n",
      " 1.64419004 1.60654814 1.59346487 1.57534455 1.55419853 1.55520557\n",
      " 1.54009835 1.54412728 1.53606951 1.52801146 1.51894568 1.52599689]\n",
      "Test RMSE: 0.024\n",
      "Train on 635 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "635/635 [==============================] - 0s 78us/sample - loss: 0.0182 - val_loss: 0.0228\n",
      "Epoch 2/50\n",
      "635/635 [==============================] - 0s 81us/sample - loss: 0.0190 - val_loss: 0.0345\n",
      "Epoch 3/50\n",
      "635/635 [==============================] - 0s 84us/sample - loss: 0.0186 - val_loss: 0.0232\n",
      "Epoch 4/50\n",
      "635/635 [==============================] - 0s 87us/sample - loss: 0.0176 - val_loss: 0.0309\n",
      "Epoch 5/50\n",
      "635/635 [==============================] - 0s 85us/sample - loss: 0.0180 - val_loss: 0.0229\n",
      "Epoch 6/50\n",
      "635/635 [==============================] - 0s 85us/sample - loss: 0.0181 - val_loss: 0.0270\n",
      "Epoch 7/50\n",
      "635/635 [==============================] - 0s 86us/sample - loss: 0.0172 - val_loss: 0.0230\n",
      "Epoch 8/50\n",
      "635/635 [==============================] - 0s 85us/sample - loss: 0.0182 - val_loss: 0.0276\n",
      "Epoch 9/50\n",
      "635/635 [==============================] - 0s 83us/sample - loss: 0.0173 - val_loss: 0.0229\n",
      "Epoch 10/50\n",
      "635/635 [==============================] - 0s 81us/sample - loss: 0.0182 - val_loss: 0.0278\n",
      "Epoch 11/50\n",
      "635/635 [==============================] - 0s 82us/sample - loss: 0.0173 - val_loss: 0.0228\n",
      "Epoch 12/50\n",
      "635/635 [==============================] - 0s 83us/sample - loss: 0.0179 - val_loss: 0.0281\n",
      "Epoch 13/50\n",
      "635/635 [==============================] - 0s 88us/sample - loss: 0.0173 - val_loss: 0.0228\n",
      "Epoch 14/50\n",
      "635/635 [==============================] - 0s 85us/sample - loss: 0.0178 - val_loss: 0.0280\n",
      "Epoch 15/50\n",
      "635/635 [==============================] - 0s 83us/sample - loss: 0.0172 - val_loss: 0.0227\n",
      "Epoch 16/50\n",
      "635/635 [==============================] - 0s 86us/sample - loss: 0.0179 - val_loss: 0.0281\n",
      "Epoch 17/50\n",
      "635/635 [==============================] - 0s 79us/sample - loss: 0.0172 - val_loss: 0.0227\n",
      "Epoch 18/50\n",
      "635/635 [==============================] - 0s 81us/sample - loss: 0.0177 - val_loss: 0.0280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "635/635 [==============================] - 0s 85us/sample - loss: 0.0170 - val_loss: 0.0227\n",
      "Epoch 20/50\n",
      "635/635 [==============================] - 0s 82us/sample - loss: 0.0177 - val_loss: 0.0281\n",
      "Epoch 21/50\n",
      "635/635 [==============================] - 0s 84us/sample - loss: 0.0170 - val_loss: 0.0226\n",
      "Epoch 22/50\n",
      "635/635 [==============================] - 0s 82us/sample - loss: 0.0176 - val_loss: 0.0281\n",
      "Epoch 23/50\n",
      "635/635 [==============================] - 0s 85us/sample - loss: 0.0170 - val_loss: 0.0226\n",
      "Epoch 24/50\n",
      "635/635 [==============================] - 0s 82us/sample - loss: 0.0177 - val_loss: 0.0283\n",
      "Epoch 25/50\n",
      "635/635 [==============================] - 0s 80us/sample - loss: 0.0170 - val_loss: 0.0226\n",
      "Epoch 26/50\n",
      "635/635 [==============================] - 0s 79us/sample - loss: 0.0176 - val_loss: 0.0282\n",
      "Epoch 27/50\n",
      "635/635 [==============================] - 0s 80us/sample - loss: 0.0169 - val_loss: 0.0226\n",
      "Epoch 28/50\n",
      "635/635 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0284\n",
      "Epoch 29/50\n",
      "635/635 [==============================] - 0s 83us/sample - loss: 0.0169 - val_loss: 0.0226\n",
      "Epoch 30/50\n",
      "635/635 [==============================] - 0s 84us/sample - loss: 0.0174 - val_loss: 0.0282\n",
      "Epoch 31/50\n",
      "635/635 [==============================] - 0s 87us/sample - loss: 0.0168 - val_loss: 0.0226\n",
      "Epoch 32/50\n",
      "635/635 [==============================] - 0s 84us/sample - loss: 0.0174 - val_loss: 0.0285\n",
      "Epoch 33/50\n",
      "635/635 [==============================] - 0s 79us/sample - loss: 0.0168 - val_loss: 0.0226\n",
      "Epoch 34/50\n",
      "635/635 [==============================] - 0s 78us/sample - loss: 0.0175 - val_loss: 0.0286\n",
      "Epoch 35/50\n",
      "635/635 [==============================] - 0s 78us/sample - loss: 0.0168 - val_loss: 0.0226\n",
      "Epoch 36/50\n",
      "635/635 [==============================] - 0s 79us/sample - loss: 0.0174 - val_loss: 0.0286\n",
      "Epoch 37/50\n",
      "635/635 [==============================] - 0s 78us/sample - loss: 0.0167 - val_loss: 0.0226\n",
      "Epoch 38/50\n",
      "635/635 [==============================] - 0s 78us/sample - loss: 0.0173 - val_loss: 0.0284\n",
      "Epoch 39/50\n",
      "635/635 [==============================] - 0s 79us/sample - loss: 0.0167 - val_loss: 0.0226\n",
      "Epoch 40/50\n",
      "635/635 [==============================] - 0s 80us/sample - loss: 0.0174 - val_loss: 0.0285\n",
      "Epoch 41/50\n",
      "635/635 [==============================] - 0s 79us/sample - loss: 0.0167 - val_loss: 0.0226\n",
      "Epoch 42/50\n",
      "635/635 [==============================] - 0s 80us/sample - loss: 0.0172 - val_loss: 0.0285\n",
      "Epoch 43/50\n",
      "635/635 [==============================] - 0s 79us/sample - loss: 0.0166 - val_loss: 0.0226\n",
      "Epoch 44/50\n",
      "635/635 [==============================] - 0s 80us/sample - loss: 0.0173 - val_loss: 0.0289\n",
      "Epoch 45/50\n",
      "635/635 [==============================] - 0s 79us/sample - loss: 0.0167 - val_loss: 0.0226\n",
      "Epoch 46/50\n",
      "635/635 [==============================] - 0s 88us/sample - loss: 0.0173 - val_loss: 0.0291\n",
      "Epoch 47/50\n",
      "635/635 [==============================] - 0s 82us/sample - loss: 0.0166 - val_loss: 0.0226\n",
      "Epoch 48/50\n",
      "635/635 [==============================] - 0s 82us/sample - loss: 0.0171 - val_loss: 0.0289\n",
      "Epoch 49/50\n",
      "635/635 [==============================] - 0s 81us/sample - loss: 0.0166 - val_loss: 0.0226\n",
      "Epoch 50/50\n",
      "635/635 [==============================] - 0s 85us/sample - loss: 0.0172 - val_loss: 0.0288\n",
      "第110个数，还剩4013个没有训练\n",
      "inv_hat [1.06196639 1.03979636 1.04235681 1.03900858 1.01934296 1.01859883\n",
      " 1.0172037  1.02883297 1.01757579 1.02725096 1.05230731 1.05427827\n",
      " 1.04964677 1.02967056 1.02967056 1.01924994 1.02343614 1.02650665\n",
      " 1.04038715 1.02520388 1.0240874  1.01506484 1.00483946 0.99805822\n",
      " 0.98766299 0.98970398 0.9836752  0.97941141 0.9763541  0.98228462]\n",
      "Test RMSE: 0.013\n",
      "Train on 561 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "561/561 [==============================] - 0s 82us/sample - loss: 0.0186 - val_loss: 0.0226\n",
      "Epoch 2/50\n",
      "561/561 [==============================] - 0s 90us/sample - loss: 0.0170 - val_loss: 0.0231\n",
      "Epoch 3/50\n",
      "561/561 [==============================] - 0s 87us/sample - loss: 0.0166 - val_loss: 0.0224\n",
      "Epoch 4/50\n",
      "561/561 [==============================] - 0s 83us/sample - loss: 0.0173 - val_loss: 0.0240\n",
      "Epoch 5/50\n",
      "561/561 [==============================] - 0s 81us/sample - loss: 0.0168 - val_loss: 0.0232\n",
      "Epoch 6/50\n",
      "561/561 [==============================] - 0s 83us/sample - loss: 0.0165 - val_loss: 0.0226\n",
      "Epoch 7/50\n",
      "561/561 [==============================] - 0s 83us/sample - loss: 0.0169 - val_loss: 0.0239\n",
      "Epoch 8/50\n",
      "561/561 [==============================] - 0s 78us/sample - loss: 0.0166 - val_loss: 0.0239\n",
      "Epoch 9/50\n",
      "561/561 [==============================] - 0s 80us/sample - loss: 0.0165 - val_loss: 0.0225\n",
      "Epoch 10/50\n",
      "561/561 [==============================] - 0s 77us/sample - loss: 0.0167 - val_loss: 0.0240\n",
      "Epoch 11/50\n",
      "561/561 [==============================] - 0s 80us/sample - loss: 0.0170 - val_loss: 0.0225\n",
      "Epoch 12/50\n",
      "561/561 [==============================] - 0s 82us/sample - loss: 0.0162 - val_loss: 0.0224\n",
      "Epoch 13/50\n",
      "561/561 [==============================] - 0s 86us/sample - loss: 0.0163 - val_loss: 0.0232\n",
      "Epoch 14/50\n",
      "561/561 [==============================] - 0s 83us/sample - loss: 0.0172 - val_loss: 0.0226\n",
      "Epoch 15/50\n",
      "561/561 [==============================] - 0s 87us/sample - loss: 0.0165 - val_loss: 0.0232\n",
      "Epoch 16/50\n",
      "561/561 [==============================] - 0s 84us/sample - loss: 0.0162 - val_loss: 0.0224\n",
      "Epoch 17/50\n",
      "561/561 [==============================] - 0s 84us/sample - loss: 0.0171 - val_loss: 0.0267\n",
      "Epoch 18/50\n",
      "561/561 [==============================] - 0s 79us/sample - loss: 0.0174 - val_loss: 0.0230\n",
      "Epoch 19/50\n",
      "561/561 [==============================] - 0s 79us/sample - loss: 0.0169 - val_loss: 0.0238\n",
      "Epoch 20/50\n",
      "561/561 [==============================] - 0s 78us/sample - loss: 0.0165 - val_loss: 0.0232\n",
      "Epoch 21/50\n",
      "561/561 [==============================] - 0s 83us/sample - loss: 0.0170 - val_loss: 0.0238\n",
      "Epoch 22/50\n",
      "561/561 [==============================] - 0s 83us/sample - loss: 0.0166 - val_loss: 0.0245\n",
      "Epoch 23/50\n",
      "561/561 [==============================] - 0s 87us/sample - loss: 0.0166 - val_loss: 0.0226\n",
      "Epoch 24/50\n",
      "561/561 [==============================] - 0s 84us/sample - loss: 0.0167 - val_loss: 0.0228\n",
      "Epoch 25/50\n",
      "561/561 [==============================] - 0s 84us/sample - loss: 0.0163 - val_loss: 0.0243\n",
      "Epoch 26/50\n",
      "561/561 [==============================] - 0s 83us/sample - loss: 0.0173 - val_loss: 0.0224\n",
      "Epoch 27/50\n",
      "561/561 [==============================] - 0s 88us/sample - loss: 0.0165 - val_loss: 0.0249\n",
      "Epoch 28/50\n",
      "561/561 [==============================] - 0s 84us/sample - loss: 0.0174 - val_loss: 0.0224\n",
      "Epoch 29/50\n",
      "561/561 [==============================] - 0s 84us/sample - loss: 0.0165 - val_loss: 0.0248\n",
      "Epoch 30/50\n",
      "561/561 [==============================] - 0s 82us/sample - loss: 0.0173 - val_loss: 0.0224\n",
      "Epoch 31/50\n",
      "561/561 [==============================] - 0s 86us/sample - loss: 0.0166 - val_loss: 0.0251\n",
      "Epoch 32/50\n",
      "561/561 [==============================] - 0s 84us/sample - loss: 0.0174 - val_loss: 0.0224\n",
      "Epoch 33/50\n",
      "561/561 [==============================] - 0s 84us/sample - loss: 0.0164 - val_loss: 0.0251\n",
      "Epoch 34/50\n",
      "561/561 [==============================] - 0s 88us/sample - loss: 0.0170 - val_loss: 0.0224\n",
      "Epoch 35/50\n",
      "561/561 [==============================] - 0s 85us/sample - loss: 0.0169 - val_loss: 0.0256\n",
      "Epoch 36/50\n",
      "561/561 [==============================] - 0s 89us/sample - loss: 0.0172 - val_loss: 0.0224\n",
      "Epoch 37/50\n",
      "561/561 [==============================] - 0s 86us/sample - loss: 0.0167 - val_loss: 0.0249\n",
      "Epoch 38/50\n",
      "561/561 [==============================] - 0s 84us/sample - loss: 0.0173 - val_loss: 0.0223\n",
      "Epoch 39/50\n",
      "561/561 [==============================] - 0s 87us/sample - loss: 0.0165 - val_loss: 0.0253\n",
      "Epoch 40/50\n",
      "561/561 [==============================] - 0s 86us/sample - loss: 0.0173 - val_loss: 0.0223\n",
      "Epoch 41/50\n",
      "561/561 [==============================] - 0s 86us/sample - loss: 0.0163 - val_loss: 0.0235\n",
      "Epoch 42/50\n",
      "561/561 [==============================] - 0s 80us/sample - loss: 0.0167 - val_loss: 0.0233\n",
      "Epoch 43/50\n",
      "561/561 [==============================] - 0s 84us/sample - loss: 0.0162 - val_loss: 0.0223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "561/561 [==============================] - 0s 83us/sample - loss: 0.0165 - val_loss: 0.0246\n",
      "Epoch 45/50\n",
      "561/561 [==============================] - 0s 86us/sample - loss: 0.0174 - val_loss: 0.0223\n",
      "Epoch 46/50\n",
      "561/561 [==============================] - 0s 82us/sample - loss: 0.0168 - val_loss: 0.0274\n",
      "Epoch 47/50\n",
      "561/561 [==============================] - 0s 79us/sample - loss: 0.0171 - val_loss: 0.0223\n",
      "Epoch 48/50\n",
      "561/561 [==============================] - 0s 79us/sample - loss: 0.0175 - val_loss: 0.0260\n",
      "Epoch 49/50\n",
      "561/561 [==============================] - 0s 81us/sample - loss: 0.0169 - val_loss: 0.0227\n",
      "Epoch 50/50\n",
      "561/561 [==============================] - 0s 81us/sample - loss: 0.0165 - val_loss: 0.0248\n",
      "第111个数，还剩4012个没有训练\n",
      "inv_hat [1.05135227 1.04438995 1.04438995 1.04339723 1.03844644 1.03844644\n",
      " 1.03844644 1.04042388 1.03745932 1.03943468 1.04637715 1.04637715\n",
      " 1.04438995 1.04042388 1.04042388 1.03745932 1.03745932 1.03844644\n",
      " 1.04042388 1.03647356 1.03647356 1.03345539 1.03041953 1.02637089\n",
      " 1.02434732 1.02637089 1.02535893 1.02434732 1.02333591 1.02535893]\n",
      "Test RMSE: 0.003\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0183 - val_loss: 0.0053\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0154 - val_loss: 0.0052\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0119 - val_loss: 0.0060\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0076 - val_loss: 0.0059\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0080 - val_loss: 0.0054\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0068 - val_loss: 0.0064\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0075 - val_loss: 0.0060\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0076 - val_loss: 0.0056\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0066 - val_loss: 0.0055\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0077 - val_loss: 0.0054\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0072 - val_loss: 0.0064\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0075 - val_loss: 0.0055\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0065 - val_loss: 0.0057\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0074 - val_loss: 0.0055\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0067 - val_loss: 0.0080\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0073 - val_loss: 0.0062\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0075 - val_loss: 0.0054\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0068 - val_loss: 0.0071\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0070 - val_loss: 0.0064\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0073 - val_loss: 0.0056\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 87us/sample - loss: 0.0064 - val_loss: 0.0057\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0072 - val_loss: 0.0055\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0071 - val_loss: 0.0055\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0069 - val_loss: 0.0055\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0069 - val_loss: 0.0055\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0068 - val_loss: 0.0055\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0068 - val_loss: 0.0055\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0064 - val_loss: 0.0065\n",
      "第112个数，还剩4011个没有训练\n",
      "inv_hat [0.93639984 0.92722578 0.92520932 0.92329359 0.91571858 0.91804275\n",
      " 0.92026594 0.92268864 0.91491016 0.91834597 0.92984713 0.92853644\n",
      " 0.92883896 0.91854805 0.9188512  0.92147861 0.92268864 0.92077123\n",
      " 0.92349522 0.9176386  0.91541544 0.91299019 0.90985775 0.91096926\n",
      " 0.91369753 0.91713331 0.9161228  0.91177765 0.91016087 0.91056507]\n",
      "Test RMSE: 0.005\n",
      "Train on 732 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "732/732 [==============================] - 0s 91us/sample - loss: 0.0159 - val_loss: 0.0205\n",
      "Epoch 2/50\n",
      "732/732 [==============================] - 0s 89us/sample - loss: 0.0166 - val_loss: 0.0209\n",
      "Epoch 3/50\n",
      "732/732 [==============================] - 0s 82us/sample - loss: 0.0158 - val_loss: 0.0233\n",
      "Epoch 4/50\n",
      "732/732 [==============================] - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0230\n",
      "Epoch 5/50\n",
      "732/732 [==============================] - 0s 83us/sample - loss: 0.0133 - val_loss: 0.0211\n",
      "Epoch 6/50\n",
      "732/732 [==============================] - 0s 84us/sample - loss: 0.0129 - val_loss: 0.0202\n",
      "Epoch 7/50\n",
      "732/732 [==============================] - 0s 82us/sample - loss: 0.0127 - val_loss: 0.0200\n",
      "Epoch 8/50\n",
      "732/732 [==============================] - 0s 86us/sample - loss: 0.0124 - val_loss: 0.0197\n",
      "Epoch 9/50\n",
      "732/732 [==============================] - 0s 91us/sample - loss: 0.0124 - val_loss: 0.0193\n",
      "Epoch 10/50\n",
      "732/732 [==============================] - 0s 88us/sample - loss: 0.0123 - val_loss: 0.0191\n",
      "Epoch 11/50\n",
      "732/732 [==============================] - 0s 86us/sample - loss: 0.0121 - val_loss: 0.0191\n",
      "Epoch 12/50\n",
      "732/732 [==============================] - 0s 85us/sample - loss: 0.0121 - val_loss: 0.0191\n",
      "Epoch 13/50\n",
      "732/732 [==============================] - 0s 88us/sample - loss: 0.0121 - val_loss: 0.0191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "732/732 [==============================] - 0s 84us/sample - loss: 0.0121 - val_loss: 0.0192\n",
      "Epoch 15/50\n",
      "732/732 [==============================] - 0s 86us/sample - loss: 0.0121 - val_loss: 0.0191\n",
      "Epoch 16/50\n",
      "732/732 [==============================] - 0s 85us/sample - loss: 0.0123 - val_loss: 0.0190\n",
      "Epoch 17/50\n",
      "732/732 [==============================] - 0s 88us/sample - loss: 0.0124 - val_loss: 0.0190\n",
      "Epoch 18/50\n",
      "732/732 [==============================] - 0s 84us/sample - loss: 0.0122 - val_loss: 0.0193\n",
      "Epoch 19/50\n",
      "732/732 [==============================] - 0s 85us/sample - loss: 0.0122 - val_loss: 0.0192\n",
      "Epoch 20/50\n",
      "732/732 [==============================] - 0s 86us/sample - loss: 0.0121 - val_loss: 0.0191\n",
      "Epoch 21/50\n",
      "732/732 [==============================] - 0s 93us/sample - loss: 0.0120 - val_loss: 0.0191\n",
      "Epoch 22/50\n",
      "732/732 [==============================] - 0s 90us/sample - loss: 0.0120 - val_loss: 0.0191\n",
      "Epoch 23/50\n",
      "732/732 [==============================] - 0s 85us/sample - loss: 0.0120 - val_loss: 0.0191\n",
      "Epoch 24/50\n",
      "732/732 [==============================] - 0s 86us/sample - loss: 0.0121 - val_loss: 0.0191\n",
      "Epoch 25/50\n",
      "732/732 [==============================] - 0s 85us/sample - loss: 0.0121 - val_loss: 0.0190\n",
      "Epoch 26/50\n",
      "732/732 [==============================] - 0s 86us/sample - loss: 0.0122 - val_loss: 0.0189\n",
      "Epoch 27/50\n",
      "732/732 [==============================] - 0s 83us/sample - loss: 0.0123 - val_loss: 0.0190\n",
      "Epoch 28/50\n",
      "732/732 [==============================] - 0s 87us/sample - loss: 0.0122 - val_loss: 0.0192\n",
      "Epoch 29/50\n",
      "732/732 [==============================] - 0s 86us/sample - loss: 0.0122 - val_loss: 0.0193\n",
      "Epoch 30/50\n",
      "732/732 [==============================] - 0s 87us/sample - loss: 0.0122 - val_loss: 0.0191\n",
      "Epoch 31/50\n",
      "732/732 [==============================] - 0s 84us/sample - loss: 0.0120 - val_loss: 0.0190\n",
      "Epoch 32/50\n",
      "732/732 [==============================] - 0s 84us/sample - loss: 0.0120 - val_loss: 0.0190\n",
      "Epoch 33/50\n",
      "732/732 [==============================] - 0s 89us/sample - loss: 0.0121 - val_loss: 0.0189\n",
      "Epoch 34/50\n",
      "732/732 [==============================] - 0s 92us/sample - loss: 0.0122 - val_loss: 0.0189\n",
      "Epoch 35/50\n",
      "732/732 [==============================] - 0s 92us/sample - loss: 0.0122 - val_loss: 0.0191\n",
      "Epoch 36/50\n",
      "732/732 [==============================] - 0s 85us/sample - loss: 0.0120 - val_loss: 0.0190\n",
      "Epoch 37/50\n",
      "732/732 [==============================] - 0s 86us/sample - loss: 0.0120 - val_loss: 0.0189\n",
      "Epoch 38/50\n",
      "732/732 [==============================] - 0s 89us/sample - loss: 0.0121 - val_loss: 0.0190\n",
      "Epoch 39/50\n",
      "732/732 [==============================] - 0s 91us/sample - loss: 0.0121 - val_loss: 0.0189\n",
      "Epoch 40/50\n",
      "732/732 [==============================] - 0s 90us/sample - loss: 0.0121 - val_loss: 0.0190\n",
      "Epoch 41/50\n",
      "732/732 [==============================] - 0s 86us/sample - loss: 0.0120 - val_loss: 0.0190\n",
      "Epoch 42/50\n",
      "732/732 [==============================] - 0s 91us/sample - loss: 0.0120 - val_loss: 0.0189\n",
      "Epoch 43/50\n",
      "732/732 [==============================] - 0s 87us/sample - loss: 0.0121 - val_loss: 0.0189\n",
      "Epoch 44/50\n",
      "732/732 [==============================] - 0s 82us/sample - loss: 0.0122 - val_loss: 0.0189\n",
      "Epoch 45/50\n",
      "732/732 [==============================] - 0s 89us/sample - loss: 0.0124 - val_loss: 0.0197\n",
      "Epoch 46/50\n",
      "732/732 [==============================] - 0s 85us/sample - loss: 0.0125 - val_loss: 0.0198\n",
      "Epoch 47/50\n",
      "732/732 [==============================] - 0s 82us/sample - loss: 0.0126 - val_loss: 0.0191\n",
      "Epoch 48/50\n",
      "732/732 [==============================] - 0s 84us/sample - loss: 0.0123 - val_loss: 0.0194\n",
      "Epoch 49/50\n",
      "732/732 [==============================] - 0s 83us/sample - loss: 0.0134 - val_loss: 0.0189\n",
      "Epoch 50/50\n",
      "732/732 [==============================] - 0s 91us/sample - loss: 0.0143 - val_loss: 0.0202\n",
      "第113个数，还剩4010个没有训练\n",
      "inv_hat [0.91896087 0.9020707  0.90306089 0.89712673 0.88335247 0.88433268\n",
      " 0.88139378 0.89022617 0.88139378 0.88825943 0.90603416 0.90801856\n",
      " 0.90405154 0.88825943 0.88924252 0.88531349 0.88924252 0.89121037\n",
      " 0.9020707  0.89022617 0.88629487 0.88041537 0.87553271 0.87455813\n",
      " 0.8706664  0.87261088 0.86969513 0.8667857  0.8667857  0.8716383 ]\n",
      "Test RMSE: 0.008\n",
      "Train on 605 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "605/605 [==============================] - 0s 88us/sample - loss: 0.0092 - val_loss: 0.0088\n",
      "Epoch 2/50\n",
      "605/605 [==============================] - 0s 86us/sample - loss: 0.0217 - val_loss: 0.0021\n",
      "Epoch 3/50\n",
      "605/605 [==============================] - 0s 85us/sample - loss: 0.0267 - val_loss: 0.0122\n",
      "Epoch 4/50\n",
      "605/605 [==============================] - 0s 83us/sample - loss: 0.0183 - val_loss: 0.0064\n",
      "Epoch 5/50\n",
      "605/605 [==============================] - 0s 83us/sample - loss: 0.0150 - val_loss: 0.0077\n",
      "Epoch 6/50\n",
      "605/605 [==============================] - 0s 83us/sample - loss: 0.0163 - val_loss: 0.0097\n",
      "Epoch 7/50\n",
      "605/605 [==============================] - 0s 85us/sample - loss: 0.0197 - val_loss: 0.0087\n",
      "Epoch 8/50\n",
      "605/605 [==============================] - 0s 89us/sample - loss: 0.0174 - val_loss: 0.0025\n",
      "Epoch 9/50\n",
      "605/605 [==============================] - 0s 92us/sample - loss: 0.0150 - val_loss: 0.0043\n",
      "Epoch 10/50\n",
      "605/605 [==============================] - 0s 84us/sample - loss: 0.0169 - val_loss: 0.0022\n",
      "Epoch 11/50\n",
      "605/605 [==============================] - 0s 84us/sample - loss: 0.0145 - val_loss: 0.0023\n",
      "Epoch 12/50\n",
      "605/605 [==============================] - 0s 89us/sample - loss: 0.0170 - val_loss: 0.0029\n",
      "Epoch 13/50\n",
      "605/605 [==============================] - 0s 87us/sample - loss: 0.0149 - val_loss: 0.0038\n",
      "Epoch 14/50\n",
      "605/605 [==============================] - 0s 88us/sample - loss: 0.0160 - val_loss: 0.0020\n",
      "Epoch 15/50\n",
      "605/605 [==============================] - 0s 84us/sample - loss: 0.0138 - val_loss: 0.0039\n",
      "Epoch 16/50\n",
      "605/605 [==============================] - 0s 84us/sample - loss: 0.0148 - val_loss: 0.0027\n",
      "Epoch 17/50\n",
      "605/605 [==============================] - 0s 84us/sample - loss: 0.0139 - val_loss: 0.0038\n",
      "Epoch 18/50\n",
      "605/605 [==============================] - 0s 89us/sample - loss: 0.0147 - val_loss: 0.0026\n",
      "Epoch 19/50\n",
      "605/605 [==============================] - 0s 90us/sample - loss: 0.0138 - val_loss: 0.0042\n",
      "Epoch 20/50\n",
      "605/605 [==============================] - 0s 89us/sample - loss: 0.0143 - val_loss: 0.0021\n",
      "Epoch 21/50\n",
      "605/605 [==============================] - 0s 88us/sample - loss: 0.0121 - val_loss: 0.0031\n",
      "Epoch 22/50\n",
      "605/605 [==============================] - 0s 84us/sample - loss: 0.0140 - val_loss: 0.0064\n",
      "Epoch 23/50\n",
      "605/605 [==============================] - 0s 82us/sample - loss: 0.0150 - val_loss: 0.0082\n",
      "Epoch 24/50\n",
      "605/605 [==============================] - 0s 82us/sample - loss: 0.0139 - val_loss: 0.0021\n",
      "Epoch 25/50\n",
      "605/605 [==============================] - 0s 82us/sample - loss: 0.0107 - val_loss: 0.0021\n",
      "Epoch 26/50\n",
      "605/605 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0062\n",
      "Epoch 27/50\n",
      "605/605 [==============================] - 0s 86us/sample - loss: 0.0143 - val_loss: 0.0073\n",
      "Epoch 28/50\n",
      "605/605 [==============================] - 0s 82us/sample - loss: 0.0139 - val_loss: 0.0026\n",
      "Epoch 29/50\n",
      "605/605 [==============================] - 0s 84us/sample - loss: 0.0098 - val_loss: 0.0029\n",
      "Epoch 30/50\n",
      "605/605 [==============================] - 0s 83us/sample - loss: 0.0151 - val_loss: 0.0045\n",
      "Epoch 31/50\n",
      "605/605 [==============================] - 0s 80us/sample - loss: 0.0132 - val_loss: 0.0075\n",
      "Epoch 32/50\n",
      "605/605 [==============================] - 0s 84us/sample - loss: 0.0128 - val_loss: 0.0034\n",
      "Epoch 33/50\n",
      "605/605 [==============================] - 0s 83us/sample - loss: 0.0104 - val_loss: 0.0032\n",
      "Epoch 34/50\n",
      "605/605 [==============================] - 0s 80us/sample - loss: 0.0141 - val_loss: 0.0030\n",
      "Epoch 35/50\n",
      "605/605 [==============================] - 0s 81us/sample - loss: 0.0086 - val_loss: 0.0064\n",
      "Epoch 36/50\n",
      "605/605 [==============================] - 0s 86us/sample - loss: 0.0160 - val_loss: 0.0031\n",
      "Epoch 37/50\n",
      "605/605 [==============================] - 0s 86us/sample - loss: 0.0124 - val_loss: 0.0048\n",
      "Epoch 38/50\n",
      "605/605 [==============================] - 0s 86us/sample - loss: 0.0112 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "605/605 [==============================] - 0s 85us/sample - loss: 0.0091 - val_loss: 0.0051\n",
      "Epoch 40/50\n",
      "605/605 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0037\n",
      "Epoch 41/50\n",
      "605/605 [==============================] - 0s 84us/sample - loss: 0.0132 - val_loss: 0.0077\n",
      "Epoch 42/50\n",
      "605/605 [==============================] - 0s 85us/sample - loss: 0.0113 - val_loss: 0.0026\n",
      "Epoch 43/50\n",
      "605/605 [==============================] - 0s 82us/sample - loss: 0.0076 - val_loss: 0.0035\n",
      "Epoch 44/50\n",
      "605/605 [==============================] - 0s 84us/sample - loss: 0.0115 - val_loss: 0.0079\n",
      "Epoch 45/50\n",
      "605/605 [==============================] - 0s 85us/sample - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 46/50\n",
      "605/605 [==============================] - 0s 84us/sample - loss: 0.0091 - val_loss: 0.0043\n",
      "Epoch 47/50\n",
      "605/605 [==============================] - 0s 83us/sample - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 48/50\n",
      "605/605 [==============================] - 0s 92us/sample - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 49/50\n",
      "605/605 [==============================] - 0s 88us/sample - loss: 0.0085 - val_loss: 0.0043\n",
      "Epoch 50/50\n",
      "605/605 [==============================] - 0s 91us/sample - loss: 0.0091 - val_loss: 0.0080\n",
      "第114个数，还剩4009个没有训练\n",
      "inv_hat [1.06857269 1.06857269 1.06857269 1.06954426 1.06954426 1.06954426\n",
      " 1.06954426 1.06954426 1.06954426 1.06954426 1.06954426 1.06954426\n",
      " 1.06954426 1.06954426 1.06954426 1.07051287 1.07051287 1.07051287\n",
      " 1.06954426 1.06954426 1.06954426 1.06954426 1.06954426 1.06954426\n",
      " 1.06954426 1.06954426 1.06954426 1.06954426 1.06954426 1.07051287]\n",
      "Test RMSE: 0.001\n",
      "Train on 1099 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1099/1099 [==============================] - 0s 88us/sample - loss: 0.0125 - val_loss: 0.0074\n",
      "Epoch 2/50\n",
      "1099/1099 [==============================] - 0s 84us/sample - loss: 0.0126 - val_loss: 0.0070\n",
      "Epoch 3/50\n",
      "1099/1099 [==============================] - 0s 79us/sample - loss: 0.0126 - val_loss: 0.0070\n",
      "Epoch 4/50\n",
      "1099/1099 [==============================] - 0s 81us/sample - loss: 0.0126 - val_loss: 0.0070\n",
      "Epoch 5/50\n",
      "1099/1099 [==============================] - 0s 83us/sample - loss: 0.0126 - val_loss: 0.0070\n",
      "Epoch 6/50\n",
      "1099/1099 [==============================] - 0s 84us/sample - loss: 0.0126 - val_loss: 0.0070\n",
      "Epoch 7/50\n",
      "1099/1099 [==============================] - 0s 85us/sample - loss: 0.0127 - val_loss: 0.0072\n",
      "Epoch 8/50\n",
      "1099/1099 [==============================] - 0s 85us/sample - loss: 0.0127 - val_loss: 0.0074\n",
      "Epoch 9/50\n",
      "1099/1099 [==============================] - 0s 82us/sample - loss: 0.0126 - val_loss: 0.0073\n",
      "Epoch 10/50\n",
      "1099/1099 [==============================] - 0s 82us/sample - loss: 0.0126 - val_loss: 0.0071\n",
      "Epoch 11/50\n",
      "1099/1099 [==============================] - 0s 81us/sample - loss: 0.0126 - val_loss: 0.0071\n",
      "Epoch 12/50\n",
      "1099/1099 [==============================] - 0s 84us/sample - loss: 0.0126 - val_loss: 0.0072\n",
      "Epoch 13/50\n",
      "1099/1099 [==============================] - 0s 81us/sample - loss: 0.0126 - val_loss: 0.0073\n",
      "Epoch 14/50\n",
      "1099/1099 [==============================] - 0s 84us/sample - loss: 0.0126 - val_loss: 0.0071\n",
      "Epoch 15/50\n",
      "1099/1099 [==============================] - 0s 85us/sample - loss: 0.0126 - val_loss: 0.0072\n",
      "Epoch 16/50\n",
      "1099/1099 [==============================] - 0s 81us/sample - loss: 0.0126 - val_loss: 0.0072\n",
      "Epoch 17/50\n",
      "1099/1099 [==============================] - 0s 84us/sample - loss: 0.0126 - val_loss: 0.0072\n",
      "Epoch 18/50\n",
      "1099/1099 [==============================] - 0s 80us/sample - loss: 0.0126 - val_loss: 0.0072\n",
      "Epoch 19/50\n",
      "1099/1099 [==============================] - 0s 80us/sample - loss: 0.0126 - val_loss: 0.0071\n",
      "Epoch 20/50\n",
      "1099/1099 [==============================] - 0s 80us/sample - loss: 0.0126 - val_loss: 0.0073\n",
      "Epoch 21/50\n",
      "1099/1099 [==============================] - 0s 78us/sample - loss: 0.0126 - val_loss: 0.0070\n",
      "Epoch 22/50\n",
      "1099/1099 [==============================] - 0s 79us/sample - loss: 0.0126 - val_loss: 0.0073\n",
      "Epoch 23/50\n",
      "1099/1099 [==============================] - 0s 82us/sample - loss: 0.0126 - val_loss: 0.0070\n",
      "Epoch 24/50\n",
      "1099/1099 [==============================] - 0s 84us/sample - loss: 0.0127 - val_loss: 0.0073\n",
      "Epoch 25/50\n",
      "1099/1099 [==============================] - 0s 84us/sample - loss: 0.0126 - val_loss: 0.0070\n",
      "Epoch 26/50\n",
      "1099/1099 [==============================] - 0s 84us/sample - loss: 0.0127 - val_loss: 0.0072\n",
      "Epoch 27/50\n",
      "1099/1099 [==============================] - 0s 84us/sample - loss: 0.0126 - val_loss: 0.0070\n",
      "Epoch 28/50\n",
      "1099/1099 [==============================] - 0s 83us/sample - loss: 0.0129 - val_loss: 0.0070\n",
      "Epoch 29/50\n",
      "1099/1099 [==============================] - 0s 84us/sample - loss: 0.0126 - val_loss: 0.0070\n",
      "Epoch 30/50\n",
      "1099/1099 [==============================] - 0s 81us/sample - loss: 0.0128 - val_loss: 0.0071\n",
      "Epoch 31/50\n",
      "1099/1099 [==============================] - 0s 81us/sample - loss: 0.0126 - val_loss: 0.0071\n",
      "Epoch 32/50\n",
      "1099/1099 [==============================] - 0s 81us/sample - loss: 0.0127 - val_loss: 0.0071\n",
      "Epoch 33/50\n",
      "1099/1099 [==============================] - 0s 83us/sample - loss: 0.0126 - val_loss: 0.0071\n",
      "Epoch 34/50\n",
      "1099/1099 [==============================] - 0s 81us/sample - loss: 0.0127 - val_loss: 0.0070\n",
      "Epoch 35/50\n",
      "1099/1099 [==============================] - 0s 84us/sample - loss: 0.0126 - val_loss: 0.0071\n",
      "Epoch 36/50\n",
      "1099/1099 [==============================] - 0s 84us/sample - loss: 0.0127 - val_loss: 0.0071\n",
      "Epoch 37/50\n",
      "1099/1099 [==============================] - 0s 78us/sample - loss: 0.0127 - val_loss: 0.0071\n",
      "Epoch 38/50\n",
      "1099/1099 [==============================] - 0s 79us/sample - loss: 0.0127 - val_loss: 0.0072\n",
      "Epoch 39/50\n",
      "1099/1099 [==============================] - 0s 79us/sample - loss: 0.0127 - val_loss: 0.0070\n",
      "Epoch 40/50\n",
      "1099/1099 [==============================] - 0s 85us/sample - loss: 0.0127 - val_loss: 0.0070\n",
      "Epoch 41/50\n",
      "1099/1099 [==============================] - 0s 81us/sample - loss: 0.0127 - val_loss: 0.0070\n",
      "Epoch 42/50\n",
      "1099/1099 [==============================] - 0s 81us/sample - loss: 0.0126 - val_loss: 0.0070\n",
      "Epoch 43/50\n",
      "1099/1099 [==============================] - 0s 81us/sample - loss: 0.0127 - val_loss: 0.0070\n",
      "Epoch 44/50\n",
      "1099/1099 [==============================] - 0s 82us/sample - loss: 0.0127 - val_loss: 0.0070\n",
      "Epoch 45/50\n",
      "1099/1099 [==============================] - 0s 84us/sample - loss: 0.0127 - val_loss: 0.0070\n",
      "Epoch 46/50\n",
      "1099/1099 [==============================] - 0s 84us/sample - loss: 0.0127 - val_loss: 0.0072\n",
      "Epoch 47/50\n",
      "1099/1099 [==============================] - 0s 85us/sample - loss: 0.0127 - val_loss: 0.0072\n",
      "Epoch 48/50\n",
      "1099/1099 [==============================] - 0s 80us/sample - loss: 0.0126 - val_loss: 0.0073\n",
      "Epoch 49/50\n",
      "1099/1099 [==============================] - 0s 80us/sample - loss: 0.0126 - val_loss: 0.0072\n",
      "Epoch 50/50\n",
      "1099/1099 [==============================] - 0s 80us/sample - loss: 0.0126 - val_loss: 0.0072\n",
      "第115个数，还剩4008个没有训练\n",
      "inv_hat [1.95602497 1.92903271 1.93902794 1.93403006 1.90705266 1.90605377\n",
      " 1.9100491  1.92203759 1.91204697 1.9250354  1.9650256  1.97302745\n",
      " 1.97602839 1.94102727 1.93502957 1.92903271 1.93802842 1.93303076\n",
      " 1.95202504 1.9210384  1.90305775 1.89606786 1.87111798 1.86812572\n",
      " 1.85915067 1.8840893  1.88708345 1.88508725 1.88309115 1.89107616]\n",
      "Test RMSE: 0.017\n",
      "Train on 996 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "996/996 [==============================] - 0s 77us/sample - loss: 0.0079 - val_loss: 0.0070\n",
      "Epoch 2/50\n",
      "996/996 [==============================] - 0s 79us/sample - loss: 0.0080 - val_loss: 0.0118\n",
      "Epoch 3/50\n",
      "996/996 [==============================] - 0s 75us/sample - loss: 0.0120 - val_loss: 0.0185\n",
      "Epoch 4/50\n",
      "996/996 [==============================] - 0s 76us/sample - loss: 0.0122 - val_loss: 0.0078\n",
      "Epoch 5/50\n",
      "996/996 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0183\n",
      "Epoch 6/50\n",
      "996/996 [==============================] - 0s 75us/sample - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 7/50\n",
      "996/996 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0149\n",
      "Epoch 8/50\n",
      "996/996 [==============================] - 0s 74us/sample - loss: 0.0128 - val_loss: 0.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "996/996 [==============================] - 0s 80us/sample - loss: 0.0101 - val_loss: 0.0165\n",
      "Epoch 10/50\n",
      "996/996 [==============================] - 0s 83us/sample - loss: 0.0120 - val_loss: 0.0076\n",
      "Epoch 11/50\n",
      "996/996 [==============================] - 0s 85us/sample - loss: 0.0096 - val_loss: 0.0146\n",
      "Epoch 12/50\n",
      "996/996 [==============================] - 0s 81us/sample - loss: 0.0117 - val_loss: 0.0066\n",
      "Epoch 13/50\n",
      "996/996 [==============================] - 0s 79us/sample - loss: 0.0076 - val_loss: 0.0120\n",
      "Epoch 14/50\n",
      "996/996 [==============================] - 0s 79us/sample - loss: 0.0100 - val_loss: 0.0071\n",
      "Epoch 15/50\n",
      "996/996 [==============================] - 0s 80us/sample - loss: 0.0089 - val_loss: 0.0172\n",
      "Epoch 16/50\n",
      "996/996 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0119\n",
      "Epoch 17/50\n",
      "996/996 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0076\n",
      "Epoch 18/50\n",
      "996/996 [==============================] - 0s 85us/sample - loss: 0.0073 - val_loss: 0.0064\n",
      "Epoch 19/50\n",
      "996/996 [==============================] - 0s 82us/sample - loss: 0.0094 - val_loss: 0.0146\n",
      "Epoch 20/50\n",
      "996/996 [==============================] - 0s 82us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 21/50\n",
      "996/996 [==============================] - 0s 84us/sample - loss: 0.0082 - val_loss: 0.0115\n",
      "Epoch 22/50\n",
      "996/996 [==============================] - 0s 80us/sample - loss: 0.0086 - val_loss: 0.0072\n",
      "Epoch 23/50\n",
      "996/996 [==============================] - 0s 79us/sample - loss: 0.0071 - val_loss: 0.0090\n",
      "Epoch 24/50\n",
      "996/996 [==============================] - 0s 80us/sample - loss: 0.0076 - val_loss: 0.0065\n",
      "Epoch 25/50\n",
      "996/996 [==============================] - 0s 76us/sample - loss: 0.0070 - val_loss: 0.0085\n",
      "Epoch 26/50\n",
      "996/996 [==============================] - 0s 76us/sample - loss: 0.0070 - val_loss: 0.0069\n",
      "Epoch 27/50\n",
      "996/996 [==============================] - 0s 77us/sample - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 28/50\n",
      "996/996 [==============================] - 0s 78us/sample - loss: 0.0069 - val_loss: 0.0099\n",
      "Epoch 29/50\n",
      "996/996 [==============================] - 0s 79us/sample - loss: 0.0072 - val_loss: 0.0060\n",
      "Epoch 30/50\n",
      "996/996 [==============================] - 0s 80us/sample - loss: 0.0067 - val_loss: 0.0074\n",
      "Epoch 31/50\n",
      "996/996 [==============================] - 0s 80us/sample - loss: 0.0074 - val_loss: 0.0067\n",
      "Epoch 32/50\n",
      "996/996 [==============================] - 0s 77us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 33/50\n",
      "996/996 [==============================] - 0s 81us/sample - loss: 0.0082 - val_loss: 0.0108\n",
      "Epoch 34/50\n",
      "996/996 [==============================] - 0s 84us/sample - loss: 0.0077 - val_loss: 0.0070\n",
      "Epoch 35/50\n",
      "996/996 [==============================] - 0s 79us/sample - loss: 0.0077 - val_loss: 0.0107\n",
      "Epoch 36/50\n",
      "996/996 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0069\n",
      "Epoch 37/50\n",
      "996/996 [==============================] - 0s 77us/sample - loss: 0.0072 - val_loss: 0.0101\n",
      "Epoch 38/50\n",
      "996/996 [==============================] - 0s 75us/sample - loss: 0.0077 - val_loss: 0.0067\n",
      "Epoch 39/50\n",
      "996/996 [==============================] - 0s 81us/sample - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 40/50\n",
      "996/996 [==============================] - 0s 80us/sample - loss: 0.0071 - val_loss: 0.0064\n",
      "Epoch 41/50\n",
      "996/996 [==============================] - 0s 80us/sample - loss: 0.0084 - val_loss: 0.0141\n",
      "Epoch 42/50\n",
      "996/996 [==============================] - 0s 77us/sample - loss: 0.0114 - val_loss: 0.0074\n",
      "Epoch 43/50\n",
      "996/996 [==============================] - 0s 78us/sample - loss: 0.0075 - val_loss: 0.0106\n",
      "Epoch 44/50\n",
      "996/996 [==============================] - 0s 79us/sample - loss: 0.0084 - val_loss: 0.0073\n",
      "Epoch 45/50\n",
      "996/996 [==============================] - 0s 85us/sample - loss: 0.0079 - val_loss: 0.0135\n",
      "Epoch 46/50\n",
      "996/996 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 47/50\n",
      "996/996 [==============================] - 0s 85us/sample - loss: 0.0068 - val_loss: 0.0084\n",
      "Epoch 48/50\n",
      "996/996 [==============================] - 0s 85us/sample - loss: 0.0072 - val_loss: 0.0065\n",
      "Epoch 49/50\n",
      "996/996 [==============================] - 0s 81us/sample - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 50/50\n",
      "996/996 [==============================] - 0s 78us/sample - loss: 0.0068 - val_loss: 0.0080\n",
      "第116个数，还剩4007个没有训练\n",
      "inv_hat [1.02879526 1.02879526 1.02980252 1.03080922 1.03080922 1.03181559\n",
      " 1.03282141 1.03282141 1.03382683 1.03483174 1.03483174 1.03583608\n",
      " 1.03583608 1.02879526 1.02778755 1.02778755 1.02879526 1.02778755\n",
      " 1.02664844 1.02765279 1.02765279 1.02765279 1.02765279 1.02765279\n",
      " 1.02765279 1.02865779 1.02865779 1.02865779 1.02865779 1.02865779]\n",
      "Test RMSE: 0.002\n",
      "Train on 668 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "668/668 [==============================] - 0s 83us/sample - loss: 0.0183 - val_loss: 0.0144\n",
      "Epoch 2/50\n",
      "668/668 [==============================] - 0s 83us/sample - loss: 0.0158 - val_loss: 0.0145\n",
      "Epoch 3/50\n",
      "668/668 [==============================] - 0s 83us/sample - loss: 0.0146 - val_loss: 0.0123\n",
      "Epoch 4/50\n",
      "668/668 [==============================] - 0s 86us/sample - loss: 0.0113 - val_loss: 0.0149\n",
      "Epoch 5/50\n",
      "668/668 [==============================] - 0s 85us/sample - loss: 0.0130 - val_loss: 0.0121\n",
      "Epoch 6/50\n",
      "668/668 [==============================] - 0s 84us/sample - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 7/50\n",
      "668/668 [==============================] - 0s 86us/sample - loss: 0.0102 - val_loss: 0.0094\n",
      "Epoch 8/50\n",
      "668/668 [==============================] - 0s 87us/sample - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 9/50\n",
      "668/668 [==============================] - 0s 88us/sample - loss: 0.0097 - val_loss: 0.0092\n",
      "Epoch 10/50\n",
      "668/668 [==============================] - 0s 86us/sample - loss: 0.0095 - val_loss: 0.0092\n",
      "Epoch 11/50\n",
      "668/668 [==============================] - 0s 84us/sample - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 12/50\n",
      "668/668 [==============================] - 0s 83us/sample - loss: 0.0095 - val_loss: 0.0094\n",
      "Epoch 13/50\n",
      "668/668 [==============================] - 0s 85us/sample - loss: 0.0096 - val_loss: 0.0091\n",
      "Epoch 14/50\n",
      "668/668 [==============================] - 0s 90us/sample - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 15/50\n",
      "668/668 [==============================] - 0s 81us/sample - loss: 0.0098 - val_loss: 0.0107\n",
      "Epoch 16/50\n",
      "668/668 [==============================] - 0s 81us/sample - loss: 0.0096 - val_loss: 0.0093\n",
      "Epoch 17/50\n",
      "668/668 [==============================] - 0s 86us/sample - loss: 0.0100 - val_loss: 0.0094\n",
      "Epoch 18/50\n",
      "668/668 [==============================] - 0s 89us/sample - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 19/50\n",
      "668/668 [==============================] - 0s 83us/sample - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 20/50\n",
      "668/668 [==============================] - 0s 84us/sample - loss: 0.0095 - val_loss: 0.0094\n",
      "Epoch 21/50\n",
      "668/668 [==============================] - 0s 82us/sample - loss: 0.0093 - val_loss: 0.0091\n",
      "Epoch 22/50\n",
      "668/668 [==============================] - 0s 91us/sample - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 23/50\n",
      "668/668 [==============================] - 0s 85us/sample - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 24/50\n",
      "668/668 [==============================] - 0s 85us/sample - loss: 0.0094 - val_loss: 0.0096\n",
      "Epoch 25/50\n",
      "668/668 [==============================] - 0s 89us/sample - loss: 0.0092 - val_loss: 0.0092\n",
      "Epoch 26/50\n",
      "668/668 [==============================] - 0s 84us/sample - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 27/50\n",
      "668/668 [==============================] - 0s 83us/sample - loss: 0.0097 - val_loss: 0.0114\n",
      "Epoch 28/50\n",
      "668/668 [==============================] - 0s 84us/sample - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 29/50\n",
      "668/668 [==============================] - 0s 82us/sample - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 30/50\n",
      "668/668 [==============================] - 0s 81us/sample - loss: 0.0095 - val_loss: 0.0106\n",
      "Epoch 31/50\n",
      "668/668 [==============================] - 0s 86us/sample - loss: 0.0098 - val_loss: 0.0113\n",
      "Epoch 32/50\n",
      "668/668 [==============================] - 0s 91us/sample - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 33/50\n",
      "668/668 [==============================] - 0s 89us/sample - loss: 0.0102 - val_loss: 0.0093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "668/668 [==============================] - 0s 82us/sample - loss: 0.0096 - val_loss: 0.0106\n",
      "Epoch 35/50\n",
      "668/668 [==============================] - 0s 87us/sample - loss: 0.0095 - val_loss: 0.0109\n",
      "Epoch 36/50\n",
      "668/668 [==============================] - 0s 86us/sample - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 37/50\n",
      "668/668 [==============================] - 0s 84us/sample - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 38/50\n",
      "668/668 [==============================] - 0s 82us/sample - loss: 0.0097 - val_loss: 0.0111\n",
      "Epoch 39/50\n",
      "668/668 [==============================] - 0s 79us/sample - loss: 0.0098 - val_loss: 0.0112\n",
      "Epoch 40/50\n",
      "668/668 [==============================] - 0s 84us/sample - loss: 0.0093 - val_loss: 0.0099\n",
      "Epoch 41/50\n",
      "668/668 [==============================] - 0s 81us/sample - loss: 0.0091 - val_loss: 0.0093\n",
      "Epoch 42/50\n",
      "668/668 [==============================] - 0s 83us/sample - loss: 0.0096 - val_loss: 0.0105\n",
      "Epoch 43/50\n",
      "668/668 [==============================] - 0s 81us/sample - loss: 0.0097 - val_loss: 0.0119\n",
      "Epoch 44/50\n",
      "668/668 [==============================] - 0s 81us/sample - loss: 0.0096 - val_loss: 0.0096\n",
      "Epoch 45/50\n",
      "668/668 [==============================] - 0s 82us/sample - loss: 0.0098 - val_loss: 0.0095\n",
      "Epoch 46/50\n",
      "668/668 [==============================] - 0s 81us/sample - loss: 0.0095 - val_loss: 0.0110\n",
      "Epoch 47/50\n",
      "668/668 [==============================] - 0s 84us/sample - loss: 0.0096 - val_loss: 0.0112\n",
      "Epoch 48/50\n",
      "668/668 [==============================] - 0s 82us/sample - loss: 0.0092 - val_loss: 0.0100\n",
      "Epoch 49/50\n",
      "668/668 [==============================] - 0s 84us/sample - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 50/50\n",
      "668/668 [==============================] - 0s 81us/sample - loss: 0.0095 - val_loss: 0.0108\n",
      "第117个数，还剩4006个没有训练\n",
      "inv_hat [1.01298488 1.01368915 1.0141922  1.01539974 1.01912317 1.01892186\n",
      " 1.01741228 1.01731163 1.01670788 1.01550026 1.01670788 1.01771411\n",
      " 1.01962689 1.02224825 1.02376232 1.02446927 1.01992908 1.02063456\n",
      " 1.02033224 1.018318   1.01932464 1.02023145 1.02134035 1.01962689\n",
      " 1.02002985 1.02426723 1.02220627 1.02180531 1.02100359 1.02221324]\n",
      "Test RMSE: 0.002\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0073 - val_loss: 0.0090\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0090 - val_loss: 0.0054\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0137\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0065\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0099 - val_loss: 0.0053\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0079 - val_loss: 0.0054\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0092 - val_loss: 0.0090\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0075 - val_loss: 0.0055\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0081 - val_loss: 0.0059\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0088 - val_loss: 0.0064\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0074 - val_loss: 0.0061\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0068 - val_loss: 0.0058\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0097 - val_loss: 0.0053\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0100 - val_loss: 0.0058\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0072 - val_loss: 0.0054\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0083 - val_loss: 0.0119\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0084 - val_loss: 0.0058\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0090 - val_loss: 0.0081\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0089 - val_loss: 0.0056\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0096 - val_loss: 0.0058\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0054\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0117 - val_loss: 0.0068\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0148 - val_loss: 0.0256\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0091 - val_loss: 0.0072\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0091 - val_loss: 0.0059\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0097 - val_loss: 0.0093\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0133 - val_loss: 0.0170\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0078 - val_loss: 0.0110\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0103 - val_loss: 0.0149\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0081 - val_loss: 0.0083\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0071 - val_loss: 0.0058\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0082 - val_loss: 0.0053\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0099 - val_loss: 0.0088\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0088 - val_loss: 0.0056\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0114 - val_loss: 0.0149\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0094 - val_loss: 0.0136\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0059\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0127 - val_loss: 0.0192\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0095 - val_loss: 0.0127\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0081 - val_loss: 0.0102\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0079 - val_loss: 0.0063\n",
      "第118个数，还剩4005个没有训练\n",
      "inv_hat [1.08407772 1.08407772 1.08502721 1.08407772 1.08407772 1.08407772\n",
      " 1.08407772 1.08502721 1.08502721 1.08597467 1.08597467 1.08880537\n",
      " 1.08974494 1.09068236 1.09161781 1.09161781 1.0925512  1.0925512\n",
      " 1.09161781 1.09068236 1.08974494 1.09068236 1.09068236 1.09161781\n",
      " 1.09161781 1.0925512  1.0925512  1.0925512  1.09348236 1.09348236]\n",
      "Test RMSE: 0.001\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0096 - val_loss: 0.0037\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0065 - val_loss: 0.0021\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0076 - val_loss: 0.0055\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0078 - val_loss: 0.0060\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0075 - val_loss: 0.0052\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0067 - val_loss: 0.0029\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0068 - val_loss: 0.0055\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0094 - val_loss: 0.0026\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0067 - val_loss: 5.4133e-04\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0065 - val_loss: 0.0022\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0052 - val_loss: 5.8830e-04\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0052 - val_loss: 8.5058e-04\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0055 - val_loss: 8.4637e-04\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0058 - val_loss: 6.6925e-04\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0076 - val_loss: 0.0060\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0085 - val_loss: 0.0043\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0067 - val_loss: 0.0019\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0061 - val_loss: 8.0318e-04\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0061 - val_loss: 0.0024\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0064 - val_loss: 0.0037\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0087 - val_loss: 0.0037\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0073 - val_loss: 0.0018\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0067 - val_loss: 0.0018\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0054 - val_loss: 0.0011\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0054 - val_loss: 0.0010\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0055 - val_loss: 8.3358e-04\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0054 - val_loss: 0.0011\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0060 - val_loss: 0.0027\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0065 - val_loss: 0.0037\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0076 - val_loss: 0.0062\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0089 - val_loss: 0.0022\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0068 - val_loss: 0.0018\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0066 - val_loss: 0.0038\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0053 - val_loss: 5.1999e-04\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0053 - val_loss: 6.6085e-04\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0051 - val_loss: 9.5582e-04\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0052 - val_loss: 9.9476e-04\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0054 - val_loss: 0.0012\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0061 - val_loss: 0.0035\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0072 - val_loss: 0.0054\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0084 - val_loss: 0.0035\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0062 - val_loss: 0.0012\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0014\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0067 - val_loss: 0.0027\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0058 - val_loss: 7.3132e-04\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0061 - val_loss: 0.0029\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0057 - val_loss: 7.4424e-04\n",
      "第119个数，还剩4004个没有训练\n",
      "inv_hat [1.07835529 1.07835529 1.07835529 1.07835529 1.07835529 1.07835529\n",
      " 1.07835529 1.07835529 1.07935045 1.07935045 1.08034553 1.08134037\n",
      " 1.08134037 1.08134037 1.08134037 1.08233525 1.08233525 1.08233525\n",
      " 1.08134037 1.08134037 1.08034553 1.08034553 1.08134037 1.08134037\n",
      " 1.08034553 1.08134037 1.08134037 1.08134037 1.08134037 1.08332992]\n",
      "Test RMSE: 0.001\n",
      "Train on 630 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "630/630 [==============================] - 0s 80us/sample - loss: 0.0183 - val_loss: 0.0241\n",
      "Epoch 2/50\n",
      "630/630 [==============================] - 0s 81us/sample - loss: 0.0152 - val_loss: 0.0034\n",
      "Epoch 3/50\n",
      "630/630 [==============================] - 0s 81us/sample - loss: 0.0123 - val_loss: 0.0072\n",
      "Epoch 4/50\n",
      "630/630 [==============================] - 0s 83us/sample - loss: 0.0080 - val_loss: 0.0036\n",
      "Epoch 5/50\n",
      "630/630 [==============================] - 0s 85us/sample - loss: 0.0058 - val_loss: 0.0161\n",
      "Epoch 6/50\n",
      "630/630 [==============================] - 0s 81us/sample - loss: 0.0085 - val_loss: 0.0038\n",
      "Epoch 7/50\n",
      "630/630 [==============================] - 0s 78us/sample - loss: 0.0058 - val_loss: 0.0101\n",
      "Epoch 8/50\n",
      "630/630 [==============================] - 0s 81us/sample - loss: 0.0071 - val_loss: 0.0065\n",
      "Epoch 9/50\n",
      "630/630 [==============================] - 0s 80us/sample - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 10/50\n",
      "630/630 [==============================] - 0s 79us/sample - loss: 0.0049 - val_loss: 0.0059\n",
      "Epoch 11/50\n",
      "630/630 [==============================] - 0s 80us/sample - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 12/50\n",
      "630/630 [==============================] - 0s 79us/sample - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 13/50\n",
      "630/630 [==============================] - 0s 84us/sample - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 14/50\n",
      "630/630 [==============================] - 0s 83us/sample - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 15/50\n",
      "630/630 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0079\n",
      "Epoch 16/50\n",
      "630/630 [==============================] - 0s 81us/sample - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 17/50\n",
      "630/630 [==============================] - 0s 84us/sample - loss: 0.0071 - val_loss: 0.0067\n",
      "Epoch 18/50\n",
      "630/630 [==============================] - 0s 86us/sample - loss: 0.0068 - val_loss: 0.0091\n",
      "Epoch 19/50\n",
      "630/630 [==============================] - 0s 86us/sample - loss: 0.0042 - val_loss: 0.0059\n",
      "Epoch 20/50\n",
      "630/630 [==============================] - 0s 86us/sample - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 21/50\n",
      "630/630 [==============================] - 0s 84us/sample - loss: 0.0074 - val_loss: 0.0151\n",
      "Epoch 22/50\n",
      "630/630 [==============================] - 0s 86us/sample - loss: 0.0040 - val_loss: 0.0060\n",
      "Epoch 23/50\n",
      "630/630 [==============================] - 0s 84us/sample - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 24/50\n",
      "630/630 [==============================] - 0s 79us/sample - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 25/50\n",
      "630/630 [==============================] - 0s 78us/sample - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 84us/sample - loss: 0.0061 - val_loss: 0.0034\n",
      "Epoch 27/50\n",
      "630/630 [==============================] - 0s 83us/sample - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 28/50\n",
      "630/630 [==============================] - 0s 81us/sample - loss: 0.0071 - val_loss: 0.0143\n",
      "Epoch 29/50\n",
      "630/630 [==============================] - 0s 78us/sample - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 30/50\n",
      "630/630 [==============================] - 0s 85us/sample - loss: 0.0039 - val_loss: 0.0057\n",
      "Epoch 31/50\n",
      "630/630 [==============================] - 0s 81us/sample - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 32/50\n",
      "630/630 [==============================] - 0s 83us/sample - loss: 0.0068 - val_loss: 0.0114\n",
      "Epoch 33/50\n",
      "630/630 [==============================] - 0s 83us/sample - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 34/50\n",
      "630/630 [==============================] - 0s 80us/sample - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 35/50\n",
      "630/630 [==============================] - 0s 79us/sample - loss: 0.0050 - val_loss: 0.0076\n",
      "Epoch 36/50\n",
      "630/630 [==============================] - 0s 78us/sample - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 37/50\n",
      "630/630 [==============================] - 0s 79us/sample - loss: 0.0060 - val_loss: 0.0036\n",
      "Epoch 38/50\n",
      "630/630 [==============================] - 0s 83us/sample - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 39/50\n",
      "630/630 [==============================] - 0s 81us/sample - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 40/50\n",
      "630/630 [==============================] - 0s 81us/sample - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 41/50\n",
      "630/630 [==============================] - 0s 84us/sample - loss: 0.0071 - val_loss: 0.0044\n",
      "Epoch 42/50\n",
      "630/630 [==============================] - 0s 84us/sample - loss: 0.0063 - val_loss: 0.0104\n",
      "Epoch 43/50\n",
      "630/630 [==============================] - 0s 83us/sample - loss: 0.0035 - val_loss: 0.0054\n",
      "Epoch 44/50\n",
      "630/630 [==============================] - 0s 83us/sample - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 45/50\n",
      "630/630 [==============================] - 0s 82us/sample - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 46/50\n",
      "630/630 [==============================] - 0s 82us/sample - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 47/50\n",
      "630/630 [==============================] - 0s 85us/sample - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 48/50\n",
      "630/630 [==============================] - 0s 86us/sample - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 49/50\n",
      "630/630 [==============================] - 0s 85us/sample - loss: 0.0076 - val_loss: 0.0136\n",
      "Epoch 50/50\n",
      "630/630 [==============================] - 0s 85us/sample - loss: 0.0031 - val_loss: 0.0045\n",
      "第120个数，还剩4003个没有训练\n",
      "inv_hat [1.09532553 1.09542073 1.09561105 1.09561105 1.09561105 1.0958013\n",
      " 1.0958013  1.0958013  1.09618144 1.09618144 1.09656126 1.09722526\n",
      " 1.09788827 1.09750959 1.09769903 1.09845588 1.09855028 1.09864479\n",
      " 1.09855028 1.09807756 1.09798292 1.09741484 1.09741484 1.09817217\n",
      " 1.09892819 1.09892819 1.09892819 1.09921128 1.0994943  1.10100029]\n",
      "Test RMSE: 0.001\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0158 - val_loss: 0.0074\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0164 - val_loss: 0.0137\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0143 - val_loss: 0.0065\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0065\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0126 - val_loss: 0.0089\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0128 - val_loss: 0.0085\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0065\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0124 - val_loss: 0.0066\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0123 - val_loss: 0.0073\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0123 - val_loss: 0.0072\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0122 - val_loss: 0.0070\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0071\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0121 - val_loss: 0.0066\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0066\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0070\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0066\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0122 - val_loss: 0.0069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0121 - val_loss: 0.0065\n",
      "第121个数，还剩4002个没有训练\n",
      "inv_hat [1.99261608 1.97254202 1.97254202 1.97053427 1.9474405  1.94141467\n",
      " 1.93538852 1.94944908 1.9373973  1.94643621 1.98157626 1.98759827\n",
      " 1.98157626 1.95145735 1.95346582 1.93639281 1.95045306 1.9544698\n",
      " 1.97856506 1.9544698  1.94041048 1.93237503 1.91328743 1.89921951\n",
      " 1.88715934 1.8911796  1.89419464 1.89017448 1.88313876 1.89218472]\n",
      "Test RMSE: 0.014\n",
      "Train on 576 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 77us/sample - loss: 0.0190 - val_loss: 0.0261\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 80us/sample - loss: 0.0201 - val_loss: 0.0272\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 76us/sample - loss: 0.0178 - val_loss: 0.0289\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 76us/sample - loss: 0.0173 - val_loss: 0.0261\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 77us/sample - loss: 0.0172 - val_loss: 0.0282\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 77us/sample - loss: 0.0170 - val_loss: 0.0264\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 77us/sample - loss: 0.0170 - val_loss: 0.0267\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 78us/sample - loss: 0.0169 - val_loss: 0.0270\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 76us/sample - loss: 0.0169 - val_loss: 0.0265\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 77us/sample - loss: 0.0169 - val_loss: 0.0272\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 80us/sample - loss: 0.0169 - val_loss: 0.0267\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 79us/sample - loss: 0.0169 - val_loss: 0.0269\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 76us/sample - loss: 0.0169 - val_loss: 0.0268\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 77us/sample - loss: 0.0169 - val_loss: 0.0268\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 82us/sample - loss: 0.0169 - val_loss: 0.0268\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 86us/sample - loss: 0.0169 - val_loss: 0.0269\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 81us/sample - loss: 0.0169 - val_loss: 0.0267\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 82us/sample - loss: 0.0169 - val_loss: 0.0269\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 85us/sample - loss: 0.0169 - val_loss: 0.0267\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 85us/sample - loss: 0.0169 - val_loss: 0.0269\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 81us/sample - loss: 0.0169 - val_loss: 0.0268\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 85us/sample - loss: 0.0169 - val_loss: 0.0270\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 81us/sample - loss: 0.0169 - val_loss: 0.0267\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 81us/sample - loss: 0.0169 - val_loss: 0.0269\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 78us/sample - loss: 0.0169 - val_loss: 0.0268\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 75us/sample - loss: 0.0169 - val_loss: 0.0269\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 79us/sample - loss: 0.0169 - val_loss: 0.0266\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 83us/sample - loss: 0.0169 - val_loss: 0.0270\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 77us/sample - loss: 0.0169 - val_loss: 0.0268\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 78us/sample - loss: 0.0169 - val_loss: 0.0269\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 74us/sample - loss: 0.0169 - val_loss: 0.0269\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 81us/sample - loss: 0.0168 - val_loss: 0.0268\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 83us/sample - loss: 0.0169 - val_loss: 0.0269\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 84us/sample - loss: 0.0169 - val_loss: 0.0268\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 82us/sample - loss: 0.0169 - val_loss: 0.0269\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 88us/sample - loss: 0.0169 - val_loss: 0.0267\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 81us/sample - loss: 0.0169 - val_loss: 0.0270\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 82us/sample - loss: 0.0169 - val_loss: 0.0268\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 84us/sample - loss: 0.0169 - val_loss: 0.0269\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 83us/sample - loss: 0.0169 - val_loss: 0.0269\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 82us/sample - loss: 0.0169 - val_loss: 0.0270\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 85us/sample - loss: 0.0169 - val_loss: 0.0268\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 79us/sample - loss: 0.0169 - val_loss: 0.0270\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 82us/sample - loss: 0.0169 - val_loss: 0.0268\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 81us/sample - loss: 0.0169 - val_loss: 0.0270\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 79us/sample - loss: 0.0169 - val_loss: 0.0268\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 82us/sample - loss: 0.0169 - val_loss: 0.0270\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 84us/sample - loss: 0.0169 - val_loss: 0.0269\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 81us/sample - loss: 0.0169 - val_loss: 0.0270\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 82us/sample - loss: 0.0169 - val_loss: 0.0268\n",
      "第122个数，还剩4001个没有训练\n",
      "inv_hat [1.2372997  1.1975674  1.20449885 1.19954671 1.16595324 1.16392575\n",
      " 1.16996305 1.19460012 1.17094523 1.1837391  1.21739833 1.23231895\n",
      " 1.21441878 1.18768499 1.1837391  1.17094523 1.16898133 1.17586022\n",
      " 1.1886722  1.16189821 1.16291206 1.14364443 1.13654472 1.13553045\n",
      " 1.11423769 1.10309309 1.09150272 1.096504   1.08749943 1.10250154]\n",
      "Test RMSE: 0.018\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0067 - val_loss: 0.0061\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0066 - val_loss: 0.0060\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0066 - val_loss: 0.0060\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0068 - val_loss: 0.0059\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0071 - val_loss: 0.0064\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0068 - val_loss: 0.0058\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0070 - val_loss: 0.0056\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0072 - val_loss: 0.0055\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0078 - val_loss: 0.0062\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0076 - val_loss: 0.0060\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0073 - val_loss: 0.0061\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0072 - val_loss: 0.0060\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0072 - val_loss: 0.0061\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0073 - val_loss: 0.0062\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0071 - val_loss: 0.0060\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0074 - val_loss: 0.0062\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0079 - val_loss: 0.0061\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0084 - val_loss: 0.0082\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0100 - val_loss: 0.0156\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0144 - val_loss: 0.0277\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0297 - val_loss: 0.0154\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0195 - val_loss: 0.0062\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0080\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0079 - val_loss: 0.0061\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0088 - val_loss: 0.0116\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0113 - val_loss: 0.0239\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0208 - val_loss: 0.0086\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0262 - val_loss: 0.0134\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0102 - val_loss: 0.0070\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0091 - val_loss: 0.0059\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0070 - val_loss: 0.0065\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0080 - val_loss: 0.0098\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0103 - val_loss: 0.0208\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0178 - val_loss: 0.0112\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0234 - val_loss: 0.0080\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0116 - val_loss: 0.0087\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0085 - val_loss: 0.0058\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0074 - val_loss: 0.0085\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0095 - val_loss: 0.0184\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0150 - val_loss: 0.0149\n",
      "第123个数，还剩4000个没有训练\n",
      "inv_hat [1.05211405 1.05211405 1.0524008  1.05115801 1.05087118 1.05039286\n",
      " 1.05106248 1.05192285 1.05364263 1.05392901 1.05459723 1.05679084\n",
      " 1.05793404 1.0587909  1.05898126 1.06078808 1.06059809 1.06116822\n",
      " 1.05774364 1.05726726 1.05526515 1.05583755 1.05726726 1.05841019\n",
      " 1.05755311 1.05736255 1.05831497 1.05869571 1.05993258 1.06154813]\n",
      "Test RMSE: 0.003\n",
      "Train on 657 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "657/657 [==============================] - 0s 88us/sample - loss: 0.0183 - val_loss: 0.0132\n",
      "Epoch 2/50\n",
      "657/657 [==============================] - 0s 85us/sample - loss: 0.0242 - val_loss: 0.0201\n",
      "Epoch 3/50\n",
      "657/657 [==============================] - 0s 84us/sample - loss: 0.0167 - val_loss: 0.0157\n",
      "Epoch 4/50\n",
      "657/657 [==============================] - 0s 88us/sample - loss: 0.0163 - val_loss: 0.0152\n",
      "Epoch 5/50\n",
      "657/657 [==============================] - 0s 89us/sample - loss: 0.0140 - val_loss: 0.0120\n",
      "Epoch 6/50\n",
      "657/657 [==============================] - 0s 91us/sample - loss: 0.0151 - val_loss: 0.0134\n",
      "Epoch 7/50\n",
      "657/657 [==============================] - 0s 88us/sample - loss: 0.0142 - val_loss: 0.0133\n",
      "Epoch 8/50\n",
      "657/657 [==============================] - 0s 85us/sample - loss: 0.0144 - val_loss: 0.0123\n",
      "Epoch 9/50\n",
      "657/657 [==============================] - 0s 91us/sample - loss: 0.0156 - val_loss: 0.0114\n",
      "Epoch 10/50\n",
      "657/657 [==============================] - 0s 87us/sample - loss: 0.0141 - val_loss: 0.0121\n",
      "Epoch 11/50\n",
      "657/657 [==============================] - 0s 89us/sample - loss: 0.0143 - val_loss: 0.0120\n",
      "Epoch 12/50\n",
      "657/657 [==============================] - 0s 90us/sample - loss: 0.0152 - val_loss: 0.0118\n",
      "Epoch 13/50\n",
      "657/657 [==============================] - 0s 89us/sample - loss: 0.0143 - val_loss: 0.0117\n",
      "Epoch 14/50\n",
      "657/657 [==============================] - 0s 89us/sample - loss: 0.0145 - val_loss: 0.0122\n",
      "Epoch 15/50\n",
      "657/657 [==============================] - 0s 89us/sample - loss: 0.0156 - val_loss: 0.0134\n",
      "Epoch 16/50\n",
      "657/657 [==============================] - 0s 87us/sample - loss: 0.0144 - val_loss: 0.0119\n",
      "Epoch 17/50\n",
      "657/657 [==============================] - 0s 92us/sample - loss: 0.0146 - val_loss: 0.0128\n",
      "Epoch 18/50\n",
      "657/657 [==============================] - 0s 89us/sample - loss: 0.0156 - val_loss: 0.0114\n",
      "Epoch 19/50\n",
      "657/657 [==============================] - 0s 87us/sample - loss: 0.0142 - val_loss: 0.0118\n",
      "Epoch 20/50\n",
      "657/657 [==============================] - 0s 83us/sample - loss: 0.0141 - val_loss: 0.0114\n",
      "Epoch 21/50\n",
      "657/657 [==============================] - 0s 84us/sample - loss: 0.0155 - val_loss: 0.0114\n",
      "Epoch 22/50\n",
      "657/657 [==============================] - 0s 93us/sample - loss: 0.0142 - val_loss: 0.0129\n",
      "Epoch 23/50\n",
      "657/657 [==============================] - 0s 90us/sample - loss: 0.0139 - val_loss: 0.0122\n",
      "Epoch 24/50\n",
      "657/657 [==============================] - 0s 92us/sample - loss: 0.0145 - val_loss: 0.0117\n",
      "Epoch 25/50\n",
      "657/657 [==============================] - 0s 92us/sample - loss: 0.0158 - val_loss: 0.0113\n",
      "Epoch 26/50\n",
      "657/657 [==============================] - 0s 92us/sample - loss: 0.0143 - val_loss: 0.0116\n",
      "Epoch 27/50\n",
      "657/657 [==============================] - 0s 95us/sample - loss: 0.0141 - val_loss: 0.0114\n",
      "Epoch 28/50\n",
      "657/657 [==============================] - 0s 91us/sample - loss: 0.0156 - val_loss: 0.0137\n",
      "Epoch 29/50\n",
      "657/657 [==============================] - 0s 88us/sample - loss: 0.0153 - val_loss: 0.0113\n",
      "Epoch 30/50\n",
      "657/657 [==============================] - 0s 91us/sample - loss: 0.0144 - val_loss: 0.0118\n",
      "Epoch 31/50\n",
      "657/657 [==============================] - 0s 88us/sample - loss: 0.0151 - val_loss: 0.0116\n",
      "Epoch 32/50\n",
      "657/657 [==============================] - 0s 90us/sample - loss: 0.0139 - val_loss: 0.0124\n",
      "Epoch 33/50\n",
      "657/657 [==============================] - 0s 89us/sample - loss: 0.0141 - val_loss: 0.0115\n",
      "Epoch 34/50\n",
      "657/657 [==============================] - 0s 84us/sample - loss: 0.0151 - val_loss: 0.0114\n",
      "Epoch 35/50\n",
      "657/657 [==============================] - 0s 92us/sample - loss: 0.0141 - val_loss: 0.0129\n",
      "Epoch 36/50\n",
      "657/657 [==============================] - 0s 86us/sample - loss: 0.0139 - val_loss: 0.0122\n",
      "Epoch 37/50\n",
      "657/657 [==============================] - 0s 92us/sample - loss: 0.0144 - val_loss: 0.0113\n",
      "Epoch 38/50\n",
      "657/657 [==============================] - 0s 86us/sample - loss: 0.0159 - val_loss: 0.0134\n",
      "Epoch 39/50\n",
      "657/657 [==============================] - 0s 84us/sample - loss: 0.0143 - val_loss: 0.0119\n",
      "Epoch 40/50\n",
      "657/657 [==============================] - 0s 86us/sample - loss: 0.0137 - val_loss: 0.0121\n",
      "Epoch 41/50\n",
      "657/657 [==============================] - 0s 84us/sample - loss: 0.0143 - val_loss: 0.0129\n",
      "Epoch 42/50\n",
      "657/657 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0133\n",
      "Epoch 43/50\n",
      "657/657 [==============================] - 0s 83us/sample - loss: 0.0145 - val_loss: 0.0120\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657 [==============================] - 0s 85us/sample - loss: 0.0142 - val_loss: 0.0128\n",
      "Epoch 45/50\n",
      "657/657 [==============================] - 0s 87us/sample - loss: 0.0139 - val_loss: 0.0119\n",
      "Epoch 46/50\n",
      "657/657 [==============================] - 0s 87us/sample - loss: 0.0147 - val_loss: 0.0119\n",
      "Epoch 47/50\n",
      "657/657 [==============================] - 0s 87us/sample - loss: 0.0158 - val_loss: 0.0115\n",
      "Epoch 48/50\n",
      "657/657 [==============================] - 0s 86us/sample - loss: 0.0145 - val_loss: 0.0114\n",
      "Epoch 49/50\n",
      "657/657 [==============================] - 0s 86us/sample - loss: 0.0141 - val_loss: 0.0113\n",
      "Epoch 50/50\n",
      "657/657 [==============================] - 0s 86us/sample - loss: 0.0148 - val_loss: 0.0125\n",
      "第124个数，还剩3999个没有训练\n",
      "inv_hat [1.06490371 1.06490371 1.06588875 1.06490371 1.06490371 1.06490371\n",
      " 1.06490371 1.06588875 1.06588875 1.06687187 1.06687187 1.06980816\n",
      " 1.06980816 1.07078233 1.07078233 1.07272366 1.07272366 1.07272366\n",
      " 1.06883157 1.06785274 1.06588875 1.06687187 1.06883157 1.07078233\n",
      " 1.06980816 1.06980816 1.07078233 1.07175426 1.07272366 1.07465519]\n",
      "Test RMSE: 0.001\n",
      "Train on 1133 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1133/1133 [==============================] - 0s 77us/sample - loss: 0.0171 - val_loss: 0.0071\n",
      "Epoch 2/50\n",
      "1133/1133 [==============================] - 0s 78us/sample - loss: 0.0172 - val_loss: 0.0108\n",
      "Epoch 3/50\n",
      "1133/1133 [==============================] - 0s 77us/sample - loss: 0.0156 - val_loss: 0.0121\n",
      "Epoch 4/50\n",
      "1133/1133 [==============================] - 0s 77us/sample - loss: 0.0169 - val_loss: 0.0072\n",
      "Epoch 5/50\n",
      "1133/1133 [==============================] - 0s 76us/sample - loss: 0.0156 - val_loss: 0.0089\n",
      "Epoch 6/50\n",
      "1133/1133 [==============================] - 0s 77us/sample - loss: 0.0161 - val_loss: 0.0070\n",
      "Epoch 7/50\n",
      "1133/1133 [==============================] - 0s 80us/sample - loss: 0.0153 - val_loss: 0.0064\n",
      "Epoch 8/50\n",
      "1133/1133 [==============================] - 0s 78us/sample - loss: 0.0147 - val_loss: 0.0077\n",
      "Epoch 9/50\n",
      "1133/1133 [==============================] - 0s 80us/sample - loss: 0.0149 - val_loss: 0.0104\n",
      "Epoch 10/50\n",
      "1133/1133 [==============================] - 0s 80us/sample - loss: 0.0152 - val_loss: 0.0078\n",
      "Epoch 11/50\n",
      "1133/1133 [==============================] - 0s 78us/sample - loss: 0.0152 - val_loss: 0.0087\n",
      "Epoch 12/50\n",
      "1133/1133 [==============================] - 0s 77us/sample - loss: 0.0154 - val_loss: 0.0076\n",
      "Epoch 13/50\n",
      "1133/1133 [==============================] - 0s 84us/sample - loss: 0.0164 - val_loss: 0.0106\n",
      "Epoch 14/50\n",
      "1133/1133 [==============================] - 0s 80us/sample - loss: 0.0156 - val_loss: 0.0097\n",
      "Epoch 15/50\n",
      "1133/1133 [==============================] - 0s 79us/sample - loss: 0.0166 - val_loss: 0.0077\n",
      "Epoch 16/50\n",
      "1133/1133 [==============================] - 0s 85us/sample - loss: 0.0152 - val_loss: 0.0077\n",
      "Epoch 17/50\n",
      "1133/1133 [==============================] - 0s 82us/sample - loss: 0.0158 - val_loss: 0.0088\n",
      "Epoch 18/50\n",
      "1133/1133 [==============================] - 0s 79us/sample - loss: 0.0147 - val_loss: 0.0092\n",
      "Epoch 19/50\n",
      "1133/1133 [==============================] - 0s 81us/sample - loss: 0.0151 - val_loss: 0.0075\n",
      "Epoch 20/50\n",
      "1133/1133 [==============================] - 0s 81us/sample - loss: 0.0150 - val_loss: 0.0073\n",
      "Epoch 21/50\n",
      "1133/1133 [==============================] - 0s 81us/sample - loss: 0.0150 - val_loss: 0.0077\n",
      "Epoch 22/50\n",
      "1133/1133 [==============================] - 0s 80us/sample - loss: 0.0148 - val_loss: 0.0093\n",
      "Epoch 23/50\n",
      "1133/1133 [==============================] - 0s 80us/sample - loss: 0.0149 - val_loss: 0.0090\n",
      "Epoch 24/50\n",
      "1133/1133 [==============================] - 0s 82us/sample - loss: 0.0150 - val_loss: 0.0078\n",
      "Epoch 25/50\n",
      "1133/1133 [==============================] - 0s 79us/sample - loss: 0.0151 - val_loss: 0.0072\n",
      "Epoch 26/50\n",
      "1133/1133 [==============================] - 0s 79us/sample - loss: 0.0150 - val_loss: 0.0078\n",
      "Epoch 27/50\n",
      "1133/1133 [==============================] - 0s 78us/sample - loss: 0.0148 - val_loss: 0.0094\n",
      "Epoch 28/50\n",
      "1133/1133 [==============================] - 0s 80us/sample - loss: 0.0150 - val_loss: 0.0105\n",
      "Epoch 29/50\n",
      "1133/1133 [==============================] - 0s 81us/sample - loss: 0.0152 - val_loss: 0.0076\n",
      "Epoch 30/50\n",
      "1133/1133 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0083\n",
      "Epoch 31/50\n",
      "1133/1133 [==============================] - 0s 83us/sample - loss: 0.0152 - val_loss: 0.0076\n",
      "Epoch 32/50\n",
      "1133/1133 [==============================] - 0s 79us/sample - loss: 0.0151 - val_loss: 0.0069\n",
      "Epoch 33/50\n",
      "1133/1133 [==============================] - 0s 78us/sample - loss: 0.0147 - val_loss: 0.0067\n",
      "Epoch 34/50\n",
      "1133/1133 [==============================] - 0s 81us/sample - loss: 0.0148 - val_loss: 0.0098\n",
      "Epoch 35/50\n",
      "1133/1133 [==============================] - 0s 80us/sample - loss: 0.0153 - val_loss: 0.0080\n",
      "Epoch 36/50\n",
      "1133/1133 [==============================] - 0s 78us/sample - loss: 0.0149 - val_loss: 0.0068\n",
      "Epoch 37/50\n",
      "1133/1133 [==============================] - 0s 79us/sample - loss: 0.0145 - val_loss: 0.0065\n",
      "Epoch 38/50\n",
      "1133/1133 [==============================] - 0s 85us/sample - loss: 0.0147 - val_loss: 0.0069\n",
      "Epoch 39/50\n",
      "1133/1133 [==============================] - 0s 78us/sample - loss: 0.0146 - val_loss: 0.0081\n",
      "Epoch 40/50\n",
      "1133/1133 [==============================] - 0s 77us/sample - loss: 0.0145 - val_loss: 0.0069\n",
      "Epoch 41/50\n",
      "1133/1133 [==============================] - 0s 80us/sample - loss: 0.0146 - val_loss: 0.0067\n",
      "Epoch 42/50\n",
      "1133/1133 [==============================] - 0s 86us/sample - loss: 0.0146 - val_loss: 0.0065\n",
      "Epoch 43/50\n",
      "1133/1133 [==============================] - 0s 82us/sample - loss: 0.0153 - val_loss: 0.0096\n",
      "Epoch 44/50\n",
      "1133/1133 [==============================] - 0s 78us/sample - loss: 0.0152 - val_loss: 0.0107\n",
      "Epoch 45/50\n",
      "1133/1133 [==============================] - 0s 84us/sample - loss: 0.0156 - val_loss: 0.0065\n",
      "Epoch 46/50\n",
      "1133/1133 [==============================] - 0s 77us/sample - loss: 0.0155 - val_loss: 0.0079\n",
      "Epoch 47/50\n",
      "1133/1133 [==============================] - 0s 79us/sample - loss: 0.0152 - val_loss: 0.0081\n",
      "Epoch 48/50\n",
      "1133/1133 [==============================] - 0s 81us/sample - loss: 0.0152 - val_loss: 0.0069\n",
      "Epoch 49/50\n",
      "1133/1133 [==============================] - 0s 78us/sample - loss: 0.0148 - val_loss: 0.0068\n",
      "Epoch 50/50\n",
      "1133/1133 [==============================] - 0s 79us/sample - loss: 0.0151 - val_loss: 0.0110\n",
      "第125个数，还剩3998个没有训练\n",
      "inv_hat [1.06211691 1.05914157 1.05914157 1.05914157 1.05715627 1.0561632\n",
      " 1.05715627 1.05814912 1.05715627 1.05814912 1.06112548 1.06211691\n",
      " 1.06211691 1.06112548 1.06112548 1.06112548 1.06112548 1.06112548\n",
      " 1.06112548 1.05914157 1.05814912 1.05715627 1.05715627 1.05715627\n",
      " 1.0561632  1.0561632  1.0561632  1.0561632  1.05715627 1.05914157]\n",
      "Test RMSE: 0.002\n",
      "Train on 497 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "497/497 [==============================] - 0s 87us/sample - loss: 0.0110 - val_loss: 0.0068\n",
      "Epoch 2/50\n",
      "497/497 [==============================] - 0s 83us/sample - loss: 0.0067 - val_loss: 0.0159\n",
      "Epoch 3/50\n",
      "497/497 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0107\n",
      "Epoch 4/50\n",
      "497/497 [==============================] - 0s 87us/sample - loss: 0.0062 - val_loss: 0.0130\n",
      "Epoch 5/50\n",
      "497/497 [==============================] - 0s 80us/sample - loss: 0.0063 - val_loss: 0.0107\n",
      "Epoch 6/50\n",
      "497/497 [==============================] - 0s 81us/sample - loss: 0.0060 - val_loss: 0.0092\n",
      "Epoch 7/50\n",
      "497/497 [==============================] - 0s 81us/sample - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 8/50\n",
      "497/497 [==============================] - 0s 79us/sample - loss: 0.0051 - val_loss: 0.0070\n",
      "Epoch 9/50\n",
      "497/497 [==============================] - 0s 84us/sample - loss: 0.0051 - val_loss: 0.0068\n",
      "Epoch 10/50\n",
      "497/497 [==============================] - 0s 82us/sample - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 11/50\n",
      "497/497 [==============================] - 0s 82us/sample - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 12/50\n",
      "497/497 [==============================] - 0s 83us/sample - loss: 0.0053 - val_loss: 0.0065\n",
      "Epoch 13/50\n",
      "497/497 [==============================] - 0s 79us/sample - loss: 0.0056 - val_loss: 0.0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "497/497 [==============================] - 0s 80us/sample - loss: 0.0054 - val_loss: 0.0029\n",
      "Epoch 15/50\n",
      "497/497 [==============================] - 0s 79us/sample - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 16/50\n",
      "497/497 [==============================] - 0s 80us/sample - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 17/50\n",
      "497/497 [==============================] - 0s 84us/sample - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 18/50\n",
      "497/497 [==============================] - 0s 81us/sample - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 19/50\n",
      "497/497 [==============================] - 0s 79us/sample - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 20/50\n",
      "497/497 [==============================] - 0s 79us/sample - loss: 0.0057 - val_loss: 0.0030\n",
      "Epoch 21/50\n",
      "497/497 [==============================] - 0s 79us/sample - loss: 0.0067 - val_loss: 0.0061\n",
      "Epoch 22/50\n",
      "497/497 [==============================] - 0s 82us/sample - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 23/50\n",
      "497/497 [==============================] - 0s 78us/sample - loss: 0.0056 - val_loss: 0.0031\n",
      "Epoch 24/50\n",
      "497/497 [==============================] - 0s 78us/sample - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 25/50\n",
      "497/497 [==============================] - 0s 83us/sample - loss: 0.0056 - val_loss: 0.0078\n",
      "Epoch 26/50\n",
      "497/497 [==============================] - 0s 82us/sample - loss: 0.0065 - val_loss: 0.0032\n",
      "Epoch 27/50\n",
      "497/497 [==============================] - 0s 81us/sample - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 28/50\n",
      "497/497 [==============================] - 0s 84us/sample - loss: 0.0060 - val_loss: 0.0068\n",
      "Epoch 29/50\n",
      "497/497 [==============================] - 0s 80us/sample - loss: 0.0059 - val_loss: 0.0034\n",
      "Epoch 30/50\n",
      "497/497 [==============================] - 0s 83us/sample - loss: 0.0051 - val_loss: 0.0030\n",
      "Epoch 31/50\n",
      "497/497 [==============================] - 0s 81us/sample - loss: 0.0060 - val_loss: 0.0063\n",
      "Epoch 32/50\n",
      "497/497 [==============================] - 0s 85us/sample - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 33/50\n",
      "497/497 [==============================] - 0s 85us/sample - loss: 0.0053 - val_loss: 0.0030\n",
      "Epoch 34/50\n",
      "497/497 [==============================] - 0s 80us/sample - loss: 0.0066 - val_loss: 0.0055\n",
      "Epoch 35/50\n",
      "497/497 [==============================] - 0s 81us/sample - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 36/50\n",
      "497/497 [==============================] - 0s 84us/sample - loss: 0.0053 - val_loss: 0.0033\n",
      "Epoch 37/50\n",
      "497/497 [==============================] - 0s 84us/sample - loss: 0.0054 - val_loss: 0.0032\n",
      "Epoch 38/50\n",
      "497/497 [==============================] - 0s 85us/sample - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 39/50\n",
      "497/497 [==============================] - 0s 84us/sample - loss: 0.0067 - val_loss: 0.0029\n",
      "Epoch 40/50\n",
      "497/497 [==============================] - 0s 83us/sample - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 41/50\n",
      "497/497 [==============================] - 0s 83us/sample - loss: 0.0053 - val_loss: 0.0057\n",
      "Epoch 42/50\n",
      "497/497 [==============================] - 0s 81us/sample - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 43/50\n",
      "497/497 [==============================] - 0s 79us/sample - loss: 0.0052 - val_loss: 0.0029\n",
      "Epoch 44/50\n",
      "497/497 [==============================] - 0s 84us/sample - loss: 0.0065 - val_loss: 0.0060\n",
      "Epoch 45/50\n",
      "497/497 [==============================] - 0s 84us/sample - loss: 0.0058 - val_loss: 0.0035\n",
      "Epoch 46/50\n",
      "497/497 [==============================] - 0s 84us/sample - loss: 0.0051 - val_loss: 0.0030\n",
      "Epoch 47/50\n",
      "497/497 [==============================] - 0s 85us/sample - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 48/50\n",
      "497/497 [==============================] - 0s 84us/sample - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 49/50\n",
      "497/497 [==============================] - 0s 82us/sample - loss: 0.0055 - val_loss: 0.0029\n",
      "Epoch 50/50\n",
      "497/497 [==============================] - 0s 82us/sample - loss: 0.0056 - val_loss: 0.0036\n",
      "第126个数，还剩3997个没有训练\n",
      "inv_hat [1.02317759 1.02327774 1.02337789 1.02347806 1.02357824 1.02367833\n",
      " 1.02367833 1.02357824 1.02377854 1.02377854 1.02407926 1.0244803\n",
      " 1.02498203 1.02508231 1.02498203 1.02548397 1.02548397 1.02568487\n",
      " 1.02538354 1.02508231 1.02498203 1.0244803  1.02427982 1.0247813\n",
      " 1.0251827  1.02538354 1.02528311 1.02538354 1.02558441 1.0264888 ]\n",
      "Test RMSE: 0.000\n",
      "Train on 935 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "935/935 [==============================] - 0s 81us/sample - loss: 0.0153 - val_loss: 0.0083\n",
      "Epoch 2/50\n",
      "935/935 [==============================] - 0s 76us/sample - loss: 0.0156 - val_loss: 0.0086\n",
      "Epoch 3/50\n",
      "935/935 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0089\n",
      "Epoch 4/50\n",
      "935/935 [==============================] - 0s 79us/sample - loss: 0.0155 - val_loss: 0.0081\n",
      "Epoch 5/50\n",
      "935/935 [==============================] - 0s 78us/sample - loss: 0.0156 - val_loss: 0.0081\n",
      "Epoch 6/50\n",
      "935/935 [==============================] - 0s 78us/sample - loss: 0.0154 - val_loss: 0.0076\n",
      "Epoch 7/50\n",
      "935/935 [==============================] - 0s 79us/sample - loss: 0.0155 - val_loss: 0.0076\n",
      "Epoch 8/50\n",
      "935/935 [==============================] - 0s 83us/sample - loss: 0.0155 - val_loss: 0.0075\n",
      "Epoch 9/50\n",
      "935/935 [==============================] - 0s 85us/sample - loss: 0.0155 - val_loss: 0.0076\n",
      "Epoch 10/50\n",
      "935/935 [==============================] - 0s 81us/sample - loss: 0.0154 - val_loss: 0.0073\n",
      "Epoch 11/50\n",
      "935/935 [==============================] - 0s 85us/sample - loss: 0.0156 - val_loss: 0.0076\n",
      "Epoch 12/50\n",
      "935/935 [==============================] - 0s 80us/sample - loss: 0.0155 - val_loss: 0.0076\n",
      "Epoch 13/50\n",
      "935/935 [==============================] - 0s 81us/sample - loss: 0.0154 - val_loss: 0.0073\n",
      "Epoch 14/50\n",
      "935/935 [==============================] - 0s 78us/sample - loss: 0.0155 - val_loss: 0.0076\n",
      "Epoch 15/50\n",
      "935/935 [==============================] - 0s 78us/sample - loss: 0.0155 - val_loss: 0.0076\n",
      "Epoch 16/50\n",
      "935/935 [==============================] - 0s 77us/sample - loss: 0.0154 - val_loss: 0.0073\n",
      "Epoch 17/50\n",
      "935/935 [==============================] - 0s 76us/sample - loss: 0.0155 - val_loss: 0.0074\n",
      "Epoch 18/50\n",
      "935/935 [==============================] - 0s 77us/sample - loss: 0.0156 - val_loss: 0.0078\n",
      "Epoch 19/50\n",
      "935/935 [==============================] - 0s 75us/sample - loss: 0.0154 - val_loss: 0.0072\n",
      "Epoch 20/50\n",
      "935/935 [==============================] - 0s 75us/sample - loss: 0.0155 - val_loss: 0.0074\n",
      "Epoch 21/50\n",
      "935/935 [==============================] - 0s 76us/sample - loss: 0.0155 - val_loss: 0.0077\n",
      "Epoch 22/50\n",
      "935/935 [==============================] - 0s 78us/sample - loss: 0.0155 - val_loss: 0.0074\n",
      "Epoch 23/50\n",
      "935/935 [==============================] - 0s 77us/sample - loss: 0.0155 - val_loss: 0.0075\n",
      "Epoch 24/50\n",
      "935/935 [==============================] - 0s 79us/sample - loss: 0.0155 - val_loss: 0.0075\n",
      "Epoch 25/50\n",
      "935/935 [==============================] - 0s 78us/sample - loss: 0.0155 - val_loss: 0.0076\n",
      "Epoch 26/50\n",
      "935/935 [==============================] - 0s 75us/sample - loss: 0.0155 - val_loss: 0.0075\n",
      "Epoch 27/50\n",
      "935/935 [==============================] - 0s 76us/sample - loss: 0.0155 - val_loss: 0.0076\n",
      "Epoch 28/50\n",
      "935/935 [==============================] - 0s 78us/sample - loss: 0.0155 - val_loss: 0.0074\n",
      "Epoch 29/50\n",
      "935/935 [==============================] - 0s 78us/sample - loss: 0.0155 - val_loss: 0.0075\n",
      "Epoch 30/50\n",
      "935/935 [==============================] - 0s 75us/sample - loss: 0.0155 - val_loss: 0.0076\n",
      "Epoch 31/50\n",
      "935/935 [==============================] - 0s 78us/sample - loss: 0.0155 - val_loss: 0.0075\n",
      "Epoch 32/50\n",
      "935/935 [==============================] - 0s 79us/sample - loss: 0.0155 - val_loss: 0.0073\n",
      "Epoch 33/50\n",
      "935/935 [==============================] - 0s 86us/sample - loss: 0.0155 - val_loss: 0.0075\n",
      "Epoch 34/50\n",
      "935/935 [==============================] - 0s 79us/sample - loss: 0.0155 - val_loss: 0.0076\n",
      "Epoch 35/50\n",
      "935/935 [==============================] - 0s 77us/sample - loss: 0.0155 - val_loss: 0.0076\n",
      "Epoch 36/50\n",
      "935/935 [==============================] - 0s 83us/sample - loss: 0.0155 - val_loss: 0.0074\n",
      "Epoch 37/50\n",
      "935/935 [==============================] - 0s 86us/sample - loss: 0.0155 - val_loss: 0.0074\n",
      "Epoch 38/50\n",
      "935/935 [==============================] - 0s 79us/sample - loss: 0.0155 - val_loss: 0.0074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "935/935 [==============================] - 0s 79us/sample - loss: 0.0156 - val_loss: 0.0077\n",
      "Epoch 40/50\n",
      "935/935 [==============================] - 0s 78us/sample - loss: 0.0155 - val_loss: 0.0078\n",
      "Epoch 41/50\n",
      "935/935 [==============================] - 0s 78us/sample - loss: 0.0155 - val_loss: 0.0073\n",
      "Epoch 42/50\n",
      "935/935 [==============================] - 0s 80us/sample - loss: 0.0156 - val_loss: 0.0076\n",
      "Epoch 43/50\n",
      "935/935 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0078\n",
      "Epoch 44/50\n",
      "935/935 [==============================] - 0s 80us/sample - loss: 0.0155 - val_loss: 0.0074\n",
      "Epoch 45/50\n",
      "935/935 [==============================] - 0s 76us/sample - loss: 0.0155 - val_loss: 0.0073\n",
      "Epoch 46/50\n",
      "935/935 [==============================] - 0s 76us/sample - loss: 0.0156 - val_loss: 0.0078\n",
      "Epoch 47/50\n",
      "935/935 [==============================] - 0s 76us/sample - loss: 0.0156 - val_loss: 0.0079\n",
      "Epoch 48/50\n",
      "935/935 [==============================] - 0s 76us/sample - loss: 0.0155 - val_loss: 0.0075\n",
      "Epoch 49/50\n",
      "935/935 [==============================] - 0s 78us/sample - loss: 0.0155 - val_loss: 0.0074\n",
      "Epoch 50/50\n",
      "935/935 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0077\n",
      "第127个数，还剩3996个没有训练\n",
      "inv_hat [0.9817152  0.95943567 0.96040205 0.95846947 0.92766817 0.92958646\n",
      " 0.93246569 0.93919181 0.9238343  0.93342589 0.95846947 0.95943567\n",
      " 0.95943567 0.94496584 0.94592902 0.93823028 0.94592902 0.94785589\n",
      " 0.95943567 0.94689236 0.94207787 0.93438629 0.92479241 0.92575075\n",
      " 0.92191874 0.92479241 0.92000417 0.91904724 0.91617783 0.92096133]\n",
      "Test RMSE: 0.012\n",
      "Train on 841 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "841/841 [==============================] - 0s 84us/sample - loss: 0.0134 - val_loss: 0.0076\n",
      "Epoch 2/50\n",
      "841/841 [==============================] - 0s 86us/sample - loss: 0.0132 - val_loss: 0.0072\n",
      "Epoch 3/50\n",
      "841/841 [==============================] - 0s 86us/sample - loss: 0.0132 - val_loss: 0.0072\n",
      "Epoch 4/50\n",
      "841/841 [==============================] - 0s 90us/sample - loss: 0.0132 - val_loss: 0.0071\n",
      "Epoch 5/50\n",
      "841/841 [==============================] - 0s 85us/sample - loss: 0.0134 - val_loss: 0.0072\n",
      "Epoch 6/50\n",
      "841/841 [==============================] - 0s 86us/sample - loss: 0.0133 - val_loss: 0.0072\n",
      "Epoch 7/50\n",
      "841/841 [==============================] - 0s 85us/sample - loss: 0.0132 - val_loss: 0.0072\n",
      "Epoch 8/50\n",
      "841/841 [==============================] - 0s 87us/sample - loss: 0.0132 - val_loss: 0.0071\n",
      "Epoch 9/50\n",
      "841/841 [==============================] - 0s 83us/sample - loss: 0.0132 - val_loss: 0.0072\n",
      "Epoch 10/50\n",
      "841/841 [==============================] - 0s 84us/sample - loss: 0.0132 - val_loss: 0.0072\n",
      "Epoch 11/50\n",
      "841/841 [==============================] - 0s 84us/sample - loss: 0.0130 - val_loss: 0.0071\n",
      "Epoch 12/50\n",
      "841/841 [==============================] - 0s 86us/sample - loss: 0.0131 - val_loss: 0.0071\n",
      "Epoch 13/50\n",
      "841/841 [==============================] - 0s 80us/sample - loss: 0.0132 - val_loss: 0.0071\n",
      "Epoch 14/50\n",
      "841/841 [==============================] - 0s 83us/sample - loss: 0.0131 - val_loss: 0.0071\n",
      "Epoch 15/50\n",
      "841/841 [==============================] - 0s 82us/sample - loss: 0.0130 - val_loss: 0.0070\n",
      "Epoch 16/50\n",
      "841/841 [==============================] - 0s 80us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 17/50\n",
      "841/841 [==============================] - 0s 79us/sample - loss: 0.0132 - val_loss: 0.0071\n",
      "Epoch 18/50\n",
      "841/841 [==============================] - 0s 79us/sample - loss: 0.0130 - val_loss: 0.0070\n",
      "Epoch 19/50\n",
      "841/841 [==============================] - 0s 82us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 20/50\n",
      "841/841 [==============================] - 0s 81us/sample - loss: 0.0133 - val_loss: 0.0071\n",
      "Epoch 21/50\n",
      "841/841 [==============================] - 0s 85us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 22/50\n",
      "841/841 [==============================] - 0s 88us/sample - loss: 0.0132 - val_loss: 0.0070\n",
      "Epoch 23/50\n",
      "841/841 [==============================] - 0s 87us/sample - loss: 0.0132 - val_loss: 0.0071\n",
      "Epoch 24/50\n",
      "841/841 [==============================] - 0s 83us/sample - loss: 0.0131 - val_loss: 0.0071\n",
      "Epoch 25/50\n",
      "841/841 [==============================] - 0s 83us/sample - loss: 0.0131 - val_loss: 0.0071\n",
      "Epoch 26/50\n",
      "841/841 [==============================] - 0s 83us/sample - loss: 0.0132 - val_loss: 0.0070\n",
      "Epoch 27/50\n",
      "841/841 [==============================] - 0s 82us/sample - loss: 0.0132 - val_loss: 0.0071\n",
      "Epoch 28/50\n",
      "841/841 [==============================] - 0s 85us/sample - loss: 0.0132 - val_loss: 0.0071\n",
      "Epoch 29/50\n",
      "841/841 [==============================] - 0s 82us/sample - loss: 0.0131 - val_loss: 0.0071\n",
      "Epoch 30/50\n",
      "841/841 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0071\n",
      "Epoch 31/50\n",
      "841/841 [==============================] - 0s 81us/sample - loss: 0.0132 - val_loss: 0.0071\n",
      "Epoch 32/50\n",
      "841/841 [==============================] - 0s 80us/sample - loss: 0.0131 - val_loss: 0.0071\n",
      "Epoch 33/50\n",
      "841/841 [==============================] - 0s 80us/sample - loss: 0.0131 - val_loss: 0.0071\n",
      "Epoch 34/50\n",
      "841/841 [==============================] - 0s 80us/sample - loss: 0.0131 - val_loss: 0.0071\n",
      "Epoch 35/50\n",
      "841/841 [==============================] - 0s 86us/sample - loss: 0.0132 - val_loss: 0.0071\n",
      "Epoch 36/50\n",
      "841/841 [==============================] - 0s 85us/sample - loss: 0.0132 - val_loss: 0.0071\n",
      "Epoch 37/50\n",
      "841/841 [==============================] - 0s 87us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 38/50\n",
      "841/841 [==============================] - 0s 85us/sample - loss: 0.0131 - val_loss: 0.0071\n",
      "Epoch 39/50\n",
      "841/841 [==============================] - 0s 88us/sample - loss: 0.0131 - val_loss: 0.0071\n",
      "Epoch 40/50\n",
      "841/841 [==============================] - 0s 86us/sample - loss: 0.0131 - val_loss: 0.0071\n",
      "Epoch 41/50\n",
      "841/841 [==============================] - 0s 83us/sample - loss: 0.0132 - val_loss: 0.0071\n",
      "Epoch 42/50\n",
      "841/841 [==============================] - 0s 85us/sample - loss: 0.0132 - val_loss: 0.0071\n",
      "Epoch 43/50\n",
      "841/841 [==============================] - 0s 87us/sample - loss: 0.0131 - val_loss: 0.0071\n",
      "Epoch 44/50\n",
      "841/841 [==============================] - 0s 87us/sample - loss: 0.0132 - val_loss: 0.0071\n",
      "Epoch 45/50\n",
      "841/841 [==============================] - 0s 86us/sample - loss: 0.0131 - val_loss: 0.0071\n",
      "Epoch 46/50\n",
      "841/841 [==============================] - 0s 82us/sample - loss: 0.0132 - val_loss: 0.0071\n",
      "Epoch 47/50\n",
      "841/841 [==============================] - 0s 86us/sample - loss: 0.0131 - val_loss: 0.0071\n",
      "Epoch 48/50\n",
      "841/841 [==============================] - 0s 89us/sample - loss: 0.0131 - val_loss: 0.0071\n",
      "Epoch 49/50\n",
      "841/841 [==============================] - 0s 80us/sample - loss: 0.0131 - val_loss: 0.0071\n",
      "Epoch 50/50\n",
      "841/841 [==============================] - 0s 79us/sample - loss: 0.0131 - val_loss: 0.0071\n",
      "第128个数，还剩3995个没有训练\n",
      "inv_hat [0.59290464 0.58002468 0.58101365 0.57903609 0.56621411 0.56424662\n",
      " 0.56424662 0.57212497 0.56424662 0.56818306 0.58101365 0.58299241\n",
      " 0.58299241 0.57607225 0.57903609 0.57508489 0.57705988 0.57903609\n",
      " 0.58596293 0.57804782 0.57508489 0.57311128 0.56621411 0.56719844\n",
      " 0.56523019 0.56719844 0.56424662 0.56523019 0.5632634  0.56621411]\n",
      "Test RMSE: 0.006\n",
      "Train on 795 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "795/795 [==============================] - 0s 85us/sample - loss: 0.0141 - val_loss: 0.0122\n",
      "Epoch 2/50\n",
      "795/795 [==============================] - 0s 83us/sample - loss: 0.0141 - val_loss: 0.0122\n",
      "Epoch 3/50\n",
      "795/795 [==============================] - 0s 84us/sample - loss: 0.0141 - val_loss: 0.0122\n",
      "Epoch 4/50\n",
      "795/795 [==============================] - 0s 87us/sample - loss: 0.0140 - val_loss: 0.0122\n",
      "Epoch 5/50\n",
      "795/795 [==============================] - 0s 85us/sample - loss: 0.0138 - val_loss: 0.0124\n",
      "Epoch 6/50\n",
      "795/795 [==============================] - 0s 85us/sample - loss: 0.0139 - val_loss: 0.0125\n",
      "Epoch 7/50\n",
      "795/795 [==============================] - 0s 84us/sample - loss: 0.0140 - val_loss: 0.0123\n",
      "Epoch 8/50\n",
      "795/795 [==============================] - 0s 82us/sample - loss: 0.0139 - val_loss: 0.0122\n",
      "Epoch 9/50\n",
      "795/795 [==============================] - 0s 87us/sample - loss: 0.0139 - val_loss: 0.0123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "795/795 [==============================] - 0s 84us/sample - loss: 0.0140 - val_loss: 0.0125\n",
      "Epoch 11/50\n",
      "795/795 [==============================] - 0s 85us/sample - loss: 0.0140 - val_loss: 0.0123\n",
      "Epoch 12/50\n",
      "795/795 [==============================] - 0s 88us/sample - loss: 0.0140 - val_loss: 0.0122\n",
      "Epoch 13/50\n",
      "795/795 [==============================] - 0s 92us/sample - loss: 0.0138 - val_loss: 0.0122\n",
      "Epoch 14/50\n",
      "795/795 [==============================] - 0s 90us/sample - loss: 0.0139 - val_loss: 0.0122\n",
      "Epoch 15/50\n",
      "795/795 [==============================] - 0s 88us/sample - loss: 0.0140 - val_loss: 0.0124\n",
      "Epoch 16/50\n",
      "795/795 [==============================] - 0s 83us/sample - loss: 0.0144 - val_loss: 0.0124\n",
      "Epoch 17/50\n",
      "795/795 [==============================] - 0s 86us/sample - loss: 0.0142 - val_loss: 0.0123\n",
      "Epoch 18/50\n",
      "795/795 [==============================] - 0s 86us/sample - loss: 0.0142 - val_loss: 0.0122\n",
      "Epoch 19/50\n",
      "795/795 [==============================] - 0s 89us/sample - loss: 0.0139 - val_loss: 0.0123\n",
      "Epoch 20/50\n",
      "795/795 [==============================] - 0s 94us/sample - loss: 0.0139 - val_loss: 0.0124\n",
      "Epoch 21/50\n",
      "795/795 [==============================] - 0s 86us/sample - loss: 0.0140 - val_loss: 0.0124\n",
      "Epoch 22/50\n",
      "795/795 [==============================] - 0s 86us/sample - loss: 0.0140 - val_loss: 0.0124\n",
      "Epoch 23/50\n",
      "795/795 [==============================] - 0s 84us/sample - loss: 0.0140 - val_loss: 0.0122\n",
      "Epoch 24/50\n",
      "795/795 [==============================] - 0s 83us/sample - loss: 0.0138 - val_loss: 0.0122\n",
      "Epoch 25/50\n",
      "795/795 [==============================] - 0s 84us/sample - loss: 0.0139 - val_loss: 0.0123\n",
      "Epoch 26/50\n",
      "795/795 [==============================] - 0s 83us/sample - loss: 0.0139 - val_loss: 0.0124\n",
      "Epoch 27/50\n",
      "795/795 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0124\n",
      "Epoch 28/50\n",
      "795/795 [==============================] - 0s 84us/sample - loss: 0.0141 - val_loss: 0.0123\n",
      "Epoch 29/50\n",
      "795/795 [==============================] - 0s 83us/sample - loss: 0.0140 - val_loss: 0.0124\n",
      "Epoch 30/50\n",
      "795/795 [==============================] - 0s 86us/sample - loss: 0.0139 - val_loss: 0.0122\n",
      "Epoch 31/50\n",
      "795/795 [==============================] - 0s 86us/sample - loss: 0.0138 - val_loss: 0.0122\n",
      "Epoch 32/50\n",
      "795/795 [==============================] - 0s 83us/sample - loss: 0.0139 - val_loss: 0.0124\n",
      "Epoch 33/50\n",
      "795/795 [==============================] - 0s 91us/sample - loss: 0.0141 - val_loss: 0.0125\n",
      "Epoch 34/50\n",
      "795/795 [==============================] - 0s 87us/sample - loss: 0.0141 - val_loss: 0.0125\n",
      "Epoch 35/50\n",
      "795/795 [==============================] - 0s 84us/sample - loss: 0.0140 - val_loss: 0.0124\n",
      "Epoch 36/50\n",
      "795/795 [==============================] - 0s 83us/sample - loss: 0.0139 - val_loss: 0.0122\n",
      "Epoch 37/50\n",
      "795/795 [==============================] - 0s 87us/sample - loss: 0.0138 - val_loss: 0.0122\n",
      "Epoch 38/50\n",
      "795/795 [==============================] - 0s 91us/sample - loss: 0.0140 - val_loss: 0.0124\n",
      "Epoch 39/50\n",
      "795/795 [==============================] - 0s 83us/sample - loss: 0.0139 - val_loss: 0.0124\n",
      "Epoch 40/50\n",
      "795/795 [==============================] - 0s 84us/sample - loss: 0.0141 - val_loss: 0.0125\n",
      "Epoch 41/50\n",
      "795/795 [==============================] - 0s 89us/sample - loss: 0.0141 - val_loss: 0.0124\n",
      "Epoch 42/50\n",
      "795/795 [==============================] - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0124\n",
      "Epoch 43/50\n",
      "795/795 [==============================] - 0s 85us/sample - loss: 0.0139 - val_loss: 0.0123\n",
      "Epoch 44/50\n",
      "795/795 [==============================] - 0s 88us/sample - loss: 0.0138 - val_loss: 0.0122\n",
      "Epoch 45/50\n",
      "795/795 [==============================] - 0s 91us/sample - loss: 0.0138 - val_loss: 0.0124\n",
      "Epoch 46/50\n",
      "795/795 [==============================] - 0s 92us/sample - loss: 0.0141 - val_loss: 0.0125\n",
      "Epoch 47/50\n",
      "795/795 [==============================] - 0s 89us/sample - loss: 0.0138 - val_loss: 0.0123\n",
      "Epoch 48/50\n",
      "795/795 [==============================] - 0s 92us/sample - loss: 0.0139 - val_loss: 0.0124\n",
      "Epoch 49/50\n",
      "795/795 [==============================] - 0s 84us/sample - loss: 0.0140 - val_loss: 0.0124\n",
      "Epoch 50/50\n",
      "795/795 [==============================] - 0s 89us/sample - loss: 0.0140 - val_loss: 0.0124\n",
      "第129个数，还剩3994个没有训练\n",
      "inv_hat [0.59384147 0.58063733 0.58063733 0.57962408 0.5644704  0.5614505\n",
      " 0.55943928 0.56749408 0.55943928 0.56346335 0.584694   0.5867244\n",
      " 0.5867244  0.5725415  0.57153125 0.5664858  0.57355215 0.57153125\n",
      " 0.57962408 0.56547792 0.55542214 0.55241385 0.54241615 0.54241615\n",
      " 0.53743524 0.54940962 0.55041055 0.54541049 0.541419   0.54541049]\n",
      "Test RMSE: 0.008\n",
      "Train on 859 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "859/859 [==============================] - 0s 80us/sample - loss: 0.0191 - val_loss: 0.0128\n",
      "Epoch 2/50\n",
      "859/859 [==============================] - 0s 77us/sample - loss: 0.0189 - val_loss: 0.0117\n",
      "Epoch 3/50\n",
      "859/859 [==============================] - 0s 79us/sample - loss: 0.0227 - val_loss: 0.0248\n",
      "Epoch 4/50\n",
      "859/859 [==============================] - 0s 77us/sample - loss: 0.0201 - val_loss: 0.0145\n",
      "Epoch 5/50\n",
      "859/859 [==============================] - 0s 78us/sample - loss: 0.0180 - val_loss: 0.0118\n",
      "Epoch 6/50\n",
      "859/859 [==============================] - 0s 75us/sample - loss: 0.0178 - val_loss: 0.0122\n",
      "Epoch 7/50\n",
      "859/859 [==============================] - 0s 88us/sample - loss: 0.0176 - val_loss: 0.0116\n",
      "Epoch 8/50\n",
      "859/859 [==============================] - 0s 82us/sample - loss: 0.0186 - val_loss: 0.0129\n",
      "Epoch 9/50\n",
      "859/859 [==============================] - 0s 85us/sample - loss: 0.0190 - val_loss: 0.0162\n",
      "Epoch 10/50\n",
      "859/859 [==============================] - 0s 84us/sample - loss: 0.0181 - val_loss: 0.0126\n",
      "Epoch 11/50\n",
      "859/859 [==============================] - 0s 83us/sample - loss: 0.0173 - val_loss: 0.0116\n",
      "Epoch 12/50\n",
      "859/859 [==============================] - 0s 76us/sample - loss: 0.0172 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "859/859 [==============================] - 0s 78us/sample - loss: 0.0174 - val_loss: 0.0115\n",
      "Epoch 14/50\n",
      "859/859 [==============================] - 0s 81us/sample - loss: 0.0180 - val_loss: 0.0120\n",
      "Epoch 15/50\n",
      "859/859 [==============================] - 0s 82us/sample - loss: 0.0185 - val_loss: 0.0143\n",
      "Epoch 16/50\n",
      "859/859 [==============================] - 0s 83us/sample - loss: 0.0180 - val_loss: 0.0127\n",
      "Epoch 17/50\n",
      "859/859 [==============================] - 0s 84us/sample - loss: 0.0173 - val_loss: 0.0116\n",
      "Epoch 18/50\n",
      "859/859 [==============================] - 0s 83us/sample - loss: 0.0172 - val_loss: 0.0117\n",
      "Epoch 19/50\n",
      "859/859 [==============================] - 0s 89us/sample - loss: 0.0174 - val_loss: 0.0115\n",
      "Epoch 20/50\n",
      "859/859 [==============================] - 0s 82us/sample - loss: 0.0179 - val_loss: 0.0119\n",
      "Epoch 21/50\n",
      "859/859 [==============================] - 0s 79us/sample - loss: 0.0182 - val_loss: 0.0137\n",
      "Epoch 22/50\n",
      "859/859 [==============================] - 0s 78us/sample - loss: 0.0179 - val_loss: 0.0126\n",
      "Epoch 23/50\n",
      "859/859 [==============================] - 0s 82us/sample - loss: 0.0173 - val_loss: 0.0116\n",
      "Epoch 24/50\n",
      "859/859 [==============================] - 0s 81us/sample - loss: 0.0172 - val_loss: 0.0116\n",
      "Epoch 25/50\n",
      "859/859 [==============================] - 0s 80us/sample - loss: 0.0174 - val_loss: 0.0116\n",
      "Epoch 26/50\n",
      "859/859 [==============================] - 0s 78us/sample - loss: 0.0178 - val_loss: 0.0117\n",
      "Epoch 27/50\n",
      "859/859 [==============================] - 0s 79us/sample - loss: 0.0180 - val_loss: 0.0127\n",
      "Epoch 28/50\n",
      "859/859 [==============================] - 0s 80us/sample - loss: 0.0177 - val_loss: 0.0122\n",
      "Epoch 29/50\n",
      "859/859 [==============================] - 0s 81us/sample - loss: 0.0174 - val_loss: 0.0117\n",
      "Epoch 30/50\n",
      "859/859 [==============================] - 0s 84us/sample - loss: 0.0172 - val_loss: 0.0116\n",
      "Epoch 31/50\n",
      "859/859 [==============================] - 0s 86us/sample - loss: 0.0174 - val_loss: 0.0116\n",
      "Epoch 32/50\n",
      "859/859 [==============================] - 0s 84us/sample - loss: 0.0175 - val_loss: 0.0116\n",
      "Epoch 33/50\n",
      "859/859 [==============================] - 0s 86us/sample - loss: 0.0177 - val_loss: 0.0118\n",
      "Epoch 34/50\n",
      "859/859 [==============================] - 0s 80us/sample - loss: 0.0178 - val_loss: 0.0123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "859/859 [==============================] - 0s 77us/sample - loss: 0.0175 - val_loss: 0.0117\n",
      "Epoch 36/50\n",
      "859/859 [==============================] - 0s 75us/sample - loss: 0.0173 - val_loss: 0.0116\n",
      "Epoch 37/50\n",
      "859/859 [==============================] - 0s 82us/sample - loss: 0.0174 - val_loss: 0.0116\n",
      "Epoch 38/50\n",
      "859/859 [==============================] - 0s 79us/sample - loss: 0.0175 - val_loss: 0.0116\n",
      "Epoch 39/50\n",
      "859/859 [==============================] - 0s 79us/sample - loss: 0.0176 - val_loss: 0.0116\n",
      "Epoch 40/50\n",
      "859/859 [==============================] - 0s 80us/sample - loss: 0.0177 - val_loss: 0.0119\n",
      "Epoch 41/50\n",
      "859/859 [==============================] - 0s 78us/sample - loss: 0.0176 - val_loss: 0.0117\n",
      "Epoch 42/50\n",
      "859/859 [==============================] - 0s 79us/sample - loss: 0.0174 - val_loss: 0.0116\n",
      "Epoch 43/50\n",
      "859/859 [==============================] - 0s 76us/sample - loss: 0.0173 - val_loss: 0.0116\n",
      "Epoch 44/50\n",
      "859/859 [==============================] - 0s 80us/sample - loss: 0.0173 - val_loss: 0.0116\n",
      "Epoch 45/50\n",
      "859/859 [==============================] - 0s 80us/sample - loss: 0.0174 - val_loss: 0.0116\n",
      "Epoch 46/50\n",
      "859/859 [==============================] - 0s 86us/sample - loss: 0.0176 - val_loss: 0.0117\n",
      "Epoch 47/50\n",
      "859/859 [==============================] - 0s 86us/sample - loss: 0.0176 - val_loss: 0.0117\n",
      "Epoch 48/50\n",
      "859/859 [==============================] - 0s 84us/sample - loss: 0.0175 - val_loss: 0.0116\n",
      "Epoch 49/50\n",
      "859/859 [==============================] - 0s 86us/sample - loss: 0.0174 - val_loss: 0.0116\n",
      "Epoch 50/50\n",
      "859/859 [==============================] - 0s 75us/sample - loss: 0.0174 - val_loss: 0.0116\n",
      "第130个数，还剩3993个没有训练\n",
      "inv_hat [0.82552178 0.78463991 0.78763155 0.78264537 0.73975714 0.74274965\n",
      " 0.74474472 0.76469347 0.7407547  0.75671434 0.80159227 0.81156333\n",
      " 0.79760357 0.76668826 0.78364256 0.77566429 0.77965348 0.78463991\n",
      " 0.82153382 0.79461209 0.79959794 0.78164806 0.76269877 0.75072957\n",
      " 0.73975714 0.75072957 0.72279842 0.7178103  0.70683593 0.7138197 ]\n",
      "Test RMSE: 0.020\n",
      "Train on 740 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0230 - val_loss: 0.0286\n",
      "Epoch 2/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0233 - val_loss: 0.0282\n",
      "Epoch 3/50\n",
      "740/740 [==============================] - 0s 88us/sample - loss: 0.0231 - val_loss: 0.0281\n",
      "Epoch 4/50\n",
      "740/740 [==============================] - 0s 90us/sample - loss: 0.0229 - val_loss: 0.0283\n",
      "Epoch 5/50\n",
      "740/740 [==============================] - 0s 89us/sample - loss: 0.0232 - val_loss: 0.0279\n",
      "Epoch 6/50\n",
      "740/740 [==============================] - 0s 91us/sample - loss: 0.0229 - val_loss: 0.0282\n",
      "Epoch 7/50\n",
      "740/740 [==============================] - 0s 91us/sample - loss: 0.0231 - val_loss: 0.0281\n",
      "Epoch 8/50\n",
      "740/740 [==============================] - 0s 86us/sample - loss: 0.0230 - val_loss: 0.0282\n",
      "Epoch 9/50\n",
      "740/740 [==============================] - 0s 82us/sample - loss: 0.0230 - val_loss: 0.0281\n",
      "Epoch 10/50\n",
      "740/740 [==============================] - 0s 79us/sample - loss: 0.0230 - val_loss: 0.0281\n",
      "Epoch 11/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0230 - val_loss: 0.0281\n",
      "Epoch 12/50\n",
      "740/740 [==============================] - 0s 86us/sample - loss: 0.0231 - val_loss: 0.0280\n",
      "Epoch 13/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0230 - val_loss: 0.0281\n",
      "Epoch 14/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0231 - val_loss: 0.0280\n",
      "Epoch 15/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0230 - val_loss: 0.0280\n",
      "Epoch 16/50\n",
      "740/740 [==============================] - 0s 82us/sample - loss: 0.0230 - val_loss: 0.0281\n",
      "Epoch 17/50\n",
      "740/740 [==============================] - 0s 90us/sample - loss: 0.0229 - val_loss: 0.0281\n",
      "Epoch 18/50\n",
      "740/740 [==============================] - 0s 83us/sample - loss: 0.0230 - val_loss: 0.0282\n",
      "Epoch 19/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0231 - val_loss: 0.0281\n",
      "Epoch 20/50\n",
      "740/740 [==============================] - 0s 80us/sample - loss: 0.0230 - val_loss: 0.0278\n",
      "Epoch 21/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0229 - val_loss: 0.0281\n",
      "Epoch 22/50\n",
      "740/740 [==============================] - 0s 87us/sample - loss: 0.0230 - val_loss: 0.0282\n",
      "Epoch 23/50\n",
      "740/740 [==============================] - 0s 89us/sample - loss: 0.0231 - val_loss: 0.0281\n",
      "Epoch 24/50\n",
      "740/740 [==============================] - 0s 87us/sample - loss: 0.0230 - val_loss: 0.0278\n",
      "Epoch 25/50\n",
      "740/740 [==============================] - 0s 89us/sample - loss: 0.0228 - val_loss: 0.0282\n",
      "Epoch 26/50\n",
      "740/740 [==============================] - 0s 89us/sample - loss: 0.0230 - val_loss: 0.0282\n",
      "Epoch 27/50\n",
      "740/740 [==============================] - 0s 91us/sample - loss: 0.0231 - val_loss: 0.0281\n",
      "Epoch 28/50\n",
      "740/740 [==============================] - 0s 89us/sample - loss: 0.0230 - val_loss: 0.0278\n",
      "Epoch 29/50\n",
      "740/740 [==============================] - 0s 87us/sample - loss: 0.0229 - val_loss: 0.0281\n",
      "Epoch 30/50\n",
      "740/740 [==============================] - 0s 83us/sample - loss: 0.0230 - val_loss: 0.0282\n",
      "Epoch 31/50\n",
      "740/740 [==============================] - 0s 89us/sample - loss: 0.0231 - val_loss: 0.0281\n",
      "Epoch 32/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0231 - val_loss: 0.0279\n",
      "Epoch 33/50\n",
      "740/740 [==============================] - 0s 89us/sample - loss: 0.0229 - val_loss: 0.0280\n",
      "Epoch 34/50\n",
      "740/740 [==============================] - 0s 90us/sample - loss: 0.0229 - val_loss: 0.0281\n",
      "Epoch 35/50\n",
      "740/740 [==============================] - 0s 81us/sample - loss: 0.0230 - val_loss: 0.0281\n",
      "Epoch 36/50\n",
      "740/740 [==============================] - 0s 88us/sample - loss: 0.0230 - val_loss: 0.0280\n",
      "Epoch 37/50\n",
      "740/740 [==============================] - 0s 86us/sample - loss: 0.0229 - val_loss: 0.0279\n",
      "Epoch 38/50\n",
      "740/740 [==============================] - 0s 82us/sample - loss: 0.0229 - val_loss: 0.0281\n",
      "Epoch 39/50\n",
      "740/740 [==============================] - 0s 89us/sample - loss: 0.0230 - val_loss: 0.0282\n",
      "Epoch 40/50\n",
      "740/740 [==============================] - 0s 82us/sample - loss: 0.0231 - val_loss: 0.0281\n",
      "Epoch 41/50\n",
      "740/740 [==============================] - 0s 83us/sample - loss: 0.0230 - val_loss: 0.0278\n",
      "Epoch 42/50\n",
      "740/740 [==============================] - 0s 89us/sample - loss: 0.0229 - val_loss: 0.0282\n",
      "Epoch 43/50\n",
      "740/740 [==============================] - 0s 92us/sample - loss: 0.0231 - val_loss: 0.0282\n",
      "Epoch 44/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0231 - val_loss: 0.0281\n",
      "Epoch 45/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0230 - val_loss: 0.0278\n",
      "Epoch 46/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0228 - val_loss: 0.0282\n",
      "Epoch 47/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0230 - val_loss: 0.0283\n",
      "Epoch 48/50\n",
      "740/740 [==============================] - 0s 83us/sample - loss: 0.0232 - val_loss: 0.0281\n",
      "Epoch 49/50\n",
      "740/740 [==============================] - 0s 82us/sample - loss: 0.0230 - val_loss: 0.0279\n",
      "Epoch 50/50\n",
      "740/740 [==============================] - 0s 89us/sample - loss: 0.0229 - val_loss: 0.0280\n",
      "第131个数，还剩3992个没有训练\n",
      "inv_hat [0.9297655  0.91375436 0.92776268 0.92876408 0.91175522 0.90775885\n",
      " 0.91375436 0.91875479 0.91275474 0.92175647 0.94479258 0.95581347\n",
      " 0.9628241  0.92776268 0.89977473 0.89080919 0.89678417 0.89080919\n",
      " 0.90276732 0.87591503 0.86208115 0.85814258 0.83661045 0.83078073\n",
      " 0.82111041 0.83661045 0.8414833  0.838558   0.8327218  0.838558  ]\n",
      "Test RMSE: 0.014\n",
      "Train on 575 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "575/575 [==============================] - 0s 79us/sample - loss: 0.0144 - val_loss: 0.0221\n",
      "Epoch 2/50\n",
      "575/575 [==============================] - 0s 86us/sample - loss: 0.0137 - val_loss: 0.0190\n",
      "Epoch 3/50\n",
      "575/575 [==============================] - 0s 88us/sample - loss: 0.0144 - val_loss: 0.0189\n",
      "Epoch 4/50\n",
      "575/575 [==============================] - 0s 87us/sample - loss: 0.0159 - val_loss: 0.0248\n",
      "Epoch 5/50\n",
      "575/575 [==============================] - 0s 84us/sample - loss: 0.0160 - val_loss: 0.0188\n",
      "Epoch 6/50\n",
      "575/575 [==============================] - 0s 81us/sample - loss: 0.0146 - val_loss: 0.0194\n",
      "Epoch 7/50\n",
      "575/575 [==============================] - 0s 86us/sample - loss: 0.0147 - val_loss: 0.0248\n",
      "Epoch 8/50\n",
      "575/575 [==============================] - 0s 91us/sample - loss: 0.0151 - val_loss: 0.0188\n",
      "Epoch 9/50\n",
      "575/575 [==============================] - 0s 83us/sample - loss: 0.0147 - val_loss: 0.0194\n",
      "Epoch 10/50\n",
      "575/575 [==============================] - 0s 89us/sample - loss: 0.0146 - val_loss: 0.0243\n",
      "Epoch 11/50\n",
      "575/575 [==============================] - 0s 84us/sample - loss: 0.0147 - val_loss: 0.0188\n",
      "Epoch 12/50\n",
      "575/575 [==============================] - 0s 81us/sample - loss: 0.0147 - val_loss: 0.0196\n",
      "Epoch 13/50\n",
      "575/575 [==============================] - 0s 83us/sample - loss: 0.0145 - val_loss: 0.0243\n",
      "Epoch 14/50\n",
      "575/575 [==============================] - 0s 84us/sample - loss: 0.0144 - val_loss: 0.0186\n",
      "Epoch 15/50\n",
      "575/575 [==============================] - 0s 86us/sample - loss: 0.0151 - val_loss: 0.0237\n",
      "Epoch 16/50\n",
      "575/575 [==============================] - 0s 82us/sample - loss: 0.0141 - val_loss: 0.0206\n",
      "Epoch 17/50\n",
      "575/575 [==============================] - 0s 89us/sample - loss: 0.0133 - val_loss: 0.0190\n",
      "Epoch 18/50\n",
      "575/575 [==============================] - 0s 86us/sample - loss: 0.0139 - val_loss: 0.0189\n",
      "Epoch 19/50\n",
      "575/575 [==============================] - 0s 82us/sample - loss: 0.0147 - val_loss: 0.0241\n",
      "Epoch 20/50\n",
      "575/575 [==============================] - 0s 86us/sample - loss: 0.0148 - val_loss: 0.0187\n",
      "Epoch 21/50\n",
      "575/575 [==============================] - 0s 79us/sample - loss: 0.0155 - val_loss: 0.0252\n",
      "Epoch 22/50\n",
      "575/575 [==============================] - 0s 85us/sample - loss: 0.0144 - val_loss: 0.0193\n",
      "Epoch 23/50\n",
      "575/575 [==============================] - 0s 87us/sample - loss: 0.0132 - val_loss: 0.0195\n",
      "Epoch 24/50\n",
      "575/575 [==============================] - 0s 83us/sample - loss: 0.0133 - val_loss: 0.0189\n",
      "Epoch 25/50\n",
      "575/575 [==============================] - 0s 84us/sample - loss: 0.0140 - val_loss: 0.0236\n",
      "Epoch 26/50\n",
      "575/575 [==============================] - 0s 84us/sample - loss: 0.0146 - val_loss: 0.0188\n",
      "Epoch 27/50\n",
      "575/575 [==============================] - 0s 87us/sample - loss: 0.0143 - val_loss: 0.0198\n",
      "Epoch 28/50\n",
      "575/575 [==============================] - 0s 80us/sample - loss: 0.0133 - val_loss: 0.0227\n",
      "Epoch 29/50\n",
      "575/575 [==============================] - 0s 83us/sample - loss: 0.0144 - val_loss: 0.0189\n",
      "Epoch 30/50\n",
      "575/575 [==============================] - 0s 81us/sample - loss: 0.0134 - val_loss: 0.0211\n",
      "Epoch 31/50\n",
      "575/575 [==============================] - 0s 88us/sample - loss: 0.0131 - val_loss: 0.0190\n",
      "Epoch 32/50\n",
      "575/575 [==============================] - 0s 80us/sample - loss: 0.0131 - val_loss: 0.0194\n",
      "Epoch 33/50\n",
      "575/575 [==============================] - 0s 79us/sample - loss: 0.0141 - val_loss: 0.0210\n",
      "Epoch 34/50\n",
      "575/575 [==============================] - 0s 83us/sample - loss: 0.0136 - val_loss: 0.0190\n",
      "Epoch 35/50\n",
      "575/575 [==============================] - 0s 82us/sample - loss: 0.0136 - val_loss: 0.0202\n",
      "Epoch 36/50\n",
      "575/575 [==============================] - 0s 82us/sample - loss: 0.0140 - val_loss: 0.0211\n",
      "Epoch 37/50\n",
      "575/575 [==============================] - 0s 82us/sample - loss: 0.0135 - val_loss: 0.0188\n",
      "Epoch 38/50\n",
      "575/575 [==============================] - 0s 83us/sample - loss: 0.0138 - val_loss: 0.0228\n",
      "Epoch 39/50\n",
      "575/575 [==============================] - 0s 80us/sample - loss: 0.0140 - val_loss: 0.0196\n",
      "Epoch 40/50\n",
      "575/575 [==============================] - 0s 79us/sample - loss: 0.0134 - val_loss: 0.0212\n",
      "Epoch 41/50\n",
      "575/575 [==============================] - 0s 81us/sample - loss: 0.0131 - val_loss: 0.0189\n",
      "Epoch 42/50\n",
      "575/575 [==============================] - 0s 83us/sample - loss: 0.0141 - val_loss: 0.0227\n",
      "Epoch 43/50\n",
      "575/575 [==============================] - 0s 86us/sample - loss: 0.0140 - val_loss: 0.0196\n",
      "Epoch 44/50\n",
      "575/575 [==============================] - 0s 82us/sample - loss: 0.0133 - val_loss: 0.0204\n",
      "Epoch 45/50\n",
      "575/575 [==============================] - 0s 84us/sample - loss: 0.0134 - val_loss: 0.0204\n",
      "Epoch 46/50\n",
      "575/575 [==============================] - 0s 81us/sample - loss: 0.0135 - val_loss: 0.0229\n",
      "Epoch 47/50\n",
      "575/575 [==============================] - 0s 84us/sample - loss: 0.0135 - val_loss: 0.0189\n",
      "Epoch 48/50\n",
      "575/575 [==============================] - 0s 81us/sample - loss: 0.0133 - val_loss: 0.0198\n",
      "Epoch 49/50\n",
      "575/575 [==============================] - 0s 82us/sample - loss: 0.0140 - val_loss: 0.0214\n",
      "Epoch 50/50\n",
      "575/575 [==============================] - 0s 81us/sample - loss: 0.0136 - val_loss: 0.0192\n",
      "第132个数，还剩3991个没有训练\n",
      "inv_hat [1.0901178  1.08209524 1.08209524 1.08008569 1.07505854 1.07606408\n",
      " 1.07505854 1.07807509 1.07505854 1.0770697  1.08510719 1.08510719\n",
      " 1.08309951 1.07807509 1.07807509 1.07505854 1.07505854 1.07606408\n",
      " 1.07908049 1.07505854 1.07405285 1.07003117 1.06601288 1.06200114\n",
      " 1.05799877 1.05999852 1.05899833 1.0570001  1.0570001  1.05799877]\n",
      "Test RMSE: 0.003\n",
      "Train on 825 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "825/825 [==============================] - 0s 85us/sample - loss: 0.0111 - val_loss: 0.0195\n",
      "Epoch 2/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0095 - val_loss: 0.0162\n",
      "Epoch 3/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0099 - val_loss: 0.0162\n",
      "Epoch 4/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0095 - val_loss: 0.0156\n",
      "Epoch 5/50\n",
      "825/825 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0218\n",
      "Epoch 6/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0092 - val_loss: 0.0127\n",
      "Epoch 7/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0140 - val_loss: 0.0093\n",
      "Epoch 8/50\n",
      "825/825 [==============================] - 0s 85us/sample - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 9/50\n",
      "825/825 [==============================] - 0s 89us/sample - loss: 0.0129 - val_loss: 0.0180\n",
      "Epoch 10/50\n",
      "825/825 [==============================] - 0s 85us/sample - loss: 0.0080 - val_loss: 0.0110\n",
      "Epoch 11/50\n",
      "825/825 [==============================] - 0s 85us/sample - loss: 0.0144 - val_loss: 0.0079\n",
      "Epoch 12/50\n",
      "825/825 [==============================] - 0s 85us/sample - loss: 0.0096 - val_loss: 0.0093\n",
      "Epoch 13/50\n",
      "825/825 [==============================] - 0s 81us/sample - loss: 0.0167 - val_loss: 0.0184\n",
      "Epoch 14/50\n",
      "825/825 [==============================] - 0s 86us/sample - loss: 0.0107 - val_loss: 0.0090\n",
      "Epoch 15/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0203 - val_loss: 0.0118\n",
      "Epoch 16/50\n",
      "825/825 [==============================] - 0s 87us/sample - loss: 0.0143 - val_loss: 0.0184\n",
      "Epoch 17/50\n",
      "825/825 [==============================] - 0s 87us/sample - loss: 0.0182 - val_loss: 0.0097\n",
      "Epoch 18/50\n",
      "825/825 [==============================] - 0s 85us/sample - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 19/50\n",
      "825/825 [==============================] - 0s 85us/sample - loss: 0.0185 - val_loss: 0.0115\n",
      "Epoch 20/50\n",
      "825/825 [==============================] - 0s 85us/sample - loss: 0.0142 - val_loss: 0.0190\n",
      "Epoch 21/50\n",
      "825/825 [==============================] - 0s 85us/sample - loss: 0.0168 - val_loss: 0.0093\n",
      "Epoch 22/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0091 - val_loss: 0.0119\n",
      "Epoch 23/50\n",
      "825/825 [==============================] - 0s 81us/sample - loss: 0.0168 - val_loss: 0.0104\n",
      "Epoch 24/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 25/50\n",
      "825/825 [==============================] - 0s 88us/sample - loss: 0.0168 - val_loss: 0.0092\n",
      "Epoch 26/50\n",
      "825/825 [==============================] - 0s 86us/sample - loss: 0.0104 - val_loss: 0.0095\n",
      "Epoch 27/50\n",
      "825/825 [==============================] - 0s 87us/sample - loss: 0.0158 - val_loss: 0.0119\n",
      "Epoch 28/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0104 - val_loss: 0.0142\n",
      "Epoch 29/50\n",
      "825/825 [==============================] - 0s 85us/sample - loss: 0.0153 - val_loss: 0.0113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "825/825 [==============================] - 0s 85us/sample - loss: 0.0098 - val_loss: 0.0091\n",
      "Epoch 31/50\n",
      "825/825 [==============================] - 0s 87us/sample - loss: 0.0169 - val_loss: 0.0135\n",
      "Epoch 32/50\n",
      "825/825 [==============================] - 0s 86us/sample - loss: 0.0108 - val_loss: 0.0141\n",
      "Epoch 33/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0148 - val_loss: 0.0113\n",
      "Epoch 34/50\n",
      "825/825 [==============================] - 0s 86us/sample - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 35/50\n",
      "825/825 [==============================] - 0s 86us/sample - loss: 0.0159 - val_loss: 0.0139\n",
      "Epoch 36/50\n",
      "825/825 [==============================] - 0s 81us/sample - loss: 0.0103 - val_loss: 0.0132\n",
      "Epoch 37/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0136 - val_loss: 0.0116\n",
      "Epoch 38/50\n",
      "825/825 [==============================] - 0s 88us/sample - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 39/50\n",
      "825/825 [==============================] - 0s 86us/sample - loss: 0.0163 - val_loss: 0.0138\n",
      "Epoch 40/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0108 - val_loss: 0.0138\n",
      "Epoch 41/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0140 - val_loss: 0.0112\n",
      "Epoch 42/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0095 - val_loss: 0.0090\n",
      "Epoch 43/50\n",
      "825/825 [==============================] - 0s 80us/sample - loss: 0.0169 - val_loss: 0.0179\n",
      "Epoch 44/50\n",
      "825/825 [==============================] - 0s 86us/sample - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 45/50\n",
      "825/825 [==============================] - 0s 86us/sample - loss: 0.0108 - val_loss: 0.0098\n",
      "Epoch 46/50\n",
      "825/825 [==============================] - 0s 85us/sample - loss: 0.0096 - val_loss: 0.0079\n",
      "Epoch 47/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 48/50\n",
      "825/825 [==============================] - 0s 79us/sample - loss: 0.0105 - val_loss: 0.0164\n",
      "Epoch 49/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0089 - val_loss: 0.0109\n",
      "Epoch 50/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0106 - val_loss: 0.0085\n",
      "第133个数，还剩3990个没有训练\n",
      "inv_hat [1.09836346 1.09738458 1.09738458 1.09738458 1.09738458 1.09934082\n",
      " 1.09934082 1.10226431 1.10226431 1.10517391 1.10903019 1.1109479\n",
      " 1.1109479  1.10998999 1.10998999 1.1119041  1.11285844 1.11285844\n",
      " 1.11476142 1.11381084 1.11476142 1.11476142 1.11476142 1.11476142\n",
      " 1.11571011 1.11665672 1.11665672 1.11665672 1.11665672 1.11665672]\n",
      "Test RMSE: 0.001\n",
      "Train on 547 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "547/547 [==============================] - 0s 83us/sample - loss: 0.0219 - val_loss: 0.0357\n",
      "Epoch 2/50\n",
      "547/547 [==============================] - 0s 82us/sample - loss: 0.0214 - val_loss: 0.0347\n",
      "Epoch 3/50\n",
      "547/547 [==============================] - 0s 84us/sample - loss: 0.0221 - val_loss: 0.0363\n",
      "Epoch 4/50\n",
      "547/547 [==============================] - 0s 84us/sample - loss: 0.0224 - val_loss: 0.0349\n",
      "Epoch 5/50\n",
      "547/547 [==============================] - 0s 86us/sample - loss: 0.0242 - val_loss: 0.0377\n",
      "Epoch 6/50\n",
      "547/547 [==============================] - 0s 83us/sample - loss: 0.0248 - val_loss: 0.0351\n",
      "Epoch 7/50\n",
      "547/547 [==============================] - 0s 85us/sample - loss: 0.0267 - val_loss: 0.0368\n",
      "Epoch 8/50\n",
      "547/547 [==============================] - 0s 90us/sample - loss: 0.0237 - val_loss: 0.0348\n",
      "Epoch 9/50\n",
      "547/547 [==============================] - 0s 84us/sample - loss: 0.0245 - val_loss: 0.0371\n",
      "Epoch 10/50\n",
      "547/547 [==============================] - 0s 86us/sample - loss: 0.0234 - val_loss: 0.0348\n",
      "Epoch 11/50\n",
      "547/547 [==============================] - 0s 85us/sample - loss: 0.0245 - val_loss: 0.0374\n",
      "Epoch 12/50\n",
      "547/547 [==============================] - 0s 86us/sample - loss: 0.0236 - val_loss: 0.0348\n",
      "Epoch 13/50\n",
      "547/547 [==============================] - 0s 80us/sample - loss: 0.0250 - val_loss: 0.0374\n",
      "Epoch 14/50\n",
      "547/547 [==============================] - 0s 82us/sample - loss: 0.0236 - val_loss: 0.0347\n",
      "Epoch 15/50\n",
      "547/547 [==============================] - 0s 86us/sample - loss: 0.0245 - val_loss: 0.0375\n",
      "Epoch 16/50\n",
      "547/547 [==============================] - 0s 84us/sample - loss: 0.0234 - val_loss: 0.0347\n",
      "Epoch 17/50\n",
      "547/547 [==============================] - 0s 84us/sample - loss: 0.0242 - val_loss: 0.0375\n",
      "Epoch 18/50\n",
      "547/547 [==============================] - 0s 88us/sample - loss: 0.0233 - val_loss: 0.0346\n",
      "Epoch 19/50\n",
      "547/547 [==============================] - 0s 86us/sample - loss: 0.0239 - val_loss: 0.0376\n",
      "Epoch 20/50\n",
      "547/547 [==============================] - 0s 93us/sample - loss: 0.0234 - val_loss: 0.0346\n",
      "Epoch 21/50\n",
      "547/547 [==============================] - 0s 86us/sample - loss: 0.0239 - val_loss: 0.0378\n",
      "Epoch 22/50\n",
      "547/547 [==============================] - 0s 85us/sample - loss: 0.0235 - val_loss: 0.0346\n",
      "Epoch 23/50\n",
      "547/547 [==============================] - 0s 89us/sample - loss: 0.0241 - val_loss: 0.0376\n",
      "Epoch 24/50\n",
      "547/547 [==============================] - 0s 85us/sample - loss: 0.0232 - val_loss: 0.0346\n",
      "Epoch 25/50\n",
      "547/547 [==============================] - 0s 84us/sample - loss: 0.0237 - val_loss: 0.0377\n",
      "Epoch 26/50\n",
      "547/547 [==============================] - 0s 85us/sample - loss: 0.0233 - val_loss: 0.0345\n",
      "Epoch 27/50\n",
      "547/547 [==============================] - 0s 84us/sample - loss: 0.0234 - val_loss: 0.0377\n",
      "Epoch 28/50\n",
      "547/547 [==============================] - 0s 80us/sample - loss: 0.0232 - val_loss: 0.0345\n",
      "Epoch 29/50\n",
      "547/547 [==============================] - 0s 90us/sample - loss: 0.0234 - val_loss: 0.0377\n",
      "Epoch 30/50\n",
      "547/547 [==============================] - 0s 86us/sample - loss: 0.0231 - val_loss: 0.0345\n",
      "Epoch 31/50\n",
      "547/547 [==============================] - 0s 84us/sample - loss: 0.0234 - val_loss: 0.0377\n",
      "Epoch 32/50\n",
      "547/547 [==============================] - 0s 85us/sample - loss: 0.0231 - val_loss: 0.0345\n",
      "Epoch 33/50\n",
      "547/547 [==============================] - 0s 87us/sample - loss: 0.0233 - val_loss: 0.0377\n",
      "Epoch 34/50\n",
      "547/547 [==============================] - 0s 82us/sample - loss: 0.0231 - val_loss: 0.0345\n",
      "Epoch 35/50\n",
      "547/547 [==============================] - 0s 84us/sample - loss: 0.0233 - val_loss: 0.0376\n",
      "Epoch 36/50\n",
      "547/547 [==============================] - 0s 86us/sample - loss: 0.0230 - val_loss: 0.0345\n",
      "Epoch 37/50\n",
      "547/547 [==============================] - 0s 83us/sample - loss: 0.0234 - val_loss: 0.0376\n",
      "Epoch 38/50\n",
      "547/547 [==============================] - 0s 81us/sample - loss: 0.0229 - val_loss: 0.0345\n",
      "Epoch 39/50\n",
      "547/547 [==============================] - 0s 83us/sample - loss: 0.0233 - val_loss: 0.0376\n",
      "Epoch 40/50\n",
      "547/547 [==============================] - 0s 88us/sample - loss: 0.0230 - val_loss: 0.0345\n",
      "Epoch 41/50\n",
      "547/547 [==============================] - 0s 82us/sample - loss: 0.0232 - val_loss: 0.0376\n",
      "Epoch 42/50\n",
      "547/547 [==============================] - 0s 83us/sample - loss: 0.0230 - val_loss: 0.0345\n",
      "Epoch 43/50\n",
      "547/547 [==============================] - 0s 83us/sample - loss: 0.0232 - val_loss: 0.0376\n",
      "Epoch 44/50\n",
      "547/547 [==============================] - 0s 87us/sample - loss: 0.0229 - val_loss: 0.0345\n",
      "Epoch 45/50\n",
      "547/547 [==============================] - 0s 85us/sample - loss: 0.0232 - val_loss: 0.0375\n",
      "Epoch 46/50\n",
      "547/547 [==============================] - 0s 88us/sample - loss: 0.0228 - val_loss: 0.0345\n",
      "Epoch 47/50\n",
      "547/547 [==============================] - 0s 83us/sample - loss: 0.0231 - val_loss: 0.0374\n",
      "Epoch 48/50\n",
      "547/547 [==============================] - 0s 83us/sample - loss: 0.0228 - val_loss: 0.0345\n",
      "Epoch 49/50\n",
      "547/547 [==============================] - 0s 86us/sample - loss: 0.0232 - val_loss: 0.0375\n",
      "Epoch 50/50\n",
      "547/547 [==============================] - 0s 86us/sample - loss: 0.0229 - val_loss: 0.0345\n",
      "第134个数，还剩3989个没有训练\n",
      "inv_hat [0.97772455 0.96295168 0.96481301 0.96795516 0.95022419 0.94721028\n",
      " 0.9479083  0.95225059 0.9430254  0.94983894 0.96785682 0.97219035\n",
      " 0.97169717 0.95953222 0.96070317 0.95457337 0.95729217 0.95700044\n",
      " 0.96697231 0.95263716 0.95283059 0.94681145 0.93924496 0.93745659\n",
      " 0.93230038 0.9337861  0.93170647 0.92775384 0.92047532 0.92283066]\n",
      "Test RMSE: 0.008\n",
      "Train on 1193 samples, validate on 30 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0074 - val_loss: 0.0042\n",
      "Epoch 2/50\n",
      "1193/1193 [==============================] - 0s 86us/sample - loss: 0.0066 - val_loss: 0.0041\n",
      "Epoch 3/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0066 - val_loss: 0.0040\n",
      "Epoch 4/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0038\n",
      "Epoch 5/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0067 - val_loss: 0.0045\n",
      "Epoch 6/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0073 - val_loss: 0.0032\n",
      "Epoch 7/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0067 - val_loss: 0.0034\n",
      "Epoch 8/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0078 - val_loss: 0.0073\n",
      "Epoch 9/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0070 - val_loss: 0.0041\n",
      "Epoch 10/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0066 - val_loss: 0.0034\n",
      "Epoch 11/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 12/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 13/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0068 - val_loss: 0.0039\n",
      "Epoch 14/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0063 - val_loss: 0.0037\n",
      "Epoch 15/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0066 - val_loss: 0.0040\n",
      "Epoch 16/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0065 - val_loss: 0.0032\n",
      "Epoch 17/50\n",
      "1193/1193 [==============================] - 0s 84us/sample - loss: 0.0062 - val_loss: 0.0035\n",
      "Epoch 18/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 19/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0063 - val_loss: 0.0034\n",
      "Epoch 20/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 21/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 22/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0077 - val_loss: 0.0056\n",
      "Epoch 23/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0070 - val_loss: 0.0046\n",
      "Epoch 24/50\n",
      "1193/1193 [==============================] - 0s 84us/sample - loss: 0.0078 - val_loss: 0.0074\n",
      "Epoch 25/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0071 - val_loss: 0.0034\n",
      "Epoch 26/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 27/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 28/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0069 - val_loss: 0.0051\n",
      "Epoch 29/50\n",
      "1193/1193 [==============================] - 0s 84us/sample - loss: 0.0069 - val_loss: 0.0033\n",
      "Epoch 30/50\n",
      "1193/1193 [==============================] - 0s 88us/sample - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 31/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0070 - val_loss: 0.0037\n",
      "Epoch 32/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0065 - val_loss: 0.0035\n",
      "Epoch 33/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0068 - val_loss: 0.0033\n",
      "Epoch 34/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 35/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0065 - val_loss: 0.0037\n",
      "Epoch 36/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 37/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 38/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0068 - val_loss: 0.0040\n",
      "Epoch 39/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0067 - val_loss: 0.0033\n",
      "Epoch 40/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0065 - val_loss: 0.0038\n",
      "Epoch 41/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0067 - val_loss: 0.0039\n",
      "Epoch 42/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 43/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0073 - val_loss: 0.0057\n",
      "Epoch 44/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0068 - val_loss: 0.0037\n",
      "Epoch 45/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0063 - val_loss: 0.0032\n",
      "Epoch 46/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 47/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0069 - val_loss: 0.0047\n",
      "Epoch 48/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0063 - val_loss: 0.0033\n",
      "Epoch 49/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0062 - val_loss: 0.0038\n",
      "Epoch 50/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0068 - val_loss: 0.0035\n",
      "第135个数，还剩3988个没有训练\n",
      "inv_hat [1.02595901 1.02595901 1.0269631  1.0269631  1.0269631  1.0269631\n",
      " 1.0269631  1.0269631  1.0269631  1.0269631  1.02798088 1.02798088\n",
      " 1.02798088 1.02798088 1.02798088 1.02798088 1.02798088 1.02798088\n",
      " 1.02798088 1.02798088 1.02899681 1.02899681 1.02899681 1.02899681\n",
      " 1.02899681 1.02899681 1.02899681 1.02899681 1.03001042 1.03001042]\n",
      "Test RMSE: 0.000\n",
      "Train on 804 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "804/804 [==============================] - 0s 84us/sample - loss: 0.0224 - val_loss: 0.0234\n",
      "Epoch 2/50\n",
      "804/804 [==============================] - 0s 87us/sample - loss: 0.0185 - val_loss: 0.0221\n",
      "Epoch 3/50\n",
      "804/804 [==============================] - 0s 85us/sample - loss: 0.0180 - val_loss: 0.0200\n",
      "Epoch 4/50\n",
      "804/804 [==============================] - 0s 88us/sample - loss: 0.0145 - val_loss: 0.0204\n",
      "Epoch 5/50\n",
      "804/804 [==============================] - 0s 86us/sample - loss: 0.0160 - val_loss: 0.0224\n",
      "Epoch 6/50\n",
      "804/804 [==============================] - 0s 84us/sample - loss: 0.0204 - val_loss: 0.0205\n",
      "Epoch 7/50\n",
      "804/804 [==============================] - 0s 84us/sample - loss: 0.0175 - val_loss: 0.0196\n",
      "Epoch 8/50\n",
      "804/804 [==============================] - 0s 85us/sample - loss: 0.0175 - val_loss: 0.0233\n",
      "Epoch 9/50\n",
      "804/804 [==============================] - 0s 88us/sample - loss: 0.0143 - val_loss: 0.0233\n",
      "Epoch 10/50\n",
      "804/804 [==============================] - 0s 90us/sample - loss: 0.0137 - val_loss: 0.0217\n",
      "Epoch 11/50\n",
      "804/804 [==============================] - 0s 90us/sample - loss: 0.0137 - val_loss: 0.0237\n",
      "Epoch 12/50\n",
      "804/804 [==============================] - 0s 96us/sample - loss: 0.0155 - val_loss: 0.0255\n",
      "Epoch 13/50\n",
      "804/804 [==============================] - 0s 92us/sample - loss: 0.0182 - val_loss: 0.0204\n",
      "Epoch 14/50\n",
      "804/804 [==============================] - 0s 88us/sample - loss: 0.0136 - val_loss: 0.0205\n",
      "Epoch 15/50\n",
      "804/804 [==============================] - 0s 90us/sample - loss: 0.0134 - val_loss: 0.0204\n",
      "Epoch 16/50\n",
      "804/804 [==============================] - 0s 86us/sample - loss: 0.0134 - val_loss: 0.0204\n",
      "Epoch 17/50\n",
      "804/804 [==============================] - 0s 86us/sample - loss: 0.0136 - val_loss: 0.0209\n",
      "Epoch 18/50\n",
      "804/804 [==============================] - 0s 83us/sample - loss: 0.0141 - val_loss: 0.0221\n",
      "Epoch 19/50\n",
      "804/804 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0235\n",
      "Epoch 20/50\n",
      "804/804 [==============================] - 0s 82us/sample - loss: 0.0180 - val_loss: 0.0198\n",
      "Epoch 21/50\n",
      "804/804 [==============================] - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0213\n",
      "Epoch 22/50\n",
      "804/804 [==============================] - 0s 88us/sample - loss: 0.0171 - val_loss: 0.0200\n",
      "Epoch 23/50\n",
      "804/804 [==============================] - 0s 89us/sample - loss: 0.0141 - val_loss: 0.0203\n",
      "Epoch 24/50\n",
      "804/804 [==============================] - 0s 85us/sample - loss: 0.0154 - val_loss: 0.0214\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 0s 91us/sample - loss: 0.0175 - val_loss: 0.0197\n",
      "Epoch 26/50\n",
      "804/804 [==============================] - 0s 86us/sample - loss: 0.0136 - val_loss: 0.0199\n",
      "Epoch 27/50\n",
      "804/804 [==============================] - 0s 90us/sample - loss: 0.0146 - val_loss: 0.0206\n",
      "Epoch 28/50\n",
      "804/804 [==============================] - 0s 88us/sample - loss: 0.0175 - val_loss: 0.0197\n",
      "Epoch 29/50\n",
      "804/804 [==============================] - 0s 84us/sample - loss: 0.0145 - val_loss: 0.0202\n",
      "Epoch 30/50\n",
      "804/804 [==============================] - 0s 85us/sample - loss: 0.0164 - val_loss: 0.0198\n",
      "Epoch 31/50\n",
      "804/804 [==============================] - 0s 89us/sample - loss: 0.0154 - val_loss: 0.0200\n",
      "Epoch 32/50\n",
      "804/804 [==============================] - 0s 82us/sample - loss: 0.0157 - val_loss: 0.0199\n",
      "Epoch 33/50\n",
      "804/804 [==============================] - 0s 81us/sample - loss: 0.0158 - val_loss: 0.0198\n",
      "Epoch 34/50\n",
      "804/804 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0198\n",
      "Epoch 35/50\n",
      "804/804 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0198\n",
      "Epoch 36/50\n",
      "804/804 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0198\n",
      "Epoch 37/50\n",
      "804/804 [==============================] - 0s 86us/sample - loss: 0.0155 - val_loss: 0.0198\n",
      "Epoch 38/50\n",
      "804/804 [==============================] - 0s 87us/sample - loss: 0.0156 - val_loss: 0.0197\n",
      "Epoch 39/50\n",
      "804/804 [==============================] - 0s 84us/sample - loss: 0.0155 - val_loss: 0.0197\n",
      "Epoch 40/50\n",
      "804/804 [==============================] - 0s 83us/sample - loss: 0.0155 - val_loss: 0.0197\n",
      "Epoch 41/50\n",
      "804/804 [==============================] - 0s 85us/sample - loss: 0.0155 - val_loss: 0.0197\n",
      "Epoch 42/50\n",
      "804/804 [==============================] - 0s 89us/sample - loss: 0.0155 - val_loss: 0.0197\n",
      "Epoch 43/50\n",
      "804/804 [==============================] - 0s 86us/sample - loss: 0.0154 - val_loss: 0.0197\n",
      "Epoch 44/50\n",
      "804/804 [==============================] - 0s 82us/sample - loss: 0.0155 - val_loss: 0.0197\n",
      "Epoch 45/50\n",
      "804/804 [==============================] - 0s 81us/sample - loss: 0.0154 - val_loss: 0.0197\n",
      "Epoch 46/50\n",
      "804/804 [==============================] - 0s 82us/sample - loss: 0.0154 - val_loss: 0.0197\n",
      "Epoch 47/50\n",
      "804/804 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0197\n",
      "Epoch 48/50\n",
      "804/804 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0197\n",
      "Epoch 49/50\n",
      "804/804 [==============================] - 0s 83us/sample - loss: 0.0152 - val_loss: 0.0198\n",
      "Epoch 50/50\n",
      "804/804 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0197\n",
      "第136个数，还剩3987个没有训练\n",
      "inv_hat [0.80080098 0.77764446 0.77613487 0.77331966 0.7532204  0.75103321\n",
      " 0.75580868 0.76649757 0.74805509 0.75272311 0.77975947 0.77955798\n",
      " 0.77613487 0.75282252 0.7522259  0.74944426 0.75531063 0.75521108\n",
      " 0.76289483 0.74379545 0.73501433 0.72843704 0.71926024 0.71984419\n",
      " 0.71353244 0.72111017 0.72062308 0.71479229 0.70677032 0.70455674]\n",
      "Test RMSE: 0.011\n",
      "Train on 884 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "884/884 [==============================] - 0s 84us/sample - loss: 0.0156 - val_loss: 0.0049\n",
      "Epoch 2/50\n",
      "884/884 [==============================] - 0s 82us/sample - loss: 0.0155 - val_loss: 0.0051\n",
      "Epoch 3/50\n",
      "884/884 [==============================] - 0s 85us/sample - loss: 0.0154 - val_loss: 0.0048\n",
      "Epoch 4/50\n",
      "884/884 [==============================] - 0s 87us/sample - loss: 0.0154 - val_loss: 0.0050\n",
      "Epoch 5/50\n",
      "884/884 [==============================] - 0s 84us/sample - loss: 0.0154 - val_loss: 0.0054\n",
      "Epoch 6/50\n",
      "884/884 [==============================] - 0s 89us/sample - loss: 0.0153 - val_loss: 0.0052\n",
      "Epoch 7/50\n",
      "884/884 [==============================] - 0s 89us/sample - loss: 0.0154 - val_loss: 0.0058\n",
      "Epoch 8/50\n",
      "884/884 [==============================] - 0s 88us/sample - loss: 0.0153 - val_loss: 0.0054\n",
      "Epoch 9/50\n",
      "884/884 [==============================] - 0s 90us/sample - loss: 0.0153 - val_loss: 0.0058\n",
      "Epoch 10/50\n",
      "884/884 [==============================] - 0s 88us/sample - loss: 0.0153 - val_loss: 0.0057\n",
      "Epoch 11/50\n",
      "884/884 [==============================] - 0s 85us/sample - loss: 0.0153 - val_loss: 0.0057\n",
      "Epoch 12/50\n",
      "884/884 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0058\n",
      "Epoch 13/50\n",
      "884/884 [==============================] - 0s 79us/sample - loss: 0.0153 - val_loss: 0.0057\n",
      "Epoch 14/50\n",
      "884/884 [==============================] - 0s 82us/sample - loss: 0.0153 - val_loss: 0.0058\n",
      "Epoch 15/50\n",
      "884/884 [==============================] - 0s 85us/sample - loss: 0.0153 - val_loss: 0.0058\n",
      "Epoch 16/50\n",
      "884/884 [==============================] - 0s 82us/sample - loss: 0.0153 - val_loss: 0.0058\n",
      "Epoch 17/50\n",
      "884/884 [==============================] - 0s 82us/sample - loss: 0.0153 - val_loss: 0.0058\n",
      "Epoch 18/50\n",
      "884/884 [==============================] - 0s 86us/sample - loss: 0.0153 - val_loss: 0.0058\n",
      "Epoch 19/50\n",
      "884/884 [==============================] - 0s 81us/sample - loss: 0.0153 - val_loss: 0.0058\n",
      "Epoch 20/50\n",
      "884/884 [==============================] - 0s 80us/sample - loss: 0.0153 - val_loss: 0.0057\n",
      "Epoch 21/50\n",
      "884/884 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0059\n",
      "Epoch 22/50\n",
      "884/884 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0058\n",
      "Epoch 23/50\n",
      "884/884 [==============================] - 0s 85us/sample - loss: 0.0153 - val_loss: 0.0058\n",
      "Epoch 24/50\n",
      "884/884 [==============================] - 0s 85us/sample - loss: 0.0153 - val_loss: 0.0059\n",
      "Epoch 25/50\n",
      "884/884 [==============================] - 0s 86us/sample - loss: 0.0152 - val_loss: 0.0058\n",
      "Epoch 26/50\n",
      "884/884 [==============================] - 0s 85us/sample - loss: 0.0153 - val_loss: 0.0059\n",
      "Epoch 27/50\n",
      "884/884 [==============================] - 0s 85us/sample - loss: 0.0153 - val_loss: 0.0059\n",
      "Epoch 28/50\n",
      "884/884 [==============================] - 0s 85us/sample - loss: 0.0153 - val_loss: 0.0059\n",
      "Epoch 29/50\n",
      "884/884 [==============================] - 0s 85us/sample - loss: 0.0153 - val_loss: 0.0058\n",
      "Epoch 30/50\n",
      "884/884 [==============================] - 0s 93us/sample - loss: 0.0153 - val_loss: 0.0059\n",
      "Epoch 31/50\n",
      "884/884 [==============================] - 0s 91us/sample - loss: 0.0152 - val_loss: 0.0058\n",
      "Epoch 32/50\n",
      "884/884 [==============================] - 0s 87us/sample - loss: 0.0153 - val_loss: 0.0061\n",
      "Epoch 33/50\n",
      "884/884 [==============================] - 0s 88us/sample - loss: 0.0152 - val_loss: 0.0058\n",
      "Epoch 34/50\n",
      "884/884 [==============================] - 0s 85us/sample - loss: 0.0153 - val_loss: 0.0059\n",
      "Epoch 35/50\n",
      "884/884 [==============================] - 0s 86us/sample - loss: 0.0152 - val_loss: 0.0059\n",
      "Epoch 36/50\n",
      "884/884 [==============================] - 0s 86us/sample - loss: 0.0153 - val_loss: 0.0060\n",
      "Epoch 37/50\n",
      "884/884 [==============================] - 0s 87us/sample - loss: 0.0152 - val_loss: 0.0059\n",
      "Epoch 38/50\n",
      "884/884 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0062\n",
      "Epoch 39/50\n",
      "884/884 [==============================] - 0s 84us/sample - loss: 0.0152 - val_loss: 0.0059\n",
      "Epoch 40/50\n",
      "884/884 [==============================] - 0s 88us/sample - loss: 0.0153 - val_loss: 0.0060\n",
      "Epoch 41/50\n",
      "884/884 [==============================] - 0s 85us/sample - loss: 0.0153 - val_loss: 0.0060\n",
      "Epoch 42/50\n",
      "884/884 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0060\n",
      "Epoch 43/50\n",
      "884/884 [==============================] - 0s 83us/sample - loss: 0.0153 - val_loss: 0.0060\n",
      "Epoch 44/50\n",
      "884/884 [==============================] - 0s 86us/sample - loss: 0.0153 - val_loss: 0.0062\n",
      "Epoch 45/50\n",
      "884/884 [==============================] - 0s 82us/sample - loss: 0.0152 - val_loss: 0.0059\n",
      "Epoch 46/50\n",
      "884/884 [==============================] - 0s 81us/sample - loss: 0.0153 - val_loss: 0.0062\n",
      "Epoch 47/50\n",
      "884/884 [==============================] - 0s 82us/sample - loss: 0.0152 - val_loss: 0.0058\n",
      "Epoch 48/50\n",
      "884/884 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0059\n",
      "Epoch 49/50\n",
      "884/884 [==============================] - 0s 82us/sample - loss: 0.0153 - val_loss: 0.0060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "884/884 [==============================] - 0s 81us/sample - loss: 0.0152 - val_loss: 0.0059\n",
      "第137个数，还剩3986个没有训练\n",
      "inv_hat [0.82429883 0.81257077 0.81354659 0.81061997 0.79991069 0.79893887\n",
      " 0.80088287 0.80672169 0.79699612 0.79991069 0.80964499 0.80867024\n",
      " 0.80867024 0.80185527 0.80282798 0.80185527 0.80574785 0.80574785\n",
      " 0.81257077 0.80282798 0.80088287 0.79602518 0.79020572 0.79117486\n",
      " 0.78826835 0.79311409 0.79214435 0.78923688 0.78633213 0.78633213]\n",
      "Test RMSE: 0.006\n",
      "Train on 1131 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1131/1131 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0124\n",
      "Epoch 2/50\n",
      "1131/1131 [==============================] - 0s 83us/sample - loss: 0.0124 - val_loss: 0.0215\n",
      "Epoch 3/50\n",
      "1131/1131 [==============================] - 0s 79us/sample - loss: 0.0187 - val_loss: 0.0084\n",
      "Epoch 4/50\n",
      "1131/1131 [==============================] - 0s 79us/sample - loss: 0.0160 - val_loss: 0.0205\n",
      "Epoch 5/50\n",
      "1131/1131 [==============================] - 0s 83us/sample - loss: 0.0133 - val_loss: 0.0252\n",
      "Epoch 6/50\n",
      "1131/1131 [==============================] - 0s 83us/sample - loss: 0.0225 - val_loss: 0.0095\n",
      "Epoch 7/50\n",
      "1131/1131 [==============================] - 0s 82us/sample - loss: 0.0164 - val_loss: 0.0353\n",
      "Epoch 8/50\n",
      "1131/1131 [==============================] - 0s 82us/sample - loss: 0.0155 - val_loss: 0.0116\n",
      "Epoch 9/50\n",
      "1131/1131 [==============================] - 0s 81us/sample - loss: 0.0171 - val_loss: 0.0125\n",
      "Epoch 10/50\n",
      "1131/1131 [==============================] - 0s 84us/sample - loss: 0.0141 - val_loss: 0.0329\n",
      "Epoch 11/50\n",
      "1131/1131 [==============================] - 0s 84us/sample - loss: 0.0149 - val_loss: 0.0079\n",
      "Epoch 12/50\n",
      "1131/1131 [==============================] - 0s 80us/sample - loss: 0.0130 - val_loss: 0.0153\n",
      "Epoch 13/50\n",
      "1131/1131 [==============================] - 0s 80us/sample - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 14/50\n",
      "1131/1131 [==============================] - 0s 79us/sample - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 15/50\n",
      "1131/1131 [==============================] - 0s 81us/sample - loss: 0.0114 - val_loss: 0.0118\n",
      "Epoch 16/50\n",
      "1131/1131 [==============================] - 0s 84us/sample - loss: 0.0124 - val_loss: 0.0082\n",
      "Epoch 17/50\n",
      "1131/1131 [==============================] - 0s 81us/sample - loss: 0.0122 - val_loss: 0.0133\n",
      "Epoch 18/50\n",
      "1131/1131 [==============================] - 0s 77us/sample - loss: 0.0106 - val_loss: 0.0092\n",
      "Epoch 19/50\n",
      "1131/1131 [==============================] - 0s 84us/sample - loss: 0.0136 - val_loss: 0.0097\n",
      "Epoch 20/50\n",
      "1131/1131 [==============================] - 0s 86us/sample - loss: 0.0113 - val_loss: 0.0171\n",
      "Epoch 21/50\n",
      "1131/1131 [==============================] - 0s 83us/sample - loss: 0.0132 - val_loss: 0.0081\n",
      "Epoch 22/50\n",
      "1131/1131 [==============================] - 0s 82us/sample - loss: 0.0127 - val_loss: 0.0144\n",
      "Epoch 23/50\n",
      "1131/1131 [==============================] - 0s 83us/sample - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 24/50\n",
      "1131/1131 [==============================] - 0s 82us/sample - loss: 0.0133 - val_loss: 0.0115\n",
      "Epoch 25/50\n",
      "1131/1131 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0129\n",
      "Epoch 26/50\n",
      "1131/1131 [==============================] - 0s 80us/sample - loss: 0.0135 - val_loss: 0.0080\n",
      "Epoch 27/50\n",
      "1131/1131 [==============================] - 0s 80us/sample - loss: 0.0123 - val_loss: 0.0191\n",
      "Epoch 28/50\n",
      "1131/1131 [==============================] - 0s 81us/sample - loss: 0.0122 - val_loss: 0.0092\n",
      "Epoch 29/50\n",
      "1131/1131 [==============================] - 0s 80us/sample - loss: 0.0136 - val_loss: 0.0116\n",
      "Epoch 30/50\n",
      "1131/1131 [==============================] - 0s 77us/sample - loss: 0.0113 - val_loss: 0.0164\n",
      "Epoch 31/50\n",
      "1131/1131 [==============================] - 0s 78us/sample - loss: 0.0136 - val_loss: 0.0085\n",
      "Epoch 32/50\n",
      "1131/1131 [==============================] - 0s 76us/sample - loss: 0.0126 - val_loss: 0.0162\n",
      "Epoch 33/50\n",
      "1131/1131 [==============================] - 0s 78us/sample - loss: 0.0125 - val_loss: 0.0115\n",
      "Epoch 34/50\n",
      "1131/1131 [==============================] - 0s 81us/sample - loss: 0.0143 - val_loss: 0.0147\n",
      "Epoch 35/50\n",
      "1131/1131 [==============================] - 0s 77us/sample - loss: 0.0117 - val_loss: 0.0183\n",
      "Epoch 36/50\n",
      "1131/1131 [==============================] - 0s 78us/sample - loss: 0.0154 - val_loss: 0.0083\n",
      "Epoch 37/50\n",
      "1131/1131 [==============================] - 0s 78us/sample - loss: 0.0140 - val_loss: 0.0252\n",
      "Epoch 38/50\n",
      "1131/1131 [==============================] - 0s 81us/sample - loss: 0.0128 - val_loss: 0.0109\n",
      "Epoch 39/50\n",
      "1131/1131 [==============================] - 0s 84us/sample - loss: 0.0145 - val_loss: 0.0107\n",
      "Epoch 40/50\n",
      "1131/1131 [==============================] - 0s 78us/sample - loss: 0.0123 - val_loss: 0.0220\n",
      "Epoch 41/50\n",
      "1131/1131 [==============================] - 0s 81us/sample - loss: 0.0130 - val_loss: 0.0080\n",
      "Epoch 42/50\n",
      "1131/1131 [==============================] - 0s 82us/sample - loss: 0.0131 - val_loss: 0.0142\n",
      "Epoch 43/50\n",
      "1131/1131 [==============================] - 0s 81us/sample - loss: 0.0114 - val_loss: 0.0133\n",
      "Epoch 44/50\n",
      "1131/1131 [==============================] - 0s 82us/sample - loss: 0.0131 - val_loss: 0.0102\n",
      "Epoch 45/50\n",
      "1131/1131 [==============================] - 0s 82us/sample - loss: 0.0114 - val_loss: 0.0130\n",
      "Epoch 46/50\n",
      "1131/1131 [==============================] - 0s 81us/sample - loss: 0.0124 - val_loss: 0.0083\n",
      "Epoch 47/50\n",
      "1131/1131 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0143\n",
      "Epoch 48/50\n",
      "1131/1131 [==============================] - 0s 78us/sample - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 49/50\n",
      "1131/1131 [==============================] - 0s 77us/sample - loss: 0.0139 - val_loss: 0.0096\n",
      "Epoch 50/50\n",
      "1131/1131 [==============================] - 0s 78us/sample - loss: 0.0115 - val_loss: 0.0174\n",
      "第138个数，还剩3985个没有训练\n",
      "inv_hat [0.18025328 0.17965851 0.17936081 0.17946007 0.17906291 0.17856609\n",
      " 0.17836724 0.17866548 0.17856609 0.17846667 0.17866548 0.17896358\n",
      " 0.17906291 0.17985687 0.17985687 0.1797577  0.17995601 0.17995601\n",
      " 0.18015422 0.18055028 0.18134086 0.18134086 0.18134086 0.18124217\n",
      " 0.18114343 0.18104466 0.18074813 0.180847   0.180847   0.18104466]\n",
      "Test RMSE: 0.001\n",
      "Train on 842 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "842/842 [==============================] - 0s 81us/sample - loss: 0.0136 - val_loss: 0.0304\n",
      "Epoch 2/50\n",
      "842/842 [==============================] - 0s 78us/sample - loss: 0.0159 - val_loss: 0.0218\n",
      "Epoch 3/50\n",
      "842/842 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0166\n",
      "Epoch 4/50\n",
      "842/842 [==============================] - 0s 79us/sample - loss: 0.0124 - val_loss: 0.0202\n",
      "Epoch 5/50\n",
      "842/842 [==============================] - 0s 79us/sample - loss: 0.0120 - val_loss: 0.0223\n",
      "Epoch 6/50\n",
      "842/842 [==============================] - 0s 78us/sample - loss: 0.0112 - val_loss: 0.0162\n",
      "Epoch 7/50\n",
      "842/842 [==============================] - 0s 84us/sample - loss: 0.0117 - val_loss: 0.0166\n",
      "Epoch 8/50\n",
      "842/842 [==============================] - 0s 86us/sample - loss: 0.0144 - val_loss: 0.0320\n",
      "Epoch 9/50\n",
      "842/842 [==============================] - 0s 86us/sample - loss: 0.0158 - val_loss: 0.0161\n",
      "Epoch 10/50\n",
      "842/842 [==============================] - 0s 82us/sample - loss: 0.0117 - val_loss: 0.0169\n",
      "Epoch 11/50\n",
      "842/842 [==============================] - 0s 84us/sample - loss: 0.0128 - val_loss: 0.0277\n",
      "Epoch 12/50\n",
      "842/842 [==============================] - 0s 88us/sample - loss: 0.0144 - val_loss: 0.0161\n",
      "Epoch 13/50\n",
      "842/842 [==============================] - 0s 83us/sample - loss: 0.0104 - val_loss: 0.0160\n",
      "Epoch 14/50\n",
      "842/842 [==============================] - 0s 79us/sample - loss: 0.0112 - val_loss: 0.0233\n",
      "Epoch 15/50\n",
      "842/842 [==============================] - 0s 79us/sample - loss: 0.0151 - val_loss: 0.0198\n",
      "Epoch 16/50\n",
      "842/842 [==============================] - 0s 80us/sample - loss: 0.0113 - val_loss: 0.0169\n",
      "Epoch 17/50\n",
      "842/842 [==============================] - 0s 85us/sample - loss: 0.0128 - val_loss: 0.0172\n",
      "Epoch 18/50\n",
      "842/842 [==============================] - 0s 86us/sample - loss: 0.0123 - val_loss: 0.0262\n",
      "Epoch 19/50\n",
      "842/842 [==============================] - 0s 86us/sample - loss: 0.0141 - val_loss: 0.0163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "842/842 [==============================] - 0s 85us/sample - loss: 0.0098 - val_loss: 0.0169\n",
      "Epoch 21/50\n",
      "842/842 [==============================] - 0s 86us/sample - loss: 0.0125 - val_loss: 0.0204\n",
      "Epoch 22/50\n",
      "842/842 [==============================] - 0s 82us/sample - loss: 0.0147 - val_loss: 0.0214\n",
      "Epoch 23/50\n",
      "842/842 [==============================] - 0s 81us/sample - loss: 0.0122 - val_loss: 0.0172\n",
      "Epoch 24/50\n",
      "842/842 [==============================] - 0s 80us/sample - loss: 0.0131 - val_loss: 0.0173\n",
      "Epoch 25/50\n",
      "842/842 [==============================] - 0s 77us/sample - loss: 0.0126 - val_loss: 0.0239\n",
      "Epoch 26/50\n",
      "842/842 [==============================] - 0s 84us/sample - loss: 0.0131 - val_loss: 0.0169\n",
      "Epoch 27/50\n",
      "842/842 [==============================] - 0s 83us/sample - loss: 0.0126 - val_loss: 0.0169\n",
      "Epoch 28/50\n",
      "842/842 [==============================] - 0s 80us/sample - loss: 0.0119 - val_loss: 0.0237\n",
      "Epoch 29/50\n",
      "842/842 [==============================] - 0s 82us/sample - loss: 0.0132 - val_loss: 0.0162\n",
      "Epoch 30/50\n",
      "842/842 [==============================] - 0s 81us/sample - loss: 0.0108 - val_loss: 0.0162\n",
      "Epoch 31/50\n",
      "842/842 [==============================] - 0s 83us/sample - loss: 0.0110 - val_loss: 0.0230\n",
      "Epoch 32/50\n",
      "842/842 [==============================] - 0s 86us/sample - loss: 0.0151 - val_loss: 0.0186\n",
      "Epoch 33/50\n",
      "842/842 [==============================] - 0s 85us/sample - loss: 0.0107 - val_loss: 0.0164\n",
      "Epoch 34/50\n",
      "842/842 [==============================] - 0s 82us/sample - loss: 0.0117 - val_loss: 0.0165\n",
      "Epoch 35/50\n",
      "842/842 [==============================] - 0s 82us/sample - loss: 0.0125 - val_loss: 0.0268\n",
      "Epoch 36/50\n",
      "842/842 [==============================] - 0s 82us/sample - loss: 0.0145 - val_loss: 0.0162\n",
      "Epoch 37/50\n",
      "842/842 [==============================] - 0s 83us/sample - loss: 0.0108 - val_loss: 0.0163\n",
      "Epoch 38/50\n",
      "842/842 [==============================] - 0s 83us/sample - loss: 0.0115 - val_loss: 0.0245\n",
      "Epoch 39/50\n",
      "842/842 [==============================] - 0s 82us/sample - loss: 0.0137 - val_loss: 0.0162\n",
      "Epoch 40/50\n",
      "842/842 [==============================] - 0s 82us/sample - loss: 0.0103 - val_loss: 0.0164\n",
      "Epoch 41/50\n",
      "842/842 [==============================] - 0s 85us/sample - loss: 0.0112 - val_loss: 0.0207\n",
      "Epoch 42/50\n",
      "842/842 [==============================] - 0s 82us/sample - loss: 0.0146 - val_loss: 0.0195\n",
      "Epoch 43/50\n",
      "842/842 [==============================] - 0s 81us/sample - loss: 0.0115 - val_loss: 0.0177\n",
      "Epoch 44/50\n",
      "842/842 [==============================] - 0s 83us/sample - loss: 0.0136 - val_loss: 0.0184\n",
      "Epoch 45/50\n",
      "842/842 [==============================] - 0s 81us/sample - loss: 0.0128 - val_loss: 0.0192\n",
      "Epoch 46/50\n",
      "842/842 [==============================] - 0s 79us/sample - loss: 0.0113 - val_loss: 0.0183\n",
      "Epoch 47/50\n",
      "842/842 [==============================] - 0s 84us/sample - loss: 0.0141 - val_loss: 0.0188\n",
      "Epoch 48/50\n",
      "842/842 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0197\n",
      "Epoch 49/50\n",
      "842/842 [==============================] - 0s 83us/sample - loss: 0.0115 - val_loss: 0.0185\n",
      "Epoch 50/50\n",
      "842/842 [==============================] - 0s 80us/sample - loss: 0.0140 - val_loss: 0.0187\n",
      "第139个数，还剩3984个没有训练\n",
      "inv_hat [1.03914597 1.02992002 1.03102037 1.02942004 1.02274096 1.02254216\n",
      " 1.02313856 1.02582649 1.02333747 1.02542792 1.03052012 1.03212168\n",
      " 1.0314208  1.02154887 1.0211519  1.01768508 1.01926832 1.02085418\n",
      " 1.02453149 1.01778397 1.01580869 1.01364148 1.01089223 1.01050038\n",
      " 1.00903272 1.00952155 1.00932605 1.00883724 1.00815362 1.01010864]\n",
      "Test RMSE: 0.004\n",
      "Train on 542 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "542/542 [==============================] - 0s 89us/sample - loss: 0.0187 - val_loss: 0.0199\n",
      "Epoch 2/50\n",
      "542/542 [==============================] - 0s 89us/sample - loss: 0.0188 - val_loss: 0.0231\n",
      "Epoch 3/50\n",
      "542/542 [==============================] - 0s 92us/sample - loss: 0.0182 - val_loss: 0.0207\n",
      "Epoch 4/50\n",
      "542/542 [==============================] - 0s 88us/sample - loss: 0.0183 - val_loss: 0.0210\n",
      "Epoch 5/50\n",
      "542/542 [==============================] - 0s 95us/sample - loss: 0.0180 - val_loss: 0.0204\n",
      "Epoch 6/50\n",
      "542/542 [==============================] - 0s 86us/sample - loss: 0.0181 - val_loss: 0.0202\n",
      "Epoch 7/50\n",
      "542/542 [==============================] - 0s 90us/sample - loss: 0.0180 - val_loss: 0.0202\n",
      "Epoch 8/50\n",
      "542/542 [==============================] - 0s 93us/sample - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 9/50\n",
      "542/542 [==============================] - 0s 88us/sample - loss: 0.0180 - val_loss: 0.0202\n",
      "Epoch 10/50\n",
      "542/542 [==============================] - 0s 88us/sample - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 11/50\n",
      "542/542 [==============================] - 0s 90us/sample - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 12/50\n",
      "542/542 [==============================] - 0s 89us/sample - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 13/50\n",
      "542/542 [==============================] - 0s 85us/sample - loss: 0.0180 - val_loss: 0.0200\n",
      "Epoch 14/50\n",
      "542/542 [==============================] - 0s 88us/sample - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 15/50\n",
      "542/542 [==============================] - 0s 87us/sample - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 16/50\n",
      "542/542 [==============================] - 0s 89us/sample - loss: 0.0180 - val_loss: 0.0200\n",
      "Epoch 17/50\n",
      "542/542 [==============================] - 0s 89us/sample - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 18/50\n",
      "542/542 [==============================] - 0s 90us/sample - loss: 0.0180 - val_loss: 0.0200\n",
      "Epoch 19/50\n",
      "542/542 [==============================] - 0s 82us/sample - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 20/50\n",
      "542/542 [==============================] - 0s 82us/sample - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 21/50\n",
      "542/542 [==============================] - 0s 87us/sample - loss: 0.0180 - val_loss: 0.0200\n",
      "Epoch 22/50\n",
      "542/542 [==============================] - 0s 89us/sample - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 23/50\n",
      "542/542 [==============================] - 0s 84us/sample - loss: 0.0180 - val_loss: 0.0200\n",
      "Epoch 24/50\n",
      "542/542 [==============================] - 0s 84us/sample - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 25/50\n",
      "542/542 [==============================] - 0s 87us/sample - loss: 0.0180 - val_loss: 0.0200\n",
      "Epoch 26/50\n",
      "542/542 [==============================] - 0s 84us/sample - loss: 0.0180 - val_loss: 0.0202\n",
      "Epoch 27/50\n",
      "542/542 [==============================] - 0s 85us/sample - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 28/50\n",
      "542/542 [==============================] - 0s 84us/sample - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 29/50\n",
      "542/542 [==============================] - 0s 89us/sample - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 30/50\n",
      "542/542 [==============================] - 0s 85us/sample - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 31/50\n",
      "542/542 [==============================] - 0s 88us/sample - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 32/50\n",
      "542/542 [==============================] - 0s 85us/sample - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 33/50\n",
      "542/542 [==============================] - 0s 87us/sample - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 34/50\n",
      "542/542 [==============================] - 0s 81us/sample - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 35/50\n",
      "542/542 [==============================] - 0s 83us/sample - loss: 0.0179 - val_loss: 0.0201\n",
      "Epoch 36/50\n",
      "542/542 [==============================] - 0s 86us/sample - loss: 0.0179 - val_loss: 0.0201\n",
      "Epoch 37/50\n",
      "542/542 [==============================] - 0s 84us/sample - loss: 0.0179 - val_loss: 0.0201\n",
      "Epoch 38/50\n",
      "542/542 [==============================] - 0s 83us/sample - loss: 0.0179 - val_loss: 0.0201\n",
      "Epoch 39/50\n",
      "542/542 [==============================] - 0s 80us/sample - loss: 0.0179 - val_loss: 0.0202\n",
      "Epoch 40/50\n",
      "542/542 [==============================] - 0s 81us/sample - loss: 0.0179 - val_loss: 0.0200\n",
      "Epoch 41/50\n",
      "542/542 [==============================] - 0s 82us/sample - loss: 0.0179 - val_loss: 0.0201\n",
      "Epoch 42/50\n",
      "542/542 [==============================] - 0s 83us/sample - loss: 0.0179 - val_loss: 0.0201\n",
      "Epoch 43/50\n",
      "542/542 [==============================] - 0s 86us/sample - loss: 0.0179 - val_loss: 0.0201\n",
      "Epoch 44/50\n",
      "542/542 [==============================] - 0s 86us/sample - loss: 0.0179 - val_loss: 0.0200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "542/542 [==============================] - 0s 85us/sample - loss: 0.0179 - val_loss: 0.0201\n",
      "Epoch 46/50\n",
      "542/542 [==============================] - 0s 89us/sample - loss: 0.0179 - val_loss: 0.0201\n",
      "Epoch 47/50\n",
      "542/542 [==============================] - 0s 82us/sample - loss: 0.0179 - val_loss: 0.0201\n",
      "Epoch 48/50\n",
      "542/542 [==============================] - 0s 83us/sample - loss: 0.0179 - val_loss: 0.0202\n",
      "Epoch 49/50\n",
      "542/542 [==============================] - 0s 86us/sample - loss: 0.0179 - val_loss: 0.0201\n",
      "Epoch 50/50\n",
      "542/542 [==============================] - 0s 85us/sample - loss: 0.0179 - val_loss: 0.0201\n",
      "第140个数，还剩3983个没有训练\n",
      "inv_hat [0.94591858 0.94177833 0.94217112 0.94197466 0.93719062 0.93719062\n",
      " 0.93787047 0.94050416 0.93738471 0.93933148 0.94522624 0.94473228\n",
      " 0.94453477 0.94138589 0.94187652 0.94187652 0.94266256 0.94236762\n",
      " 0.9443374  0.94011293 0.93796771 0.93738471 0.93486975 0.93554502\n",
      " 0.93515897 0.93748182 0.93767612 0.93641522 0.93486975 0.93554502]\n",
      "Test RMSE: 0.002\n",
      "Train on 498 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "498/498 [==============================] - 0s 83us/sample - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 2/50\n",
      "498/498 [==============================] - 0s 87us/sample - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 3/50\n",
      "498/498 [==============================] - 0s 83us/sample - loss: 0.0060 - val_loss: 0.0031\n",
      "Epoch 4/50\n",
      "498/498 [==============================] - 0s 84us/sample - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 5/50\n",
      "498/498 [==============================] - 0s 80us/sample - loss: 0.0058 - val_loss: 0.0031\n",
      "Epoch 6/50\n",
      "498/498 [==============================] - 0s 83us/sample - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 7/50\n",
      "498/498 [==============================] - 0s 86us/sample - loss: 0.0062 - val_loss: 0.0031\n",
      "Epoch 8/50\n",
      "498/498 [==============================] - 0s 87us/sample - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 9/50\n",
      "498/498 [==============================] - 0s 87us/sample - loss: 0.0068 - val_loss: 0.0031\n",
      "Epoch 10/50\n",
      "498/498 [==============================] - 0s 83us/sample - loss: 0.0070 - val_loss: 0.0035\n",
      "Epoch 11/50\n",
      "498/498 [==============================] - 0s 88us/sample - loss: 0.0082 - val_loss: 0.0037\n",
      "Epoch 12/50\n",
      "498/498 [==============================] - 0s 88us/sample - loss: 0.0077 - val_loss: 0.0037\n",
      "Epoch 13/50\n",
      "498/498 [==============================] - 0s 82us/sample - loss: 0.0076 - val_loss: 0.0032\n",
      "Epoch 14/50\n",
      "498/498 [==============================] - 0s 83us/sample - loss: 0.0074 - val_loss: 0.0038\n",
      "Epoch 15/50\n",
      "498/498 [==============================] - 0s 85us/sample - loss: 0.0073 - val_loss: 0.0031\n",
      "Epoch 16/50\n",
      "498/498 [==============================] - 0s 87us/sample - loss: 0.0073 - val_loss: 0.0035\n",
      "Epoch 17/50\n",
      "498/498 [==============================] - 0s 86us/sample - loss: 0.0073 - val_loss: 0.0033\n",
      "Epoch 18/50\n",
      "498/498 [==============================] - 0s 84us/sample - loss: 0.0071 - val_loss: 0.0032\n",
      "Epoch 19/50\n",
      "498/498 [==============================] - 0s 86us/sample - loss: 0.0071 - val_loss: 0.0032\n",
      "Epoch 20/50\n",
      "498/498 [==============================] - 0s 82us/sample - loss: 0.0072 - val_loss: 0.0032\n",
      "Epoch 21/50\n",
      "498/498 [==============================] - 0s 88us/sample - loss: 0.0071 - val_loss: 0.0033\n",
      "Epoch 22/50\n",
      "498/498 [==============================] - 0s 87us/sample - loss: 0.0072 - val_loss: 0.0032\n",
      "Epoch 23/50\n",
      "498/498 [==============================] - 0s 87us/sample - loss: 0.0070 - val_loss: 0.0034\n",
      "Epoch 24/50\n",
      "498/498 [==============================] - 0s 88us/sample - loss: 0.0072 - val_loss: 0.0032\n",
      "Epoch 25/50\n",
      "498/498 [==============================] - 0s 90us/sample - loss: 0.0068 - val_loss: 0.0033\n",
      "Epoch 26/50\n",
      "498/498 [==============================] - 0s 89us/sample - loss: 0.0070 - val_loss: 0.0032\n",
      "Epoch 27/50\n",
      "498/498 [==============================] - 0s 90us/sample - loss: 0.0068 - val_loss: 0.0033\n",
      "Epoch 28/50\n",
      "498/498 [==============================] - 0s 85us/sample - loss: 0.0069 - val_loss: 0.0031\n",
      "Epoch 29/50\n",
      "498/498 [==============================] - 0s 83us/sample - loss: 0.0067 - val_loss: 0.0032\n",
      "Epoch 30/50\n",
      "498/498 [==============================] - 0s 83us/sample - loss: 0.0071 - val_loss: 0.0032\n",
      "Epoch 31/50\n",
      "498/498 [==============================] - 0s 84us/sample - loss: 0.0068 - val_loss: 0.0035\n",
      "Epoch 32/50\n",
      "498/498 [==============================] - 0s 82us/sample - loss: 0.0068 - val_loss: 0.0031\n",
      "Epoch 33/50\n",
      "498/498 [==============================] - 0s 85us/sample - loss: 0.0066 - val_loss: 0.0035\n",
      "Epoch 34/50\n",
      "498/498 [==============================] - 0s 82us/sample - loss: 0.0068 - val_loss: 0.0031\n",
      "Epoch 35/50\n",
      "498/498 [==============================] - 0s 84us/sample - loss: 0.0067 - val_loss: 0.0036\n",
      "Epoch 36/50\n",
      "498/498 [==============================] - 0s 81us/sample - loss: 0.0069 - val_loss: 0.0031\n",
      "Epoch 37/50\n",
      "498/498 [==============================] - 0s 87us/sample - loss: 0.0065 - val_loss: 0.0036\n",
      "Epoch 38/50\n",
      "498/498 [==============================] - 0s 81us/sample - loss: 0.0069 - val_loss: 0.0031\n",
      "Epoch 39/50\n",
      "498/498 [==============================] - 0s 82us/sample - loss: 0.0065 - val_loss: 0.0036\n",
      "Epoch 40/50\n",
      "498/498 [==============================] - 0s 79us/sample - loss: 0.0068 - val_loss: 0.0031\n",
      "Epoch 41/50\n",
      "498/498 [==============================] - 0s 82us/sample - loss: 0.0066 - val_loss: 0.0038\n",
      "Epoch 42/50\n",
      "498/498 [==============================] - 0s 85us/sample - loss: 0.0070 - val_loss: 0.0031\n",
      "Epoch 43/50\n",
      "498/498 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0038\n",
      "Epoch 44/50\n",
      "498/498 [==============================] - 0s 82us/sample - loss: 0.0068 - val_loss: 0.0031\n",
      "Epoch 45/50\n",
      "498/498 [==============================] - 0s 81us/sample - loss: 0.0063 - val_loss: 0.0037\n",
      "Epoch 46/50\n",
      "498/498 [==============================] - 0s 85us/sample - loss: 0.0067 - val_loss: 0.0031\n",
      "Epoch 47/50\n",
      "498/498 [==============================] - 0s 84us/sample - loss: 0.0064 - val_loss: 0.0037\n",
      "Epoch 48/50\n",
      "498/498 [==============================] - 0s 82us/sample - loss: 0.0071 - val_loss: 0.0031\n",
      "Epoch 49/50\n",
      "498/498 [==============================] - 0s 80us/sample - loss: 0.0064 - val_loss: 0.0043\n",
      "Epoch 50/50\n",
      "498/498 [==============================] - 0s 83us/sample - loss: 0.0068 - val_loss: 0.0031\n",
      "第141个数，还剩3982个没有训练\n",
      "inv_hat [1.07059333 1.07049661 1.07069004 1.07088335 1.07097997 1.07117303\n",
      " 1.07126957 1.07175177 1.07194451 1.07223341 1.07309854 1.07329042\n",
      " 1.07415283 1.07415283 1.07434421 1.07482202 1.07510844 1.07539449\n",
      " 1.07529913 1.07472649 1.07434421 1.07396136 1.07386557 1.07415283\n",
      " 1.07434421 1.07472649 1.07472649 1.07453535 1.07482202 1.07577564]\n",
      "Test RMSE: 0.000\n",
      "Train on 934 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "934/934 [==============================] - 0s 77us/sample - loss: 0.0173 - val_loss: 0.0147\n",
      "Epoch 2/50\n",
      "934/934 [==============================] - 0s 80us/sample - loss: 0.0167 - val_loss: 0.0111\n",
      "Epoch 3/50\n",
      "934/934 [==============================] - 0s 80us/sample - loss: 0.0161 - val_loss: 0.0133\n",
      "Epoch 4/50\n",
      "934/934 [==============================] - 0s 80us/sample - loss: 0.0158 - val_loss: 0.0113\n",
      "Epoch 5/50\n",
      "934/934 [==============================] - 0s 80us/sample - loss: 0.0157 - val_loss: 0.0114\n",
      "Epoch 6/50\n",
      "934/934 [==============================] - 0s 80us/sample - loss: 0.0157 - val_loss: 0.0119\n",
      "Epoch 7/50\n",
      "934/934 [==============================] - 0s 83us/sample - loss: 0.0157 - val_loss: 0.0114\n",
      "Epoch 8/50\n",
      "934/934 [==============================] - 0s 79us/sample - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 9/50\n",
      "934/934 [==============================] - 0s 76us/sample - loss: 0.0156 - val_loss: 0.0117\n",
      "Epoch 10/50\n",
      "934/934 [==============================] - 0s 79us/sample - loss: 0.0156 - val_loss: 0.0114\n",
      "Epoch 11/50\n",
      "934/934 [==============================] - 0s 78us/sample - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 12/50\n",
      "934/934 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0114\n",
      "Epoch 13/50\n",
      "934/934 [==============================] - 0s 77us/sample - loss: 0.0156 - val_loss: 0.0117\n",
      "Epoch 14/50\n",
      "934/934 [==============================] - 0s 80us/sample - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 15/50\n",
      "934/934 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "934/934 [==============================] - 0s 80us/sample - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 17/50\n",
      "934/934 [==============================] - 0s 79us/sample - loss: 0.0156 - val_loss: 0.0116\n",
      "Epoch 18/50\n",
      "934/934 [==============================] - 0s 78us/sample - loss: 0.0156 - val_loss: 0.0116\n",
      "Epoch 19/50\n",
      "934/934 [==============================] - 0s 76us/sample - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 20/50\n",
      "934/934 [==============================] - 0s 88us/sample - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 21/50\n",
      "934/934 [==============================] - 0s 78us/sample - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 22/50\n",
      "934/934 [==============================] - 0s 78us/sample - loss: 0.0156 - val_loss: 0.0116\n",
      "Epoch 23/50\n",
      "934/934 [==============================] - 0s 74us/sample - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 24/50\n",
      "934/934 [==============================] - 0s 78us/sample - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 25/50\n",
      "934/934 [==============================] - 0s 77us/sample - loss: 0.0156 - val_loss: 0.0116\n",
      "Epoch 26/50\n",
      "934/934 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 27/50\n",
      "934/934 [==============================] - 0s 78us/sample - loss: 0.0156 - val_loss: 0.0114\n",
      "Epoch 28/50\n",
      "934/934 [==============================] - 0s 80us/sample - loss: 0.0156 - val_loss: 0.0114\n",
      "Epoch 29/50\n",
      "934/934 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0116\n",
      "Epoch 30/50\n",
      "934/934 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 31/50\n",
      "934/934 [==============================] - 0s 79us/sample - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 32/50\n",
      "934/934 [==============================] - 0s 85us/sample - loss: 0.0156 - val_loss: 0.0114\n",
      "Epoch 33/50\n",
      "934/934 [==============================] - 0s 78us/sample - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 34/50\n",
      "934/934 [==============================] - 0s 78us/sample - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 35/50\n",
      "934/934 [==============================] - 0s 80us/sample - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 36/50\n",
      "934/934 [==============================] - 0s 80us/sample - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 37/50\n",
      "934/934 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 38/50\n",
      "934/934 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 39/50\n",
      "934/934 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 40/50\n",
      "934/934 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 41/50\n",
      "934/934 [==============================] - 0s 80us/sample - loss: 0.0156 - val_loss: 0.0114\n",
      "Epoch 42/50\n",
      "934/934 [==============================] - 0s 80us/sample - loss: 0.0156 - val_loss: 0.0114\n",
      "Epoch 43/50\n",
      "934/934 [==============================] - 0s 79us/sample - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 44/50\n",
      "934/934 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0116\n",
      "Epoch 45/50\n",
      "934/934 [==============================] - 0s 78us/sample - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 46/50\n",
      "934/934 [==============================] - 0s 77us/sample - loss: 0.0156 - val_loss: 0.0114\n",
      "Epoch 47/50\n",
      "934/934 [==============================] - 0s 80us/sample - loss: 0.0156 - val_loss: 0.0114\n",
      "Epoch 48/50\n",
      "934/934 [==============================] - 0s 79us/sample - loss: 0.0156 - val_loss: 0.0114\n",
      "Epoch 49/50\n",
      "934/934 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 50/50\n",
      "934/934 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0116\n",
      "第142个数，还剩3981个没有训练\n",
      "inv_hat [0.82940094 0.80527069 0.80537113 0.79663487 0.78139033 0.78239249\n",
      " 0.7829938  0.79583191 0.78058877 0.7886082  0.8087871  0.81109847\n",
      " 0.80185575 0.78469774 0.78570028 0.77497986 0.77688242 0.78028816\n",
      " 0.78900938 0.77217708 0.77097626 0.76227762 0.7555866  0.75159556\n",
      " 0.740635   0.73715237 0.72920127 0.7218587  0.71967813 0.7218587 ]\n",
      "Test RMSE: 0.010\n",
      "Train on 880 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "880/880 [==============================] - 0s 86us/sample - loss: 0.0174 - val_loss: 0.0104\n",
      "Epoch 2/50\n",
      "880/880 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0111\n",
      "Epoch 3/50\n",
      "880/880 [==============================] - 0s 85us/sample - loss: 0.0173 - val_loss: 0.0110\n",
      "Epoch 4/50\n",
      "880/880 [==============================] - 0s 83us/sample - loss: 0.0174 - val_loss: 0.0114\n",
      "Epoch 5/50\n",
      "880/880 [==============================] - 0s 80us/sample - loss: 0.0173 - val_loss: 0.0110\n",
      "Epoch 6/50\n",
      "880/880 [==============================] - 0s 81us/sample - loss: 0.0174 - val_loss: 0.0115\n",
      "Epoch 7/50\n",
      "880/880 [==============================] - 0s 80us/sample - loss: 0.0173 - val_loss: 0.0111\n",
      "Epoch 8/50\n",
      "880/880 [==============================] - 0s 81us/sample - loss: 0.0174 - val_loss: 0.0117\n",
      "Epoch 9/50\n",
      "880/880 [==============================] - 0s 81us/sample - loss: 0.0173 - val_loss: 0.0112\n",
      "Epoch 10/50\n",
      "880/880 [==============================] - 0s 79us/sample - loss: 0.0174 - val_loss: 0.0118\n",
      "Epoch 11/50\n",
      "880/880 [==============================] - 0s 81us/sample - loss: 0.0173 - val_loss: 0.0113\n",
      "Epoch 12/50\n",
      "880/880 [==============================] - 0s 82us/sample - loss: 0.0174 - val_loss: 0.0118\n",
      "Epoch 13/50\n",
      "880/880 [==============================] - 0s 83us/sample - loss: 0.0173 - val_loss: 0.0113\n",
      "Epoch 14/50\n",
      "880/880 [==============================] - 0s 84us/sample - loss: 0.0174 - val_loss: 0.0117\n",
      "Epoch 15/50\n",
      "880/880 [==============================] - 0s 84us/sample - loss: 0.0173 - val_loss: 0.0116\n",
      "Epoch 16/50\n",
      "880/880 [==============================] - 0s 87us/sample - loss: 0.0174 - val_loss: 0.0116\n",
      "Epoch 17/50\n",
      "880/880 [==============================] - 0s 85us/sample - loss: 0.0174 - val_loss: 0.0116\n",
      "Epoch 18/50\n",
      "880/880 [==============================] - 0s 84us/sample - loss: 0.0174 - val_loss: 0.0119\n",
      "Epoch 19/50\n",
      "880/880 [==============================] - 0s 85us/sample - loss: 0.0173 - val_loss: 0.0117\n",
      "Epoch 20/50\n",
      "880/880 [==============================] - 0s 84us/sample - loss: 0.0174 - val_loss: 0.0117\n",
      "Epoch 21/50\n",
      "880/880 [==============================] - 0s 83us/sample - loss: 0.0173 - val_loss: 0.0116\n",
      "Epoch 22/50\n",
      "880/880 [==============================] - 0s 83us/sample - loss: 0.0174 - val_loss: 0.0120\n",
      "Epoch 23/50\n",
      "880/880 [==============================] - 0s 82us/sample - loss: 0.0173 - val_loss: 0.0118\n",
      "Epoch 24/50\n",
      "880/880 [==============================] - 0s 82us/sample - loss: 0.0174 - val_loss: 0.0119\n",
      "Epoch 25/50\n",
      "880/880 [==============================] - 0s 84us/sample - loss: 0.0174 - val_loss: 0.0121\n",
      "Epoch 26/50\n",
      "880/880 [==============================] - 0s 82us/sample - loss: 0.0173 - val_loss: 0.0121\n",
      "Epoch 27/50\n",
      "880/880 [==============================] - 0s 82us/sample - loss: 0.0173 - val_loss: 0.0118\n",
      "Epoch 28/50\n",
      "880/880 [==============================] - 0s 87us/sample - loss: 0.0174 - val_loss: 0.0123\n",
      "Epoch 29/50\n",
      "880/880 [==============================] - 0s 88us/sample - loss: 0.0173 - val_loss: 0.0120\n",
      "Epoch 30/50\n",
      "880/880 [==============================] - 0s 86us/sample - loss: 0.0173 - val_loss: 0.0119\n",
      "Epoch 31/50\n",
      "880/880 [==============================] - 0s 85us/sample - loss: 0.0174 - val_loss: 0.0124\n",
      "Epoch 32/50\n",
      "880/880 [==============================] - 0s 85us/sample - loss: 0.0173 - val_loss: 0.0120\n",
      "Epoch 33/50\n",
      "880/880 [==============================] - 0s 86us/sample - loss: 0.0174 - val_loss: 0.0124\n",
      "Epoch 34/50\n",
      "880/880 [==============================] - 0s 82us/sample - loss: 0.0173 - val_loss: 0.0122\n",
      "Epoch 35/50\n",
      "880/880 [==============================] - 0s 84us/sample - loss: 0.0174 - val_loss: 0.0125\n",
      "Epoch 36/50\n",
      "880/880 [==============================] - 0s 82us/sample - loss: 0.0173 - val_loss: 0.0122\n",
      "Epoch 37/50\n",
      "880/880 [==============================] - 0s 82us/sample - loss: 0.0174 - val_loss: 0.0125\n",
      "Epoch 38/50\n",
      "880/880 [==============================] - 0s 86us/sample - loss: 0.0174 - val_loss: 0.0125\n",
      "Epoch 39/50\n",
      "880/880 [==============================] - 0s 82us/sample - loss: 0.0174 - val_loss: 0.0126\n",
      "Epoch 40/50\n",
      "880/880 [==============================] - 0s 81us/sample - loss: 0.0174 - val_loss: 0.0124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "880/880 [==============================] - 0s 81us/sample - loss: 0.0174 - val_loss: 0.0128\n",
      "Epoch 42/50\n",
      "880/880 [==============================] - 0s 88us/sample - loss: 0.0173 - val_loss: 0.0122\n",
      "Epoch 43/50\n",
      "880/880 [==============================] - 0s 88us/sample - loss: 0.0174 - val_loss: 0.0122\n",
      "Epoch 44/50\n",
      "880/880 [==============================] - 0s 85us/sample - loss: 0.0174 - val_loss: 0.0126\n",
      "Epoch 45/50\n",
      "880/880 [==============================] - 0s 83us/sample - loss: 0.0173 - val_loss: 0.0123\n",
      "Epoch 46/50\n",
      "880/880 [==============================] - 0s 84us/sample - loss: 0.0174 - val_loss: 0.0125\n",
      "Epoch 47/50\n",
      "880/880 [==============================] - 0s 86us/sample - loss: 0.0174 - val_loss: 0.0127\n",
      "Epoch 48/50\n",
      "880/880 [==============================] - 0s 84us/sample - loss: 0.0173 - val_loss: 0.0122\n",
      "Epoch 49/50\n",
      "880/880 [==============================] - 0s 83us/sample - loss: 0.0174 - val_loss: 0.0126\n",
      "Epoch 50/50\n",
      "880/880 [==============================] - 0s 86us/sample - loss: 0.0173 - val_loss: 0.0124\n",
      "第143个数，还剩3980个没有训练\n",
      "inv_hat [0.9576724  0.93333576 0.93527705 0.93527705 0.90626902 0.90434402\n",
      " 0.90723193 0.91784278 0.90434402 0.91012242 0.93333576 0.93624814\n",
      " 0.93139542 0.91591104 0.91591104 0.9053064  0.91108647 0.91301543\n",
      " 0.92364469 0.90723193 0.9014588  0.89665596 0.88898718 0.88994468\n",
      " 0.88516022 0.89569626 0.88994468 0.88898718 0.88324867 0.88420429]\n",
      "Test RMSE: 0.012\n",
      "Train on 870 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "870/870 [==============================] - 0s 94us/sample - loss: 0.0083 - val_loss: 0.0047\n",
      "Epoch 2/50\n",
      "870/870 [==============================] - 0s 88us/sample - loss: 0.0086 - val_loss: 0.0030\n",
      "Epoch 3/50\n",
      "870/870 [==============================] - 0s 84us/sample - loss: 0.0089 - val_loss: 0.0032\n",
      "Epoch 4/50\n",
      "870/870 [==============================] - 0s 89us/sample - loss: 0.0079 - val_loss: 0.0027\n",
      "Epoch 5/50\n",
      "870/870 [==============================] - 0s 86us/sample - loss: 0.0060 - val_loss: 0.0035\n",
      "Epoch 6/50\n",
      "870/870 [==============================] - 0s 88us/sample - loss: 0.0138 - val_loss: 0.0232\n",
      "Epoch 7/50\n",
      "870/870 [==============================] - 0s 89us/sample - loss: 0.0136 - val_loss: 0.0118\n",
      "Epoch 8/50\n",
      "870/870 [==============================] - 0s 90us/sample - loss: 0.0076 - val_loss: 0.0041\n",
      "Epoch 9/50\n",
      "870/870 [==============================] - 0s 88us/sample - loss: 0.0128 - val_loss: 0.0096\n",
      "Epoch 10/50\n",
      "870/870 [==============================] - 0s 88us/sample - loss: 0.0090 - val_loss: 0.0055\n",
      "Epoch 11/50\n",
      "870/870 [==============================] - 0s 90us/sample - loss: 0.0211 - val_loss: 0.0114\n",
      "Epoch 12/50\n",
      "870/870 [==============================] - 0s 94us/sample - loss: 0.0179 - val_loss: 0.0121\n",
      "Epoch 13/50\n",
      "870/870 [==============================] - 0s 90us/sample - loss: 0.0121 - val_loss: 0.0076\n",
      "Epoch 14/50\n",
      "870/870 [==============================] - 0s 89us/sample - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 15/50\n",
      "870/870 [==============================] - 0s 91us/sample - loss: 0.0193 - val_loss: 0.0052\n",
      "Epoch 16/50\n",
      "870/870 [==============================] - 0s 87us/sample - loss: 0.0154 - val_loss: 0.0108\n",
      "Epoch 17/50\n",
      "870/870 [==============================] - 0s 86us/sample - loss: 0.0155 - val_loss: 0.0026\n",
      "Epoch 18/50\n",
      "870/870 [==============================] - 0s 87us/sample - loss: 0.0119 - val_loss: 0.0129\n",
      "Epoch 19/50\n",
      "870/870 [==============================] - 0s 86us/sample - loss: 0.0171 - val_loss: 0.0031\n",
      "Epoch 20/50\n",
      "870/870 [==============================] - 0s 87us/sample - loss: 0.0104 - val_loss: 0.0056\n",
      "Epoch 21/50\n",
      "870/870 [==============================] - 0s 85us/sample - loss: 0.0150 - val_loss: 0.0032\n",
      "Epoch 22/50\n",
      "870/870 [==============================] - 0s 87us/sample - loss: 0.0144 - val_loss: 0.0127\n",
      "Epoch 23/50\n",
      "870/870 [==============================] - 0s 90us/sample - loss: 0.0150 - val_loss: 0.0033\n",
      "Epoch 24/50\n",
      "870/870 [==============================] - 0s 86us/sample - loss: 0.0075 - val_loss: 0.0041\n",
      "Epoch 25/50\n",
      "870/870 [==============================] - 0s 83us/sample - loss: 0.0139 - val_loss: 0.0048\n",
      "Epoch 26/50\n",
      "870/870 [==============================] - 0s 87us/sample - loss: 0.0129 - val_loss: 0.0108\n",
      "Epoch 27/50\n",
      "870/870 [==============================] - 0s 87us/sample - loss: 0.0154 - val_loss: 0.0042\n",
      "Epoch 28/50\n",
      "870/870 [==============================] - 0s 86us/sample - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 29/50\n",
      "870/870 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0031\n",
      "Epoch 30/50\n",
      "870/870 [==============================] - 0s 86us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 31/50\n",
      "870/870 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0030\n",
      "Epoch 32/50\n",
      "870/870 [==============================] - 0s 81us/sample - loss: 0.0085 - val_loss: 0.0059\n",
      "Epoch 33/50\n",
      "870/870 [==============================] - 0s 82us/sample - loss: 0.0128 - val_loss: 0.0045\n",
      "Epoch 34/50\n",
      "870/870 [==============================] - 0s 84us/sample - loss: 0.0112 - val_loss: 0.0073\n",
      "Epoch 35/50\n",
      "870/870 [==============================] - 0s 82us/sample - loss: 0.0123 - val_loss: 0.0030\n",
      "Epoch 36/50\n",
      "870/870 [==============================] - 0s 81us/sample - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 37/50\n",
      "870/870 [==============================] - 0s 84us/sample - loss: 0.0136 - val_loss: 0.0030\n",
      "Epoch 38/50\n",
      "870/870 [==============================] - 0s 92us/sample - loss: 0.0105 - val_loss: 0.0067\n",
      "Epoch 39/50\n",
      "870/870 [==============================] - 0s 91us/sample - loss: 0.0131 - val_loss: 0.0032\n",
      "Epoch 40/50\n",
      "870/870 [==============================] - 0s 90us/sample - loss: 0.0080 - val_loss: 0.0065\n",
      "Epoch 41/50\n",
      "870/870 [==============================] - 0s 91us/sample - loss: 0.0116 - val_loss: 0.0043\n",
      "Epoch 42/50\n",
      "870/870 [==============================] - 0s 88us/sample - loss: 0.0083 - val_loss: 0.0034\n",
      "Epoch 43/50\n",
      "870/870 [==============================] - 0s 89us/sample - loss: 0.0119 - val_loss: 0.0046\n",
      "Epoch 44/50\n",
      "870/870 [==============================] - 0s 89us/sample - loss: 0.0119 - val_loss: 0.0109\n",
      "Epoch 45/50\n",
      "870/870 [==============================] - 0s 89us/sample - loss: 0.0125 - val_loss: 0.0026\n",
      "Epoch 46/50\n",
      "870/870 [==============================] - 0s 87us/sample - loss: 0.0082 - val_loss: 0.0048\n",
      "Epoch 47/50\n",
      "870/870 [==============================] - 0s 88us/sample - loss: 0.0127 - val_loss: 0.0026\n",
      "Epoch 48/50\n",
      "870/870 [==============================] - 0s 90us/sample - loss: 0.0094 - val_loss: 0.0083\n",
      "Epoch 49/50\n",
      "870/870 [==============================] - 0s 88us/sample - loss: 0.0121 - val_loss: 0.0030\n",
      "Epoch 50/50\n",
      "870/870 [==============================] - 0s 84us/sample - loss: 0.0091 - val_loss: 0.0054\n",
      "第144个数，还剩3979个没有训练\n",
      "inv_hat [1.13205971 1.13264369 1.13264369 1.13264369 1.13283813 1.13283813\n",
      " 1.13283813 1.13264369 1.13303261 1.13303261 1.13312982 1.13390676\n",
      " 1.13448867 1.13516671 1.13574717 1.13594053 1.13603718 1.1364235\n",
      " 1.13565044 1.13487629 1.13419773 1.13351838 1.13380968 1.13419773\n",
      " 1.13448867 1.13506989 1.13545708 1.13565044 1.13613382 1.13719537]\n",
      "Test RMSE: 0.001\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0124 - val_loss: 0.0066\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0125 - val_loss: 0.0059\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0123 - val_loss: 0.0062\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0120 - val_loss: 0.0062\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0119 - val_loss: 0.0060\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0119 - val_loss: 0.0059\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0119 - val_loss: 0.0060\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0120 - val_loss: 0.0063\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0120 - val_loss: 0.0061\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0120 - val_loss: 0.0061\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0119 - val_loss: 0.0060\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0120 - val_loss: 0.0061\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0119 - val_loss: 0.0060\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0119 - val_loss: 0.0060\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0120 - val_loss: 0.0061\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0120 - val_loss: 0.0061\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0120 - val_loss: 0.0061\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0120 - val_loss: 0.0061\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0119 - val_loss: 0.0060\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0120 - val_loss: 0.0061\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0120 - val_loss: 0.0061\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0120 - val_loss: 0.0061\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0120 - val_loss: 0.0061\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0120 - val_loss: 0.0061\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0120 - val_loss: 0.0061\n",
      "第145个数，还剩3978个没有训练\n",
      "inv_hat [1.19633228 1.16803369 1.17376712 1.16773729 1.14581931 1.14404399\n",
      " 1.13921283 1.15460107 1.14079014 1.15173881 1.18177884 1.1816799\n",
      " 1.17574477 1.1531205  1.15578575 1.14207186 1.15173881 1.15410757\n",
      " 1.17376712 1.15746406 1.15272577 1.14226909 1.13004933 1.12679956\n",
      " 1.115581   1.12099205 1.11981116 1.11676142 1.11282742 1.11567938]\n",
      "Test RMSE: 0.013\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0130 - val_loss: 0.0127\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0136 - val_loss: 0.0123\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0146 - val_loss: 0.0154\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0138 - val_loss: 0.0127\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0121\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0130 - val_loss: 0.0125\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0131 - val_loss: 0.0131\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0131 - val_loss: 0.0127\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0129 - val_loss: 0.0124\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0124\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0130 - val_loss: 0.0126\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0129 - val_loss: 0.0126\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0129 - val_loss: 0.0124\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0130 - val_loss: 0.0126\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0129 - val_loss: 0.0124\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0129 - val_loss: 0.0126\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0129 - val_loss: 0.0124\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0130 - val_loss: 0.0125\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0129 - val_loss: 0.0126\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0130 - val_loss: 0.0125\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0130 - val_loss: 0.0125\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0130 - val_loss: 0.0125\n",
      "第146个数，还剩3977个没有训练\n",
      "inv_hat [4.0815415  4.00267503 4.03440806 4.04057438 3.94764155 3.93659168\n",
      " 3.92982215 3.98486458 3.94833838 3.99093436 4.13600504 4.15438453\n",
      " 4.16163561 4.04504999 3.98824768 3.95202154 3.99103371 4.00357026\n",
      " 4.07030681 4.00665422 3.98158041 3.95431093 3.88799902 3.86847615\n",
      " 3.82364156 3.87873607 3.86887464 3.85104236 3.84526388 3.88750088]\n",
      "Test RMSE: 0.054\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0116 - val_loss: 0.0079\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0117 - val_loss: 0.0079\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0120 - val_loss: 0.0087\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0120 - val_loss: 0.0084\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0115 - val_loss: 0.0081\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0118 - val_loss: 0.0081\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0120 - val_loss: 0.0090\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0130 - val_loss: 0.0095\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0116 - val_loss: 0.0082\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0084\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0120 - val_loss: 0.0087\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0138 - val_loss: 0.0109\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0121 - val_loss: 0.0081\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0124 - val_loss: 0.0088\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 87us/sample - loss: 0.0121 - val_loss: 0.0085\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0137 - val_loss: 0.0115\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0122 - val_loss: 0.0081\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0124 - val_loss: 0.0091\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0121 - val_loss: 0.0087\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0138 - val_loss: 0.0117\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0121 - val_loss: 0.0082\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0091\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0138 - val_loss: 0.0119\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0121 - val_loss: 0.0082\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0090\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0121 - val_loss: 0.0089\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0137 - val_loss: 0.0116\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0119 - val_loss: 0.0084\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0126 - val_loss: 0.0088\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0121 - val_loss: 0.0091\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0136 - val_loss: 0.0113\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0118 - val_loss: 0.0084\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0126 - val_loss: 0.0087\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0122 - val_loss: 0.0094\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0135 - val_loss: 0.0108\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0117 - val_loss: 0.0085\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0126 - val_loss: 0.0085\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0097\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0134 - val_loss: 0.0102\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0116 - val_loss: 0.0085\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0125 - val_loss: 0.0084\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0116 - val_loss: 0.0085\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0124 - val_loss: 0.0083\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0122 - val_loss: 0.0099\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0094\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0115 - val_loss: 0.0085\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0123 - val_loss: 0.0082\n",
      "第147个数，还剩3976个没有训练\n",
      "inv_hat [1.6940401  1.6555794  1.68023323 1.68319174 1.63881623 1.62797015\n",
      " 1.62994206 1.65163502 1.6358582  1.64867678 1.69897133 1.71277925\n",
      " 1.72658761 1.67628835 1.64177433 1.61613851 1.62501222 1.62205426\n",
      " 1.63684417 1.60135015 1.57867666 1.57867666 1.54910714 1.55107819\n",
      " 1.53925185 1.5658625  1.56881953 1.55994872 1.5500927  1.55403498]\n",
      "Test RMSE: 0.023\n",
      "Train on 746 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "746/746 [==============================] - 0s 89us/sample - loss: 0.0199 - val_loss: 0.0067\n",
      "Epoch 2/50\n",
      "746/746 [==============================] - 0s 89us/sample - loss: 0.0311 - val_loss: 0.0208\n",
      "Epoch 3/50\n",
      "746/746 [==============================] - 0s 81us/sample - loss: 0.0191 - val_loss: 0.0146\n",
      "Epoch 4/50\n",
      "746/746 [==============================] - 0s 81us/sample - loss: 0.0221 - val_loss: 0.0059\n",
      "Epoch 5/50\n",
      "746/746 [==============================] - 0s 80us/sample - loss: 0.0148 - val_loss: 0.0067\n",
      "Epoch 6/50\n",
      "746/746 [==============================] - 0s 81us/sample - loss: 0.0236 - val_loss: 0.0159\n",
      "Epoch 7/50\n",
      "746/746 [==============================] - 0s 81us/sample - loss: 0.0150 - val_loss: 0.0053\n",
      "Epoch 8/50\n",
      "746/746 [==============================] - 0s 80us/sample - loss: 0.0143 - val_loss: 0.0064\n",
      "Epoch 9/50\n",
      "746/746 [==============================] - 0s 80us/sample - loss: 0.0177 - val_loss: 0.0106\n",
      "Epoch 10/50\n",
      "746/746 [==============================] - 0s 77us/sample - loss: 0.0168 - val_loss: 0.0050\n",
      "Epoch 11/50\n",
      "746/746 [==============================] - 0s 79us/sample - loss: 0.0133 - val_loss: 0.0054\n",
      "Epoch 12/50\n",
      "746/746 [==============================] - 0s 82us/sample - loss: 0.0201 - val_loss: 0.0103\n",
      "Epoch 13/50\n",
      "746/746 [==============================] - 0s 85us/sample - loss: 0.0130 - val_loss: 0.0053\n",
      "Epoch 14/50\n",
      "746/746 [==============================] - 0s 88us/sample - loss: 0.0132 - val_loss: 0.0053\n",
      "Epoch 15/50\n",
      "746/746 [==============================] - 0s 85us/sample - loss: 0.0128 - val_loss: 0.0053\n",
      "Epoch 16/50\n",
      "746/746 [==============================] - 0s 85us/sample - loss: 0.0128 - val_loss: 0.0057\n",
      "Epoch 17/50\n",
      "746/746 [==============================] - 0s 84us/sample - loss: 0.0151 - val_loss: 0.0049\n",
      "Epoch 18/50\n",
      "746/746 [==============================] - 0s 84us/sample - loss: 0.0125 - val_loss: 0.0050\n",
      "Epoch 19/50\n",
      "746/746 [==============================] - 0s 81us/sample - loss: 0.0149 - val_loss: 0.0053\n",
      "Epoch 20/50\n",
      "746/746 [==============================] - 0s 85us/sample - loss: 0.0133 - val_loss: 0.0071\n",
      "Epoch 21/50\n",
      "746/746 [==============================] - 0s 82us/sample - loss: 0.0162 - val_loss: 0.0068\n",
      "Epoch 22/50\n",
      "746/746 [==============================] - 0s 80us/sample - loss: 0.0160 - val_loss: 0.0066\n",
      "Epoch 23/50\n",
      "746/746 [==============================] - 0s 90us/sample - loss: 0.0143 - val_loss: 0.0082\n",
      "Epoch 24/50\n",
      "746/746 [==============================] - 0s 84us/sample - loss: 0.0176 - val_loss: 0.0066\n",
      "Epoch 25/50\n",
      "746/746 [==============================] - 0s 83us/sample - loss: 0.0131 - val_loss: 0.0053\n",
      "Epoch 26/50\n",
      "746/746 [==============================] - 0s 88us/sample - loss: 0.0157 - val_loss: 0.0100\n",
      "Epoch 27/50\n",
      "746/746 [==============================] - 0s 90us/sample - loss: 0.0139 - val_loss: 0.0050\n",
      "Epoch 28/50\n",
      "746/746 [==============================] - 0s 86us/sample - loss: 0.0121 - val_loss: 0.0061\n",
      "Epoch 29/50\n",
      "746/746 [==============================] - 0s 88us/sample - loss: 0.0125 - val_loss: 0.0065\n",
      "Epoch 30/50\n",
      "746/746 [==============================] - 0s 84us/sample - loss: 0.0119 - val_loss: 0.0056\n",
      "Epoch 31/50\n",
      "746/746 [==============================] - 0s 87us/sample - loss: 0.0120 - val_loss: 0.0062\n",
      "Epoch 32/50\n",
      "746/746 [==============================] - 0s 87us/sample - loss: 0.0120 - val_loss: 0.0060\n",
      "Epoch 33/50\n",
      "746/746 [==============================] - 0s 88us/sample - loss: 0.0121 - val_loss: 0.0059\n",
      "Epoch 34/50\n",
      "746/746 [==============================] - 0s 84us/sample - loss: 0.0119 - val_loss: 0.0053\n",
      "Epoch 35/50\n",
      "746/746 [==============================] - 0s 91us/sample - loss: 0.0121 - val_loss: 0.0050\n",
      "Epoch 36/50\n",
      "746/746 [==============================] - 0s 87us/sample - loss: 0.0122 - val_loss: 0.0059\n",
      "Epoch 37/50\n",
      "746/746 [==============================] - 0s 89us/sample - loss: 0.0128 - val_loss: 0.0054\n",
      "Epoch 38/50\n",
      "746/746 [==============================] - 0s 84us/sample - loss: 0.0132 - val_loss: 0.0052\n",
      "Epoch 39/50\n",
      "746/746 [==============================] - 0s 85us/sample - loss: 0.0127 - val_loss: 0.0060\n",
      "Epoch 40/50\n",
      "746/746 [==============================] - 0s 84us/sample - loss: 0.0144 - val_loss: 0.0050\n",
      "Epoch 41/50\n",
      "746/746 [==============================] - 0s 87us/sample - loss: 0.0130 - val_loss: 0.0051\n",
      "Epoch 42/50\n",
      "746/746 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0088\n",
      "Epoch 43/50\n",
      "746/746 [==============================] - 0s 79us/sample - loss: 0.0145 - val_loss: 0.0049\n",
      "Epoch 44/50\n",
      "746/746 [==============================] - 0s 87us/sample - loss: 0.0142 - val_loss: 0.0051\n",
      "Epoch 45/50\n",
      "746/746 [==============================] - 0s 89us/sample - loss: 0.0163 - val_loss: 0.0108\n",
      "Epoch 46/50\n",
      "746/746 [==============================] - 0s 91us/sample - loss: 0.0146 - val_loss: 0.0055\n",
      "Epoch 47/50\n",
      "746/746 [==============================] - 0s 90us/sample - loss: 0.0131 - val_loss: 0.0050\n",
      "Epoch 48/50\n",
      "746/746 [==============================] - 0s 87us/sample - loss: 0.0148 - val_loss: 0.0086\n",
      "Epoch 49/50\n",
      "746/746 [==============================] - 0s 84us/sample - loss: 0.0139 - val_loss: 0.0056\n",
      "Epoch 50/50\n",
      "746/746 [==============================] - 0s 80us/sample - loss: 0.0126 - val_loss: 0.0051\n",
      "第148个数，还剩3975个没有训练\n",
      "inv_hat [1.11390867 1.11390867 1.11390867 1.11296729 1.11296729 1.11296729\n",
      " 1.11296729 1.11390867 1.11390867 1.1148483  1.116722   1.1176561\n",
      " 1.1176561  1.116722   1.116722   1.116722   1.1176561  1.1176561\n",
      " 1.11858822 1.11578614 1.11578614 1.11390867 1.11202404 1.11202404\n",
      " 1.11107902 1.11107902 1.11107902 1.11107902 1.11107902 1.11202404]\n",
      "Test RMSE: 0.001\n",
      "Train on 701 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "701/701 [==============================] - 0s 79us/sample - loss: 0.0129 - val_loss: 0.0105\n",
      "Epoch 2/50\n",
      "701/701 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0044\n",
      "Epoch 3/50\n",
      "701/701 [==============================] - 0s 79us/sample - loss: 0.0120 - val_loss: 0.0057\n",
      "Epoch 4/50\n",
      "701/701 [==============================] - 0s 78us/sample - loss: 0.0119 - val_loss: 0.0052\n",
      "Epoch 5/50\n",
      "701/701 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0041\n",
      "Epoch 6/50\n",
      "701/701 [==============================] - 0s 85us/sample - loss: 0.0118 - val_loss: 0.0046\n",
      "Epoch 7/50\n",
      "701/701 [==============================] - 0s 89us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 8/50\n",
      "701/701 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 9/50\n",
      "701/701 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 10/50\n",
      "701/701 [==============================] - 0s 84us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 11/50\n",
      "701/701 [==============================] - 0s 84us/sample - loss: 0.0118 - val_loss: 0.0045\n",
      "Epoch 12/50\n",
      "701/701 [==============================] - 0s 81us/sample - loss: 0.0118 - val_loss: 0.0046\n",
      "Epoch 13/50\n",
      "701/701 [==============================] - 0s 85us/sample - loss: 0.0118 - val_loss: 0.0044\n",
      "Epoch 14/50\n",
      "701/701 [==============================] - 0s 83us/sample - loss: 0.0118 - val_loss: 0.0046\n",
      "Epoch 15/50\n",
      "701/701 [==============================] - 0s 81us/sample - loss: 0.0118 - val_loss: 0.0046\n",
      "Epoch 16/50\n",
      "701/701 [==============================] - 0s 82us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 17/50\n",
      "701/701 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0045\n",
      "Epoch 18/50\n",
      "701/701 [==============================] - 0s 83us/sample - loss: 0.0118 - val_loss: 0.0045\n",
      "Epoch 19/50\n",
      "701/701 [==============================] - 0s 83us/sample - loss: 0.0118 - val_loss: 0.0045\n",
      "Epoch 20/50\n",
      "701/701 [==============================] - 0s 82us/sample - loss: 0.0118 - val_loss: 0.0043\n",
      "Epoch 21/50\n",
      "701/701 [==============================] - 0s 84us/sample - loss: 0.0118 - val_loss: 0.0045\n",
      "Epoch 22/50\n",
      "701/701 [==============================] - 0s 81us/sample - loss: 0.0118 - val_loss: 0.0043\n",
      "Epoch 23/50\n",
      "701/701 [==============================] - 0s 77us/sample - loss: 0.0118 - val_loss: 0.0045\n",
      "Epoch 24/50\n",
      "701/701 [==============================] - 0s 84us/sample - loss: 0.0118 - val_loss: 0.0043\n",
      "Epoch 25/50\n",
      "701/701 [==============================] - 0s 83us/sample - loss: 0.0118 - val_loss: 0.0044\n",
      "Epoch 26/50\n",
      "701/701 [==============================] - 0s 81us/sample - loss: 0.0118 - val_loss: 0.0044\n",
      "Epoch 27/50\n",
      "701/701 [==============================] - 0s 81us/sample - loss: 0.0118 - val_loss: 0.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "701/701 [==============================] - 0s 85us/sample - loss: 0.0118 - val_loss: 0.0039\n",
      "Epoch 29/50\n",
      "701/701 [==============================] - 0s 83us/sample - loss: 0.0118 - val_loss: 0.0040\n",
      "Epoch 30/50\n",
      "701/701 [==============================] - 0s 86us/sample - loss: 0.0118 - val_loss: 0.0042\n",
      "Epoch 31/50\n",
      "701/701 [==============================] - 0s 84us/sample - loss: 0.0118 - val_loss: 0.0039\n",
      "Epoch 32/50\n",
      "701/701 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0043\n",
      "Epoch 33/50\n",
      "701/701 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0040\n",
      "Epoch 34/50\n",
      "701/701 [==============================] - 0s 85us/sample - loss: 0.0118 - val_loss: 0.0040\n",
      "Epoch 35/50\n",
      "701/701 [==============================] - 0s 83us/sample - loss: 0.0118 - val_loss: 0.0039\n",
      "Epoch 36/50\n",
      "701/701 [==============================] - 0s 84us/sample - loss: 0.0118 - val_loss: 0.0040\n",
      "Epoch 37/50\n",
      "701/701 [==============================] - 0s 82us/sample - loss: 0.0118 - val_loss: 0.0040\n",
      "Epoch 38/50\n",
      "701/701 [==============================] - 0s 83us/sample - loss: 0.0118 - val_loss: 0.0041\n",
      "Epoch 39/50\n",
      "701/701 [==============================] - 0s 81us/sample - loss: 0.0118 - val_loss: 0.0039\n",
      "Epoch 40/50\n",
      "701/701 [==============================] - 0s 82us/sample - loss: 0.0118 - val_loss: 0.0038\n",
      "Epoch 41/50\n",
      "701/701 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0039\n",
      "Epoch 42/50\n",
      "701/701 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0038\n",
      "Epoch 43/50\n",
      "701/701 [==============================] - 0s 84us/sample - loss: 0.0118 - val_loss: 0.0038\n",
      "Epoch 44/50\n",
      "701/701 [==============================] - 0s 84us/sample - loss: 0.0118 - val_loss: 0.0038\n",
      "Epoch 45/50\n",
      "701/701 [==============================] - 0s 81us/sample - loss: 0.0118 - val_loss: 0.0037\n",
      "Epoch 46/50\n",
      "701/701 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0037\n",
      "Epoch 47/50\n",
      "701/701 [==============================] - 0s 82us/sample - loss: 0.0118 - val_loss: 0.0037\n",
      "Epoch 48/50\n",
      "701/701 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0038\n",
      "Epoch 49/50\n",
      "701/701 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0037\n",
      "Epoch 50/50\n",
      "701/701 [==============================] - 0s 81us/sample - loss: 0.0118 - val_loss: 0.0037\n",
      "第149个数，还剩3974个没有训练\n",
      "inv_hat [1.07980906 1.07912285 1.07931891 1.07951503 1.07961305 1.07961305\n",
      " 1.07961305 1.08010281 1.08000499 1.08049437 1.08029861 1.08078773\n",
      " 1.08098329 1.08088551 1.07980906 1.08010281 1.08010281 1.07980906\n",
      " 1.08000499 1.07986929 1.07957831 1.07967537 1.07967537 1.07957831\n",
      " 1.07948123 1.07967537 1.07967537 1.07967537 1.0797724  1.07981357]\n",
      "Test RMSE: 0.000\n",
      "Train on 1193 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0108 - val_loss: 0.0302\n",
      "Epoch 2/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0299\n",
      "Epoch 3/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0083 - val_loss: 0.0292\n",
      "Epoch 4/50\n",
      "1193/1193 [==============================] - 0s 86us/sample - loss: 0.0072 - val_loss: 0.0303\n",
      "Epoch 5/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0078 - val_loss: 0.0295\n",
      "Epoch 6/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0085 - val_loss: 0.0302\n",
      "Epoch 7/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0073 - val_loss: 0.0291\n",
      "Epoch 8/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0080 - val_loss: 0.0308\n",
      "Epoch 9/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0078 - val_loss: 0.0302\n",
      "Epoch 10/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0083 - val_loss: 0.0314\n",
      "Epoch 11/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0075 - val_loss: 0.0285\n",
      "Epoch 12/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0067 - val_loss: 0.0285\n",
      "Epoch 13/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0071 - val_loss: 0.0302\n",
      "Epoch 14/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0075 - val_loss: 0.0281\n",
      "Epoch 15/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0067 - val_loss: 0.0291\n",
      "Epoch 16/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0071 - val_loss: 0.0297\n",
      "Epoch 17/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0299\n",
      "Epoch 18/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0072 - val_loss: 0.0290\n",
      "Epoch 19/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0069 - val_loss: 0.0289\n",
      "Epoch 20/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0068 - val_loss: 0.0287\n",
      "Epoch 21/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0071 - val_loss: 0.0289\n",
      "Epoch 22/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0078 - val_loss: 0.0303\n",
      "Epoch 23/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0075 - val_loss: 0.0296\n",
      "Epoch 24/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0081 - val_loss: 0.0296\n",
      "Epoch 25/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0072 - val_loss: 0.0287\n",
      "Epoch 26/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0071 - val_loss: 0.0293\n",
      "Epoch 27/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0072 - val_loss: 0.0298\n",
      "Epoch 28/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0079 - val_loss: 0.0296\n",
      "Epoch 29/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0078 - val_loss: 0.0286\n",
      "Epoch 30/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0076 - val_loss: 0.0286\n",
      "Epoch 31/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0077 - val_loss: 0.0306\n",
      "Epoch 32/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0074 - val_loss: 0.0287\n",
      "Epoch 33/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0068 - val_loss: 0.0296\n",
      "Epoch 34/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0075 - val_loss: 0.0284\n",
      "Epoch 35/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0072 - val_loss: 0.0294\n",
      "Epoch 36/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0084 - val_loss: 0.0291\n",
      "Epoch 37/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0082 - val_loss: 0.0303\n",
      "Epoch 38/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0076 - val_loss: 0.0289\n",
      "Epoch 39/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0072 - val_loss: 0.0288\n",
      "Epoch 40/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0072 - val_loss: 0.0299\n",
      "Epoch 41/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0078 - val_loss: 0.0302\n",
      "Epoch 42/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0082 - val_loss: 0.0292\n",
      "Epoch 43/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0081 - val_loss: 0.0298\n",
      "Epoch 44/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0076 - val_loss: 0.0289\n",
      "Epoch 45/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0069 - val_loss: 0.0282\n",
      "Epoch 46/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0068 - val_loss: 0.0280\n",
      "Epoch 47/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0076 - val_loss: 0.0300\n",
      "Epoch 48/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0074 - val_loss: 0.0287\n",
      "Epoch 49/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0078 - val_loss: 0.0298\n",
      "Epoch 50/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0071 - val_loss: 0.0283\n",
      "第150个数，还剩3973个没有训练\n",
      "inv_hat [1.04404306 1.04404306 1.04404306 1.04404306 1.04404306 1.04504449\n",
      " 1.04504449 1.04504449 1.04504449 1.04504449 1.04504449 1.04604381\n",
      " 1.04604381 1.04604381 1.04604381 1.04604381 1.04604381 1.04704078\n",
      " 1.04704078 1.00002297 1.00002297 1.00101883 1.00101883 1.00101883\n",
      " 1.00101883 1.00101883 1.00101883 1.00201552 1.00201552 1.00201552]\n",
      "Test RMSE: 0.009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 553 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "553/553 [==============================] - 0s 85us/sample - loss: 0.0057 - val_loss: 0.0072\n",
      "Epoch 2/50\n",
      "553/553 [==============================] - 0s 84us/sample - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 3/50\n",
      "553/553 [==============================] - 0s 85us/sample - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 4/50\n",
      "553/553 [==============================] - 0s 80us/sample - loss: 0.0053 - val_loss: 0.0070\n",
      "Epoch 5/50\n",
      "553/553 [==============================] - 0s 88us/sample - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 6/50\n",
      "553/553 [==============================] - 0s 83us/sample - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 7/50\n",
      "553/553 [==============================] - 0s 80us/sample - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 8/50\n",
      "553/553 [==============================] - 0s 82us/sample - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 9/50\n",
      "553/553 [==============================] - 0s 84us/sample - loss: 0.0053 - val_loss: 0.0070\n",
      "Epoch 10/50\n",
      "553/553 [==============================] - 0s 85us/sample - loss: 0.0052 - val_loss: 0.0069\n",
      "Epoch 11/50\n",
      "553/553 [==============================] - 0s 84us/sample - loss: 0.0053 - val_loss: 0.0071\n",
      "Epoch 12/50\n",
      "553/553 [==============================] - 0s 86us/sample - loss: 0.0053 - val_loss: 0.0070\n",
      "Epoch 13/50\n",
      "553/553 [==============================] - 0s 89us/sample - loss: 0.0052 - val_loss: 0.0069\n",
      "Epoch 14/50\n",
      "553/553 [==============================] - 0s 85us/sample - loss: 0.0053 - val_loss: 0.0070\n",
      "Epoch 15/50\n",
      "553/553 [==============================] - 0s 80us/sample - loss: 0.0052 - val_loss: 0.0070\n",
      "Epoch 16/50\n",
      "553/553 [==============================] - 0s 80us/sample - loss: 0.0052 - val_loss: 0.0069\n",
      "Epoch 17/50\n",
      "553/553 [==============================] - 0s 82us/sample - loss: 0.0052 - val_loss: 0.0069\n",
      "Epoch 18/50\n",
      "553/553 [==============================] - 0s 83us/sample - loss: 0.0052 - val_loss: 0.0069\n",
      "Epoch 19/50\n",
      "553/553 [==============================] - 0s 79us/sample - loss: 0.0052 - val_loss: 0.0069\n",
      "Epoch 20/50\n",
      "553/553 [==============================] - 0s 80us/sample - loss: 0.0052 - val_loss: 0.0069\n",
      "Epoch 21/50\n",
      "553/553 [==============================] - 0s 83us/sample - loss: 0.0052 - val_loss: 0.0070\n",
      "Epoch 22/50\n",
      "553/553 [==============================] - 0s 87us/sample - loss: 0.0052 - val_loss: 0.0070\n",
      "Epoch 23/50\n",
      "553/553 [==============================] - 0s 85us/sample - loss: 0.0052 - val_loss: 0.0069\n",
      "Epoch 24/50\n",
      "553/553 [==============================] - 0s 82us/sample - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 25/50\n",
      "553/553 [==============================] - 0s 86us/sample - loss: 0.0053 - val_loss: 0.0071\n",
      "Epoch 26/50\n",
      "553/553 [==============================] - 0s 86us/sample - loss: 0.0053 - val_loss: 0.0070\n",
      "Epoch 27/50\n",
      "553/553 [==============================] - 0s 86us/sample - loss: 0.0052 - val_loss: 0.0069\n",
      "Epoch 28/50\n",
      "553/553 [==============================] - 0s 83us/sample - loss: 0.0052 - val_loss: 0.0070\n",
      "Epoch 29/50\n",
      "553/553 [==============================] - 0s 86us/sample - loss: 0.0052 - val_loss: 0.0069\n",
      "Epoch 30/50\n",
      "553/553 [==============================] - 0s 86us/sample - loss: 0.0052 - val_loss: 0.0069\n",
      "Epoch 31/50\n",
      "553/553 [==============================] - 0s 81us/sample - loss: 0.0052 - val_loss: 0.0069\n",
      "Epoch 32/50\n",
      "553/553 [==============================] - 0s 81us/sample - loss: 0.0052 - val_loss: 0.0071\n",
      "Epoch 33/50\n",
      "553/553 [==============================] - 0s 80us/sample - loss: 0.0052 - val_loss: 0.0071\n",
      "Epoch 34/50\n",
      "553/553 [==============================] - 0s 83us/sample - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 35/50\n",
      "553/553 [==============================] - 0s 80us/sample - loss: 0.0052 - val_loss: 0.0070\n",
      "Epoch 36/50\n",
      "553/553 [==============================] - 0s 83us/sample - loss: 0.0053 - val_loss: 0.0073\n",
      "Epoch 37/50\n",
      "553/553 [==============================] - 0s 85us/sample - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 38/50\n",
      "553/553 [==============================] - 0s 92us/sample - loss: 0.0052 - val_loss: 0.0070\n",
      "Epoch 39/50\n",
      "553/553 [==============================] - 0s 87us/sample - loss: 0.0052 - val_loss: 0.0073\n",
      "Epoch 40/50\n",
      "553/553 [==============================] - 0s 86us/sample - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 41/50\n",
      "553/553 [==============================] - 0s 86us/sample - loss: 0.0052 - val_loss: 0.0070\n",
      "Epoch 42/50\n",
      "553/553 [==============================] - 0s 83us/sample - loss: 0.0052 - val_loss: 0.0072\n",
      "Epoch 43/50\n",
      "553/553 [==============================] - 0s 83us/sample - loss: 0.0052 - val_loss: 0.0069\n",
      "Epoch 44/50\n",
      "553/553 [==============================] - 0s 89us/sample - loss: 0.0052 - val_loss: 0.0070\n",
      "Epoch 45/50\n",
      "553/553 [==============================] - 0s 83us/sample - loss: 0.0052 - val_loss: 0.0070\n",
      "Epoch 46/50\n",
      "553/553 [==============================] - 0s 97us/sample - loss: 0.0052 - val_loss: 0.0071\n",
      "Epoch 47/50\n",
      "553/553 [==============================] - 0s 88us/sample - loss: 0.0052 - val_loss: 0.0070\n",
      "Epoch 48/50\n",
      "553/553 [==============================] - 0s 90us/sample - loss: 0.0052 - val_loss: 0.0071\n",
      "Epoch 49/50\n",
      "553/553 [==============================] - 0s 91us/sample - loss: 0.0052 - val_loss: 0.0070\n",
      "Epoch 50/50\n",
      "553/553 [==============================] - 0s 87us/sample - loss: 0.0052 - val_loss: 0.0070\n",
      "第151个数，还剩3972个没有训练\n",
      "inv_hat [1.05064973 1.05134216 1.05134216 1.05144097 1.05153975 1.05163849\n",
      " 1.05124331 1.05144097 1.05153975 1.05193442 1.05223015 1.05331179\n",
      " 1.05370418 1.0544872  1.05478019 1.05556012 1.05575477 1.05604637\n",
      " 1.0544872  1.05380218 1.05282064 1.05213161 1.05252549 1.05282064\n",
      " 1.05331179 1.05360613 1.05429162 1.05242704 1.05252549 1.05380218]\n",
      "Test RMSE: 0.001\n",
      "Train on 572 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "572/572 [==============================] - 0s 80us/sample - loss: 0.0157 - val_loss: 0.0065\n",
      "Epoch 2/50\n",
      "572/572 [==============================] - 0s 82us/sample - loss: 0.0144 - val_loss: 0.0063\n",
      "Epoch 3/50\n",
      "572/572 [==============================] - 0s 82us/sample - loss: 0.0152 - val_loss: 0.0074\n",
      "Epoch 4/50\n",
      "572/572 [==============================] - 0s 80us/sample - loss: 0.0143 - val_loss: 0.0059\n",
      "Epoch 5/50\n",
      "572/572 [==============================] - 0s 77us/sample - loss: 0.0142 - val_loss: 0.0066\n",
      "Epoch 6/50\n",
      "572/572 [==============================] - 0s 76us/sample - loss: 0.0143 - val_loss: 0.0061\n",
      "Epoch 7/50\n",
      "572/572 [==============================] - 0s 78us/sample - loss: 0.0141 - val_loss: 0.0060\n",
      "Epoch 8/50\n",
      "572/572 [==============================] - 0s 77us/sample - loss: 0.0141 - val_loss: 0.0062\n",
      "Epoch 9/50\n",
      "572/572 [==============================] - 0s 79us/sample - loss: 0.0141 - val_loss: 0.0059\n",
      "Epoch 10/50\n",
      "572/572 [==============================] - 0s 80us/sample - loss: 0.0141 - val_loss: 0.0062\n",
      "Epoch 11/50\n",
      "572/572 [==============================] - 0s 78us/sample - loss: 0.0141 - val_loss: 0.0060\n",
      "Epoch 12/50\n",
      "572/572 [==============================] - 0s 86us/sample - loss: 0.0141 - val_loss: 0.0060\n",
      "Epoch 13/50\n",
      "572/572 [==============================] - 0s 84us/sample - loss: 0.0141 - val_loss: 0.0061\n",
      "Epoch 14/50\n",
      "572/572 [==============================] - 0s 88us/sample - loss: 0.0141 - val_loss: 0.0061\n",
      "Epoch 15/50\n",
      "572/572 [==============================] - 0s 84us/sample - loss: 0.0141 - val_loss: 0.0060\n",
      "Epoch 16/50\n",
      "572/572 [==============================] - 0s 91us/sample - loss: 0.0141 - val_loss: 0.0062\n",
      "Epoch 17/50\n",
      "572/572 [==============================] - 0s 82us/sample - loss: 0.0141 - val_loss: 0.0060\n",
      "Epoch 18/50\n",
      "572/572 [==============================] - 0s 80us/sample - loss: 0.0141 - val_loss: 0.0060\n",
      "Epoch 19/50\n",
      "572/572 [==============================] - 0s 81us/sample - loss: 0.0141 - val_loss: 0.0062\n",
      "Epoch 20/50\n",
      "572/572 [==============================] - 0s 81us/sample - loss: 0.0141 - val_loss: 0.0061\n",
      "Epoch 21/50\n",
      "572/572 [==============================] - 0s 83us/sample - loss: 0.0141 - val_loss: 0.0060\n",
      "Epoch 22/50\n",
      "572/572 [==============================] - 0s 80us/sample - loss: 0.0141 - val_loss: 0.0061\n",
      "Epoch 23/50\n",
      "572/572 [==============================] - 0s 77us/sample - loss: 0.0141 - val_loss: 0.0061\n",
      "Epoch 24/50\n",
      "572/572 [==============================] - 0s 81us/sample - loss: 0.0141 - val_loss: 0.0062\n",
      "Epoch 25/50\n",
      "572/572 [==============================] - 0s 83us/sample - loss: 0.0141 - val_loss: 0.0060\n",
      "Epoch 26/50\n",
      "572/572 [==============================] - 0s 82us/sample - loss: 0.0141 - val_loss: 0.0061\n",
      "Epoch 27/50\n",
      "572/572 [==============================] - 0s 84us/sample - loss: 0.0141 - val_loss: 0.0061\n",
      "Epoch 28/50\n",
      "572/572 [==============================] - 0s 86us/sample - loss: 0.0141 - val_loss: 0.0061\n",
      "Epoch 29/50\n",
      "572/572 [==============================] - 0s 86us/sample - loss: 0.0141 - val_loss: 0.0062\n",
      "Epoch 30/50\n",
      "572/572 [==============================] - 0s 87us/sample - loss: 0.0141 - val_loss: 0.0061\n",
      "Epoch 31/50\n",
      "572/572 [==============================] - 0s 87us/sample - loss: 0.0141 - val_loss: 0.0062\n",
      "Epoch 32/50\n",
      "572/572 [==============================] - 0s 83us/sample - loss: 0.0141 - val_loss: 0.0061\n",
      "Epoch 33/50\n",
      "572/572 [==============================] - 0s 80us/sample - loss: 0.0141 - val_loss: 0.0061\n",
      "Epoch 34/50\n",
      "572/572 [==============================] - 0s 83us/sample - loss: 0.0141 - val_loss: 0.0063\n",
      "Epoch 35/50\n",
      "572/572 [==============================] - 0s 86us/sample - loss: 0.0141 - val_loss: 0.0060\n",
      "Epoch 36/50\n",
      "572/572 [==============================] - 0s 83us/sample - loss: 0.0141 - val_loss: 0.0063\n",
      "Epoch 37/50\n",
      "572/572 [==============================] - 0s 84us/sample - loss: 0.0141 - val_loss: 0.0060\n",
      "Epoch 38/50\n",
      "572/572 [==============================] - 0s 85us/sample - loss: 0.0141 - val_loss: 0.0062\n",
      "Epoch 39/50\n",
      "572/572 [==============================] - 0s 83us/sample - loss: 0.0141 - val_loss: 0.0062\n",
      "Epoch 40/50\n",
      "572/572 [==============================] - 0s 82us/sample - loss: 0.0141 - val_loss: 0.0061\n",
      "Epoch 41/50\n",
      "572/572 [==============================] - 0s 80us/sample - loss: 0.0141 - val_loss: 0.0063\n",
      "Epoch 42/50\n",
      "572/572 [==============================] - 0s 79us/sample - loss: 0.0140 - val_loss: 0.0061\n",
      "Epoch 43/50\n",
      "572/572 [==============================] - 0s 80us/sample - loss: 0.0141 - val_loss: 0.0063\n",
      "Epoch 44/50\n",
      "572/572 [==============================] - 0s 86us/sample - loss: 0.0140 - val_loss: 0.0061\n",
      "Epoch 45/50\n",
      "572/572 [==============================] - 0s 79us/sample - loss: 0.0141 - val_loss: 0.0062\n",
      "Epoch 46/50\n",
      "572/572 [==============================] - 0s 82us/sample - loss: 0.0141 - val_loss: 0.0062\n",
      "Epoch 47/50\n",
      "572/572 [==============================] - 0s 79us/sample - loss: 0.0140 - val_loss: 0.0062\n",
      "Epoch 48/50\n",
      "572/572 [==============================] - 0s 80us/sample - loss: 0.0141 - val_loss: 0.0062\n",
      "Epoch 49/50\n",
      "572/572 [==============================] - 0s 79us/sample - loss: 0.0140 - val_loss: 0.0062\n",
      "Epoch 50/50\n",
      "572/572 [==============================] - 0s 85us/sample - loss: 0.0141 - val_loss: 0.0064\n",
      "第152个数，还剩3971个没有训练\n",
      "inv_hat [1.41110222 1.41089947 1.41312965 1.41485307 1.40796021 1.41769192\n",
      " 1.41414345 1.404717   1.40177828 1.41617104 1.4256017  1.40948034\n",
      " 1.40380495 1.40502112 1.40421034 1.40127173 1.46833165 1.45949683\n",
      " 1.46630034 1.46792535 1.46020753 1.46173068 1.45553698 1.39225547\n",
      " 1.39843482 1.42610889 1.41272415 1.42377615 1.42874899 1.43777108]\n",
      "Test RMSE: 0.019\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0129 - val_loss: 0.0099\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0128 - val_loss: 0.0097\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0126 - val_loss: 0.0099\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0126 - val_loss: 0.0099\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0126 - val_loss: 0.0099\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0126 - val_loss: 0.0100\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0125 - val_loss: 0.0101\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0126 - val_loss: 0.0099\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0125 - val_loss: 0.0098\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0125 - val_loss: 0.0101\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0126 - val_loss: 0.0100\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0126 - val_loss: 0.0100\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0125 - val_loss: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0126 - val_loss: 0.0100\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0126 - val_loss: 0.0099\n",
      "第153个数，还剩3970个没有训练\n",
      "inv_hat [1.69896287 1.66415895 1.66566995 1.65448405 1.63198274 1.63753583\n",
      " 1.63238659 1.64974487 1.6336993  1.64823188 1.68247955 1.68599936\n",
      " 1.67513462 1.64974487 1.64903875 1.63117479 1.63430512 1.63904997\n",
      " 1.65458488 1.62996276 1.63188175 1.60995122 1.59325569 1.57127482\n",
      " 1.54876348 1.54407571 1.53631368 1.52715771 1.52785441 1.53710977]\n",
      "Test RMSE: 0.016\n",
      "Train on 976 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "976/976 [==============================] - 0s 81us/sample - loss: 0.0184 - val_loss: 0.0136\n",
      "Epoch 2/50\n",
      "976/976 [==============================] - 0s 80us/sample - loss: 0.0177 - val_loss: 0.0112\n",
      "Epoch 3/50\n",
      "976/976 [==============================] - 0s 81us/sample - loss: 0.0171 - val_loss: 0.0100\n",
      "Epoch 4/50\n",
      "976/976 [==============================] - 0s 78us/sample - loss: 0.0169 - val_loss: 0.0101\n",
      "Epoch 5/50\n",
      "976/976 [==============================] - 0s 82us/sample - loss: 0.0168 - val_loss: 0.0100\n",
      "Epoch 6/50\n",
      "976/976 [==============================] - 0s 81us/sample - loss: 0.0168 - val_loss: 0.0100\n",
      "Epoch 7/50\n",
      "976/976 [==============================] - 0s 80us/sample - loss: 0.0168 - val_loss: 0.0100\n",
      "Epoch 8/50\n",
      "976/976 [==============================] - 0s 80us/sample - loss: 0.0168 - val_loss: 0.0099\n",
      "Epoch 9/50\n",
      "976/976 [==============================] - 0s 79us/sample - loss: 0.0168 - val_loss: 0.0099\n",
      "Epoch 10/50\n",
      "976/976 [==============================] - 0s 77us/sample - loss: 0.0168 - val_loss: 0.0100\n",
      "Epoch 11/50\n",
      "976/976 [==============================] - 0s 83us/sample - loss: 0.0170 - val_loss: 0.0101\n",
      "Epoch 12/50\n",
      "976/976 [==============================] - 0s 80us/sample - loss: 0.0172 - val_loss: 0.0101\n",
      "Epoch 13/50\n",
      "976/976 [==============================] - 0s 83us/sample - loss: 0.0178 - val_loss: 0.0099\n",
      "Epoch 14/50\n",
      "976/976 [==============================] - 0s 85us/sample - loss: 0.0178 - val_loss: 0.0101\n",
      "Epoch 15/50\n",
      "976/976 [==============================] - 0s 84us/sample - loss: 0.0176 - val_loss: 0.0104\n",
      "Epoch 16/50\n",
      "976/976 [==============================] - 0s 83us/sample - loss: 0.0172 - val_loss: 0.0108\n",
      "Epoch 17/50\n",
      "976/976 [==============================] - 0s 78us/sample - loss: 0.0169 - val_loss: 0.0104\n",
      "Epoch 18/50\n",
      "976/976 [==============================] - 0s 78us/sample - loss: 0.0165 - val_loss: 0.0100\n",
      "Epoch 19/50\n",
      "976/976 [==============================] - 0s 81us/sample - loss: 0.0167 - val_loss: 0.0100\n",
      "Epoch 20/50\n",
      "976/976 [==============================] - 0s 81us/sample - loss: 0.0168 - val_loss: 0.0101\n",
      "Epoch 21/50\n",
      "976/976 [==============================] - 0s 78us/sample - loss: 0.0170 - val_loss: 0.0101\n",
      "Epoch 22/50\n",
      "976/976 [==============================] - 0s 81us/sample - loss: 0.0172 - val_loss: 0.0101\n",
      "Epoch 23/50\n",
      "976/976 [==============================] - 0s 81us/sample - loss: 0.0177 - val_loss: 0.0100\n",
      "Epoch 24/50\n",
      "976/976 [==============================] - 0s 80us/sample - loss: 0.0177 - val_loss: 0.0102\n",
      "Epoch 25/50\n",
      "976/976 [==============================] - 0s 80us/sample - loss: 0.0172 - val_loss: 0.0108\n",
      "Epoch 26/50\n",
      "976/976 [==============================] - 0s 82us/sample - loss: 0.0168 - val_loss: 0.0105\n",
      "Epoch 27/50\n",
      "976/976 [==============================] - 0s 83us/sample - loss: 0.0166 - val_loss: 0.0101\n",
      "Epoch 28/50\n",
      "976/976 [==============================] - 0s 79us/sample - loss: 0.0165 - val_loss: 0.0099\n",
      "Epoch 29/50\n",
      "976/976 [==============================] - 0s 79us/sample - loss: 0.0168 - val_loss: 0.0100\n",
      "Epoch 30/50\n",
      "976/976 [==============================] - 0s 78us/sample - loss: 0.0169 - val_loss: 0.0100\n",
      "Epoch 31/50\n",
      "976/976 [==============================] - 0s 78us/sample - loss: 0.0174 - val_loss: 0.0100\n",
      "Epoch 32/50\n",
      "976/976 [==============================] - 0s 78us/sample - loss: 0.0173 - val_loss: 0.0100\n",
      "Epoch 33/50\n",
      "976/976 [==============================] - 0s 83us/sample - loss: 0.0171 - val_loss: 0.0101\n",
      "Epoch 34/50\n",
      "976/976 [==============================] - 0s 80us/sample - loss: 0.0170 - val_loss: 0.0103\n",
      "Epoch 35/50\n",
      "976/976 [==============================] - 0s 78us/sample - loss: 0.0168 - val_loss: 0.0101\n",
      "Epoch 36/50\n",
      "976/976 [==============================] - 0s 77us/sample - loss: 0.0166 - val_loss: 0.0100\n",
      "Epoch 37/50\n",
      "976/976 [==============================] - 0s 78us/sample - loss: 0.0168 - val_loss: 0.0100\n",
      "Epoch 38/50\n",
      "976/976 [==============================] - 0s 81us/sample - loss: 0.0169 - val_loss: 0.0100\n",
      "Epoch 39/50\n",
      "976/976 [==============================] - 0s 78us/sample - loss: 0.0169 - val_loss: 0.0099\n",
      "Epoch 40/50\n",
      "976/976 [==============================] - 0s 78us/sample - loss: 0.0171 - val_loss: 0.0100\n",
      "Epoch 41/50\n",
      "976/976 [==============================] - 0s 78us/sample - loss: 0.0170 - val_loss: 0.0100\n",
      "Epoch 42/50\n",
      "976/976 [==============================] - 0s 79us/sample - loss: 0.0172 - val_loss: 0.0100\n",
      "Epoch 43/50\n",
      "976/976 [==============================] - 0s 79us/sample - loss: 0.0171 - val_loss: 0.0102\n",
      "Epoch 44/50\n",
      "976/976 [==============================] - 0s 81us/sample - loss: 0.0167 - val_loss: 0.0103\n",
      "Epoch 45/50\n",
      "976/976 [==============================] - 0s 86us/sample - loss: 0.0166 - val_loss: 0.0101\n",
      "Epoch 46/50\n",
      "976/976 [==============================] - 0s 86us/sample - loss: 0.0166 - val_loss: 0.0100\n",
      "Epoch 47/50\n",
      "976/976 [==============================] - 0s 79us/sample - loss: 0.0167 - val_loss: 0.0100\n",
      "Epoch 48/50\n",
      "976/976 [==============================] - 0s 78us/sample - loss: 0.0170 - val_loss: 0.0101\n",
      "Epoch 49/50\n",
      "976/976 [==============================] - 0s 77us/sample - loss: 0.0170 - val_loss: 0.0100\n",
      "Epoch 50/50\n",
      "976/976 [==============================] - 0s 77us/sample - loss: 0.0173 - val_loss: 0.0100\n",
      "第154个数，还剩3969个没有训练\n",
      "inv_hat [1.02123427 1.00091598 1.00451123 1.00581037 0.98081254 0.97932468\n",
      " 0.97882893 0.98836179 0.9785315  0.98051492 1.00451123 1.00891013\n",
      " 1.00581037 0.98945592 0.98438625 0.97318267 0.97783759 0.9766484\n",
      " 0.9871686  0.97338057 0.97159963 0.96636212 0.95798256 0.95906555\n",
      " 0.95277063 0.95758885 0.95591621 0.95316363 0.94825549 0.95277063]\n",
      "Test RMSE: 0.009\n",
      "Train on 869 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "869/869 [==============================] - 0s 99us/sample - loss: 0.0112 - val_loss: 0.0047\n",
      "Epoch 2/50\n",
      "869/869 [==============================] - 0s 86us/sample - loss: 0.0110 - val_loss: 0.0047\n",
      "Epoch 3/50\n",
      "869/869 [==============================] - 0s 86us/sample - loss: 0.0108 - val_loss: 0.0048\n",
      "Epoch 4/50\n",
      "869/869 [==============================] - 0s 84us/sample - loss: 0.0108 - val_loss: 0.0048\n",
      "Epoch 5/50\n",
      "869/869 [==============================] - 0s 84us/sample - loss: 0.0109 - val_loss: 0.0047\n",
      "Epoch 6/50\n",
      "869/869 [==============================] - 0s 81us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 7/50\n",
      "869/869 [==============================] - 0s 85us/sample - loss: 0.0108 - val_loss: 0.0047\n",
      "Epoch 8/50\n",
      "869/869 [==============================] - 0s 88us/sample - loss: 0.0113 - val_loss: 0.0047\n",
      "Epoch 9/50\n",
      "869/869 [==============================] - 0s 88us/sample - loss: 0.0110 - val_loss: 0.0047\n",
      "Epoch 10/50\n",
      "869/869 [==============================] - 0s 88us/sample - loss: 0.0111 - val_loss: 0.0047\n",
      "Epoch 11/50\n",
      "869/869 [==============================] - 0s 86us/sample - loss: 0.0112 - val_loss: 0.0047\n",
      "Epoch 12/50\n",
      "869/869 [==============================] - 0s 86us/sample - loss: 0.0109 - val_loss: 0.0047\n",
      "Epoch 13/50\n",
      "869/869 [==============================] - 0s 81us/sample - loss: 0.0110 - val_loss: 0.0047\n",
      "Epoch 14/50\n",
      "869/869 [==============================] - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0047\n",
      "Epoch 15/50\n",
      "869/869 [==============================] - 0s 88us/sample - loss: 0.0111 - val_loss: 0.0047\n",
      "Epoch 16/50\n",
      "869/869 [==============================] - 0s 87us/sample - loss: 0.0111 - val_loss: 0.0047\n",
      "Epoch 17/50\n",
      "869/869 [==============================] - 0s 80us/sample - loss: 0.0112 - val_loss: 0.0047\n",
      "Epoch 18/50\n",
      "869/869 [==============================] - 0s 83us/sample - loss: 0.0114 - val_loss: 0.0047\n",
      "Epoch 19/50\n",
      "869/869 [==============================] - 0s 84us/sample - loss: 0.0115 - val_loss: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "869/869 [==============================] - 0s 84us/sample - loss: 0.0124 - val_loss: 0.0050\n",
      "Epoch 21/50\n",
      "869/869 [==============================] - 0s 84us/sample - loss: 0.0125 - val_loss: 0.0056\n",
      "Epoch 22/50\n",
      "869/869 [==============================] - 0s 84us/sample - loss: 0.0120 - val_loss: 0.0056\n",
      "Epoch 23/50\n",
      "869/869 [==============================] - 0s 82us/sample - loss: 0.0116 - val_loss: 0.0051\n",
      "Epoch 24/50\n",
      "869/869 [==============================] - 0s 84us/sample - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 25/50\n",
      "869/869 [==============================] - 0s 84us/sample - loss: 0.0114 - val_loss: 0.0050\n",
      "Epoch 26/50\n",
      "869/869 [==============================] - 0s 87us/sample - loss: 0.0114 - val_loss: 0.0051\n",
      "Epoch 27/50\n",
      "869/869 [==============================] - 0s 84us/sample - loss: 0.0114 - val_loss: 0.0050\n",
      "Epoch 28/50\n",
      "869/869 [==============================] - 0s 86us/sample - loss: 0.0114 - val_loss: 0.0050\n",
      "Epoch 29/50\n",
      "869/869 [==============================] - 0s 87us/sample - loss: 0.0114 - val_loss: 0.0051\n",
      "Epoch 30/50\n",
      "869/869 [==============================] - 0s 88us/sample - loss: 0.0113 - val_loss: 0.0052\n",
      "Epoch 31/50\n",
      "869/869 [==============================] - 0s 88us/sample - loss: 0.0111 - val_loss: 0.0050\n",
      "Epoch 32/50\n",
      "869/869 [==============================] - 0s 86us/sample - loss: 0.0111 - val_loss: 0.0048\n",
      "Epoch 33/50\n",
      "869/869 [==============================] - 0s 84us/sample - loss: 0.0115 - val_loss: 0.0053\n",
      "Epoch 34/50\n",
      "869/869 [==============================] - 0s 83us/sample - loss: 0.0112 - val_loss: 0.0050\n",
      "Epoch 35/50\n",
      "869/869 [==============================] - 0s 85us/sample - loss: 0.0111 - val_loss: 0.0049\n",
      "Epoch 36/50\n",
      "869/869 [==============================] - 0s 86us/sample - loss: 0.0111 - val_loss: 0.0049\n",
      "Epoch 37/50\n",
      "869/869 [==============================] - 0s 82us/sample - loss: 0.0113 - val_loss: 0.0050\n",
      "Epoch 38/50\n",
      "869/869 [==============================] - 0s 81us/sample - loss: 0.0112 - val_loss: 0.0050\n",
      "Epoch 39/50\n",
      "869/869 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0049\n",
      "Epoch 40/50\n",
      "869/869 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0049\n",
      "Epoch 41/50\n",
      "869/869 [==============================] - 0s 83us/sample - loss: 0.0112 - val_loss: 0.0050\n",
      "Epoch 42/50\n",
      "869/869 [==============================] - 0s 86us/sample - loss: 0.0111 - val_loss: 0.0049\n",
      "Epoch 43/50\n",
      "869/869 [==============================] - 0s 86us/sample - loss: 0.0111 - val_loss: 0.0050\n",
      "Epoch 44/50\n",
      "869/869 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0051\n",
      "Epoch 45/50\n",
      "869/869 [==============================] - 0s 83us/sample - loss: 0.0110 - val_loss: 0.0051\n",
      "Epoch 46/50\n",
      "869/869 [==============================] - 0s 85us/sample - loss: 0.0110 - val_loss: 0.0051\n",
      "Epoch 47/50\n",
      "869/869 [==============================] - 0s 83us/sample - loss: 0.0109 - val_loss: 0.0051\n",
      "Epoch 48/50\n",
      "869/869 [==============================] - 0s 85us/sample - loss: 0.0109 - val_loss: 0.0050\n",
      "Epoch 49/50\n",
      "869/869 [==============================] - 0s 86us/sample - loss: 0.0110 - val_loss: 0.0050\n",
      "Epoch 50/50\n",
      "869/869 [==============================] - 0s 86us/sample - loss: 0.0110 - val_loss: 0.0049\n",
      "第155个数，还剩3968个没有训练\n",
      "inv_hat [0.51487768 0.50591068 0.50591068 0.5029267  0.49101618 0.49002554\n",
      " 0.49101618 0.49597383 0.48903515 0.49101618 0.51188625 0.51188625\n",
      " 0.51188625 0.50193254 0.49895193 0.49498174 0.49696626 0.49696626\n",
      " 0.50491574 0.49696626 0.49299838 0.48705533 0.47914802 0.47717423\n",
      " 0.47520169 0.47816096 0.47520169 0.47323038 0.47126031 0.47520169]\n",
      "Test RMSE: 0.006\n",
      "Train on 583 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "583/583 [==============================] - 0s 88us/sample - loss: 0.0193 - val_loss: 0.0138\n",
      "Epoch 2/50\n",
      "583/583 [==============================] - 0s 86us/sample - loss: 0.0210 - val_loss: 0.0161\n",
      "Epoch 3/50\n",
      "583/583 [==============================] - 0s 89us/sample - loss: 0.0175 - val_loss: 0.0134\n",
      "Epoch 4/50\n",
      "583/583 [==============================] - 0s 89us/sample - loss: 0.0178 - val_loss: 0.0146\n",
      "Epoch 5/50\n",
      "583/583 [==============================] - 0s 88us/sample - loss: 0.0163 - val_loss: 0.0133\n",
      "Epoch 6/50\n",
      "583/583 [==============================] - 0s 90us/sample - loss: 0.0166 - val_loss: 0.0149\n",
      "Epoch 7/50\n",
      "583/583 [==============================] - 0s 88us/sample - loss: 0.0162 - val_loss: 0.0134\n",
      "Epoch 8/50\n",
      "583/583 [==============================] - 0s 86us/sample - loss: 0.0171 - val_loss: 0.0154\n",
      "Epoch 9/50\n",
      "583/583 [==============================] - 0s 86us/sample - loss: 0.0162 - val_loss: 0.0134\n",
      "Epoch 10/50\n",
      "583/583 [==============================] - 0s 84us/sample - loss: 0.0174 - val_loss: 0.0153\n",
      "Epoch 11/50\n",
      "583/583 [==============================] - 0s 86us/sample - loss: 0.0160 - val_loss: 0.0134\n",
      "Epoch 12/50\n",
      "583/583 [==============================] - 0s 90us/sample - loss: 0.0169 - val_loss: 0.0150\n",
      "Epoch 13/50\n",
      "583/583 [==============================] - 0s 93us/sample - loss: 0.0162 - val_loss: 0.0134\n",
      "Epoch 14/50\n",
      "583/583 [==============================] - 0s 88us/sample - loss: 0.0167 - val_loss: 0.0152\n",
      "Epoch 15/50\n",
      "583/583 [==============================] - 0s 86us/sample - loss: 0.0160 - val_loss: 0.0136\n",
      "Epoch 16/50\n",
      "583/583 [==============================] - 0s 95us/sample - loss: 0.0170 - val_loss: 0.0155\n",
      "Epoch 17/50\n",
      "583/583 [==============================] - 0s 95us/sample - loss: 0.0162 - val_loss: 0.0133\n",
      "Epoch 18/50\n",
      "583/583 [==============================] - 0s 94us/sample - loss: 0.0170 - val_loss: 0.0148\n",
      "Epoch 19/50\n",
      "583/583 [==============================] - 0s 99us/sample - loss: 0.0159 - val_loss: 0.0135\n",
      "Epoch 20/50\n",
      "583/583 [==============================] - 0s 97us/sample - loss: 0.0161 - val_loss: 0.0144\n",
      "Epoch 21/50\n",
      "583/583 [==============================] - 0s 98us/sample - loss: 0.0158 - val_loss: 0.0137\n",
      "Epoch 22/50\n",
      "583/583 [==============================] - 0s 91us/sample - loss: 0.0160 - val_loss: 0.0145\n",
      "Epoch 23/50\n",
      "583/583 [==============================] - 0s 90us/sample - loss: 0.0158 - val_loss: 0.0137\n",
      "Epoch 24/50\n",
      "583/583 [==============================] - 0s 91us/sample - loss: 0.0160 - val_loss: 0.0144\n",
      "Epoch 25/50\n",
      "583/583 [==============================] - 0s 87us/sample - loss: 0.0158 - val_loss: 0.0137\n",
      "Epoch 26/50\n",
      "583/583 [==============================] - 0s 91us/sample - loss: 0.0162 - val_loss: 0.0149\n",
      "Epoch 27/50\n",
      "583/583 [==============================] - 0s 90us/sample - loss: 0.0157 - val_loss: 0.0137\n",
      "Epoch 28/50\n",
      "583/583 [==============================] - 0s 91us/sample - loss: 0.0163 - val_loss: 0.0146\n",
      "Epoch 29/50\n",
      "583/583 [==============================] - 0s 90us/sample - loss: 0.0158 - val_loss: 0.0137\n",
      "Epoch 30/50\n",
      "583/583 [==============================] - 0s 87us/sample - loss: 0.0162 - val_loss: 0.0149\n",
      "Epoch 31/50\n",
      "583/583 [==============================] - 0s 89us/sample - loss: 0.0157 - val_loss: 0.0136\n",
      "Epoch 32/50\n",
      "583/583 [==============================] - 0s 85us/sample - loss: 0.0163 - val_loss: 0.0146\n",
      "Epoch 33/50\n",
      "583/583 [==============================] - 0s 88us/sample - loss: 0.0161 - val_loss: 0.0133\n",
      "Epoch 34/50\n",
      "583/583 [==============================] - 0s 86us/sample - loss: 0.0165 - val_loss: 0.0153\n",
      "Epoch 35/50\n",
      "583/583 [==============================] - 0s 87us/sample - loss: 0.0162 - val_loss: 0.0136\n",
      "Epoch 36/50\n",
      "583/583 [==============================] - 0s 87us/sample - loss: 0.0167 - val_loss: 0.0153\n",
      "Epoch 37/50\n",
      "583/583 [==============================] - 0s 85us/sample - loss: 0.0159 - val_loss: 0.0135\n",
      "Epoch 38/50\n",
      "583/583 [==============================] - 0s 88us/sample - loss: 0.0164 - val_loss: 0.0147\n",
      "Epoch 39/50\n",
      "583/583 [==============================] - 0s 85us/sample - loss: 0.0160 - val_loss: 0.0135\n",
      "Epoch 40/50\n",
      "583/583 [==============================] - 0s 83us/sample - loss: 0.0164 - val_loss: 0.0153\n",
      "Epoch 41/50\n",
      "583/583 [==============================] - 0s 84us/sample - loss: 0.0158 - val_loss: 0.0137\n",
      "Epoch 42/50\n",
      "583/583 [==============================] - 0s 85us/sample - loss: 0.0164 - val_loss: 0.0148\n",
      "Epoch 43/50\n",
      "583/583 [==============================] - 0s 87us/sample - loss: 0.0160 - val_loss: 0.0138\n",
      "Epoch 44/50\n",
      "583/583 [==============================] - 0s 98us/sample - loss: 0.0160 - val_loss: 0.0148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "583/583 [==============================] - 0s 92us/sample - loss: 0.0159 - val_loss: 0.0139\n",
      "Epoch 46/50\n",
      "583/583 [==============================] - 0s 92us/sample - loss: 0.0162 - val_loss: 0.0153\n",
      "Epoch 47/50\n",
      "583/583 [==============================] - 0s 96us/sample - loss: 0.0158 - val_loss: 0.0138\n",
      "Epoch 48/50\n",
      "583/583 [==============================] - 0s 98us/sample - loss: 0.0164 - val_loss: 0.0149\n",
      "Epoch 49/50\n",
      "583/583 [==============================] - 0s 90us/sample - loss: 0.0161 - val_loss: 0.0137\n",
      "Epoch 50/50\n",
      "583/583 [==============================] - 0s 93us/sample - loss: 0.0163 - val_loss: 0.0153\n",
      "第156个数，还剩3967个没有训练\n",
      "inv_hat [0.9066137  0.9017095  0.90366869 0.90366869 0.89877727 0.89780174\n",
      " 0.89877727 0.9017095  0.89975375 0.90073115 0.90759691 0.90858087\n",
      " 0.9066137  0.90073115 0.89975375 0.89780174 0.89780174 0.89780174\n",
      " 0.89975375 0.89585355 0.894881   0.89390949 0.89196967 0.89293906\n",
      " 0.89293906 0.89390949 0.89293906 0.89293906 0.89293906 0.89390949]\n",
      "Test RMSE: 0.003\n",
      "Train on 830 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "830/830 [==============================] - 0s 83us/sample - loss: 0.0210 - val_loss: 0.0190\n",
      "Epoch 2/50\n",
      "830/830 [==============================] - 0s 84us/sample - loss: 0.0211 - val_loss: 0.0191\n",
      "Epoch 3/50\n",
      "830/830 [==============================] - 0s 87us/sample - loss: 0.0211 - val_loss: 0.0190\n",
      "Epoch 4/50\n",
      "830/830 [==============================] - 0s 84us/sample - loss: 0.0210 - val_loss: 0.0190\n",
      "Epoch 5/50\n",
      "830/830 [==============================] - 0s 84us/sample - loss: 0.0210 - val_loss: 0.0189\n",
      "Epoch 6/50\n",
      "830/830 [==============================] - 0s 86us/sample - loss: 0.0211 - val_loss: 0.0189\n",
      "Epoch 7/50\n",
      "830/830 [==============================] - 0s 83us/sample - loss: 0.0211 - val_loss: 0.0190\n",
      "Epoch 8/50\n",
      "830/830 [==============================] - 0s 82us/sample - loss: 0.0211 - val_loss: 0.0190\n",
      "Epoch 9/50\n",
      "830/830 [==============================] - 0s 80us/sample - loss: 0.0210 - val_loss: 0.0189\n",
      "Epoch 10/50\n",
      "830/830 [==============================] - 0s 86us/sample - loss: 0.0210 - val_loss: 0.0189\n",
      "Epoch 11/50\n",
      "830/830 [==============================] - 0s 85us/sample - loss: 0.0211 - val_loss: 0.0189\n",
      "Epoch 12/50\n",
      "830/830 [==============================] - 0s 83us/sample - loss: 0.0211 - val_loss: 0.0189\n",
      "Epoch 13/50\n",
      "830/830 [==============================] - 0s 82us/sample - loss: 0.0211 - val_loss: 0.0190\n",
      "Epoch 14/50\n",
      "830/830 [==============================] - 0s 81us/sample - loss: 0.0210 - val_loss: 0.0190\n",
      "Epoch 15/50\n",
      "830/830 [==============================] - 0s 81us/sample - loss: 0.0210 - val_loss: 0.0188\n",
      "Epoch 16/50\n",
      "830/830 [==============================] - 0s 82us/sample - loss: 0.0211 - val_loss: 0.0189\n",
      "Epoch 17/50\n",
      "830/830 [==============================] - 0s 80us/sample - loss: 0.0211 - val_loss: 0.0189\n",
      "Epoch 18/50\n",
      "830/830 [==============================] - 0s 81us/sample - loss: 0.0210 - val_loss: 0.0189\n",
      "Epoch 19/50\n",
      "830/830 [==============================] - 0s 84us/sample - loss: 0.0210 - val_loss: 0.0189\n",
      "Epoch 20/50\n",
      "830/830 [==============================] - 0s 84us/sample - loss: 0.0211 - val_loss: 0.0188\n",
      "Epoch 21/50\n",
      "830/830 [==============================] - 0s 82us/sample - loss: 0.0211 - val_loss: 0.0188\n",
      "Epoch 22/50\n",
      "830/830 [==============================] - 0s 83us/sample - loss: 0.0211 - val_loss: 0.0188\n",
      "Epoch 23/50\n",
      "830/830 [==============================] - 0s 83us/sample - loss: 0.0210 - val_loss: 0.0188\n",
      "Epoch 24/50\n",
      "830/830 [==============================] - 0s 87us/sample - loss: 0.0210 - val_loss: 0.0188\n",
      "Epoch 25/50\n",
      "830/830 [==============================] - 0s 82us/sample - loss: 0.0210 - val_loss: 0.0188\n",
      "Epoch 26/50\n",
      "830/830 [==============================] - 0s 84us/sample - loss: 0.0211 - val_loss: 0.0188\n",
      "Epoch 27/50\n",
      "830/830 [==============================] - 0s 85us/sample - loss: 0.0211 - val_loss: 0.0188\n",
      "Epoch 28/50\n",
      "830/830 [==============================] - 0s 84us/sample - loss: 0.0210 - val_loss: 0.0188\n",
      "Epoch 29/50\n",
      "830/830 [==============================] - 0s 85us/sample - loss: 0.0210 - val_loss: 0.0187\n",
      "Epoch 30/50\n",
      "830/830 [==============================] - 0s 85us/sample - loss: 0.0211 - val_loss: 0.0187\n",
      "Epoch 31/50\n",
      "830/830 [==============================] - 0s 80us/sample - loss: 0.0211 - val_loss: 0.0187\n",
      "Epoch 32/50\n",
      "830/830 [==============================] - 0s 83us/sample - loss: 0.0211 - val_loss: 0.0188\n",
      "Epoch 33/50\n",
      "830/830 [==============================] - 0s 83us/sample - loss: 0.0210 - val_loss: 0.0187\n",
      "Epoch 34/50\n",
      "830/830 [==============================] - 0s 86us/sample - loss: 0.0210 - val_loss: 0.0187\n",
      "Epoch 35/50\n",
      "830/830 [==============================] - 0s 82us/sample - loss: 0.0210 - val_loss: 0.0186\n",
      "Epoch 36/50\n",
      "830/830 [==============================] - 0s 84us/sample - loss: 0.0211 - val_loss: 0.0187\n",
      "Epoch 37/50\n",
      "830/830 [==============================] - 0s 84us/sample - loss: 0.0210 - val_loss: 0.0186\n",
      "Epoch 38/50\n",
      "830/830 [==============================] - 0s 82us/sample - loss: 0.0210 - val_loss: 0.0186\n",
      "Epoch 39/50\n",
      "830/830 [==============================] - 0s 81us/sample - loss: 0.0210 - val_loss: 0.0186\n",
      "Epoch 40/50\n",
      "830/830 [==============================] - 0s 87us/sample - loss: 0.0211 - val_loss: 0.0186\n",
      "Epoch 41/50\n",
      "830/830 [==============================] - 0s 88us/sample - loss: 0.0211 - val_loss: 0.0187\n",
      "Epoch 42/50\n",
      "830/830 [==============================] - 0s 85us/sample - loss: 0.0210 - val_loss: 0.0186\n",
      "Epoch 43/50\n",
      "830/830 [==============================] - 0s 85us/sample - loss: 0.0210 - val_loss: 0.0186\n",
      "Epoch 44/50\n",
      "830/830 [==============================] - 0s 83us/sample - loss: 0.0210 - val_loss: 0.0186\n",
      "Epoch 45/50\n",
      "830/830 [==============================] - 0s 81us/sample - loss: 0.0210 - val_loss: 0.0186\n",
      "Epoch 46/50\n",
      "830/830 [==============================] - 0s 80us/sample - loss: 0.0210 - val_loss: 0.0185\n",
      "Epoch 47/50\n",
      "830/830 [==============================] - 0s 83us/sample - loss: 0.0211 - val_loss: 0.0186\n",
      "Epoch 48/50\n",
      "830/830 [==============================] - 0s 83us/sample - loss: 0.0210 - val_loss: 0.0185\n",
      "Epoch 49/50\n",
      "830/830 [==============================] - 0s 85us/sample - loss: 0.0210 - val_loss: 0.0185\n",
      "Epoch 50/50\n",
      "830/830 [==============================] - 0s 87us/sample - loss: 0.0211 - val_loss: 0.0185\n",
      "第157个数，还剩3966个没有训练\n",
      "inv_hat [0.66820972 0.65346303 0.66163632 0.66588235 0.64762431 0.6461163\n",
      " 0.64742315 0.65245544 0.64390614 0.64993817 0.66861463 0.67621414\n",
      " 0.67966365 0.65901047 0.64029369 0.63168615 0.63568564 0.63318512\n",
      " 0.63969215 0.62281521 0.61646094 0.61358884 0.60028204 0.59861416\n",
      " 0.5922539  0.60136222 0.60028204 0.59782989 0.59079006 0.59303523]\n",
      "Test RMSE: 0.010\n",
      "Train on 1193 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0151 - val_loss: 0.0061\n",
      "Epoch 2/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0149 - val_loss: 0.0091\n",
      "Epoch 3/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0146 - val_loss: 0.0084\n",
      "Epoch 4/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0136 - val_loss: 0.0062\n",
      "Epoch 5/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0132 - val_loss: 0.0058\n",
      "Epoch 6/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0132 - val_loss: 0.0059\n",
      "Epoch 7/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0134 - val_loss: 0.0061\n",
      "Epoch 8/50\n",
      "1193/1193 [==============================] - 0s 75us/sample - loss: 0.0138 - val_loss: 0.0063\n",
      "Epoch 9/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0136 - val_loss: 0.0061\n",
      "Epoch 10/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0132 - val_loss: 0.0058\n",
      "Epoch 11/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0132 - val_loss: 0.0058\n",
      "Epoch 12/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0134 - val_loss: 0.0058\n",
      "Epoch 13/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0136 - val_loss: 0.0060\n",
      "Epoch 14/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0135 - val_loss: 0.0059\n",
      "Epoch 15/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0132 - val_loss: 0.0058\n",
      "Epoch 16/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 17/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0132 - val_loss: 0.0058\n",
      "Epoch 18/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0133 - val_loss: 0.0058\n",
      "Epoch 19/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0134 - val_loss: 0.0058\n",
      "Epoch 20/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0133 - val_loss: 0.0058\n",
      "Epoch 21/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0132 - val_loss: 0.0058\n",
      "Epoch 22/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0130 - val_loss: 0.0058\n",
      "Epoch 23/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 24/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0132 - val_loss: 0.0058\n",
      "Epoch 25/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0132 - val_loss: 0.0058\n",
      "Epoch 26/50\n",
      "1193/1193 [==============================] - 0s 75us/sample - loss: 0.0132 - val_loss: 0.0058\n",
      "Epoch 27/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 28/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 29/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 30/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 31/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 32/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 33/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 34/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 35/50\n",
      "1193/1193 [==============================] - 0s 84us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 36/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 37/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 38/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 39/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 40/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 41/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 42/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 43/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0130 - val_loss: 0.0058\n",
      "Epoch 44/50\n",
      "1193/1193 [==============================] - 0s 85us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 45/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 46/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 47/50\n",
      "1193/1193 [==============================] - 0s 87us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 48/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 49/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 50/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0130 - val_loss: 0.0058\n",
      "第158个数，还剩3965个没有训练\n",
      "inv_hat [0.3536329  0.32368268 0.32867151 0.32867151 0.30074984 0.29277947\n",
      " 0.28680395 0.30672977 0.29178344 0.30573299 0.35762928 0.36162636\n",
      " 0.355631   0.32068996 0.32268504 0.30473624 0.3107174  0.32268504\n",
      " 0.3526339  0.33366151 0.32966941 0.32168751 0.30772661 0.30373957\n",
      " 0.29377561 0.29875696 0.29477176 0.29078741 0.29078741 0.29875696]\n",
      "Test RMSE: 0.017\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0123 - val_loss: 0.0110\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0124 - val_loss: 0.0107\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0124 - val_loss: 0.0106\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0124 - val_loss: 0.0101\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0125 - val_loss: 0.0098\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0126 - val_loss: 0.0094\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0125 - val_loss: 0.0095\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0123 - val_loss: 0.0093\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0123 - val_loss: 0.0094\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0122 - val_loss: 0.0094\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0121 - val_loss: 0.0094\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0121 - val_loss: 0.0094\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0121 - val_loss: 0.0094\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0121 - val_loss: 0.0094\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0121 - val_loss: 0.0095\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0121 - val_loss: 0.0097\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0121 - val_loss: 0.0097\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0121 - val_loss: 0.0097\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0121 - val_loss: 0.0097\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0121 - val_loss: 0.0096\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0099\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0099\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0122 - val_loss: 0.0099\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0121 - val_loss: 0.0099\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0121 - val_loss: 0.0101\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0102\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0101\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0122 - val_loss: 0.0102\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0122 - val_loss: 0.0102\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0103\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0103\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0104\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0123 - val_loss: 0.0102\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0122 - val_loss: 0.0100\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0101\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0122 - val_loss: 0.0102\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0103\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0104\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0103\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0122 - val_loss: 0.0104\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0101\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0102\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0122 - val_loss: 0.0103\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0103\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0103\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0103\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0122 - val_loss: 0.0103\n",
      "第159个数，还剩3964个没有训练\n",
      "inv_hat [2.54638154 2.5007979  2.50575582 2.49187229 2.45316634 2.45515216\n",
      " 2.44720757 2.47500604 2.45515216 2.48095955 2.49187229 2.49980649\n",
      " 2.48492856 2.43826739 2.43429336 2.4124269  2.41938629 2.42733732\n",
      " 2.46110973 2.42634376 2.42833113 2.40049408 2.37263373 2.33777638\n",
      " 2.30986444 2.31285613 2.30088806 2.28492424 2.27892617 2.29590017]\n",
      "Test RMSE: 0.026\n",
      "Train on 881 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "881/881 [==============================] - 0s 86us/sample - loss: 0.0120 - val_loss: 0.0072\n",
      "Epoch 2/50\n",
      "881/881 [==============================] - 0s 85us/sample - loss: 0.0120 - val_loss: 0.0071\n",
      "Epoch 3/50\n",
      "881/881 [==============================] - 0s 83us/sample - loss: 0.0120 - val_loss: 0.0070\n",
      "Epoch 4/50\n",
      "881/881 [==============================] - 0s 81us/sample - loss: 0.0119 - val_loss: 0.0071\n",
      "Epoch 5/50\n",
      "881/881 [==============================] - 0s 84us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 6/50\n",
      "881/881 [==============================] - 0s 80us/sample - loss: 0.0120 - val_loss: 0.0073\n",
      "Epoch 7/50\n",
      "881/881 [==============================] - 0s 80us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 8/50\n",
      "881/881 [==============================] - 0s 86us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 9/50\n",
      "881/881 [==============================] - 0s 89us/sample - loss: 0.0120 - val_loss: 0.0071\n",
      "Epoch 10/50\n",
      "881/881 [==============================] - 0s 86us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 11/50\n",
      "881/881 [==============================] - 0s 87us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 12/50\n",
      "881/881 [==============================] - 0s 84us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 13/50\n",
      "881/881 [==============================] - 0s 83us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 14/50\n",
      "881/881 [==============================] - 0s 85us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 15/50\n",
      "881/881 [==============================] - 0s 82us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 16/50\n",
      "881/881 [==============================] - 0s 83us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 17/50\n",
      "881/881 [==============================] - 0s 88us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 18/50\n",
      "881/881 [==============================] - 0s 85us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 19/50\n",
      "881/881 [==============================] - 0s 86us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 20/50\n",
      "881/881 [==============================] - 0s 88us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 21/50\n",
      "881/881 [==============================] - 0s 89us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 22/50\n",
      "881/881 [==============================] - 0s 85us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 23/50\n",
      "881/881 [==============================] - 0s 84us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 24/50\n",
      "881/881 [==============================] - 0s 86us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 25/50\n",
      "881/881 [==============================] - 0s 84us/sample - loss: 0.0119 - val_loss: 0.0074\n",
      "Epoch 26/50\n",
      "881/881 [==============================] - 0s 86us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 27/50\n",
      "881/881 [==============================] - 0s 86us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 28/50\n",
      "881/881 [==============================] - 0s 91us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 29/50\n",
      "881/881 [==============================] - 0s 88us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 30/50\n",
      "881/881 [==============================] - 0s 82us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 31/50\n",
      "881/881 [==============================] - 0s 83us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 32/50\n",
      "881/881 [==============================] - 0s 81us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 33/50\n",
      "881/881 [==============================] - 0s 80us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 34/50\n",
      "881/881 [==============================] - 0s 83us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 35/50\n",
      "881/881 [==============================] - 0s 85us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 36/50\n",
      "881/881 [==============================] - 0s 84us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 37/50\n",
      "881/881 [==============================] - 0s 81us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 38/50\n",
      "881/881 [==============================] - 0s 83us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 39/50\n",
      "881/881 [==============================] - 0s 88us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 40/50\n",
      "881/881 [==============================] - 0s 86us/sample - loss: 0.0119 - val_loss: 0.0074\n",
      "Epoch 41/50\n",
      "881/881 [==============================] - 0s 88us/sample - loss: 0.0120 - val_loss: 0.0074\n",
      "Epoch 42/50\n",
      "881/881 [==============================] - 0s 87us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 43/50\n",
      "881/881 [==============================] - 0s 87us/sample - loss: 0.0119 - val_loss: 0.0074\n",
      "Epoch 44/50\n",
      "881/881 [==============================] - 0s 90us/sample - loss: 0.0120 - val_loss: 0.0074\n",
      "Epoch 45/50\n",
      "881/881 [==============================] - 0s 87us/sample - loss: 0.0120 - val_loss: 0.0073\n",
      "Epoch 46/50\n",
      "881/881 [==============================] - 0s 86us/sample - loss: 0.0121 - val_loss: 0.0073\n",
      "Epoch 47/50\n",
      "881/881 [==============================] - 0s 91us/sample - loss: 0.0122 - val_loss: 0.0072\n",
      "Epoch 48/50\n",
      "881/881 [==============================] - 0s 89us/sample - loss: 0.0121 - val_loss: 0.0071\n",
      "Epoch 49/50\n",
      "881/881 [==============================] - 0s 88us/sample - loss: 0.0120 - val_loss: 0.0071\n",
      "Epoch 50/50\n",
      "881/881 [==============================] - 0s 84us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "第160个数，还剩3963个没有训练\n",
      "inv_hat [0.64791261 0.61905693 0.62194081 0.61329027 0.58894845 0.59014006\n",
      " 0.5850764  0.60176156 0.5895443  0.60593503 0.64353219 0.64841047\n",
      " 0.63915258 0.60901596 0.60623315 0.59182824 0.59599963 0.60066865\n",
      " 0.62243809 0.59927777 0.60027125 0.58249537 0.56453741 0.54253538\n",
      " 0.52441955 0.5258048  0.51818751 0.50820144 0.50474239 0.51522067]\n",
      "Test RMSE: 0.016\n",
      "Train on 856 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "856/856 [==============================] - 0s 81us/sample - loss: 0.0176 - val_loss: 0.0126\n",
      "Epoch 2/50\n",
      "856/856 [==============================] - 0s 82us/sample - loss: 0.0175 - val_loss: 0.0132\n",
      "Epoch 3/50\n",
      "856/856 [==============================] - 0s 79us/sample - loss: 0.0176 - val_loss: 0.0130\n",
      "Epoch 4/50\n",
      "856/856 [==============================] - 0s 81us/sample - loss: 0.0176 - val_loss: 0.0125\n",
      "Epoch 5/50\n",
      "856/856 [==============================] - 0s 80us/sample - loss: 0.0175 - val_loss: 0.0130\n",
      "Epoch 6/50\n",
      "856/856 [==============================] - 0s 84us/sample - loss: 0.0175 - val_loss: 0.0129\n",
      "Epoch 7/50\n",
      "856/856 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0127\n",
      "Epoch 8/50\n",
      "856/856 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0129\n",
      "Epoch 9/50\n",
      "856/856 [==============================] - 0s 76us/sample - loss: 0.0175 - val_loss: 0.0128\n",
      "Epoch 10/50\n",
      "856/856 [==============================] - 0s 75us/sample - loss: 0.0175 - val_loss: 0.0129\n",
      "Epoch 11/50\n",
      "856/856 [==============================] - 0s 80us/sample - loss: 0.0175 - val_loss: 0.0129\n",
      "Epoch 12/50\n",
      "856/856 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0128\n",
      "Epoch 13/50\n",
      "856/856 [==============================] - 0s 81us/sample - loss: 0.0175 - val_loss: 0.0128\n",
      "Epoch 14/50\n",
      "856/856 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0130\n",
      "Epoch 15/50\n",
      "856/856 [==============================] - 0s 86us/sample - loss: 0.0175 - val_loss: 0.0128\n",
      "Epoch 16/50\n",
      "856/856 [==============================] - 0s 85us/sample - loss: 0.0175 - val_loss: 0.0128\n",
      "Epoch 17/50\n",
      "856/856 [==============================] - 0s 79us/sample - loss: 0.0175 - val_loss: 0.0129\n",
      "Epoch 18/50\n",
      "856/856 [==============================] - 0s 77us/sample - loss: 0.0175 - val_loss: 0.0129\n",
      "Epoch 19/50\n",
      "856/856 [==============================] - 0s 79us/sample - loss: 0.0175 - val_loss: 0.0129\n",
      "Epoch 20/50\n",
      "856/856 [==============================] - 0s 76us/sample - loss: 0.0175 - val_loss: 0.0128\n",
      "Epoch 21/50\n",
      "856/856 [==============================] - 0s 77us/sample - loss: 0.0175 - val_loss: 0.0129\n",
      "Epoch 22/50\n",
      "856/856 [==============================] - 0s 77us/sample - loss: 0.0175 - val_loss: 0.0129\n",
      "Epoch 23/50\n",
      "856/856 [==============================] - 0s 76us/sample - loss: 0.0175 - val_loss: 0.0130\n",
      "Epoch 24/50\n",
      "856/856 [==============================] - 0s 77us/sample - loss: 0.0175 - val_loss: 0.0128\n",
      "Epoch 25/50\n",
      "856/856 [==============================] - 0s 87us/sample - loss: 0.0175 - val_loss: 0.0129\n",
      "Epoch 26/50\n",
      "856/856 [==============================] - 0s 81us/sample - loss: 0.0175 - val_loss: 0.0129\n",
      "Epoch 27/50\n",
      "856/856 [==============================] - 0s 79us/sample - loss: 0.0175 - val_loss: 0.0130\n",
      "Epoch 28/50\n",
      "856/856 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0130\n",
      "Epoch 29/50\n",
      "856/856 [==============================] - 0s 85us/sample - loss: 0.0175 - val_loss: 0.0128\n",
      "Epoch 30/50\n",
      "856/856 [==============================] - 0s 80us/sample - loss: 0.0175 - val_loss: 0.0128\n",
      "Epoch 31/50\n",
      "856/856 [==============================] - 0s 77us/sample - loss: 0.0175 - val_loss: 0.0132\n",
      "Epoch 32/50\n",
      "856/856 [==============================] - 0s 81us/sample - loss: 0.0175 - val_loss: 0.0130\n",
      "Epoch 33/50\n",
      "856/856 [==============================] - 0s 81us/sample - loss: 0.0175 - val_loss: 0.0127\n",
      "Epoch 34/50\n",
      "856/856 [==============================] - 0s 82us/sample - loss: 0.0175 - val_loss: 0.0127\n",
      "Epoch 35/50\n",
      "856/856 [==============================] - 0s 81us/sample - loss: 0.0175 - val_loss: 0.0131\n",
      "Epoch 36/50\n",
      "856/856 [==============================] - 0s 82us/sample - loss: 0.0175 - val_loss: 0.0132\n",
      "Epoch 37/50\n",
      "856/856 [==============================] - 0s 80us/sample - loss: 0.0176 - val_loss: 0.0129\n",
      "Epoch 38/50\n",
      "856/856 [==============================] - 0s 76us/sample - loss: 0.0175 - val_loss: 0.0128\n",
      "Epoch 39/50\n",
      "856/856 [==============================] - 0s 76us/sample - loss: 0.0175 - val_loss: 0.0129\n",
      "Epoch 40/50\n",
      "856/856 [==============================] - ETA: 0s - loss: 0.017 - 0s 78us/sample - loss: 0.0175 - val_loss: 0.0130\n",
      "Epoch 41/50\n",
      "856/856 [==============================] - 0s 79us/sample - loss: 0.0175 - val_loss: 0.0131\n",
      "Epoch 42/50\n",
      "856/856 [==============================] - 0s 81us/sample - loss: 0.0175 - val_loss: 0.0129\n",
      "Epoch 43/50\n",
      "856/856 [==============================] - 0s 79us/sample - loss: 0.0175 - val_loss: 0.0128\n",
      "Epoch 44/50\n",
      "856/856 [==============================] - 0s 80us/sample - loss: 0.0175 - val_loss: 0.0128\n",
      "Epoch 45/50\n",
      "856/856 [==============================] - 0s 80us/sample - loss: 0.0175 - val_loss: 0.0130\n",
      "Epoch 46/50\n",
      "856/856 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0131\n",
      "Epoch 47/50\n",
      "856/856 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0131\n",
      "Epoch 48/50\n",
      "856/856 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0127\n",
      "Epoch 49/50\n",
      "856/856 [==============================] - 0s 84us/sample - loss: 0.0175 - val_loss: 0.0126\n",
      "Epoch 50/50\n",
      "856/856 [==============================] - 0s 84us/sample - loss: 0.0175 - val_loss: 0.0128\n",
      "第161个数，还剩3962个没有训练\n",
      "inv_hat [0.89000057 0.86342732 0.86511876 0.85835323 0.83537807 0.84273666\n",
      " 0.83348901 0.84591919 0.83607411 0.85099183 0.88260286 0.88861964\n",
      " 0.87559954 0.85447343 0.85198655 0.83507983 0.83517922 0.83746619\n",
      " 0.84940029 0.8292141  0.83448318 0.81669104 0.79825569 0.76717692\n",
      " 0.74959253 0.74542553 0.73957572 0.73412646 0.73680097 0.75167695]\n",
      "Test RMSE: 0.015\n",
      "Train on 788 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "788/788 [==============================] - 0s 82us/sample - loss: 0.0083 - val_loss: 0.0057\n",
      "Epoch 2/50\n",
      "788/788 [==============================] - 0s 79us/sample - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 3/50\n",
      "788/788 [==============================] - 0s 78us/sample - loss: 0.0089 - val_loss: 0.0076\n",
      "Epoch 4/50\n",
      "788/788 [==============================] - 0s 84us/sample - loss: 0.0089 - val_loss: 0.0100\n",
      "Epoch 5/50\n",
      "788/788 [==============================] - 0s 83us/sample - loss: 0.0114 - val_loss: 0.0084\n",
      "Epoch 6/50\n",
      "788/788 [==============================] - 0s 83us/sample - loss: 0.0087 - val_loss: 0.0063\n",
      "Epoch 7/50\n",
      "788/788 [==============================] - 0s 80us/sample - loss: 0.0071 - val_loss: 0.0067\n",
      "Epoch 8/50\n",
      "788/788 [==============================] - 0s 83us/sample - loss: 0.0072 - val_loss: 0.0057\n",
      "Epoch 9/50\n",
      "788/788 [==============================] - 0s 83us/sample - loss: 0.0067 - val_loss: 0.0061\n",
      "Epoch 10/50\n",
      "788/788 [==============================] - 0s 85us/sample - loss: 0.0079 - val_loss: 0.0063\n",
      "Epoch 11/50\n",
      "788/788 [==============================] - 0s 86us/sample - loss: 0.0107 - val_loss: 0.0074\n",
      "Epoch 12/50\n",
      "788/788 [==============================] - 0s 88us/sample - loss: 0.0097 - val_loss: 0.0058\n",
      "Epoch 13/50\n",
      "788/788 [==============================] - 0s 79us/sample - loss: 0.0074 - val_loss: 0.0064\n",
      "Epoch 14/50\n",
      "788/788 [==============================] - 0s 75us/sample - loss: 0.0078 - val_loss: 0.0061\n",
      "Epoch 15/50\n",
      "788/788 [==============================] - 0s 78us/sample - loss: 0.0098 - val_loss: 0.0066\n",
      "Epoch 16/50\n",
      "788/788 [==============================] - 0s 79us/sample - loss: 0.0086 - val_loss: 0.0059\n",
      "Epoch 17/50\n",
      "788/788 [==============================] - 0s 75us/sample - loss: 0.0077 - val_loss: 0.0060\n",
      "Epoch 18/50\n",
      "788/788 [==============================] - 0s 77us/sample - loss: 0.0082 - val_loss: 0.0060\n",
      "Epoch 19/50\n",
      "788/788 [==============================] - 0s 77us/sample - loss: 0.0094 - val_loss: 0.0058\n",
      "Epoch 20/50\n",
      "788/788 [==============================] - 0s 77us/sample - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 21/50\n",
      "788/788 [==============================] - 0s 76us/sample - loss: 0.0068 - val_loss: 0.0055\n",
      "Epoch 22/50\n",
      "788/788 [==============================] - 0s 79us/sample - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 23/50\n",
      "788/788 [==============================] - 0s 82us/sample - loss: 0.0071 - val_loss: 0.0052\n",
      "Epoch 24/50\n",
      "788/788 [==============================] - 0s 77us/sample - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 25/50\n",
      "788/788 [==============================] - 0s 78us/sample - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 26/50\n",
      "788/788 [==============================] - 0s 78us/sample - loss: 0.0075 - val_loss: 0.0078\n",
      "Epoch 27/50\n",
      "788/788 [==============================] - 0s 78us/sample - loss: 0.0095 - val_loss: 0.0063\n",
      "Epoch 28/50\n",
      "788/788 [==============================] - 0s 79us/sample - loss: 0.0067 - val_loss: 0.0055\n",
      "Epoch 29/50\n",
      "788/788 [==============================] - 0s 80us/sample - loss: 0.0073 - val_loss: 0.0074\n",
      "Epoch 30/50\n",
      "788/788 [==============================] - 0s 82us/sample - loss: 0.0098 - val_loss: 0.0056\n",
      "Epoch 31/50\n",
      "788/788 [==============================] - 0s 83us/sample - loss: 0.0075 - val_loss: 0.0060\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "788/788 [==============================] - 0s 79us/sample - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 33/50\n",
      "788/788 [==============================] - 0s 79us/sample - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 34/50\n",
      "788/788 [==============================] - 0s 74us/sample - loss: 0.0090 - val_loss: 0.0056\n",
      "Epoch 35/50\n",
      "788/788 [==============================] - 0s 75us/sample - loss: 0.0069 - val_loss: 0.0059\n",
      "Epoch 36/50\n",
      "788/788 [==============================] - 0s 75us/sample - loss: 0.0084 - val_loss: 0.0079\n",
      "Epoch 37/50\n",
      "788/788 [==============================] - 0s 79us/sample - loss: 0.0102 - val_loss: 0.0058\n",
      "Epoch 38/50\n",
      "788/788 [==============================] - 0s 78us/sample - loss: 0.0080 - val_loss: 0.0056\n",
      "Epoch 39/50\n",
      "788/788 [==============================] - 0s 76us/sample - loss: 0.0076 - val_loss: 0.0058\n",
      "Epoch 40/50\n",
      "788/788 [==============================] - 0s 78us/sample - loss: 0.0083 - val_loss: 0.0065\n",
      "Epoch 41/50\n",
      "788/788 [==============================] - 0s 81us/sample - loss: 0.0093 - val_loss: 0.0058\n",
      "Epoch 42/50\n",
      "788/788 [==============================] - 0s 78us/sample - loss: 0.0073 - val_loss: 0.0063\n",
      "Epoch 43/50\n",
      "788/788 [==============================] - 0s 77us/sample - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 44/50\n",
      "788/788 [==============================] - 0s 78us/sample - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 45/50\n",
      "788/788 [==============================] - 0s 82us/sample - loss: 0.0092 - val_loss: 0.0062\n",
      "Epoch 46/50\n",
      "788/788 [==============================] - 0s 84us/sample - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 47/50\n",
      "788/788 [==============================] - 0s 78us/sample - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 48/50\n",
      "788/788 [==============================] - 0s 78us/sample - loss: 0.0085 - val_loss: 0.0058\n",
      "Epoch 49/50\n",
      "788/788 [==============================] - 0s 82us/sample - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 50/50\n",
      "788/788 [==============================] - 0s 78us/sample - loss: 0.0065 - val_loss: 0.0052\n",
      "第162个数，还剩3961个没有训练\n",
      "inv_hat [0.99505937 0.99505937 0.99505937 0.99505937 0.99406005 0.99406005\n",
      " 0.99406005 0.99406005 0.99505937 0.99505937 0.99505937 0.99705853\n",
      " 0.99805838 0.99905636 1.0000534  1.0010504  1.0010504  1.0010504\n",
      " 0.99905636 0.99805838 0.99705853 0.99705853 0.99805838 0.99905636\n",
      " 0.99905636 0.99905636 1.0000534  1.0000534  1.0000534  1.00204715]\n",
      "Test RMSE: 0.001\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0102 - val_loss: 0.0068\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0157 - val_loss: 0.0137\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0130 - val_loss: 0.0114\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0169 - val_loss: 0.0075\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0143 - val_loss: 0.0065\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0259 - val_loss: 0.0267\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0097 - val_loss: 0.0078\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0146 - val_loss: 0.0067\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0237 - val_loss: 0.0311\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0090 - val_loss: 0.0068\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0149 - val_loss: 0.0077\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0098 - val_loss: 0.0081\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0154 - val_loss: 0.0073\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0073\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0124 - val_loss: 0.0067\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0147 - val_loss: 0.0071\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0093 - val_loss: 0.0092\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0082 - val_loss: 0.0077\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0083 - val_loss: 0.0094\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0111 - val_loss: 0.0074\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0092 - val_loss: 0.0075\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0097 - val_loss: 0.0075\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0173 - val_loss: 0.0113\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0121 - val_loss: 0.0071\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0081 - val_loss: 0.0074\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0126 - val_loss: 0.0071\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0102 - val_loss: 0.0066\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0143 - val_loss: 0.0088\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0079 - val_loss: 0.0085\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0107 - val_loss: 0.0072\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0089 - val_loss: 0.0073\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0064 - val_loss: 0.0068\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 88us/sample - loss: 0.0078 - val_loss: 0.0074\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0161 - val_loss: 0.0124\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0077 - val_loss: 0.0071\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0122 - val_loss: 0.0072\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0077 - val_loss: 0.0078\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 87us/sample - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 87us/sample - loss: 0.0097 - val_loss: 0.0068\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0131 - val_loss: 0.0082\n",
      "第163个数，还剩3960个没有训练\n",
      "inv_hat [1.20703474 1.19991339 1.20194881 1.20296615 1.19685973 1.19685973\n",
      " 1.19584156 1.19991339 1.19685973 1.20093113 1.21008457 1.2121172\n",
      " 1.21110099 1.20398351 1.20296615 1.19889568 1.20093113 1.20398351\n",
      " 1.21008457 1.20398351 1.20194881 1.19889568 1.19482326 1.19278655\n",
      " 1.18973082 1.19074952 1.19074952 1.18973082 1.18871217 1.19380504]\n",
      "Test RMSE: 0.004\n",
      "Train on 603 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "603/603 [==============================] - 0s 87us/sample - loss: 0.0104 - val_loss: 0.0071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "603/603 [==============================] - 0s 88us/sample - loss: 0.0229 - val_loss: 0.0154\n",
      "Epoch 3/50\n",
      "603/603 [==============================] - 0s 90us/sample - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 4/50\n",
      "603/603 [==============================] - 0s 90us/sample - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 5/50\n",
      "603/603 [==============================] - 0s 87us/sample - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 6/50\n",
      "603/603 [==============================] - 0s 87us/sample - loss: 0.0075 - val_loss: 0.0046\n",
      "Epoch 7/50\n",
      "603/603 [==============================] - 0s 87us/sample - loss: 0.0074 - val_loss: 0.0046\n",
      "Epoch 8/50\n",
      "603/603 [==============================] - 0s 88us/sample - loss: 0.0088 - val_loss: 0.0054\n",
      "Epoch 9/50\n",
      "603/603 [==============================] - 0s 86us/sample - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 10/50\n",
      "603/603 [==============================] - 0s 88us/sample - loss: 0.0110 - val_loss: 0.0162\n",
      "Epoch 11/50\n",
      "603/603 [==============================] - 0s 93us/sample - loss: 0.0083 - val_loss: 0.0052\n",
      "Epoch 12/50\n",
      "603/603 [==============================] - 0s 87us/sample - loss: 0.0071 - val_loss: 0.0046\n",
      "Epoch 13/50\n",
      "603/603 [==============================] - 0s 88us/sample - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 14/50\n",
      "603/603 [==============================] - 0s 83us/sample - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 15/50\n",
      "603/603 [==============================] - 0s 84us/sample - loss: 0.0073 - val_loss: 0.0056\n",
      "Epoch 16/50\n",
      "603/603 [==============================] - 0s 89us/sample - loss: 0.0081 - val_loss: 0.0063\n",
      "Epoch 17/50\n",
      "603/603 [==============================] - 0s 89us/sample - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 18/50\n",
      "603/603 [==============================] - 0s 89us/sample - loss: 0.0073 - val_loss: 0.0059\n",
      "Epoch 19/50\n",
      "603/603 [==============================] - 0s 85us/sample - loss: 0.0081 - val_loss: 0.0062\n",
      "Epoch 20/50\n",
      "603/603 [==============================] - 0s 91us/sample - loss: 0.0085 - val_loss: 0.0098\n",
      "Epoch 21/50\n",
      "603/603 [==============================] - 0s 88us/sample - loss: 0.0069 - val_loss: 0.0051\n",
      "Epoch 22/50\n",
      "603/603 [==============================] - 0s 89us/sample - loss: 0.0074 - val_loss: 0.0057\n",
      "Epoch 23/50\n",
      "603/603 [==============================] - 0s 89us/sample - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 24/50\n",
      "603/603 [==============================] - 0s 92us/sample - loss: 0.0061 - val_loss: 0.0053\n",
      "Epoch 25/50\n",
      "603/603 [==============================] - 0s 84us/sample - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 26/50\n",
      "603/603 [==============================] - 0s 86us/sample - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 27/50\n",
      "603/603 [==============================] - 0s 87us/sample - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 28/50\n",
      "603/603 [==============================] - 0s 85us/sample - loss: 0.0060 - val_loss: 0.0054\n",
      "Epoch 29/50\n",
      "603/603 [==============================] - 0s 90us/sample - loss: 0.0066 - val_loss: 0.0060\n",
      "Epoch 30/50\n",
      "603/603 [==============================] - 0s 86us/sample - loss: 0.0060 - val_loss: 0.0068\n",
      "Epoch 31/50\n",
      "603/603 [==============================] - 0s 82us/sample - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 32/50\n",
      "603/603 [==============================] - 0s 82us/sample - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 33/50\n",
      "603/603 [==============================] - 0s 82us/sample - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 34/50\n",
      "603/603 [==============================] - 0s 86us/sample - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 35/50\n",
      "603/603 [==============================] - 0s 85us/sample - loss: 0.0072 - val_loss: 0.0047\n",
      "Epoch 36/50\n",
      "603/603 [==============================] - 0s 84us/sample - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 37/50\n",
      "603/603 [==============================] - 0s 87us/sample - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 38/50\n",
      "603/603 [==============================] - 0s 85us/sample - loss: 0.0059 - val_loss: 0.0068\n",
      "Epoch 39/50\n",
      "603/603 [==============================] - 0s 85us/sample - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 40/50\n",
      "603/603 [==============================] - 0s 87us/sample - loss: 0.0057 - val_loss: 0.0075\n",
      "Epoch 41/50\n",
      "603/603 [==============================] - 0s 82us/sample - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 42/50\n",
      "603/603 [==============================] - 0s 87us/sample - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 43/50\n",
      "603/603 [==============================] - 0s 90us/sample - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 44/50\n",
      "603/603 [==============================] - 0s 97us/sample - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 45/50\n",
      "603/603 [==============================] - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 46/50\n",
      "603/603 [==============================] - 0s 90us/sample - loss: 0.0066 - val_loss: 0.0059\n",
      "Epoch 47/50\n",
      "603/603 [==============================] - 0s 92us/sample - loss: 0.0062 - val_loss: 0.0086\n",
      "Epoch 48/50\n",
      "603/603 [==============================] - 0s 89us/sample - loss: 0.0061 - val_loss: 0.0068\n",
      "Epoch 49/50\n",
      "603/603 [==============================] - 0s 92us/sample - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 50/50\n",
      "603/603 [==============================] - 0s 90us/sample - loss: 0.0056 - val_loss: 0.0064\n",
      "第164个数，还剩3959个没有训练\n",
      "inv_hat [1.06504022 1.06601426 1.06601426 1.06601426 1.06601426 1.06601426\n",
      " 1.06601426 1.06698608 1.06756796 1.06785854 1.06824576 1.06979042\n",
      " 1.07046414 1.07094456 1.07161608 1.07228629 1.07276418 1.07324149\n",
      " 1.07266875 1.07219061 1.07171192 1.07152022 1.07219061 1.07276418\n",
      " 1.07276418 1.07305066 1.07352744 1.07352744 1.07400365 1.07514346]\n",
      "Test RMSE: 0.001\n",
      "Train on 1194 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1194/1194 [==============================] - 0s 83us/sample - loss: 0.0109 - val_loss: 0.0151\n",
      "Epoch 2/50\n",
      "1194/1194 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0149\n",
      "Epoch 3/50\n",
      "1194/1194 [==============================] - 0s 78us/sample - loss: 0.0105 - val_loss: 0.0146\n",
      "Epoch 4/50\n",
      "1194/1194 [==============================] - 0s 75us/sample - loss: 0.0107 - val_loss: 0.0149\n",
      "Epoch 5/50\n",
      "1194/1194 [==============================] - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0159\n",
      "Epoch 6/50\n",
      "1194/1194 [==============================] - 0s 82us/sample - loss: 0.0107 - val_loss: 0.0155\n",
      "Epoch 7/50\n",
      "1194/1194 [==============================] - 0s 78us/sample - loss: 0.0104 - val_loss: 0.0146\n",
      "Epoch 8/50\n",
      "1194/1194 [==============================] - 0s 82us/sample - loss: 0.0110 - val_loss: 0.0161\n",
      "Epoch 9/50\n",
      "1194/1194 [==============================] - 0s 79us/sample - loss: 0.0107 - val_loss: 0.0146\n",
      "Epoch 10/50\n",
      "1194/1194 [==============================] - 0s 78us/sample - loss: 0.0100 - val_loss: 0.0131\n",
      "Epoch 11/50\n",
      "1194/1194 [==============================] - 0s 79us/sample - loss: 0.0107 - val_loss: 0.0155\n",
      "Epoch 12/50\n",
      "1194/1194 [==============================] - 0s 78us/sample - loss: 0.0108 - val_loss: 0.0153\n",
      "Epoch 13/50\n",
      "1194/1194 [==============================] - 0s 82us/sample - loss: 0.0100 - val_loss: 0.0130\n",
      "Epoch 14/50\n",
      "1194/1194 [==============================] - 0s 80us/sample - loss: 0.0103 - val_loss: 0.0147\n",
      "Epoch 15/50\n",
      "1194/1194 [==============================] - 0s 80us/sample - loss: 0.0120 - val_loss: 0.0170\n",
      "Epoch 16/50\n",
      "1194/1194 [==============================] - 0s 80us/sample - loss: 0.0103 - val_loss: 0.0138\n",
      "Epoch 17/50\n",
      "1194/1194 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0124\n",
      "Epoch 18/50\n",
      "1194/1194 [==============================] - 0s 84us/sample - loss: 0.0103 - val_loss: 0.0152\n",
      "Epoch 19/50\n",
      "1194/1194 [==============================] - 0s 81us/sample - loss: 0.0113 - val_loss: 0.0163\n",
      "Epoch 20/50\n",
      "1194/1194 [==============================] - 0s 82us/sample - loss: 0.0100 - val_loss: 0.0133\n",
      "Epoch 21/50\n",
      "1194/1194 [==============================] - 0s 83us/sample - loss: 0.0099 - val_loss: 0.0126\n",
      "Epoch 22/50\n",
      "1194/1194 [==============================] - 0s 83us/sample - loss: 0.0104 - val_loss: 0.0151\n",
      "Epoch 23/50\n",
      "1194/1194 [==============================] - 0s 83us/sample - loss: 0.0112 - val_loss: 0.0161\n",
      "Epoch 24/50\n",
      "1194/1194 [==============================] - 0s 83us/sample - loss: 0.0099 - val_loss: 0.0129\n",
      "Epoch 25/50\n",
      "1194/1194 [==============================] - 0s 85us/sample - loss: 0.0098 - val_loss: 0.0127\n",
      "Epoch 26/50\n",
      "1194/1194 [==============================] - 0s 82us/sample - loss: 0.0101 - val_loss: 0.0138\n",
      "Epoch 27/50\n",
      "1194/1194 [==============================] - 0s 83us/sample - loss: 0.0109 - val_loss: 0.0158\n",
      "Epoch 28/50\n",
      "1194/1194 [==============================] - 0s 82us/sample - loss: 0.0104 - val_loss: 0.0141\n",
      "Epoch 29/50\n",
      "1194/1194 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0120\n",
      "Epoch 30/50\n",
      "1194/1194 [==============================] - 0s 83us/sample - loss: 0.0098 - val_loss: 0.0133\n",
      "Epoch 31/50\n",
      "1194/1194 [==============================] - 0s 86us/sample - loss: 0.0098 - val_loss: 0.0130\n",
      "Epoch 32/50\n",
      "1194/1194 [==============================] - 0s 87us/sample - loss: 0.0099 - val_loss: 0.0133\n",
      "Epoch 33/50\n",
      "1194/1194 [==============================] - 0s 86us/sample - loss: 0.0101 - val_loss: 0.0137\n",
      "Epoch 34/50\n",
      "1194/1194 [==============================] - 0s 83us/sample - loss: 0.0102 - val_loss: 0.0134\n",
      "Epoch 35/50\n",
      "1194/1194 [==============================] - 0s 76us/sample - loss: 0.0097 - val_loss: 0.0117\n",
      "Epoch 36/50\n",
      "1194/1194 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0116\n",
      "Epoch 37/50\n",
      "1194/1194 [==============================] - 0s 79us/sample - loss: 0.0097 - val_loss: 0.0117\n",
      "Epoch 38/50\n",
      "1194/1194 [==============================] - 0s 78us/sample - loss: 0.0097 - val_loss: 0.0123\n",
      "Epoch 39/50\n",
      "1194/1194 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0130\n",
      "Epoch 40/50\n",
      "1194/1194 [==============================] - 0s 77us/sample - loss: 0.0100 - val_loss: 0.0132\n",
      "Epoch 41/50\n",
      "1194/1194 [==============================] - 0s 79us/sample - loss: 0.0098 - val_loss: 0.0123\n",
      "Epoch 42/50\n",
      "1194/1194 [==============================] - 0s 79us/sample - loss: 0.0096 - val_loss: 0.0117\n",
      "Epoch 43/50\n",
      "1194/1194 [==============================] - 0s 82us/sample - loss: 0.0097 - val_loss: 0.0118\n",
      "Epoch 44/50\n",
      "1194/1194 [==============================] - 0s 77us/sample - loss: 0.0098 - val_loss: 0.0116\n",
      "Epoch 45/50\n",
      "1194/1194 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0119\n",
      "Epoch 46/50\n",
      "1194/1194 [==============================] - 0s 78us/sample - loss: 0.0099 - val_loss: 0.0115\n",
      "Epoch 47/50\n",
      "1194/1194 [==============================] - 0s 79us/sample - loss: 0.0097 - val_loss: 0.0124\n",
      "Epoch 48/50\n",
      "1194/1194 [==============================] - 0s 82us/sample - loss: 0.0096 - val_loss: 0.0118\n",
      "Epoch 49/50\n",
      "1194/1194 [==============================] - 0s 79us/sample - loss: 0.0098 - val_loss: 0.0125\n",
      "Epoch 50/50\n",
      "1194/1194 [==============================] - 0s 78us/sample - loss: 0.0104 - val_loss: 0.0140\n",
      "第165个数，还剩3958个没有训练\n",
      "inv_hat [1.10141482 1.10045268 1.10333458 1.10360335 1.10141482 1.10333458\n",
      " 1.10333458 1.10429232 1.10333458 1.10333458 1.10620322 1.09948928\n",
      " 1.09173156 1.09367901 1.09465084 1.09465084 1.09948928 1.10141482\n",
      " 1.09755795 1.09659032 1.09948928 1.0985243  1.0985243  1.09659032\n",
      " 1.09465084 1.09659032 1.09572694 1.09473653 1.09562121 1.09270589]\n",
      "Test RMSE: 0.003\n",
      "Train on 1039 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1039/1039 [==============================] - 0s 79us/sample - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 2/50\n",
      "1039/1039 [==============================] - 0s 79us/sample - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 3/50\n",
      "1039/1039 [==============================] - 0s 79us/sample - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 4/50\n",
      "1039/1039 [==============================] - 0s 82us/sample - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 5/50\n",
      "1039/1039 [==============================] - 0s 82us/sample - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 6/50\n",
      "1039/1039 [==============================] - 0s 81us/sample - loss: 0.0061 - val_loss: 0.0036\n",
      "Epoch 7/50\n",
      "1039/1039 [==============================] - 0s 83us/sample - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 8/50\n",
      "1039/1039 [==============================] - 0s 82us/sample - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 9/50\n",
      "1039/1039 [==============================] - 0s 81us/sample - loss: 0.0094 - val_loss: 0.0037\n",
      "Epoch 10/50\n",
      "1039/1039 [==============================] - 0s 83us/sample - loss: 0.0076 - val_loss: 0.0032\n",
      "Epoch 11/50\n",
      "1039/1039 [==============================] - 0s 83us/sample - loss: 0.0087 - val_loss: 0.0073\n",
      "Epoch 12/50\n",
      "1039/1039 [==============================] - 0s 81us/sample - loss: 0.0161 - val_loss: 0.0211\n",
      "Epoch 13/50\n",
      "1039/1039 [==============================] - 0s 84us/sample - loss: 0.0085 - val_loss: 0.0038\n",
      "Epoch 14/50\n",
      "1039/1039 [==============================] - 0s 87us/sample - loss: 0.0061 - val_loss: 0.0029\n",
      "Epoch 15/50\n",
      "1039/1039 [==============================] - 0s 83us/sample - loss: 0.0066 - val_loss: 0.0042\n",
      "Epoch 16/50\n",
      "1039/1039 [==============================] - 0s 84us/sample - loss: 0.0098 - val_loss: 0.0038\n",
      "Epoch 17/50\n",
      "1039/1039 [==============================] - 0s 84us/sample - loss: 0.0091 - val_loss: 0.0064\n",
      "Epoch 18/50\n",
      "1039/1039 [==============================] - 0s 82us/sample - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 19/50\n",
      "1039/1039 [==============================] - 0s 79us/sample - loss: 0.0152 - val_loss: 0.0167\n",
      "Epoch 20/50\n",
      "1039/1039 [==============================] - 0s 81us/sample - loss: 0.0074 - val_loss: 0.0036\n",
      "Epoch 21/50\n",
      "1039/1039 [==============================] - 0s 81us/sample - loss: 0.0072 - val_loss: 0.0035\n",
      "Epoch 22/50\n",
      "1039/1039 [==============================] - 0s 80us/sample - loss: 0.0074 - val_loss: 0.0030\n",
      "Epoch 23/50\n",
      "1039/1039 [==============================] - 0s 79us/sample - loss: 0.0086 - val_loss: 0.0037\n",
      "Epoch 24/50\n",
      "1039/1039 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0078\n",
      "Epoch 25/50\n",
      "1039/1039 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 26/50\n",
      "1039/1039 [==============================] - 0s 79us/sample - loss: 0.0131 - val_loss: 0.0064\n",
      "Epoch 27/50\n",
      "1039/1039 [==============================] - 0s 81us/sample - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 28/50\n",
      "1039/1039 [==============================] - 0s 84us/sample - loss: 0.0080 - val_loss: 0.0044\n",
      "Epoch 29/50\n",
      "1039/1039 [==============================] - 0s 84us/sample - loss: 0.0073 - val_loss: 0.0030\n",
      "Epoch 30/50\n",
      "1039/1039 [==============================] - 0s 84us/sample - loss: 0.0093 - val_loss: 0.0037\n",
      "Epoch 31/50\n",
      "1039/1039 [==============================] - 0s 82us/sample - loss: 0.0075 - val_loss: 0.0040\n",
      "Epoch 32/50\n",
      "1039/1039 [==============================] - 0s 88us/sample - loss: 0.0073 - val_loss: 0.0052\n",
      "Epoch 33/50\n",
      "1039/1039 [==============================] - 0s 84us/sample - loss: 0.0131 - val_loss: 0.0158\n",
      "Epoch 34/50\n",
      "1039/1039 [==============================] - 0s 78us/sample - loss: 0.0075 - val_loss: 0.0034\n",
      "Epoch 35/50\n",
      "1039/1039 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0043\n",
      "Epoch 36/50\n",
      "1039/1039 [==============================] - 0s 85us/sample - loss: 0.0099 - val_loss: 0.0092\n",
      "Epoch 37/50\n",
      "1039/1039 [==============================] - 0s 80us/sample - loss: 0.0058 - val_loss: 0.0034\n",
      "Epoch 38/50\n",
      "1039/1039 [==============================] - 0s 81us/sample - loss: 0.0083 - val_loss: 0.0057\n",
      "Epoch 39/50\n",
      "1039/1039 [==============================] - 0s 82us/sample - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 40/50\n",
      "1039/1039 [==============================] - 0s 78us/sample - loss: 0.0119 - val_loss: 0.0055\n",
      "Epoch 41/50\n",
      "1039/1039 [==============================] - 0s 80us/sample - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 42/50\n",
      "1039/1039 [==============================] - 0s 79us/sample - loss: 0.0071 - val_loss: 0.0039\n",
      "Epoch 43/50\n",
      "1039/1039 [==============================] - 0s 80us/sample - loss: 0.0078 - val_loss: 0.0039\n",
      "Epoch 44/50\n",
      "1039/1039 [==============================] - 0s 87us/sample - loss: 0.0070 - val_loss: 0.0034\n",
      "Epoch 45/50\n",
      "1039/1039 [==============================] - 0s 84us/sample - loss: 0.0073 - val_loss: 0.0037\n",
      "Epoch 46/50\n",
      "1039/1039 [==============================] - 0s 82us/sample - loss: 0.0061 - val_loss: 0.0066\n",
      "Epoch 47/50\n",
      "1039/1039 [==============================] - 0s 84us/sample - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 48/50\n",
      "1039/1039 [==============================] - 0s 81us/sample - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1039/1039 [==============================] - 0s 81us/sample - loss: 0.0066 - val_loss: 0.0040\n",
      "Epoch 50/50\n",
      "1039/1039 [==============================] - 0s 83us/sample - loss: 0.0088 - val_loss: 0.0069\n",
      "第166个数，还剩3957个没有训练\n",
      "inv_hat [1.06587185 1.06587185 1.06587185 1.06686844 1.06886025 1.06786488\n",
      " 1.06786488 1.06786488 1.06786488 1.06886025 1.06886025 1.0708503\n",
      " 1.06985525 1.0708503  1.06985525 1.0708503  1.06985525 1.06886025\n",
      " 1.06985525 1.06985525 1.0708503  1.0718453  1.0728401  1.0728401\n",
      " 1.0708503  1.0718453  1.0718453  1.0718453  1.0708503  1.0708503 ]\n",
      "Test RMSE: 0.002\n",
      "Train on 753 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "753/753 [==============================] - 0s 81us/sample - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 2/50\n",
      "753/753 [==============================] - 0s 89us/sample - loss: 0.0086 - val_loss: 0.0060\n",
      "Epoch 3/50\n",
      "753/753 [==============================] - 0s 89us/sample - loss: 0.0083 - val_loss: 0.0031\n",
      "Epoch 4/50\n",
      "753/753 [==============================] - 0s 88us/sample - loss: 0.0079 - val_loss: 0.0038\n",
      "Epoch 5/50\n",
      "753/753 [==============================] - 0s 85us/sample - loss: 0.0080 - val_loss: 0.0030\n",
      "Epoch 6/50\n",
      "753/753 [==============================] - 0s 81us/sample - loss: 0.0079 - val_loss: 0.0033\n",
      "Epoch 7/50\n",
      "753/753 [==============================] - 0s 90us/sample - loss: 0.0079 - val_loss: 0.0030\n",
      "Epoch 8/50\n",
      "753/753 [==============================] - 0s 86us/sample - loss: 0.0079 - val_loss: 0.0032\n",
      "Epoch 9/50\n",
      "753/753 [==============================] - 0s 81us/sample - loss: 0.0079 - val_loss: 0.0031\n",
      "Epoch 10/50\n",
      "753/753 [==============================] - 0s 78us/sample - loss: 0.0079 - val_loss: 0.0031\n",
      "Epoch 11/50\n",
      "753/753 [==============================] - 0s 81us/sample - loss: 0.0079 - val_loss: 0.0032\n",
      "Epoch 12/50\n",
      "753/753 [==============================] - 0s 82us/sample - loss: 0.0079 - val_loss: 0.0031\n",
      "Epoch 13/50\n",
      "753/753 [==============================] - 0s 79us/sample - loss: 0.0079 - val_loss: 0.0031\n",
      "Epoch 14/50\n",
      "753/753 [==============================] - 0s 82us/sample - loss: 0.0079 - val_loss: 0.0034\n",
      "Epoch 15/50\n",
      "753/753 [==============================] - 0s 82us/sample - loss: 0.0079 - val_loss: 0.0031\n",
      "Epoch 16/50\n",
      "753/753 [==============================] - 0s 82us/sample - loss: 0.0079 - val_loss: 0.0031\n",
      "Epoch 17/50\n",
      "753/753 [==============================] - 0s 83us/sample - loss: 0.0079 - val_loss: 0.0035\n",
      "Epoch 18/50\n",
      "753/753 [==============================] - 0s 87us/sample - loss: 0.0079 - val_loss: 0.0030\n",
      "Epoch 19/50\n",
      "753/753 [==============================] - 0s 82us/sample - loss: 0.0079 - val_loss: 0.0030\n",
      "Epoch 20/50\n",
      "753/753 [==============================] - 0s 88us/sample - loss: 0.0079 - val_loss: 0.0034\n",
      "Epoch 21/50\n",
      "753/753 [==============================] - 0s 84us/sample - loss: 0.0079 - val_loss: 0.0031\n",
      "Epoch 22/50\n",
      "753/753 [==============================] - 0s 81us/sample - loss: 0.0079 - val_loss: 0.0031\n",
      "Epoch 23/50\n",
      "753/753 [==============================] - 0s 83us/sample - loss: 0.0079 - val_loss: 0.0033\n",
      "Epoch 24/50\n",
      "753/753 [==============================] - 0s 82us/sample - loss: 0.0079 - val_loss: 0.0031\n",
      "Epoch 25/50\n",
      "753/753 [==============================] - 0s 80us/sample - loss: 0.0079 - val_loss: 0.0032\n",
      "Epoch 26/50\n",
      "753/753 [==============================] - 0s 78us/sample - loss: 0.0079 - val_loss: 0.0032\n",
      "Epoch 27/50\n",
      "753/753 [==============================] - 0s 81us/sample - loss: 0.0079 - val_loss: 0.0031\n",
      "Epoch 28/50\n",
      "753/753 [==============================] - 0s 81us/sample - loss: 0.0079 - val_loss: 0.0031\n",
      "Epoch 29/50\n",
      "753/753 [==============================] - 0s 80us/sample - loss: 0.0079 - val_loss: 0.0032\n",
      "Epoch 30/50\n",
      "753/753 [==============================] - 0s 81us/sample - loss: 0.0079 - val_loss: 0.0033\n",
      "Epoch 31/50\n",
      "753/753 [==============================] - 0s 80us/sample - loss: 0.0079 - val_loss: 0.0031\n",
      "Epoch 32/50\n",
      "753/753 [==============================] - 0s 81us/sample - loss: 0.0079 - val_loss: 0.0032\n",
      "Epoch 33/50\n",
      "753/753 [==============================] - 0s 83us/sample - loss: 0.0079 - val_loss: 0.0032\n",
      "Epoch 34/50\n",
      "753/753 [==============================] - 0s 80us/sample - loss: 0.0079 - val_loss: 0.0032\n",
      "Epoch 35/50\n",
      "753/753 [==============================] - 0s 78us/sample - loss: 0.0079 - val_loss: 0.0032\n",
      "Epoch 36/50\n",
      "753/753 [==============================] - 0s 79us/sample - loss: 0.0079 - val_loss: 0.0034\n",
      "Epoch 37/50\n",
      "753/753 [==============================] - 0s 84us/sample - loss: 0.0079 - val_loss: 0.0031\n",
      "Epoch 38/50\n",
      "753/753 [==============================] - 0s 80us/sample - loss: 0.0079 - val_loss: 0.0031\n",
      "Epoch 39/50\n",
      "753/753 [==============================] - 0s 79us/sample - loss: 0.0079 - val_loss: 0.0034\n",
      "Epoch 40/50\n",
      "753/753 [==============================] - 0s 82us/sample - loss: 0.0079 - val_loss: 0.0032\n",
      "Epoch 41/50\n",
      "753/753 [==============================] - 0s 85us/sample - loss: 0.0079 - val_loss: 0.0032\n",
      "Epoch 42/50\n",
      "753/753 [==============================] - 0s 84us/sample - loss: 0.0079 - val_loss: 0.0035\n",
      "Epoch 43/50\n",
      "753/753 [==============================] - 0s 88us/sample - loss: 0.0079 - val_loss: 0.0031\n",
      "Epoch 44/50\n",
      "753/753 [==============================] - 0s 88us/sample - loss: 0.0079 - val_loss: 0.0033\n",
      "Epoch 45/50\n",
      "753/753 [==============================] - 0s 81us/sample - loss: 0.0079 - val_loss: 0.0033\n",
      "Epoch 46/50\n",
      "753/753 [==============================] - 0s 84us/sample - loss: 0.0079 - val_loss: 0.0032\n",
      "Epoch 47/50\n",
      "753/753 [==============================] - 0s 84us/sample - loss: 0.0079 - val_loss: 0.0033\n",
      "Epoch 48/50\n",
      "753/753 [==============================] - 0s 88us/sample - loss: 0.0079 - val_loss: 0.0033\n",
      "Epoch 49/50\n",
      "753/753 [==============================] - 0s 84us/sample - loss: 0.0079 - val_loss: 0.0032\n",
      "Epoch 50/50\n",
      "753/753 [==============================] - 0s 90us/sample - loss: 0.0079 - val_loss: 0.0033\n",
      "第167个数，还剩3956个没有训练\n",
      "inv_hat [1.03933451 1.03983314 1.03963364 1.03983314 1.0397334  1.04013235\n",
      " 1.0397334  1.03943426 1.03993288 1.04083027 1.04173447 1.0419368\n",
      " 1.04112926 1.04127716 1.04127716 1.04137768 1.0415787  1.04218158\n",
      " 1.04218158 1.04218158 1.04228207 1.04208107 1.04238257 1.04274577\n",
      " 1.04365537 1.04335219 1.04365537 1.04405939 1.04436242 1.04638054]\n",
      "Test RMSE: 0.001\n",
      "Train on 650 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "650/650 [==============================] - 0s 93us/sample - loss: 0.0180 - val_loss: 0.0246\n",
      "Epoch 2/50\n",
      "650/650 [==============================] - 0s 90us/sample - loss: 0.0182 - val_loss: 0.0244\n",
      "Epoch 3/50\n",
      "650/650 [==============================] - 0s 88us/sample - loss: 0.0180 - val_loss: 0.0247\n",
      "Epoch 4/50\n",
      "650/650 [==============================] - 0s 87us/sample - loss: 0.0183 - val_loss: 0.0244\n",
      "Epoch 5/50\n",
      "650/650 [==============================] - 0s 86us/sample - loss: 0.0181 - val_loss: 0.0248\n",
      "Epoch 6/50\n",
      "650/650 [==============================] - 0s 85us/sample - loss: 0.0182 - val_loss: 0.0244\n",
      "Epoch 7/50\n",
      "650/650 [==============================] - 0s 83us/sample - loss: 0.0181 - val_loss: 0.0249\n",
      "Epoch 8/50\n",
      "650/650 [==============================] - 0s 86us/sample - loss: 0.0183 - val_loss: 0.0243\n",
      "Epoch 9/50\n",
      "650/650 [==============================] - 0s 88us/sample - loss: 0.0181 - val_loss: 0.0249\n",
      "Epoch 10/50\n",
      "650/650 [==============================] - 0s 86us/sample - loss: 0.0183 - val_loss: 0.0243\n",
      "Epoch 11/50\n",
      "650/650 [==============================] - 0s 90us/sample - loss: 0.0181 - val_loss: 0.0249\n",
      "Epoch 12/50\n",
      "650/650 [==============================] - 0s 91us/sample - loss: 0.0183 - val_loss: 0.0243\n",
      "Epoch 13/50\n",
      "650/650 [==============================] - 0s 87us/sample - loss: 0.0182 - val_loss: 0.0252\n",
      "Epoch 14/50\n",
      "650/650 [==============================] - 0s 90us/sample - loss: 0.0183 - val_loss: 0.0243\n",
      "Epoch 15/50\n",
      "650/650 [==============================] - 0s 88us/sample - loss: 0.0182 - val_loss: 0.0251\n",
      "Epoch 16/50\n",
      "650/650 [==============================] - 0s 91us/sample - loss: 0.0184 - val_loss: 0.0243\n",
      "Epoch 17/50\n",
      "650/650 [==============================] - 0s 88us/sample - loss: 0.0182 - val_loss: 0.0250\n",
      "Epoch 18/50\n",
      "650/650 [==============================] - 0s 87us/sample - loss: 0.0184 - val_loss: 0.0243\n",
      "Epoch 19/50\n",
      "650/650 [==============================] - 0s 90us/sample - loss: 0.0181 - val_loss: 0.0251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "650/650 [==============================] - 0s 89us/sample - loss: 0.0183 - val_loss: 0.0243\n",
      "Epoch 21/50\n",
      "650/650 [==============================] - 0s 87us/sample - loss: 0.0182 - val_loss: 0.0253\n",
      "Epoch 22/50\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 0.0185 - val_loss: 0.0243\n",
      "Epoch 23/50\n",
      "650/650 [==============================] - 0s 91us/sample - loss: 0.0182 - val_loss: 0.0251\n",
      "Epoch 24/50\n",
      "650/650 [==============================] - 0s 88us/sample - loss: 0.0184 - val_loss: 0.0243\n",
      "Epoch 25/50\n",
      "650/650 [==============================] - 0s 84us/sample - loss: 0.0182 - val_loss: 0.0251\n",
      "Epoch 26/50\n",
      "650/650 [==============================] - 0s 85us/sample - loss: 0.0184 - val_loss: 0.0243\n",
      "Epoch 27/50\n",
      "650/650 [==============================] - 0s 91us/sample - loss: 0.0182 - val_loss: 0.0251\n",
      "Epoch 28/50\n",
      "650/650 [==============================] - 0s 91us/sample - loss: 0.0183 - val_loss: 0.0243\n",
      "Epoch 29/50\n",
      "650/650 [==============================] - 0s 90us/sample - loss: 0.0182 - val_loss: 0.0253\n",
      "Epoch 30/50\n",
      "650/650 [==============================] - 0s 87us/sample - loss: 0.0185 - val_loss: 0.0243\n",
      "Epoch 31/50\n",
      "650/650 [==============================] - 0s 87us/sample - loss: 0.0184 - val_loss: 0.0253\n",
      "Epoch 32/50\n",
      "650/650 [==============================] - 0s 89us/sample - loss: 0.0187 - val_loss: 0.0243\n",
      "Epoch 33/50\n",
      "650/650 [==============================] - 0s 93us/sample - loss: 0.0183 - val_loss: 0.0253\n",
      "Epoch 34/50\n",
      "650/650 [==============================] - 0s 96us/sample - loss: 0.0185 - val_loss: 0.0243\n",
      "Epoch 35/50\n",
      "650/650 [==============================] - 0s 89us/sample - loss: 0.0182 - val_loss: 0.0252\n",
      "Epoch 36/50\n",
      "650/650 [==============================] - 0s 94us/sample - loss: 0.0184 - val_loss: 0.0243\n",
      "Epoch 37/50\n",
      "650/650 [==============================] - 0s 88us/sample - loss: 0.0182 - val_loss: 0.0251\n",
      "Epoch 38/50\n",
      "650/650 [==============================] - 0s 93us/sample - loss: 0.0184 - val_loss: 0.0243\n",
      "Epoch 39/50\n",
      "650/650 [==============================] - 0s 91us/sample - loss: 0.0182 - val_loss: 0.0250\n",
      "Epoch 40/50\n",
      "650/650 [==============================] - 0s 87us/sample - loss: 0.0183 - val_loss: 0.0243\n",
      "Epoch 41/50\n",
      "650/650 [==============================] - 0s 87us/sample - loss: 0.0182 - val_loss: 0.0250\n",
      "Epoch 42/50\n",
      "650/650 [==============================] - 0s 88us/sample - loss: 0.0183 - val_loss: 0.0243\n",
      "Epoch 43/50\n",
      "650/650 [==============================] - 0s 88us/sample - loss: 0.0182 - val_loss: 0.0251\n",
      "Epoch 44/50\n",
      "650/650 [==============================] - 0s 85us/sample - loss: 0.0183 - val_loss: 0.0243\n",
      "Epoch 45/50\n",
      "650/650 [==============================] - 0s 87us/sample - loss: 0.0182 - val_loss: 0.0250\n",
      "Epoch 46/50\n",
      "650/650 [==============================] - 0s 87us/sample - loss: 0.0184 - val_loss: 0.0243\n",
      "Epoch 47/50\n",
      "650/650 [==============================] - 0s 88us/sample - loss: 0.0182 - val_loss: 0.0252\n",
      "Epoch 48/50\n",
      "650/650 [==============================] - 0s 88us/sample - loss: 0.0183 - val_loss: 0.0243\n",
      "Epoch 49/50\n",
      "650/650 [==============================] - 0s 95us/sample - loss: 0.0182 - val_loss: 0.0251\n",
      "Epoch 50/50\n",
      "650/650 [==============================] - 0s 87us/sample - loss: 0.0184 - val_loss: 0.0243\n",
      "第168个数，还剩3955个没有训练\n",
      "inv_hat [1.08202698 1.06203066 1.07001628 1.07201565 1.04910562 1.04415537\n",
      " 1.04910562 1.06003769 1.05009724 1.05705106 1.08804247 1.09205514\n",
      " 1.09506527 1.08002309 1.07701864 1.07401622 1.07701864 1.07201565\n",
      " 1.08202698 1.06402517 1.05705106 1.05406816 1.042179   1.04514441\n",
      " 1.0411917  1.05506206 1.05506206 1.0530748  1.04910562 1.04811462]\n",
      "Test RMSE: 0.011\n",
      "Train on 478 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "478/478 [==============================] - 0s 91us/sample - loss: 0.0211 - val_loss: 0.0238\n",
      "Epoch 2/50\n",
      "478/478 [==============================] - 0s 89us/sample - loss: 0.0223 - val_loss: 0.0183\n",
      "Epoch 3/50\n",
      "478/478 [==============================] - 0s 89us/sample - loss: 0.0212 - val_loss: 0.0211\n",
      "Epoch 4/50\n",
      "478/478 [==============================] - 0s 87us/sample - loss: 0.0211 - val_loss: 0.0182\n",
      "Epoch 5/50\n",
      "478/478 [==============================] - 0s 90us/sample - loss: 0.0213 - val_loss: 0.0222\n",
      "Epoch 6/50\n",
      "478/478 [==============================] - 0s 87us/sample - loss: 0.0216 - val_loss: 0.0183\n",
      "Epoch 7/50\n",
      "478/478 [==============================] - 0s 87us/sample - loss: 0.0211 - val_loss: 0.0212\n",
      "Epoch 8/50\n",
      "478/478 [==============================] - 0s 85us/sample - loss: 0.0212 - val_loss: 0.0182\n",
      "Epoch 9/50\n",
      "478/478 [==============================] - 0s 82us/sample - loss: 0.0212 - val_loss: 0.0217\n",
      "Epoch 10/50\n",
      "478/478 [==============================] - 0s 84us/sample - loss: 0.0214 - val_loss: 0.0182\n",
      "Epoch 11/50\n",
      "478/478 [==============================] - 0s 84us/sample - loss: 0.0211 - val_loss: 0.0211\n",
      "Epoch 12/50\n",
      "478/478 [==============================] - 0s 84us/sample - loss: 0.0212 - val_loss: 0.0182\n",
      "Epoch 13/50\n",
      "478/478 [==============================] - 0s 85us/sample - loss: 0.0212 - val_loss: 0.0214\n",
      "Epoch 14/50\n",
      "478/478 [==============================] - 0s 88us/sample - loss: 0.0213 - val_loss: 0.0182\n",
      "Epoch 15/50\n",
      "478/478 [==============================] - 0s 82us/sample - loss: 0.0211 - val_loss: 0.0211\n",
      "Epoch 16/50\n",
      "478/478 [==============================] - 0s 85us/sample - loss: 0.0212 - val_loss: 0.0182\n",
      "Epoch 17/50\n",
      "478/478 [==============================] - 0s 84us/sample - loss: 0.0211 - val_loss: 0.0211\n",
      "Epoch 18/50\n",
      "478/478 [==============================] - 0s 85us/sample - loss: 0.0212 - val_loss: 0.0182\n",
      "Epoch 19/50\n",
      "478/478 [==============================] - 0s 83us/sample - loss: 0.0211 - val_loss: 0.0212\n",
      "Epoch 20/50\n",
      "478/478 [==============================] - 0s 85us/sample - loss: 0.0212 - val_loss: 0.0182\n",
      "Epoch 21/50\n",
      "478/478 [==============================] - 0s 83us/sample - loss: 0.0210 - val_loss: 0.0211\n",
      "Epoch 22/50\n",
      "478/478 [==============================] - 0s 88us/sample - loss: 0.0212 - val_loss: 0.0182\n",
      "Epoch 23/50\n",
      "478/478 [==============================] - 0s 86us/sample - loss: 0.0210 - val_loss: 0.0212\n",
      "Epoch 24/50\n",
      "478/478 [==============================] - 0s 86us/sample - loss: 0.0212 - val_loss: 0.0182\n",
      "Epoch 25/50\n",
      "478/478 [==============================] - 0s 87us/sample - loss: 0.0210 - val_loss: 0.0212\n",
      "Epoch 26/50\n",
      "478/478 [==============================] - 0s 89us/sample - loss: 0.0212 - val_loss: 0.0182\n",
      "Epoch 27/50\n",
      "478/478 [==============================] - 0s 91us/sample - loss: 0.0209 - val_loss: 0.0212\n",
      "Epoch 28/50\n",
      "478/478 [==============================] - 0s 85us/sample - loss: 0.0212 - val_loss: 0.0182\n",
      "Epoch 29/50\n",
      "478/478 [==============================] - 0s 86us/sample - loss: 0.0209 - val_loss: 0.0212\n",
      "Epoch 30/50\n",
      "478/478 [==============================] - 0s 82us/sample - loss: 0.0212 - val_loss: 0.0182\n",
      "Epoch 31/50\n",
      "478/478 [==============================] - 0s 90us/sample - loss: 0.0209 - val_loss: 0.0211\n",
      "Epoch 32/50\n",
      "478/478 [==============================] - 0s 83us/sample - loss: 0.0212 - val_loss: 0.0182\n",
      "Epoch 33/50\n",
      "478/478 [==============================] - 0s 81us/sample - loss: 0.0209 - val_loss: 0.0211\n",
      "Epoch 34/50\n",
      "478/478 [==============================] - 0s 81us/sample - loss: 0.0211 - val_loss: 0.0182\n",
      "Epoch 35/50\n",
      "478/478 [==============================] - 0s 89us/sample - loss: 0.0209 - val_loss: 0.0212\n",
      "Epoch 36/50\n",
      "478/478 [==============================] - 0s 89us/sample - loss: 0.0212 - val_loss: 0.0182\n",
      "Epoch 37/50\n",
      "478/478 [==============================] - 0s 83us/sample - loss: 0.0209 - val_loss: 0.0211\n",
      "Epoch 38/50\n",
      "478/478 [==============================] - 0s 86us/sample - loss: 0.0211 - val_loss: 0.0181\n",
      "Epoch 39/50\n",
      "478/478 [==============================] - 0s 82us/sample - loss: 0.0209 - val_loss: 0.0211\n",
      "Epoch 40/50\n",
      "478/478 [==============================] - 0s 84us/sample - loss: 0.0211 - val_loss: 0.0181\n",
      "Epoch 41/50\n",
      "478/478 [==============================] - 0s 87us/sample - loss: 0.0209 - val_loss: 0.0211\n",
      "Epoch 42/50\n",
      "478/478 [==============================] - 0s 87us/sample - loss: 0.0211 - val_loss: 0.0181\n",
      "Epoch 43/50\n",
      "478/478 [==============================] - 0s 85us/sample - loss: 0.0208 - val_loss: 0.0211\n",
      "Epoch 44/50\n",
      "478/478 [==============================] - 0s 83us/sample - loss: 0.0211 - val_loss: 0.0181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "478/478 [==============================] - 0s 82us/sample - loss: 0.0208 - val_loss: 0.0211\n",
      "Epoch 46/50\n",
      "478/478 [==============================] - 0s 90us/sample - loss: 0.0211 - val_loss: 0.0181\n",
      "Epoch 47/50\n",
      "478/478 [==============================] - 0s 89us/sample - loss: 0.0208 - val_loss: 0.0211\n",
      "Epoch 48/50\n",
      "478/478 [==============================] - 0s 85us/sample - loss: 0.0211 - val_loss: 0.0181\n",
      "Epoch 49/50\n",
      "478/478 [==============================] - 0s 83us/sample - loss: 0.0207 - val_loss: 0.0210\n",
      "Epoch 50/50\n",
      "478/478 [==============================] - 0s 86us/sample - loss: 0.0211 - val_loss: 0.0181\n",
      "第169个数，还剩3954个没有训练\n",
      "inv_hat [1.00407044 0.99376126 0.99532542 0.99151744 0.98385371 0.98414344\n",
      " 0.98067355 0.98772538 0.98211747 0.98898759 1.0027886  1.00328153\n",
      " 1.00121305 0.98918191 0.98801653 0.98308156 0.98578727 0.98879325\n",
      " 0.99561897 0.98772538 0.98675576 0.98192476 0.97808139 0.97273463\n",
      " 0.96526351 0.96620437 0.96469969 0.96263677 0.96310495 0.96875186]\n",
      "Test RMSE: 0.006\n",
      "Train on 676 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "676/676 [==============================] - 0s 87us/sample - loss: 0.0188 - val_loss: 0.0175\n",
      "Epoch 2/50\n",
      "676/676 [==============================] - 0s 87us/sample - loss: 0.0186 - val_loss: 0.0175\n",
      "Epoch 3/50\n",
      "676/676 [==============================] - 0s 87us/sample - loss: 0.0187 - val_loss: 0.0175\n",
      "Epoch 4/50\n",
      "676/676 [==============================] - 0s 85us/sample - loss: 0.0186 - val_loss: 0.0175\n",
      "Epoch 5/50\n",
      "676/676 [==============================] - 0s 87us/sample - loss: 0.0185 - val_loss: 0.0175\n",
      "Epoch 6/50\n",
      "676/676 [==============================] - 0s 86us/sample - loss: 0.0187 - val_loss: 0.0175\n",
      "Epoch 7/50\n",
      "676/676 [==============================] - 0s 85us/sample - loss: 0.0185 - val_loss: 0.0175\n",
      "Epoch 8/50\n",
      "676/676 [==============================] - 0s 83us/sample - loss: 0.0187 - val_loss: 0.0175\n",
      "Epoch 9/50\n",
      "676/676 [==============================] - 0s 84us/sample - loss: 0.0185 - val_loss: 0.0175\n",
      "Epoch 10/50\n",
      "676/676 [==============================] - 0s 83us/sample - loss: 0.0187 - val_loss: 0.0175\n",
      "Epoch 11/50\n",
      "676/676 [==============================] - 0s 85us/sample - loss: 0.0186 - val_loss: 0.0175\n",
      "Epoch 12/50\n",
      "676/676 [==============================] - 0s 85us/sample - loss: 0.0186 - val_loss: 0.0175\n",
      "Epoch 13/50\n",
      "676/676 [==============================] - 0s 86us/sample - loss: 0.0186 - val_loss: 0.0175\n",
      "Epoch 14/50\n",
      "676/676 [==============================] - 0s 90us/sample - loss: 0.0186 - val_loss: 0.0175\n",
      "Epoch 15/50\n",
      "676/676 [==============================] - 0s 86us/sample - loss: 0.0186 - val_loss: 0.0175\n",
      "Epoch 16/50\n",
      "676/676 [==============================] - 0s 83us/sample - loss: 0.0185 - val_loss: 0.0175\n",
      "Epoch 17/50\n",
      "676/676 [==============================] - 0s 91us/sample - loss: 0.0187 - val_loss: 0.0175\n",
      "Epoch 18/50\n",
      "676/676 [==============================] - 0s 83us/sample - loss: 0.0185 - val_loss: 0.0175\n",
      "Epoch 19/50\n",
      "676/676 [==============================] - 0s 86us/sample - loss: 0.0186 - val_loss: 0.0175\n",
      "Epoch 20/50\n",
      "676/676 [==============================] - 0s 82us/sample - loss: 0.0186 - val_loss: 0.0175\n",
      "Epoch 21/50\n",
      "676/676 [==============================] - 0s 88us/sample - loss: 0.0186 - val_loss: 0.0175\n",
      "Epoch 22/50\n",
      "676/676 [==============================] - 0s 83us/sample - loss: 0.0186 - val_loss: 0.0175\n",
      "Epoch 23/50\n",
      "676/676 [==============================] - 0s 80us/sample - loss: 0.0186 - val_loss: 0.0175\n",
      "Epoch 24/50\n",
      "676/676 [==============================] - 0s 85us/sample - loss: 0.0186 - val_loss: 0.0175\n",
      "Epoch 25/50\n",
      "676/676 [==============================] - 0s 84us/sample - loss: 0.0186 - val_loss: 0.0175\n",
      "Epoch 26/50\n",
      "676/676 [==============================] - 0s 88us/sample - loss: 0.0185 - val_loss: 0.0175\n",
      "Epoch 27/50\n",
      "676/676 [==============================] - 0s 80us/sample - loss: 0.0186 - val_loss: 0.0175\n",
      "Epoch 28/50\n",
      "676/676 [==============================] - 0s 84us/sample - loss: 0.0186 - val_loss: 0.0175\n",
      "Epoch 29/50\n",
      "676/676 [==============================] - 0s 86us/sample - loss: 0.0186 - val_loss: 0.0175\n",
      "Epoch 30/50\n",
      "676/676 [==============================] - 0s 86us/sample - loss: 0.0185 - val_loss: 0.0175\n",
      "Epoch 31/50\n",
      "676/676 [==============================] - 0s 89us/sample - loss: 0.0186 - val_loss: 0.0176\n",
      "Epoch 32/50\n",
      "676/676 [==============================] - 0s 86us/sample - loss: 0.0186 - val_loss: 0.0176\n",
      "Epoch 33/50\n",
      "676/676 [==============================] - 0s 87us/sample - loss: 0.0186 - val_loss: 0.0176\n",
      "Epoch 34/50\n",
      "676/676 [==============================] - 0s 86us/sample - loss: 0.0186 - val_loss: 0.0176\n",
      "Epoch 35/50\n",
      "676/676 [==============================] - 0s 90us/sample - loss: 0.0186 - val_loss: 0.0175\n",
      "Epoch 36/50\n",
      "676/676 [==============================] - 0s 85us/sample - loss: 0.0185 - val_loss: 0.0175\n",
      "Epoch 37/50\n",
      "676/676 [==============================] - 0s 85us/sample - loss: 0.0187 - val_loss: 0.0176\n",
      "Epoch 38/50\n",
      "676/676 [==============================] - 0s 90us/sample - loss: 0.0186 - val_loss: 0.0176\n",
      "Epoch 39/50\n",
      "676/676 [==============================] - 0s 87us/sample - loss: 0.0185 - val_loss: 0.0175\n",
      "Epoch 40/50\n",
      "676/676 [==============================] - 0s 86us/sample - loss: 0.0186 - val_loss: 0.0176\n",
      "Epoch 41/50\n",
      "676/676 [==============================] - 0s 85us/sample - loss: 0.0186 - val_loss: 0.0176\n",
      "Epoch 42/50\n",
      "676/676 [==============================] - 0s 89us/sample - loss: 0.0185 - val_loss: 0.0176\n",
      "Epoch 43/50\n",
      "676/676 [==============================] - 0s 85us/sample - loss: 0.0186 - val_loss: 0.0176\n",
      "Epoch 44/50\n",
      "676/676 [==============================] - 0s 91us/sample - loss: 0.0186 - val_loss: 0.0176\n",
      "Epoch 45/50\n",
      "676/676 [==============================] - 0s 87us/sample - loss: 0.0185 - val_loss: 0.0176\n",
      "Epoch 46/50\n",
      "676/676 [==============================] - 0s 91us/sample - loss: 0.0186 - val_loss: 0.0177\n",
      "Epoch 47/50\n",
      "676/676 [==============================] - 0s 87us/sample - loss: 0.0186 - val_loss: 0.0176\n",
      "Epoch 48/50\n",
      "676/676 [==============================] - 0s 80us/sample - loss: 0.0186 - val_loss: 0.0176\n",
      "Epoch 49/50\n",
      "676/676 [==============================] - 0s 80us/sample - loss: 0.0186 - val_loss: 0.0177\n",
      "Epoch 50/50\n",
      "676/676 [==============================] - 0s 80us/sample - loss: 0.0186 - val_loss: 0.0176\n",
      "第170个数，还剩3953个没有训练\n",
      "inv_hat [0.75318125 0.72582726 0.72970735 0.72970735 0.70371934 0.70086289\n",
      " 0.70753811 0.71520938 0.69801314 0.70276648 0.7229237  0.72679634\n",
      " 0.72776605 0.70467294 0.69611701 0.70086289 0.70371934 0.70086289\n",
      " 0.70658235 0.69044717 0.68574392 0.68199585 0.67175767 0.66827201\n",
      " 0.6701175  0.67474684 0.67104158 0.6701175  0.66827201 0.66827201]\n",
      "Test RMSE: 0.011\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0082\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0116 - val_loss: 0.0082\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0115 - val_loss: 0.0084\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0083\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0115 - val_loss: 0.0084\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0115 - val_loss: 0.0086\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0115 - val_loss: 0.0089\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0115 - val_loss: 0.0089\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0115 - val_loss: 0.0089\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0115 - val_loss: 0.0089\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0115 - val_loss: 0.0090\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0115 - val_loss: 0.0091\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0115 - val_loss: 0.0093\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0115 - val_loss: 0.0092\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0114 - val_loss: 0.0090\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0114 - val_loss: 0.0091\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0114 - val_loss: 0.0089\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0114 - val_loss: 0.0089\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0089\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0114 - val_loss: 0.0087\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0089\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0087\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0085\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0114 - val_loss: 0.0086\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0086\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0114 - val_loss: 0.0087\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0114 - val_loss: 0.0087\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0114 - val_loss: 0.0085\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0114 - val_loss: 0.0087\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0114 - val_loss: 0.0086\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0114 - val_loss: 0.0087\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0114 - val_loss: 0.0084\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0114 - val_loss: 0.0085\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0114 - val_loss: 0.0087\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0086\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0115 - val_loss: 0.0089\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0115 - val_loss: 0.0089\n",
      "第171个数，还剩3952个没有训练\n",
      "inv_hat [1.86870095 1.81154297 1.82433857 1.82630802 1.77223174 1.75653386\n",
      " 1.75751442 1.78106867 1.75261168 1.76830582 1.83221736 1.83123244\n",
      " 1.82926253 1.77615866 1.77812247 1.78401531 1.79777339 1.7967904\n",
      " 1.82926253 1.7938415  1.7732134  1.76045682 1.73987204 1.73791303\n",
      " 1.73399584 1.75947593 1.76045682 1.75359223 1.74673068 1.76830582]\n",
      "Test RMSE: 0.027\n",
      "Train on 688 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "688/688 [==============================] - 0s 83us/sample - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 2/50\n",
      "688/688 [==============================] - 0s 85us/sample - loss: 0.0074 - val_loss: 0.0112\n",
      "Epoch 3/50\n",
      "688/688 [==============================] - 0s 81us/sample - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 4/50\n",
      "688/688 [==============================] - 0s 80us/sample - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 5/50\n",
      "688/688 [==============================] - 0s 79us/sample - loss: 0.0077 - val_loss: 0.0114\n",
      "Epoch 6/50\n",
      "688/688 [==============================] - 0s 80us/sample - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 7/50\n",
      "688/688 [==============================] - 0s 83us/sample - loss: 0.0123 - val_loss: 0.0098\n",
      "Epoch 8/50\n",
      "688/688 [==============================] - 0s 85us/sample - loss: 0.0160 - val_loss: 0.0130\n",
      "Epoch 9/50\n",
      "688/688 [==============================] - 0s 86us/sample - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 10/50\n",
      "688/688 [==============================] - 0s 87us/sample - loss: 0.0059 - val_loss: 0.0099\n",
      "Epoch 11/50\n",
      "688/688 [==============================] - 0s 85us/sample - loss: 0.0085 - val_loss: 0.0110\n",
      "Epoch 12/50\n",
      "688/688 [==============================] - 0s 83us/sample - loss: 0.0101 - val_loss: 0.0072\n",
      "Epoch 13/50\n",
      "688/688 [==============================] - 0s 80us/sample - loss: 0.0140 - val_loss: 0.0131\n",
      "Epoch 14/50\n",
      "688/688 [==============================] - 0s 77us/sample - loss: 0.0058 - val_loss: 0.0060\n",
      "Epoch 15/50\n",
      "688/688 [==============================] - 0s 78us/sample - loss: 0.0057 - val_loss: 0.0116\n",
      "Epoch 16/50\n",
      "688/688 [==============================] - 0s 78us/sample - loss: 0.0077 - val_loss: 0.0072\n",
      "Epoch 17/50\n",
      "688/688 [==============================] - 0s 80us/sample - loss: 0.0056 - val_loss: 0.0096\n",
      "Epoch 18/50\n",
      "688/688 [==============================] - 0s 80us/sample - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 19/50\n",
      "688/688 [==============================] - 0s 81us/sample - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 20/50\n",
      "688/688 [==============================] - 0s 86us/sample - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 21/50\n",
      "688/688 [==============================] - 0s 83us/sample - loss: 0.0098 - val_loss: 0.0041\n",
      "Epoch 22/50\n",
      "688/688 [==============================] - 0s 81us/sample - loss: 0.0067 - val_loss: 0.0041\n",
      "Epoch 23/50\n",
      "688/688 [==============================] - 0s 81us/sample - loss: 0.0091 - val_loss: 0.0072\n",
      "Epoch 24/50\n",
      "688/688 [==============================] - 0s 81us/sample - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 25/50\n",
      "688/688 [==============================] - 0s 86us/sample - loss: 0.0101 - val_loss: 0.0048\n",
      "Epoch 26/50\n",
      "688/688 [==============================] - 0s 84us/sample - loss: 0.0096 - val_loss: 0.0050\n",
      "Epoch 27/50\n",
      "688/688 [==============================] - 0s 83us/sample - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 28/50\n",
      "688/688 [==============================] - 0s 83us/sample - loss: 0.0075 - val_loss: 0.0064\n",
      "Epoch 29/50\n",
      "688/688 [==============================] - 0s 83us/sample - loss: 0.0096 - val_loss: 0.0113\n",
      "Epoch 30/50\n",
      "688/688 [==============================] - 0s 85us/sample - loss: 0.0091 - val_loss: 0.0052\n",
      "Epoch 31/50\n",
      "688/688 [==============================] - 0s 87us/sample - loss: 0.0049 - val_loss: 0.0059\n",
      "Epoch 32/50\n",
      "688/688 [==============================] - 0s 86us/sample - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 33/50\n",
      "688/688 [==============================] - 0s 86us/sample - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 34/50\n",
      "688/688 [==============================] - 0s 81us/sample - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 35/50\n",
      "688/688 [==============================] - 0s 79us/sample - loss: 0.0099 - val_loss: 0.0081\n",
      "Epoch 36/50\n",
      "688/688 [==============================] - 0s 80us/sample - loss: 0.0078 - val_loss: 0.0056\n",
      "Epoch 37/50\n",
      "688/688 [==============================] - 0s 81us/sample - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 38/50\n",
      "688/688 [==============================] - 0s 84us/sample - loss: 0.0091 - val_loss: 0.0048\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 0s 90us/sample - loss: 0.0085 - val_loss: 0.0064\n",
      "Epoch 40/50\n",
      "688/688 [==============================] - 0s 87us/sample - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 41/50\n",
      "688/688 [==============================] - 0s 85us/sample - loss: 0.0084 - val_loss: 0.0093\n",
      "Epoch 42/50\n",
      "688/688 [==============================] - 0s 81us/sample - loss: 0.0059 - val_loss: 0.0084\n",
      "Epoch 43/50\n",
      "688/688 [==============================] - 0s 80us/sample - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 44/50\n",
      "688/688 [==============================] - 0s 79us/sample - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 45/50\n",
      "688/688 [==============================] - 0s 79us/sample - loss: 0.0092 - val_loss: 0.0094\n",
      "Epoch 46/50\n",
      "688/688 [==============================] - 0s 83us/sample - loss: 0.0054 - val_loss: 0.0066\n",
      "Epoch 47/50\n",
      "688/688 [==============================] - 0s 81us/sample - loss: 0.0066 - val_loss: 0.0058\n",
      "Epoch 48/50\n",
      "688/688 [==============================] - 0s 80us/sample - loss: 0.0061 - val_loss: 0.0057\n",
      "Epoch 49/50\n",
      "688/688 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 50/50\n",
      "688/688 [==============================] - 0s 77us/sample - loss: 0.0045 - val_loss: 0.0059\n",
      "第172个数，还剩3951个没有训练\n",
      "inv_hat [1.0588099  1.05784254 1.05784254 1.05784254 1.05784254 1.05784254\n",
      " 1.05784254 1.05784254 1.05784254 1.05784254 1.0588099  1.0588099\n",
      " 1.0588099  1.0588099  1.0588099  1.0588099  1.05977353 1.05977353\n",
      " 1.0588099  1.0588099  1.0588099  1.0588099  1.05784254 1.0588099\n",
      " 1.0588099  1.0588099  1.0588099  1.0588099  1.0588099  1.05977353]\n",
      "Test RMSE: 0.001\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0117 - val_loss: 0.0131\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0099 - val_loss: 0.0143\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0233 - val_loss: 0.0215\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0203 - val_loss: 0.0536\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0237 - val_loss: 0.0027\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0083 - val_loss: 0.0014\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0080 - val_loss: 0.0180\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0116 - val_loss: 0.0166\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0190 - val_loss: 0.0166\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0171 - val_loss: 0.0408\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0151 - val_loss: 0.0026\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0141 - val_loss: 0.0277\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0168 - val_loss: 0.0191\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0053\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0096 - val_loss: 0.0064\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0153 - val_loss: 0.0271\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0106 - val_loss: 0.0032\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0185 - val_loss: 0.0171\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0137 - val_loss: 0.0239\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0116 - val_loss: 0.0053\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0144 - val_loss: 0.0274\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0121 - val_loss: 0.0019\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0175 - val_loss: 0.0152\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0102 - val_loss: 0.0192\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0135 - val_loss: 0.0035\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0136 - val_loss: 0.0163\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0076 - val_loss: 0.0020\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0184 - val_loss: 0.0124\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0108 - val_loss: 0.0206\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0114 - val_loss: 0.0057\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0140 - val_loss: 0.0265\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - ETA: 0s - loss: 0.014 - 0s 83us/sample - loss: 0.0125 - val_loss: 0.0062\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0129 - val_loss: 0.0140\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0123 - val_loss: 0.0274\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0022\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0138 - val_loss: 0.0194\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0079\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0137 - val_loss: 0.0119\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0121 - val_loss: 0.0223\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0101 - val_loss: 0.0034\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0115 - val_loss: 0.0219\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0123 - val_loss: 0.0084\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0083\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0071 - val_loss: 0.0104\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0104 - val_loss: 0.0100\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0139 - val_loss: 0.0273\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0100 - val_loss: 0.0031\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0123 - val_loss: 0.0205\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0134 - val_loss: 0.0157\n",
      "第173个数，还剩3950个没有训练\n",
      "inv_hat [1.16774057 1.16774057 1.16774057 1.16774057 1.16774057 1.16774057\n",
      " 1.16774057 1.16774057 1.16774057 1.16774057 1.16874112 1.16874112\n",
      " 1.16974164 1.16974164 1.17074237 1.17074237 1.17074237 1.17074237\n",
      " 1.17074237 1.16974164 1.16974164 1.16874112 1.16774057 1.16774057\n",
      " 1.16774057 1.16874112 1.16874112 1.16874112 1.16874112 1.16974164]\n",
      "Test RMSE: 0.008\n",
      "Train on 476 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "476/476 [==============================] - 0s 85us/sample - loss: 0.0077 - val_loss: 0.0221\n",
      "Epoch 2/50\n",
      "476/476 [==============================] - 0s 84us/sample - loss: 0.0067 - val_loss: 0.0238\n",
      "Epoch 3/50\n",
      "476/476 [==============================] - 0s 84us/sample - loss: 0.0073 - val_loss: 0.0221\n",
      "Epoch 4/50\n",
      "476/476 [==============================] - 0s 82us/sample - loss: 0.0069 - val_loss: 0.0251\n",
      "Epoch 5/50\n",
      "476/476 [==============================] - 0s 85us/sample - loss: 0.0078 - val_loss: 0.0219\n",
      "Epoch 6/50\n",
      "476/476 [==============================] - 0s 85us/sample - loss: 0.0082 - val_loss: 0.0240\n",
      "Epoch 7/50\n",
      "476/476 [==============================] - 0s 89us/sample - loss: 0.0086 - val_loss: 0.0230\n",
      "Epoch 8/50\n",
      "476/476 [==============================] - 0s 84us/sample - loss: 0.0073 - val_loss: 0.0233\n",
      "Epoch 9/50\n",
      "476/476 [==============================] - 0s 81us/sample - loss: 0.0067 - val_loss: 0.0222\n",
      "Epoch 10/50\n",
      "476/476 [==============================] - 0s 81us/sample - loss: 0.0069 - val_loss: 0.0241\n",
      "Epoch 11/50\n",
      "476/476 [==============================] - 0s 82us/sample - loss: 0.0071 - val_loss: 0.0221\n",
      "Epoch 12/50\n",
      "476/476 [==============================] - 0s 81us/sample - loss: 0.0066 - val_loss: 0.0230\n",
      "Epoch 13/50\n",
      "476/476 [==============================] - 0s 83us/sample - loss: 0.0069 - val_loss: 0.0222\n",
      "Epoch 14/50\n",
      "476/476 [==============================] - 0s 88us/sample - loss: 0.0065 - val_loss: 0.0226\n",
      "Epoch 15/50\n",
      "476/476 [==============================] - 0s 92us/sample - loss: 0.0069 - val_loss: 0.0225\n",
      "Epoch 16/50\n",
      "476/476 [==============================] - 0s 88us/sample - loss: 0.0065 - val_loss: 0.0222\n",
      "Epoch 17/50\n",
      "476/476 [==============================] - 0s 86us/sample - loss: 0.0064 - val_loss: 0.0223\n",
      "Epoch 18/50\n",
      "476/476 [==============================] - 0s 88us/sample - loss: 0.0067 - val_loss: 0.0221\n",
      "Epoch 19/50\n",
      "476/476 [==============================] - 0s 89us/sample - loss: 0.0064 - val_loss: 0.0222\n",
      "Epoch 20/50\n",
      "476/476 [==============================] - 0s 88us/sample - loss: 0.0064 - val_loss: 0.0221\n",
      "Epoch 21/50\n",
      "476/476 [==============================] - 0s 86us/sample - loss: 0.0062 - val_loss: 0.0227\n",
      "Epoch 22/50\n",
      "476/476 [==============================] - 0s 87us/sample - loss: 0.0064 - val_loss: 0.0224\n",
      "Epoch 23/50\n",
      "476/476 [==============================] - 0s 86us/sample - loss: 0.0070 - val_loss: 0.0242\n",
      "Epoch 24/50\n",
      "476/476 [==============================] - 0s 84us/sample - loss: 0.0065 - val_loss: 0.0222\n",
      "Epoch 25/50\n",
      "476/476 [==============================] - 0s 88us/sample - loss: 0.0065 - val_loss: 0.0221\n",
      "Epoch 26/50\n",
      "476/476 [==============================] - 0s 88us/sample - loss: 0.0063 - val_loss: 0.0220\n",
      "Epoch 27/50\n",
      "476/476 [==============================] - 0s 92us/sample - loss: 0.0065 - val_loss: 0.0222\n",
      "Epoch 28/50\n",
      "476/476 [==============================] - 0s 86us/sample - loss: 0.0064 - val_loss: 0.0227\n",
      "Epoch 29/50\n",
      "476/476 [==============================] - 0s 82us/sample - loss: 0.0065 - val_loss: 0.0234\n",
      "Epoch 30/50\n",
      "476/476 [==============================] - 0s 82us/sample - loss: 0.0066 - val_loss: 0.0234\n",
      "Epoch 31/50\n",
      "476/476 [==============================] - 0s 81us/sample - loss: 0.0063 - val_loss: 0.0225\n",
      "Epoch 32/50\n",
      "476/476 [==============================] - 0s 84us/sample - loss: 0.0063 - val_loss: 0.0225\n",
      "Epoch 33/50\n",
      "476/476 [==============================] - 0s 92us/sample - loss: 0.0063 - val_loss: 0.0230\n",
      "Epoch 34/50\n",
      "476/476 [==============================] - 0s 85us/sample - loss: 0.0063 - val_loss: 0.0226\n",
      "Epoch 35/50\n",
      "476/476 [==============================] - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0227\n",
      "Epoch 36/50\n",
      "476/476 [==============================] - 0s 89us/sample - loss: 0.0066 - val_loss: 0.0231\n",
      "Epoch 37/50\n",
      "476/476 [==============================] - 0s 87us/sample - loss: 0.0064 - val_loss: 0.0226\n",
      "Epoch 38/50\n",
      "476/476 [==============================] - 0s 88us/sample - loss: 0.0070 - val_loss: 0.0241\n",
      "Epoch 39/50\n",
      "476/476 [==============================] - 0s 85us/sample - loss: 0.0063 - val_loss: 0.0223\n",
      "Epoch 40/50\n",
      "476/476 [==============================] - 0s 83us/sample - loss: 0.0066 - val_loss: 0.0220\n",
      "Epoch 41/50\n",
      "476/476 [==============================] - 0s 83us/sample - loss: 0.0062 - val_loss: 0.0226\n",
      "Epoch 42/50\n",
      "476/476 [==============================] - 0s 82us/sample - loss: 0.0063 - val_loss: 0.0226\n",
      "Epoch 43/50\n",
      "476/476 [==============================] - 0s 80us/sample - loss: 0.0062 - val_loss: 0.0232\n",
      "Epoch 44/50\n",
      "476/476 [==============================] - 0s 88us/sample - loss: 0.0063 - val_loss: 0.0237\n",
      "Epoch 45/50\n",
      "476/476 [==============================] - 0s 82us/sample - loss: 0.0063 - val_loss: 0.0237\n",
      "Epoch 46/50\n",
      "476/476 [==============================] - 0s 83us/sample - loss: 0.0069 - val_loss: 0.0240\n",
      "Epoch 47/50\n",
      "476/476 [==============================] - 0s 85us/sample - loss: 0.0063 - val_loss: 0.0223\n",
      "Epoch 48/50\n",
      "476/476 [==============================] - 0s 86us/sample - loss: 0.0063 - val_loss: 0.0226\n",
      "Epoch 49/50\n",
      "476/476 [==============================] - 0s 86us/sample - loss: 0.0061 - val_loss: 0.0234\n",
      "Epoch 50/50\n",
      "476/476 [==============================] - 0s 94us/sample - loss: 0.0062 - val_loss: 0.0229\n",
      "第174个数，还剩3949个没有训练\n",
      "inv_hat [1.06291079 1.06291079 1.06291079 1.0638634  1.0638634  1.0638634\n",
      " 1.0638634  1.0638634  1.0638634  1.0638634  1.0638634  1.06575667\n",
      " 1.06575667 1.06669725 1.06669725 1.06763355 1.06763355 1.06763355\n",
      " 1.06763355 1.03515668 1.03515668 1.03415036 1.03415036 1.03515668\n",
      " 1.03515668 1.0361638  1.0361638  1.0361638  1.03717127 1.03817912]\n",
      "Test RMSE: 0.006\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0096 - val_loss: 0.0045\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0094 - val_loss: 0.0046\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0093 - val_loss: 0.0045\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0045\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0044\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0094 - val_loss: 0.0044\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0094 - val_loss: 0.0044\n",
      "第175个数，还剩3948个没有训练\n",
      "inv_hat [1.3301828  1.30347846 1.3084207  1.30644364 1.28076219 1.2738546\n",
      " 1.2778014  1.28964764 1.27286799 1.28273629 1.30940936 1.31435327\n",
      " 1.31534229 1.29261049 1.29952574 1.29261049 1.29952574 1.30446683\n",
      " 1.31732028 1.30249027 1.29952574 1.29656168 1.28372348 1.28569793\n",
      " 1.2778014  1.28372348 1.28372348 1.28076219 1.28273629 1.28569793]\n",
      "Test RMSE: 0.012\n",
      "Train on 659 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "659/659 [==============================] - 0s 84us/sample - loss: 0.0114 - val_loss: 0.0488\n",
      "Epoch 2/50\n",
      "659/659 [==============================] - 0s 85us/sample - loss: 0.0145 - val_loss: 0.0488\n",
      "Epoch 3/50\n",
      "659/659 [==============================] - 0s 87us/sample - loss: 0.0113 - val_loss: 0.0491\n",
      "Epoch 4/50\n",
      "659/659 [==============================] - 0s 82us/sample - loss: 0.0133 - val_loss: 0.0494\n",
      "Epoch 5/50\n",
      "659/659 [==============================] - 0s 88us/sample - loss: 0.0130 - val_loss: 0.0485\n",
      "Epoch 6/50\n",
      "659/659 [==============================] - 0s 86us/sample - loss: 0.0101 - val_loss: 0.0481\n",
      "Epoch 7/50\n",
      "659/659 [==============================] - 0s 87us/sample - loss: 0.0102 - val_loss: 0.0489\n",
      "Epoch 8/50\n",
      "659/659 [==============================] - 0s 88us/sample - loss: 0.0135 - val_loss: 0.0496\n",
      "Epoch 9/50\n",
      "659/659 [==============================] - 0s 86us/sample - loss: 0.0135 - val_loss: 0.0480\n",
      "Epoch 10/50\n",
      "659/659 [==============================] - 0s 87us/sample - loss: 0.0119 - val_loss: 0.0495\n",
      "Epoch 11/50\n",
      "659/659 [==============================] - 0s 84us/sample - loss: 0.0127 - val_loss: 0.0486\n",
      "Epoch 12/50\n",
      "659/659 [==============================] - 0s 83us/sample - loss: 0.0100 - val_loss: 0.0488\n",
      "Epoch 13/50\n",
      "659/659 [==============================] - 0s 88us/sample - loss: 0.0127 - val_loss: 0.0487\n",
      "Epoch 14/50\n",
      "659/659 [==============================] - 0s 85us/sample - loss: 0.0102 - val_loss: 0.0489\n",
      "Epoch 15/50\n",
      "659/659 [==============================] - 0s 85us/sample - loss: 0.0126 - val_loss: 0.0498\n",
      "Epoch 16/50\n",
      "659/659 [==============================] - 0s 85us/sample - loss: 0.0133 - val_loss: 0.0480\n",
      "Epoch 17/50\n",
      "659/659 [==============================] - 0s 85us/sample - loss: 0.0124 - val_loss: 0.0496\n",
      "Epoch 18/50\n",
      "659/659 [==============================] - 0s 88us/sample - loss: 0.0118 - val_loss: 0.0493\n",
      "Epoch 19/50\n",
      "659/659 [==============================] - 0s 90us/sample - loss: 0.0106 - val_loss: 0.0486\n",
      "Epoch 20/50\n",
      "659/659 [==============================] - 0s 85us/sample - loss: 0.0144 - val_loss: 0.0498\n",
      "Epoch 21/50\n",
      "659/659 [==============================] - 0s 84us/sample - loss: 0.0097 - val_loss: 0.0489\n",
      "Epoch 22/50\n",
      "659/659 [==============================] - 0s 87us/sample - loss: 0.0102 - val_loss: 0.0499\n",
      "Epoch 23/50\n",
      "659/659 [==============================] - 0s 88us/sample - loss: 0.0107 - val_loss: 0.0485\n",
      "Epoch 24/50\n",
      "659/659 [==============================] - 0s 86us/sample - loss: 0.0148 - val_loss: 0.0504\n",
      "Epoch 25/50\n",
      "659/659 [==============================] - 0s 91us/sample - loss: 0.0096 - val_loss: 0.0490\n",
      "Epoch 26/50\n",
      "659/659 [==============================] - 0s 88us/sample - loss: 0.0093 - val_loss: 0.0488\n",
      "Epoch 27/50\n",
      "659/659 [==============================] - 0s 87us/sample - loss: 0.0110 - val_loss: 0.0483\n",
      "Epoch 28/50\n",
      "659/659 [==============================] - 0s 89us/sample - loss: 0.0106 - val_loss: 0.0494\n",
      "Epoch 29/50\n",
      "659/659 [==============================] - 0s 85us/sample - loss: 0.0130 - val_loss: 0.0489\n",
      "Epoch 30/50\n",
      "659/659 [==============================] - 0s 86us/sample - loss: 0.0112 - val_loss: 0.0489\n",
      "Epoch 31/50\n",
      "659/659 [==============================] - 0s 83us/sample - loss: 0.0122 - val_loss: 0.0488\n",
      "Epoch 32/50\n",
      "659/659 [==============================] - 0s 86us/sample - loss: 0.0111 - val_loss: 0.0492\n",
      "Epoch 33/50\n",
      "659/659 [==============================] - 0s 85us/sample - loss: 0.0121 - val_loss: 0.0500\n",
      "Epoch 34/50\n",
      "659/659 [==============================] - 0s 84us/sample - loss: 0.0137 - val_loss: 0.0481\n",
      "Epoch 35/50\n",
      "659/659 [==============================] - 0s 89us/sample - loss: 0.0120 - val_loss: 0.0503\n",
      "Epoch 36/50\n",
      "659/659 [==============================] - 0s 86us/sample - loss: 0.0127 - val_loss: 0.0480\n",
      "Epoch 37/50\n",
      "659/659 [==============================] - 0s 90us/sample - loss: 0.0102 - val_loss: 0.0487\n",
      "Epoch 38/50\n",
      "659/659 [==============================] - 0s 90us/sample - loss: 0.0109 - val_loss: 0.0504\n",
      "Epoch 39/50\n",
      "659/659 [==============================] - 0s 89us/sample - loss: 0.0130 - val_loss: 0.0483\n",
      "Epoch 40/50\n",
      "659/659 [==============================] - 0s 88us/sample - loss: 0.0140 - val_loss: 0.0504\n",
      "Epoch 41/50\n",
      "659/659 [==============================] - 0s 84us/sample - loss: 0.0119 - val_loss: 0.0480\n",
      "Epoch 42/50\n",
      "659/659 [==============================] - 0s 82us/sample - loss: 0.0129 - val_loss: 0.0505\n",
      "Epoch 43/50\n",
      "659/659 [==============================] - 0s 83us/sample - loss: 0.0131 - val_loss: 0.0482\n",
      "Epoch 44/50\n",
      "659/659 [==============================] - 0s 85us/sample - loss: 0.0097 - val_loss: 0.0488\n",
      "Epoch 45/50\n",
      "659/659 [==============================] - 0s 84us/sample - loss: 0.0114 - val_loss: 0.0503\n",
      "Epoch 46/50\n",
      "659/659 [==============================] - 0s 89us/sample - loss: 0.0141 - val_loss: 0.0484\n",
      "Epoch 47/50\n",
      "659/659 [==============================] - 0s 86us/sample - loss: 0.0139 - val_loss: 0.0510\n",
      "Epoch 48/50\n",
      "659/659 [==============================] - 0s 88us/sample - loss: 0.0149 - val_loss: 0.0483\n",
      "Epoch 49/50\n",
      "659/659 [==============================] - 0s 90us/sample - loss: 0.0131 - val_loss: 0.0511\n",
      "Epoch 50/50\n",
      "659/659 [==============================] - 0s 87us/sample - loss: 0.0166 - val_loss: 0.0480\n",
      "第176个数，还剩3947个没有训练\n",
      "inv_hat [1.05587448 1.04902615 1.05070226 1.05001302 1.03935386 1.03935386\n",
      " 1.04105836 1.04485689 1.03945421 1.04276013 1.05246838 1.05432235\n",
      " 1.05354311 1.0478388  1.04744221 1.04465747 1.04664824 1.04833392\n",
      " 1.05168454 1.04565377 1.04215992 1.04045704 1.03473515 1.03624146\n",
      " 1.03272818 1.03573936 1.03343035 1.03212665 1.03032421 1.0320264 ]\n",
      "Test RMSE: 0.004\n",
      "Train on 1130 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1130/1130 [==============================] - 0s 82us/sample - loss: 0.0133 - val_loss: 0.0108\n",
      "Epoch 2/50\n",
      "1130/1130 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0087\n",
      "Epoch 3/50\n",
      "1130/1130 [==============================] - 0s 84us/sample - loss: 0.0100 - val_loss: 0.0054\n",
      "Epoch 4/50\n",
      "1130/1130 [==============================] - 0s 84us/sample - loss: 0.0104 - val_loss: 0.0064\n",
      "Epoch 5/50\n",
      "1130/1130 [==============================] - 0s 82us/sample - loss: 0.0107 - val_loss: 0.0056\n",
      "Epoch 6/50\n",
      "1130/1130 [==============================] - 0s 82us/sample - loss: 0.0110 - val_loss: 0.0070\n",
      "Epoch 7/50\n",
      "1130/1130 [==============================] - 0s 79us/sample - loss: 0.0126 - val_loss: 0.0096\n",
      "Epoch 8/50\n",
      "1130/1130 [==============================] - 0s 80us/sample - loss: 0.0112 - val_loss: 0.0059\n",
      "Epoch 9/50\n",
      "1130/1130 [==============================] - 0s 83us/sample - loss: 0.0096 - val_loss: 0.0058\n",
      "Epoch 10/50\n",
      "1130/1130 [==============================] - 0s 85us/sample - loss: 0.0105 - val_loss: 0.0062\n",
      "Epoch 11/50\n",
      "1130/1130 [==============================] - 0s 80us/sample - loss: 0.0103 - val_loss: 0.0052\n",
      "Epoch 12/50\n",
      "1130/1130 [==============================] - 0s 86us/sample - loss: 0.0117 - val_loss: 0.0076\n",
      "Epoch 13/50\n",
      "1130/1130 [==============================] - 0s 79us/sample - loss: 0.0119 - val_loss: 0.0078\n",
      "Epoch 14/50\n",
      "1130/1130 [==============================] - 0s 83us/sample - loss: 0.0102 - val_loss: 0.0052\n",
      "Epoch 15/50\n",
      "1130/1130 [==============================] - 0s 82us/sample - loss: 0.0099 - val_loss: 0.0060\n",
      "Epoch 16/50\n",
      "1130/1130 [==============================] - 0s 83us/sample - loss: 0.0105 - val_loss: 0.0056\n",
      "Epoch 17/50\n",
      "1130/1130 [==============================] - 0s 81us/sample - loss: 0.0106 - val_loss: 0.0062\n",
      "Epoch 18/50\n",
      "1130/1130 [==============================] - 0s 80us/sample - loss: 0.0121 - val_loss: 0.0083\n",
      "Epoch 19/50\n",
      "1130/1130 [==============================] - 0s 79us/sample - loss: 0.0112 - val_loss: 0.0063\n",
      "Epoch 20/50\n",
      "1130/1130 [==============================] - 0s 80us/sample - loss: 0.0096 - val_loss: 0.0056\n",
      "Epoch 21/50\n",
      "1130/1130 [==============================] - 0s 80us/sample - loss: 0.0103 - val_loss: 0.0061\n",
      "Epoch 22/50\n",
      "1130/1130 [==============================] - 0s 79us/sample - loss: 0.0102 - val_loss: 0.0052\n",
      "Epoch 23/50\n",
      "1130/1130 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0071\n",
      "Epoch 24/50\n",
      "1130/1130 [==============================] - 0s 79us/sample - loss: 0.0119 - val_loss: 0.0076\n",
      "Epoch 25/50\n",
      "1130/1130 [==============================] - 0s 77us/sample - loss: 0.0101 - val_loss: 0.0052\n",
      "Epoch 26/50\n",
      "1130/1130 [==============================] - 0s 80us/sample - loss: 0.0099 - val_loss: 0.0060\n",
      "Epoch 27/50\n",
      "1130/1130 [==============================] - 0s 79us/sample - loss: 0.0105 - val_loss: 0.0056\n",
      "Epoch 28/50\n",
      "1130/1130 [==============================] - 0s 79us/sample - loss: 0.0106 - val_loss: 0.0063\n",
      "Epoch 29/50\n",
      "1130/1130 [==============================] - 0s 80us/sample - loss: 0.0123 - val_loss: 0.0087\n",
      "Epoch 30/50\n",
      "1130/1130 [==============================] - 0s 81us/sample - loss: 0.0112 - val_loss: 0.0062\n",
      "Epoch 31/50\n",
      "1130/1130 [==============================] - 0s 87us/sample - loss: 0.0095 - val_loss: 0.0055\n",
      "Epoch 32/50\n",
      "1130/1130 [==============================] - 0s 82us/sample - loss: 0.0104 - val_loss: 0.0060\n",
      "Epoch 33/50\n",
      "1130/1130 [==============================] - 0s 79us/sample - loss: 0.0102 - val_loss: 0.0052\n",
      "Epoch 34/50\n",
      "1130/1130 [==============================] - 0s 80us/sample - loss: 0.0114 - val_loss: 0.0071\n",
      "Epoch 35/50\n",
      "1130/1130 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0075\n",
      "Epoch 36/50\n",
      "1130/1130 [==============================] - 0s 81us/sample - loss: 0.0100 - val_loss: 0.0052\n",
      "Epoch 37/50\n",
      "1130/1130 [==============================] - 0s 82us/sample - loss: 0.0100 - val_loss: 0.0058\n",
      "Epoch 38/50\n",
      "1130/1130 [==============================] - 0s 79us/sample - loss: 0.0102 - val_loss: 0.0052\n",
      "Epoch 39/50\n",
      "1130/1130 [==============================] - 0s 77us/sample - loss: 0.0106 - val_loss: 0.0065\n",
      "Epoch 40/50\n",
      "1130/1130 [==============================] - 0s 81us/sample - loss: 0.0120 - val_loss: 0.0079\n",
      "Epoch 41/50\n",
      "1130/1130 [==============================] - 0s 81us/sample - loss: 0.0107 - val_loss: 0.0055\n",
      "Epoch 42/50\n",
      "1130/1130 [==============================] - 0s 81us/sample - loss: 0.0096 - val_loss: 0.0056\n",
      "Epoch 43/50\n",
      "1130/1130 [==============================] - 0s 79us/sample - loss: 0.0102 - val_loss: 0.0056\n",
      "Epoch 44/50\n",
      "1130/1130 [==============================] - 0s 76us/sample - loss: 0.0101 - val_loss: 0.0055\n",
      "Epoch 45/50\n",
      "1130/1130 [==============================] - 0s 75us/sample - loss: 0.0114 - val_loss: 0.0070\n",
      "Epoch 46/50\n",
      "1130/1130 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0065\n",
      "Epoch 47/50\n",
      "1130/1130 [==============================] - 0s 78us/sample - loss: 0.0099 - val_loss: 0.0052\n",
      "Epoch 48/50\n",
      "1130/1130 [==============================] - 0s 79us/sample - loss: 0.0099 - val_loss: 0.0056\n",
      "Epoch 49/50\n",
      "1130/1130 [==============================] - 0s 77us/sample - loss: 0.0101 - val_loss: 0.0052\n",
      "Epoch 50/50\n",
      "1130/1130 [==============================] - 0s 77us/sample - loss: 0.0104 - val_loss: 0.0061\n",
      "第177个数，还剩3946个没有训练\n",
      "inv_hat [1.58994149 1.56118455 1.57010543 1.56316675 1.53939257 1.53642258\n",
      " 1.53840249 1.55622996 1.53543269 1.55127642 1.58894923 1.584981\n",
      " 1.5879572  1.54929535 1.55028594 1.53840249 1.55127642 1.55127642\n",
      " 1.57307993 1.54137271 1.52751517 1.51267782 1.49093624 1.48698598\n",
      " 1.47119277 1.48599838 1.48994864 1.48204909 1.47316619 1.48303626]\n",
      "Test RMSE: 0.020\n",
      "Train on 796 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "796/796 [==============================] - 0s 85us/sample - loss: 0.0116 - val_loss: 0.0082\n",
      "Epoch 2/50\n",
      "796/796 [==============================] - 0s 92us/sample - loss: 0.0112 - val_loss: 0.0062\n",
      "Epoch 3/50\n",
      "796/796 [==============================] - 0s 90us/sample - loss: 0.0112 - val_loss: 0.0063\n",
      "Epoch 4/50\n",
      "796/796 [==============================] - 0s 83us/sample - loss: 0.0111 - val_loss: 0.0056\n",
      "Epoch 5/50\n",
      "796/796 [==============================] - 0s 88us/sample - loss: 0.0110 - val_loss: 0.0058\n",
      "Epoch 6/50\n",
      "796/796 [==============================] - 0s 86us/sample - loss: 0.0110 - val_loss: 0.0064\n",
      "Epoch 7/50\n",
      "796/796 [==============================] - 0s 88us/sample - loss: 0.0110 - val_loss: 0.0062\n",
      "Epoch 8/50\n",
      "796/796 [==============================] - 0s 88us/sample - loss: 0.0109 - val_loss: 0.0056\n",
      "Epoch 9/50\n",
      "796/796 [==============================] - 0s 88us/sample - loss: 0.0110 - val_loss: 0.0062\n",
      "Epoch 10/50\n",
      "796/796 [==============================] - 0s 87us/sample - loss: 0.0110 - val_loss: 0.0061\n",
      "Epoch 11/50\n",
      "796/796 [==============================] - 0s 88us/sample - loss: 0.0110 - val_loss: 0.0064\n",
      "Epoch 12/50\n",
      "796/796 [==============================] - 0s 90us/sample - loss: 0.0109 - val_loss: 0.0055\n",
      "Epoch 13/50\n",
      "796/796 [==============================] - 0s 85us/sample - loss: 0.0111 - val_loss: 0.0058\n",
      "Epoch 14/50\n",
      "796/796 [==============================] - 0s 88us/sample - loss: 0.0110 - val_loss: 0.0065\n",
      "Epoch 15/50\n",
      "796/796 [==============================] - 0s 83us/sample - loss: 0.0110 - val_loss: 0.0066\n",
      "Epoch 16/50\n",
      "796/796 [==============================] - 0s 84us/sample - loss: 0.0110 - val_loss: 0.0064\n",
      "Epoch 17/50\n",
      "796/796 [==============================] - 0s 84us/sample - loss: 0.0109 - val_loss: 0.0055\n",
      "Epoch 18/50\n",
      "796/796 [==============================] - 0s 86us/sample - loss: 0.0111 - val_loss: 0.0063\n",
      "Epoch 19/50\n",
      "796/796 [==============================] - 0s 86us/sample - loss: 0.0111 - val_loss: 0.0064\n",
      "Epoch 20/50\n",
      "796/796 [==============================] - 0s 84us/sample - loss: 0.0110 - val_loss: 0.0061\n",
      "Epoch 21/50\n",
      "796/796 [==============================] - 0s 81us/sample - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 22/50\n",
      "796/796 [==============================] - 0s 85us/sample - loss: 0.0112 - val_loss: 0.0062\n",
      "Epoch 23/50\n",
      "796/796 [==============================] - 0s 83us/sample - loss: 0.0110 - val_loss: 0.0067\n",
      "Epoch 24/50\n",
      "796/796 [==============================] - 0s 85us/sample - loss: 0.0110 - val_loss: 0.0063\n",
      "Epoch 25/50\n",
      "796/796 [==============================] - 0s 84us/sample - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "796/796 [==============================] - 0s 88us/sample - loss: 0.0111 - val_loss: 0.0060\n",
      "Epoch 27/50\n",
      "796/796 [==============================] - 0s 88us/sample - loss: 0.0110 - val_loss: 0.0065\n",
      "Epoch 28/50\n",
      "796/796 [==============================] - 0s 85us/sample - loss: 0.0110 - val_loss: 0.0067\n",
      "Epoch 29/50\n",
      "796/796 [==============================] - 0s 87us/sample - loss: 0.0110 - val_loss: 0.0065\n",
      "Epoch 30/50\n",
      "796/796 [==============================] - 0s 84us/sample - loss: 0.0110 - val_loss: 0.0056\n",
      "Epoch 31/50\n",
      "796/796 [==============================] - 0s 85us/sample - loss: 0.0111 - val_loss: 0.0065\n",
      "Epoch 32/50\n",
      "796/796 [==============================] - 0s 85us/sample - loss: 0.0110 - val_loss: 0.0066\n",
      "Epoch 33/50\n",
      "796/796 [==============================] - 0s 83us/sample - loss: 0.0110 - val_loss: 0.0061\n",
      "Epoch 34/50\n",
      "796/796 [==============================] - 0s 84us/sample - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 35/50\n",
      "796/796 [==============================] - 0s 86us/sample - loss: 0.0111 - val_loss: 0.0059\n",
      "Epoch 36/50\n",
      "796/796 [==============================] - 0s 87us/sample - loss: 0.0110 - val_loss: 0.0063\n",
      "Epoch 37/50\n",
      "796/796 [==============================] - 0s 85us/sample - loss: 0.0110 - val_loss: 0.0063\n",
      "Epoch 38/50\n",
      "796/796 [==============================] - 0s 84us/sample - loss: 0.0110 - val_loss: 0.0064\n",
      "Epoch 39/50\n",
      "796/796 [==============================] - 0s 90us/sample - loss: 0.0109 - val_loss: 0.0061\n",
      "Epoch 40/50\n",
      "796/796 [==============================] - 0s 87us/sample - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 41/50\n",
      "796/796 [==============================] - 0s 85us/sample - loss: 0.0113 - val_loss: 0.0061\n",
      "Epoch 42/50\n",
      "796/796 [==============================] - 0s 85us/sample - loss: 0.0110 - val_loss: 0.0064\n",
      "Epoch 43/50\n",
      "796/796 [==============================] - 0s 87us/sample - loss: 0.0109 - val_loss: 0.0064\n",
      "Epoch 44/50\n",
      "796/796 [==============================] - 0s 89us/sample - loss: 0.0109 - val_loss: 0.0064\n",
      "Epoch 45/50\n",
      "796/796 [==============================] - 0s 91us/sample - loss: 0.0109 - val_loss: 0.0055\n",
      "Epoch 46/50\n",
      "796/796 [==============================] - 0s 87us/sample - loss: 0.0110 - val_loss: 0.0056\n",
      "Epoch 47/50\n",
      "796/796 [==============================] - 0s 89us/sample - loss: 0.0111 - val_loss: 0.0065\n",
      "Epoch 48/50\n",
      "796/796 [==============================] - 0s 86us/sample - loss: 0.0111 - val_loss: 0.0065\n",
      "Epoch 49/50\n",
      "796/796 [==============================] - 0s 84us/sample - loss: 0.0111 - val_loss: 0.0067\n",
      "Epoch 50/50\n",
      "796/796 [==============================] - 0s 88us/sample - loss: 0.0110 - val_loss: 0.0062\n",
      "第178个数，还剩3945个没有训练\n",
      "inv_hat [0.54438535 0.53565748 0.53759469 0.53372154 0.52117117 0.51924556\n",
      " 0.52020819 0.52695649 0.52020819 0.52406227 0.53468931 0.5327541\n",
      " 0.5327541  0.52309825 0.52309825 0.51924556 0.52406227 0.52406227\n",
      " 0.5327541  0.52213457 0.51828329 0.51155723 0.50484899 0.50484899\n",
      " 0.50006848 0.50389211 0.50389211 0.50006848 0.49339167 0.49434436]\n",
      "Test RMSE: 0.006\n",
      "Train on 524 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "524/524 [==============================] - 0s 91us/sample - loss: 0.0081 - val_loss: 0.0040\n",
      "Epoch 2/50\n",
      "524/524 [==============================] - 0s 85us/sample - loss: 0.0091 - val_loss: 0.0032\n",
      "Epoch 3/50\n",
      "524/524 [==============================] - 0s 98us/sample - loss: 0.0102 - val_loss: 0.0045\n",
      "Epoch 4/50\n",
      "524/524 [==============================] - 0s 90us/sample - loss: 0.0095 - val_loss: 0.0077\n",
      "Epoch 5/50\n",
      "524/524 [==============================] - 0s 92us/sample - loss: 0.0077 - val_loss: 0.0034\n",
      "Epoch 6/50\n",
      "524/524 [==============================] - 0s 87us/sample - loss: 0.0072 - val_loss: 0.0023\n",
      "Epoch 7/50\n",
      "524/524 [==============================] - 0s 90us/sample - loss: 0.0073 - val_loss: 0.0035\n",
      "Epoch 8/50\n",
      "524/524 [==============================] - 0s 88us/sample - loss: 0.0078 - val_loss: 0.0020\n",
      "Epoch 9/50\n",
      "524/524 [==============================] - 0s 93us/sample - loss: 0.0077 - val_loss: 0.0032\n",
      "Epoch 10/50\n",
      "524/524 [==============================] - 0s 88us/sample - loss: 0.0081 - val_loss: 0.0028\n",
      "Epoch 11/50\n",
      "524/524 [==============================] - 0s 92us/sample - loss: 0.0073 - val_loss: 0.0027\n",
      "Epoch 12/50\n",
      "524/524 [==============================] - 0s 92us/sample - loss: 0.0075 - val_loss: 0.0019\n",
      "Epoch 13/50\n",
      "524/524 [==============================] - 0s 89us/sample - loss: 0.0076 - val_loss: 0.0033\n",
      "Epoch 14/50\n",
      "524/524 [==============================] - 0s 94us/sample - loss: 0.0079 - val_loss: 0.0028\n",
      "Epoch 15/50\n",
      "524/524 [==============================] - 0s 94us/sample - loss: 0.0073 - val_loss: 0.0034\n",
      "Epoch 16/50\n",
      "524/524 [==============================] - 0s 91us/sample - loss: 0.0079 - val_loss: 0.0028\n",
      "Epoch 17/50\n",
      "524/524 [==============================] - 0s 90us/sample - loss: 0.0067 - val_loss: 0.0020\n",
      "Epoch 18/50\n",
      "524/524 [==============================] - 0s 96us/sample - loss: 0.0071 - val_loss: 0.0019\n",
      "Epoch 19/50\n",
      "524/524 [==============================] - 0s 91us/sample - loss: 0.0071 - val_loss: 0.0033\n",
      "Epoch 20/50\n",
      "524/524 [==============================] - 0s 86us/sample - loss: 0.0080 - val_loss: 0.0034\n",
      "Epoch 21/50\n",
      "524/524 [==============================] - 0s 87us/sample - loss: 0.0067 - val_loss: 0.0019\n",
      "Epoch 22/50\n",
      "524/524 [==============================] - 0s 87us/sample - loss: 0.0068 - val_loss: 0.0021\n",
      "Epoch 23/50\n",
      "524/524 [==============================] - 0s 93us/sample - loss: 0.0068 - val_loss: 0.0029\n",
      "Epoch 24/50\n",
      "524/524 [==============================] - 0s 90us/sample - loss: 0.0073 - val_loss: 0.0022\n",
      "Epoch 25/50\n",
      "524/524 [==============================] - 0s 86us/sample - loss: 0.0067 - val_loss: 0.0023\n",
      "Epoch 26/50\n",
      "524/524 [==============================] - 0s 86us/sample - loss: 0.0076 - val_loss: 0.0032\n",
      "Epoch 27/50\n",
      "524/524 [==============================] - 0s 88us/sample - loss: 0.0070 - val_loss: 0.0027\n",
      "Epoch 28/50\n",
      "524/524 [==============================] - 0s 93us/sample - loss: 0.0076 - val_loss: 0.0030\n",
      "Epoch 29/50\n",
      "524/524 [==============================] - 0s 88us/sample - loss: 0.0074 - val_loss: 0.0019\n",
      "Epoch 30/50\n",
      "524/524 [==============================] - 0s 87us/sample - loss: 0.0076 - val_loss: 0.0037\n",
      "Epoch 31/50\n",
      "524/524 [==============================] - 0s 89us/sample - loss: 0.0075 - val_loss: 0.0019\n",
      "Epoch 32/50\n",
      "524/524 [==============================] - 0s 84us/sample - loss: 0.0069 - val_loss: 0.0019\n",
      "Epoch 33/50\n",
      "524/524 [==============================] - 0s 89us/sample - loss: 0.0071 - val_loss: 0.0019\n",
      "Epoch 34/50\n",
      "524/524 [==============================] - 0s 89us/sample - loss: 0.0079 - val_loss: 0.0047\n",
      "Epoch 35/50\n",
      "524/524 [==============================] - 0s 90us/sample - loss: 0.0082 - val_loss: 0.0038\n",
      "Epoch 36/50\n",
      "524/524 [==============================] - 0s 91us/sample - loss: 0.0065 - val_loss: 0.0019\n",
      "Epoch 37/50\n",
      "524/524 [==============================] - 0s 93us/sample - loss: 0.0068 - val_loss: 0.0020\n",
      "Epoch 38/50\n",
      "524/524 [==============================] - 0s 95us/sample - loss: 0.0067 - val_loss: 0.0029\n",
      "Epoch 39/50\n",
      "524/524 [==============================] - 0s 89us/sample - loss: 0.0072 - val_loss: 0.0020\n",
      "Epoch 40/50\n",
      "524/524 [==============================] - 0s 90us/sample - loss: 0.0066 - val_loss: 0.0019\n",
      "Epoch 41/50\n",
      "524/524 [==============================] - 0s 91us/sample - loss: 0.0071 - val_loss: 0.0023\n",
      "Epoch 42/50\n",
      "524/524 [==============================] - 0s 95us/sample - loss: 0.0070 - val_loss: 0.0034\n",
      "Epoch 43/50\n",
      "524/524 [==============================] - 0s 91us/sample - loss: 0.0080 - val_loss: 0.0028\n",
      "Epoch 44/50\n",
      "524/524 [==============================] - 0s 91us/sample - loss: 0.0067 - val_loss: 0.0020\n",
      "Epoch 45/50\n",
      "524/524 [==============================] - 0s 88us/sample - loss: 0.0078 - val_loss: 0.0036\n",
      "Epoch 46/50\n",
      "524/524 [==============================] - 0s 89us/sample - loss: 0.0069 - val_loss: 0.0019\n",
      "Epoch 47/50\n",
      "524/524 [==============================] - 0s 96us/sample - loss: 0.0067 - val_loss: 0.0020\n",
      "Epoch 48/50\n",
      "524/524 [==============================] - 0s 91us/sample - loss: 0.0068 - val_loss: 0.0019\n",
      "Epoch 49/50\n",
      "524/524 [==============================] - 0s 93us/sample - loss: 0.0072 - val_loss: 0.0040\n",
      "Epoch 50/50\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.013 - 0s 96us/sample - loss: 0.0079 - val_loss: 0.0033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第179个数，还剩3944个没有训练\n",
      "inv_hat [1.02738697 1.02748469 1.02767991 1.0278751  1.02807015 1.02836234\n",
      " 1.02826506 1.02836234 1.0284597  1.02865431 1.02894596 1.02914009\n",
      " 1.02933417 1.02943117 1.02962504 1.02991543 1.03001219 1.02981862\n",
      " 1.02972191 1.02952811 1.02962504 1.02972191 1.02972191 1.02981862\n",
      " 1.03001219 1.03001219 1.03001219 1.03001219 1.03030222 1.03078474]\n",
      "Test RMSE: 0.000\n",
      "Train on 835 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "835/835 [==============================] - 0s 82us/sample - loss: 0.0170 - val_loss: 0.0107\n",
      "Epoch 2/50\n",
      "835/835 [==============================] - ETA: 0s - loss: 0.017 - 0s 77us/sample - loss: 0.0173 - val_loss: 0.0124\n",
      "Epoch 3/50\n",
      "835/835 [==============================] - 0s 80us/sample - loss: 0.0170 - val_loss: 0.0105\n",
      "Epoch 4/50\n",
      "835/835 [==============================] - 0s 80us/sample - loss: 0.0171 - val_loss: 0.0120\n",
      "Epoch 5/50\n",
      "835/835 [==============================] - 0s 82us/sample - loss: 0.0170 - val_loss: 0.0111\n",
      "Epoch 6/50\n",
      "835/835 [==============================] - 0s 80us/sample - loss: 0.0170 - val_loss: 0.0113\n",
      "Epoch 7/50\n",
      "835/835 [==============================] - 0s 81us/sample - loss: 0.0170 - val_loss: 0.0116\n",
      "Epoch 8/50\n",
      "835/835 [==============================] - 0s 79us/sample - loss: 0.0170 - val_loss: 0.0117\n",
      "Epoch 9/50\n",
      "835/835 [==============================] - 0s 78us/sample - loss: 0.0170 - val_loss: 0.0115\n",
      "Epoch 10/50\n",
      "835/835 [==============================] - 0s 77us/sample - loss: 0.0170 - val_loss: 0.0113\n",
      "Epoch 11/50\n",
      "835/835 [==============================] - 0s 82us/sample - loss: 0.0170 - val_loss: 0.0115\n",
      "Epoch 12/50\n",
      "835/835 [==============================] - 0s 78us/sample - loss: 0.0170 - val_loss: 0.0111\n",
      "Epoch 13/50\n",
      "835/835 [==============================] - 0s 81us/sample - loss: 0.0170 - val_loss: 0.0114\n",
      "Epoch 14/50\n",
      "835/835 [==============================] - 0s 87us/sample - loss: 0.0170 - val_loss: 0.0116\n",
      "Epoch 15/50\n",
      "835/835 [==============================] - 0s 80us/sample - loss: 0.0169 - val_loss: 0.0113\n",
      "Epoch 16/50\n",
      "835/835 [==============================] - 0s 83us/sample - loss: 0.0170 - val_loss: 0.0113\n",
      "Epoch 17/50\n",
      "835/835 [==============================] - 0s 79us/sample - loss: 0.0170 - val_loss: 0.0111\n",
      "Epoch 18/50\n",
      "835/835 [==============================] - 0s 79us/sample - loss: 0.0170 - val_loss: 0.0115\n",
      "Epoch 19/50\n",
      "835/835 [==============================] - 0s 83us/sample - loss: 0.0169 - val_loss: 0.0113\n",
      "Epoch 20/50\n",
      "835/835 [==============================] - 0s 81us/sample - loss: 0.0170 - val_loss: 0.0115\n",
      "Epoch 21/50\n",
      "835/835 [==============================] - 0s 80us/sample - loss: 0.0169 - val_loss: 0.0112\n",
      "Epoch 22/50\n",
      "835/835 [==============================] - 0s 86us/sample - loss: 0.0170 - val_loss: 0.0109\n",
      "Epoch 23/50\n",
      "835/835 [==============================] - 0s 81us/sample - loss: 0.0170 - val_loss: 0.0114\n",
      "Epoch 24/50\n",
      "835/835 [==============================] - 0s 84us/sample - loss: 0.0169 - val_loss: 0.0110\n",
      "Epoch 25/50\n",
      "835/835 [==============================] - 0s 81us/sample - loss: 0.0169 - val_loss: 0.0109\n",
      "Epoch 26/50\n",
      "835/835 [==============================] - 0s 81us/sample - loss: 0.0170 - val_loss: 0.0112\n",
      "Epoch 27/50\n",
      "835/835 [==============================] - 0s 80us/sample - loss: 0.0170 - val_loss: 0.0114\n",
      "Epoch 28/50\n",
      "835/835 [==============================] - 0s 85us/sample - loss: 0.0169 - val_loss: 0.0111\n",
      "Epoch 29/50\n",
      "835/835 [==============================] - 0s 87us/sample - loss: 0.0169 - val_loss: 0.0109\n",
      "Epoch 30/50\n",
      "835/835 [==============================] - 0s 86us/sample - loss: 0.0170 - val_loss: 0.0111\n",
      "Epoch 31/50\n",
      "835/835 [==============================] - 0s 86us/sample - loss: 0.0170 - val_loss: 0.0112\n",
      "Epoch 32/50\n",
      "835/835 [==============================] - 0s 88us/sample - loss: 0.0169 - val_loss: 0.0111\n",
      "Epoch 33/50\n",
      "835/835 [==============================] - 0s 83us/sample - loss: 0.0169 - val_loss: 0.0111\n",
      "Epoch 34/50\n",
      "835/835 [==============================] - 0s 83us/sample - loss: 0.0170 - val_loss: 0.0112\n",
      "Epoch 35/50\n",
      "835/835 [==============================] - 0s 82us/sample - loss: 0.0170 - val_loss: 0.0113\n",
      "Epoch 36/50\n",
      "835/835 [==============================] - 0s 77us/sample - loss: 0.0169 - val_loss: 0.0113\n",
      "Epoch 37/50\n",
      "835/835 [==============================] - 0s 77us/sample - loss: 0.0170 - val_loss: 0.0114\n",
      "Epoch 38/50\n",
      "835/835 [==============================] - 0s 79us/sample - loss: 0.0169 - val_loss: 0.0114\n",
      "Epoch 39/50\n",
      "835/835 [==============================] - 0s 81us/sample - loss: 0.0169 - val_loss: 0.0113\n",
      "Epoch 40/50\n",
      "835/835 [==============================] - 0s 84us/sample - loss: 0.0170 - val_loss: 0.0112\n",
      "Epoch 41/50\n",
      "835/835 [==============================] - 0s 83us/sample - loss: 0.0170 - val_loss: 0.0115\n",
      "Epoch 42/50\n",
      "835/835 [==============================] - 0s 86us/sample - loss: 0.0169 - val_loss: 0.0113\n",
      "Epoch 43/50\n",
      "835/835 [==============================] - 0s 85us/sample - loss: 0.0169 - val_loss: 0.0113\n",
      "Epoch 44/50\n",
      "835/835 [==============================] - 0s 87us/sample - loss: 0.0169 - val_loss: 0.0110\n",
      "Epoch 45/50\n",
      "835/835 [==============================] - 0s 85us/sample - loss: 0.0170 - val_loss: 0.0111\n",
      "Epoch 46/50\n",
      "835/835 [==============================] - 0s 80us/sample - loss: 0.0170 - val_loss: 0.0113\n",
      "Epoch 47/50\n",
      "835/835 [==============================] - 0s 84us/sample - loss: 0.0169 - val_loss: 0.0111\n",
      "Epoch 48/50\n",
      "835/835 [==============================] - 0s 84us/sample - loss: 0.0170 - val_loss: 0.0114\n",
      "Epoch 49/50\n",
      "835/835 [==============================] - 0s 88us/sample - loss: 0.0169 - val_loss: 0.0112\n",
      "Epoch 50/50\n",
      "835/835 [==============================] - 0s 89us/sample - loss: 0.0169 - val_loss: 0.0108\n",
      "第180个数，还剩3943个没有训练\n",
      "inv_hat [0.53264453 0.51996037 0.51316124 0.51122271 0.49482266 0.49386241\n",
      " 0.49963156 0.5044528  0.48906875 0.49578345 0.51122271 0.50735137\n",
      " 0.5044528  0.49194339 0.49290266 0.48906875 0.49386241 0.49194339\n",
      " 0.49674471 0.48524317 0.47856889 0.47761759 0.46908075 0.47192132\n",
      " 0.4728693  0.47952072 0.48047313 0.47381786 0.46435785 0.46058992]\n",
      "Test RMSE: 0.008\n",
      "Train on 848 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "848/848 [==============================] - 0s 83us/sample - loss: 0.0192 - val_loss: 0.0198\n",
      "Epoch 2/50\n",
      "848/848 [==============================] - 0s 83us/sample - loss: 0.0190 - val_loss: 0.0214\n",
      "Epoch 3/50\n",
      "848/848 [==============================] - 0s 85us/sample - loss: 0.0192 - val_loss: 0.0220\n",
      "Epoch 4/50\n",
      "848/848 [==============================] - 0s 82us/sample - loss: 0.0192 - val_loss: 0.0201\n",
      "Epoch 5/50\n",
      "848/848 [==============================] - 0s 83us/sample - loss: 0.0190 - val_loss: 0.0202\n",
      "Epoch 6/50\n",
      "848/848 [==============================] - 0s 85us/sample - loss: 0.0190 - val_loss: 0.0202\n",
      "Epoch 7/50\n",
      "848/848 [==============================] - 0s 82us/sample - loss: 0.0190 - val_loss: 0.0211\n",
      "Epoch 8/50\n",
      "848/848 [==============================] - 0s 85us/sample - loss: 0.0191 - val_loss: 0.0211\n",
      "Epoch 9/50\n",
      "848/848 [==============================] - 0s 82us/sample - loss: 0.0191 - val_loss: 0.0202\n",
      "Epoch 10/50\n",
      "848/848 [==============================] - 0s 87us/sample - loss: 0.0190 - val_loss: 0.0197\n",
      "Epoch 11/50\n",
      "848/848 [==============================] - 0s 83us/sample - loss: 0.0190 - val_loss: 0.0207\n",
      "Epoch 12/50\n",
      "848/848 [==============================] - 0s 82us/sample - loss: 0.0190 - val_loss: 0.0213\n",
      "Epoch 13/50\n",
      "848/848 [==============================] - 0s 78us/sample - loss: 0.0191 - val_loss: 0.0213\n",
      "Epoch 14/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0191 - val_loss: 0.0205\n",
      "Epoch 15/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0190 - val_loss: 0.0193\n",
      "Epoch 16/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0190 - val_loss: 0.0211\n",
      "Epoch 17/50\n",
      "848/848 [==============================] - 0s 75us/sample - loss: 0.0192 - val_loss: 0.0231\n",
      "Epoch 18/50\n",
      "848/848 [==============================] - 0s 76us/sample - loss: 0.0194 - val_loss: 0.0196\n",
      "Epoch 19/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 20/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0190 - val_loss: 0.0215\n",
      "Epoch 21/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0192 - val_loss: 0.0208\n",
      "Epoch 22/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0191 - val_loss: 0.0204\n",
      "Epoch 23/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0190 - val_loss: 0.0193\n",
      "Epoch 24/50\n",
      "848/848 [==============================] - 0s 76us/sample - loss: 0.0189 - val_loss: 0.0210\n",
      "Epoch 25/50\n",
      "848/848 [==============================] - 0s 77us/sample - loss: 0.0192 - val_loss: 0.0230\n",
      "Epoch 26/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0194 - val_loss: 0.0198\n",
      "Epoch 27/50\n",
      "848/848 [==============================] - 0s 83us/sample - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 28/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0191 - val_loss: 0.0206\n",
      "Epoch 29/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0190 - val_loss: 0.0191\n",
      "Epoch 30/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0190 - val_loss: 0.0211\n",
      "Epoch 31/50\n",
      "848/848 [==============================] - 0s 76us/sample - loss: 0.0193 - val_loss: 0.0244\n",
      "Epoch 32/50\n",
      "848/848 [==============================] - 0s 77us/sample - loss: 0.0199 - val_loss: 0.0195\n",
      "Epoch 33/50\n",
      "848/848 [==============================] - 0s 77us/sample - loss: 0.0189 - val_loss: 0.0174\n",
      "Epoch 34/50\n",
      "848/848 [==============================] - 0s 81us/sample - loss: 0.0198 - val_loss: 0.0227\n",
      "Epoch 35/50\n",
      "848/848 [==============================] - 0s 83us/sample - loss: 0.0197 - val_loss: 0.0243\n",
      "Epoch 36/50\n",
      "848/848 [==============================] - 0s 87us/sample - loss: 0.0198 - val_loss: 0.0187\n",
      "Epoch 37/50\n",
      "848/848 [==============================] - 0s 83us/sample - loss: 0.0189 - val_loss: 0.0189\n",
      "Epoch 38/50\n",
      "848/848 [==============================] - 0s 83us/sample - loss: 0.0193 - val_loss: 0.0239\n",
      "Epoch 39/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0197 - val_loss: 0.0208\n",
      "Epoch 40/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0190 - val_loss: 0.0193\n",
      "Epoch 41/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0189 - val_loss: 0.0208\n",
      "Epoch 42/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0192 - val_loss: 0.0242\n",
      "Epoch 43/50\n",
      "848/848 [==============================] - 0s 87us/sample - loss: 0.0198 - val_loss: 0.0201\n",
      "Epoch 44/50\n",
      "848/848 [==============================] - 0s 88us/sample - loss: 0.0188 - val_loss: 0.0187\n",
      "Epoch 45/50\n",
      "848/848 [==============================] - 0s 78us/sample - loss: 0.0191 - val_loss: 0.0221\n",
      "Epoch 46/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0193 - val_loss: 0.0234\n",
      "Epoch 47/50\n",
      "848/848 [==============================] - 0s 78us/sample - loss: 0.0195 - val_loss: 0.0190\n",
      "Epoch 48/50\n",
      "848/848 [==============================] - 0s 76us/sample - loss: 0.0188 - val_loss: 0.0193\n",
      "Epoch 49/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0190 - val_loss: 0.0222\n",
      "Epoch 50/50\n",
      "848/848 [==============================] - 0s 77us/sample - loss: 0.0194 - val_loss: 0.0239\n",
      "第181个数，还剩3942个没有训练\n",
      "inv_hat [0.87115978 0.85945303 0.85945303 0.85751527 0.84884806 0.84597948\n",
      " 0.8450257  0.8498066  0.8450257  0.8498066  0.8643148  0.86528998\n",
      " 0.86236723 0.8498066  0.85076629 0.84693446 0.8498066  0.85076629\n",
      " 0.85848364 0.8498066  0.84884806 0.8450257  0.83932931 0.83649864\n",
      " 0.83180825 0.83649864 0.83461828 0.8336802  0.83087441 0.83180825]\n",
      "Test RMSE: 0.007\n",
      "Train on 916 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "916/916 [==============================] - 0s 77us/sample - loss: 0.0148 - val_loss: 0.0094\n",
      "Epoch 2/50\n",
      "916/916 [==============================] - 0s 80us/sample - loss: 0.0141 - val_loss: 0.0093\n",
      "Epoch 3/50\n",
      "916/916 [==============================] - 0s 86us/sample - loss: 0.0143 - val_loss: 0.0095\n",
      "Epoch 4/50\n",
      "916/916 [==============================] - 0s 79us/sample - loss: 0.0143 - val_loss: 0.0098\n",
      "Epoch 5/50\n",
      "916/916 [==============================] - 0s 77us/sample - loss: 0.0141 - val_loss: 0.0100\n",
      "Epoch 6/50\n",
      "916/916 [==============================] - 0s 79us/sample - loss: 0.0140 - val_loss: 0.0098\n",
      "Epoch 7/50\n",
      "916/916 [==============================] - 0s 77us/sample - loss: 0.0140 - val_loss: 0.0096\n",
      "Epoch 8/50\n",
      "916/916 [==============================] - 0s 79us/sample - loss: 0.0141 - val_loss: 0.0096\n",
      "Epoch 9/50\n",
      "916/916 [==============================] - 0s 79us/sample - loss: 0.0141 - val_loss: 0.0096\n",
      "Epoch 10/50\n",
      "916/916 [==============================] - 0s 78us/sample - loss: 0.0141 - val_loss: 0.0096\n",
      "Epoch 11/50\n",
      "916/916 [==============================] - 0s 80us/sample - loss: 0.0141 - val_loss: 0.0097\n",
      "Epoch 12/50\n",
      "916/916 [==============================] - 0s 80us/sample - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 13/50\n",
      "916/916 [==============================] - 0s 83us/sample - loss: 0.0140 - val_loss: 0.0098\n",
      "Epoch 14/50\n",
      "916/916 [==============================] - 0s 79us/sample - loss: 0.0140 - val_loss: 0.0097\n",
      "Epoch 15/50\n",
      "916/916 [==============================] - 0s 83us/sample - loss: 0.0141 - val_loss: 0.0097\n",
      "Epoch 16/50\n",
      "916/916 [==============================] - 0s 77us/sample - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 17/50\n",
      "916/916 [==============================] - 0s 84us/sample - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 18/50\n",
      "916/916 [==============================] - 0s 85us/sample - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 19/50\n",
      "916/916 [==============================] - 0s 80us/sample - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 20/50\n",
      "916/916 [==============================] - 0s 78us/sample - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 21/50\n",
      "916/916 [==============================] - 0s 76us/sample - loss: 0.0141 - val_loss: 0.0099\n",
      "Epoch 22/50\n",
      "916/916 [==============================] - 0s 78us/sample - loss: 0.0140 - val_loss: 0.0098\n",
      "Epoch 23/50\n",
      "916/916 [==============================] - 0s 78us/sample - loss: 0.0140 - val_loss: 0.0097\n",
      "Epoch 24/50\n",
      "916/916 [==============================] - 0s 77us/sample - loss: 0.0141 - val_loss: 0.0097\n",
      "Epoch 25/50\n",
      "916/916 [==============================] - 0s 81us/sample - loss: 0.0141 - val_loss: 0.0097\n",
      "Epoch 26/50\n",
      "916/916 [==============================] - 0s 82us/sample - loss: 0.0141 - val_loss: 0.0097\n",
      "Epoch 27/50\n",
      "916/916 [==============================] - 0s 81us/sample - loss: 0.0141 - val_loss: 0.0097\n",
      "Epoch 28/50\n",
      "916/916 [==============================] - 0s 79us/sample - loss: 0.0141 - val_loss: 0.0097\n",
      "Epoch 29/50\n",
      "916/916 [==============================] - 0s 84us/sample - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 30/50\n",
      "916/916 [==============================] - 0s 83us/sample - loss: 0.0141 - val_loss: 0.0097\n",
      "Epoch 31/50\n",
      "916/916 [==============================] - 0s 84us/sample - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 32/50\n",
      "916/916 [==============================] - 0s 85us/sample - loss: 0.0141 - val_loss: 0.0097\n",
      "Epoch 33/50\n",
      "916/916 [==============================] - 0s 84us/sample - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 34/50\n",
      "916/916 [==============================] - 0s 80us/sample - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 35/50\n",
      "916/916 [==============================] - 0s 76us/sample - loss: 0.0141 - val_loss: 0.0097\n",
      "Epoch 36/50\n",
      "916/916 [==============================] - 0s 78us/sample - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 37/50\n",
      "916/916 [==============================] - 0s 82us/sample - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 38/50\n",
      "916/916 [==============================] - 0s 82us/sample - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 39/50\n",
      "916/916 [==============================] - 0s 80us/sample - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 40/50\n",
      "916/916 [==============================] - 0s 81us/sample - loss: 0.0141 - val_loss: 0.0097\n",
      "Epoch 41/50\n",
      "916/916 [==============================] - 0s 81us/sample - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 42/50\n",
      "916/916 [==============================] - 0s 83us/sample - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 43/50\n",
      "916/916 [==============================] - 0s 84us/sample - loss: 0.0141 - val_loss: 0.0097\n",
      "Epoch 44/50\n",
      "916/916 [==============================] - 0s 80us/sample - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 45/50\n",
      "916/916 [==============================] - 0s 81us/sample - loss: 0.0141 - val_loss: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "916/916 [==============================] - 0s 83us/sample - loss: 0.0140 - val_loss: 0.0101\n",
      "Epoch 47/50\n",
      "916/916 [==============================] - 0s 83us/sample - loss: 0.0140 - val_loss: 0.0098\n",
      "Epoch 48/50\n",
      "916/916 [==============================] - 0s 78us/sample - loss: 0.0141 - val_loss: 0.0096\n",
      "Epoch 49/50\n",
      "916/916 [==============================] - 0s 80us/sample - loss: 0.0141 - val_loss: 0.0097\n",
      "Epoch 50/50\n",
      "916/916 [==============================] - 0s 77us/sample - loss: 0.0141 - val_loss: 0.0099\n",
      "第182个数，还剩3941个没有训练\n",
      "inv_hat [0.88419197 0.86604899 0.87195468 0.87447563 0.85283153 0.85071512\n",
      " 0.85475705 0.8658556  0.85283153 0.85899802 0.88107925 0.88623645\n",
      " 0.88652861 0.86517869 0.8571659  0.85119599 0.85851579 0.8574551\n",
      " 0.86604899 0.84802401 0.84303365 0.8370966  0.82497999 0.82659832\n",
      " 0.82003672 0.82802721 0.82250702 0.82155659 0.81624135 0.81956194]\n",
      "Test RMSE: 0.011\n",
      "Train on 843 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "843/843 [==============================] - 0s 76us/sample - loss: 0.0177 - val_loss: 0.0130\n",
      "Epoch 2/50\n",
      "843/843 [==============================] - 0s 78us/sample - loss: 0.0181 - val_loss: 0.0131\n",
      "Epoch 3/50\n",
      "843/843 [==============================] - 0s 78us/sample - loss: 0.0174 - val_loss: 0.0147\n",
      "Epoch 4/50\n",
      "843/843 [==============================] - 0s 82us/sample - loss: 0.0181 - val_loss: 0.0127\n",
      "Epoch 5/50\n",
      "843/843 [==============================] - 0s 85us/sample - loss: 0.0171 - val_loss: 0.0129\n",
      "Epoch 6/50\n",
      "843/843 [==============================] - 0s 83us/sample - loss: 0.0170 - val_loss: 0.0128\n",
      "Epoch 7/50\n",
      "843/843 [==============================] - 0s 88us/sample - loss: 0.0171 - val_loss: 0.0130\n",
      "Epoch 8/50\n",
      "843/843 [==============================] - 0s 86us/sample - loss: 0.0171 - val_loss: 0.0131\n",
      "Epoch 9/50\n",
      "843/843 [==============================] - 0s 85us/sample - loss: 0.0171 - val_loss: 0.0129\n",
      "Epoch 10/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0170 - val_loss: 0.0128\n",
      "Epoch 11/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0170 - val_loss: 0.0130\n",
      "Epoch 12/50\n",
      "843/843 [==============================] - 0s 79us/sample - loss: 0.0171 - val_loss: 0.0131\n",
      "Epoch 13/50\n",
      "843/843 [==============================] - 0s 79us/sample - loss: 0.0171 - val_loss: 0.0129\n",
      "Epoch 14/50\n",
      "843/843 [==============================] - 0s 78us/sample - loss: 0.0170 - val_loss: 0.0128\n",
      "Epoch 15/50\n",
      "843/843 [==============================] - 0s 83us/sample - loss: 0.0171 - val_loss: 0.0131\n",
      "Epoch 16/50\n",
      "843/843 [==============================] - 0s 79us/sample - loss: 0.0171 - val_loss: 0.0132\n",
      "Epoch 17/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0171 - val_loss: 0.0129\n",
      "Epoch 18/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0170 - val_loss: 0.0129\n",
      "Epoch 19/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0170 - val_loss: 0.0130\n",
      "Epoch 20/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0170 - val_loss: 0.0131\n",
      "Epoch 21/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0171 - val_loss: 0.0130\n",
      "Epoch 22/50\n",
      "843/843 [==============================] - 0s 82us/sample - loss: 0.0171 - val_loss: 0.0127\n",
      "Epoch 23/50\n",
      "843/843 [==============================] - 0s 85us/sample - loss: 0.0171 - val_loss: 0.0131\n",
      "Epoch 24/50\n",
      "843/843 [==============================] - 0s 84us/sample - loss: 0.0171 - val_loss: 0.0134\n",
      "Epoch 25/50\n",
      "843/843 [==============================] - 0s 85us/sample - loss: 0.0172 - val_loss: 0.0128\n",
      "Epoch 26/50\n",
      "843/843 [==============================] - 0s 82us/sample - loss: 0.0170 - val_loss: 0.0129\n",
      "Epoch 27/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0170 - val_loss: 0.0130\n",
      "Epoch 28/50\n",
      "843/843 [==============================] - 0s 79us/sample - loss: 0.0170 - val_loss: 0.0131\n",
      "Epoch 29/50\n",
      "843/843 [==============================] - 0s 85us/sample - loss: 0.0171 - val_loss: 0.0130\n",
      "Epoch 30/50\n",
      "843/843 [==============================] - 0s 79us/sample - loss: 0.0171 - val_loss: 0.0128\n",
      "Epoch 31/50\n",
      "843/843 [==============================] - 0s 82us/sample - loss: 0.0171 - val_loss: 0.0130\n",
      "Epoch 32/50\n",
      "843/843 [==============================] - 0s 82us/sample - loss: 0.0170 - val_loss: 0.0132\n",
      "Epoch 33/50\n",
      "843/843 [==============================] - 0s 80us/sample - loss: 0.0171 - val_loss: 0.0129\n",
      "Epoch 34/50\n",
      "843/843 [==============================] - 0s 82us/sample - loss: 0.0170 - val_loss: 0.0128\n",
      "Epoch 35/50\n",
      "843/843 [==============================] - 0s 79us/sample - loss: 0.0171 - val_loss: 0.0129\n",
      "Epoch 36/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0170 - val_loss: 0.0133\n",
      "Epoch 37/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0171 - val_loss: 0.0131\n",
      "Epoch 38/50\n",
      "843/843 [==============================] - 0s 77us/sample - loss: 0.0171 - val_loss: 0.0129\n",
      "Epoch 39/50\n",
      "843/843 [==============================] - 0s 79us/sample - loss: 0.0170 - val_loss: 0.0128\n",
      "Epoch 40/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0170 - val_loss: 0.0131\n",
      "Epoch 41/50\n",
      "843/843 [==============================] - 0s 86us/sample - loss: 0.0171 - val_loss: 0.0133\n",
      "Epoch 42/50\n",
      "843/843 [==============================] - 0s 77us/sample - loss: 0.0171 - val_loss: 0.0129\n",
      "Epoch 43/50\n",
      "843/843 [==============================] - 0s 79us/sample - loss: 0.0171 - val_loss: 0.0128\n",
      "Epoch 44/50\n",
      "843/843 [==============================] - 0s 77us/sample - loss: 0.0171 - val_loss: 0.0130\n",
      "Epoch 45/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0170 - val_loss: 0.0134\n",
      "Epoch 46/50\n",
      "843/843 [==============================] - 0s 85us/sample - loss: 0.0172 - val_loss: 0.0130\n",
      "Epoch 47/50\n",
      "843/843 [==============================] - 0s 80us/sample - loss: 0.0171 - val_loss: 0.0129\n",
      "Epoch 48/50\n",
      "843/843 [==============================] - 0s 81us/sample - loss: 0.0171 - val_loss: 0.0128\n",
      "Epoch 49/50\n",
      "843/843 [==============================] - 0s 82us/sample - loss: 0.0171 - val_loss: 0.0133\n",
      "Epoch 50/50\n",
      "843/843 [==============================] - 0s 78us/sample - loss: 0.0172 - val_loss: 0.0136\n",
      "第183个数，还剩3940个没有训练\n",
      "inv_hat [0.88003629 0.8537843  0.8554677  0.84852609 0.82517186 0.83272202\n",
      " 0.82318547 0.83560366 0.8259665  0.84067245 0.87210881 0.87775694\n",
      " 0.86527292 0.84454934 0.84206404 0.82546982 0.82556918 0.82765517\n",
      " 0.83938032 0.81941184 0.82437728 0.80670635 0.7883596  0.75776681\n",
      " 0.74017708 0.73603054 0.73040561 0.72488229 0.72754496 0.74264594]\n",
      "Test RMSE: 0.015\n",
      "Train on 510 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "510/510 [==============================] - 0s 89us/sample - loss: 0.0204 - val_loss: 0.0219\n",
      "Epoch 2/50\n",
      "510/510 [==============================] - 0s 91us/sample - loss: 0.0237 - val_loss: 0.0149\n",
      "Epoch 3/50\n",
      "510/510 [==============================] - 0s 92us/sample - loss: 0.0205 - val_loss: 0.0169\n",
      "Epoch 4/50\n",
      "510/510 [==============================] - 0s 93us/sample - loss: 0.0210 - val_loss: 0.0182\n",
      "Epoch 5/50\n",
      "510/510 [==============================] - 0s 96us/sample - loss: 0.0197 - val_loss: 0.0157\n",
      "Epoch 6/50\n",
      "510/510 [==============================] - 0s 95us/sample - loss: 0.0197 - val_loss: 0.0174\n",
      "Epoch 7/50\n",
      "510/510 [==============================] - 0s 95us/sample - loss: 0.0197 - val_loss: 0.0160\n",
      "Epoch 8/50\n",
      "510/510 [==============================] - 0s 92us/sample - loss: 0.0197 - val_loss: 0.0175\n",
      "Epoch 9/50\n",
      "510/510 [==============================] - 0s 93us/sample - loss: 0.0196 - val_loss: 0.0162\n",
      "Epoch 10/50\n",
      "510/510 [==============================] - 0s 91us/sample - loss: 0.0196 - val_loss: 0.0176\n",
      "Epoch 11/50\n",
      "510/510 [==============================] - 0s 92us/sample - loss: 0.0196 - val_loss: 0.0170\n",
      "Epoch 12/50\n",
      "510/510 [==============================] - 0s 92us/sample - loss: 0.0196 - val_loss: 0.0175\n",
      "Epoch 13/50\n",
      "510/510 [==============================] - 0s 94us/sample - loss: 0.0195 - val_loss: 0.0174\n",
      "Epoch 14/50\n",
      "510/510 [==============================] - 0s 92us/sample - loss: 0.0196 - val_loss: 0.0175\n",
      "Epoch 15/50\n",
      "510/510 [==============================] - 0s 87us/sample - loss: 0.0196 - val_loss: 0.0179\n",
      "Epoch 16/50\n",
      "510/510 [==============================] - 0s 85us/sample - loss: 0.0196 - val_loss: 0.0174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "510/510 [==============================] - 0s 90us/sample - loss: 0.0196 - val_loss: 0.0176\n",
      "Epoch 18/50\n",
      "510/510 [==============================] - 0s 87us/sample - loss: 0.0195 - val_loss: 0.0166\n",
      "Epoch 19/50\n",
      "510/510 [==============================] - 0s 90us/sample - loss: 0.0196 - val_loss: 0.0180\n",
      "Epoch 20/50\n",
      "510/510 [==============================] - 0s 89us/sample - loss: 0.0195 - val_loss: 0.0167\n",
      "Epoch 21/50\n",
      "510/510 [==============================] - 0s 92us/sample - loss: 0.0196 - val_loss: 0.0181\n",
      "Epoch 22/50\n",
      "510/510 [==============================] - 0s 86us/sample - loss: 0.0195 - val_loss: 0.0165\n",
      "Epoch 23/50\n",
      "510/510 [==============================] - 0s 89us/sample - loss: 0.0197 - val_loss: 0.0181\n",
      "Epoch 24/50\n",
      "510/510 [==============================] - 0s 90us/sample - loss: 0.0195 - val_loss: 0.0161\n",
      "Epoch 25/50\n",
      "510/510 [==============================] - 0s 86us/sample - loss: 0.0196 - val_loss: 0.0182\n",
      "Epoch 26/50\n",
      "510/510 [==============================] - 0s 89us/sample - loss: 0.0195 - val_loss: 0.0161\n",
      "Epoch 27/50\n",
      "510/510 [==============================] - 0s 90us/sample - loss: 0.0196 - val_loss: 0.0182\n",
      "Epoch 28/50\n",
      "510/510 [==============================] - 0s 94us/sample - loss: 0.0195 - val_loss: 0.0161\n",
      "Epoch 29/50\n",
      "510/510 [==============================] - 0s 98us/sample - loss: 0.0196 - val_loss: 0.0181\n",
      "Epoch 30/50\n",
      "510/510 [==============================] - 0s 98us/sample - loss: 0.0195 - val_loss: 0.0163\n",
      "Epoch 31/50\n",
      "510/510 [==============================] - 0s 95us/sample - loss: 0.0196 - val_loss: 0.0176\n",
      "Epoch 32/50\n",
      "510/510 [==============================] - 0s 96us/sample - loss: 0.0195 - val_loss: 0.0163\n",
      "Epoch 33/50\n",
      "510/510 [==============================] - 0s 90us/sample - loss: 0.0195 - val_loss: 0.0180\n",
      "Epoch 34/50\n",
      "510/510 [==============================] - 0s 93us/sample - loss: 0.0195 - val_loss: 0.0170\n",
      "Epoch 35/50\n",
      "510/510 [==============================] - 0s 96us/sample - loss: 0.0196 - val_loss: 0.0178\n",
      "Epoch 36/50\n",
      "510/510 [==============================] - 0s 92us/sample - loss: 0.0195 - val_loss: 0.0163\n",
      "Epoch 37/50\n",
      "510/510 [==============================] - 0s 90us/sample - loss: 0.0196 - val_loss: 0.0180\n",
      "Epoch 38/50\n",
      "510/510 [==============================] - 0s 89us/sample - loss: 0.0195 - val_loss: 0.0166\n",
      "Epoch 39/50\n",
      "510/510 [==============================] - 0s 91us/sample - loss: 0.0195 - val_loss: 0.0179\n",
      "Epoch 40/50\n",
      "510/510 [==============================] - 0s 85us/sample - loss: 0.0195 - val_loss: 0.0165\n",
      "Epoch 41/50\n",
      "510/510 [==============================] - 0s 86us/sample - loss: 0.0196 - val_loss: 0.0180\n",
      "Epoch 42/50\n",
      "510/510 [==============================] - 0s 86us/sample - loss: 0.0195 - val_loss: 0.0165\n",
      "Epoch 43/50\n",
      "510/510 [==============================] - 0s 88us/sample - loss: 0.0196 - val_loss: 0.0179\n",
      "Epoch 44/50\n",
      "510/510 [==============================] - 0s 95us/sample - loss: 0.0195 - val_loss: 0.0163\n",
      "Epoch 45/50\n",
      "510/510 [==============================] - 0s 92us/sample - loss: 0.0196 - val_loss: 0.0178\n",
      "Epoch 46/50\n",
      "510/510 [==============================] - 0s 89us/sample - loss: 0.0195 - val_loss: 0.0159\n",
      "Epoch 47/50\n",
      "510/510 [==============================] - 0s 100us/sample - loss: 0.0195 - val_loss: 0.0183\n",
      "Epoch 48/50\n",
      "510/510 [==============================] - 0s 95us/sample - loss: 0.0196 - val_loss: 0.0161\n",
      "Epoch 49/50\n",
      "510/510 [==============================] - 0s 90us/sample - loss: 0.0198 - val_loss: 0.0186\n",
      "Epoch 50/50\n",
      "510/510 [==============================] - 0s 93us/sample - loss: 0.0195 - val_loss: 0.0161\n",
      "第184个数，还剩3939个没有训练\n",
      "inv_hat [1.05321278 1.04949543 1.04949543 1.04900265 1.04583052 1.04553156\n",
      " 1.04543186 1.04682499 1.04443351 1.04473332 1.04801459 1.0491013\n",
      " 1.04880527 1.04742032 1.04821248 1.04811355 1.04860788 1.04880527\n",
      " 1.04821248 1.04583052 1.04453347 1.04323232 1.04303175 1.04383335\n",
      " 1.0434328  1.04383335 1.04333256 1.04303175 1.04303175 1.04543186]\n",
      "Test RMSE: 0.002\n",
      "Train on 585 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "585/585 [==============================] - 0s 92us/sample - loss: 0.0084 - val_loss: 0.0158\n",
      "Epoch 2/50\n",
      "585/585 [==============================] - 0s 89us/sample - loss: 0.0082 - val_loss: 0.0160\n",
      "Epoch 3/50\n",
      "585/585 [==============================] - 0s 88us/sample - loss: 0.0081 - val_loss: 0.0195\n",
      "Epoch 4/50\n",
      "585/585 [==============================] - 0s 93us/sample - loss: 0.0115 - val_loss: 0.0168\n",
      "Epoch 5/50\n",
      "585/585 [==============================] - 0s 85us/sample - loss: 0.0110 - val_loss: 0.0183\n",
      "Epoch 6/50\n",
      "585/585 [==============================] - 0s 86us/sample - loss: 0.0142 - val_loss: 0.0194\n",
      "Epoch 7/50\n",
      "585/585 [==============================] - 0s 89us/sample - loss: 0.0096 - val_loss: 0.0175\n",
      "Epoch 8/50\n",
      "585/585 [==============================] - 0s 89us/sample - loss: 0.0128 - val_loss: 0.0197\n",
      "Epoch 9/50\n",
      "585/585 [==============================] - 0s 91us/sample - loss: 0.0102 - val_loss: 0.0225\n",
      "Epoch 10/50\n",
      "585/585 [==============================] - 0s 92us/sample - loss: 0.0107 - val_loss: 0.0196\n",
      "Epoch 11/50\n",
      "585/585 [==============================] - 0s 88us/sample - loss: 0.0111 - val_loss: 0.0209\n",
      "Epoch 12/50\n",
      "585/585 [==============================] - 0s 88us/sample - loss: 0.0089 - val_loss: 0.0154\n",
      "Epoch 13/50\n",
      "585/585 [==============================] - 0s 86us/sample - loss: 0.0105 - val_loss: 0.0180\n",
      "Epoch 14/50\n",
      "585/585 [==============================] - 0s 91us/sample - loss: 0.0095 - val_loss: 0.0174\n",
      "Epoch 15/50\n",
      "585/585 [==============================] - 0s 91us/sample - loss: 0.0116 - val_loss: 0.0184\n",
      "Epoch 16/50\n",
      "585/585 [==============================] - 0s 88us/sample - loss: 0.0102 - val_loss: 0.0248\n",
      "Epoch 17/50\n",
      "585/585 [==============================] - 0s 86us/sample - loss: 0.0096 - val_loss: 0.0189\n",
      "Epoch 18/50\n",
      "585/585 [==============================] - 0s 87us/sample - loss: 0.0118 - val_loss: 0.0193\n",
      "Epoch 19/50\n",
      "585/585 [==============================] - 0s 90us/sample - loss: 0.0096 - val_loss: 0.0221\n",
      "Epoch 20/50\n",
      "585/585 [==============================] - 0s 85us/sample - loss: 0.0091 - val_loss: 0.0172\n",
      "Epoch 21/50\n",
      "585/585 [==============================] - 0s 87us/sample - loss: 0.0116 - val_loss: 0.0179\n",
      "Epoch 22/50\n",
      "585/585 [==============================] - 0s 87us/sample - loss: 0.0094 - val_loss: 0.0219\n",
      "Epoch 23/50\n",
      "585/585 [==============================] - 0s 86us/sample - loss: 0.0088 - val_loss: 0.0174\n",
      "Epoch 24/50\n",
      "585/585 [==============================] - 0s 88us/sample - loss: 0.0111 - val_loss: 0.0178\n",
      "Epoch 25/50\n",
      "585/585 [==============================] - 0s 92us/sample - loss: 0.0093 - val_loss: 0.0214\n",
      "Epoch 26/50\n",
      "585/585 [==============================] - 0s 88us/sample - loss: 0.0088 - val_loss: 0.0172\n",
      "Epoch 27/50\n",
      "585/585 [==============================] - 0s 89us/sample - loss: 0.0110 - val_loss: 0.0175\n",
      "Epoch 28/50\n",
      "585/585 [==============================] - 0s 90us/sample - loss: 0.0092 - val_loss: 0.0207\n",
      "Epoch 29/50\n",
      "585/585 [==============================] - 0s 87us/sample - loss: 0.0086 - val_loss: 0.0171\n",
      "Epoch 30/50\n",
      "585/585 [==============================] - 0s 86us/sample - loss: 0.0105 - val_loss: 0.0166\n",
      "Epoch 31/50\n",
      "585/585 [==============================] - 0s 91us/sample - loss: 0.0091 - val_loss: 0.0209\n",
      "Epoch 32/50\n",
      "585/585 [==============================] - 0s 94us/sample - loss: 0.0086 - val_loss: 0.0174\n",
      "Epoch 33/50\n",
      "585/585 [==============================] - 0s 93us/sample - loss: 0.0107 - val_loss: 0.0166\n",
      "Epoch 34/50\n",
      "585/585 [==============================] - 0s 85us/sample - loss: 0.0090 - val_loss: 0.0204\n",
      "Epoch 35/50\n",
      "585/585 [==============================] - 0s 86us/sample - loss: 0.0085 - val_loss: 0.0171\n",
      "Epoch 36/50\n",
      "585/585 [==============================] - 0s 85us/sample - loss: 0.0105 - val_loss: 0.0172\n",
      "Epoch 37/50\n",
      "585/585 [==============================] - 0s 83us/sample - loss: 0.0092 - val_loss: 0.0188\n",
      "Epoch 38/50\n",
      "585/585 [==============================] - 0s 83us/sample - loss: 0.0082 - val_loss: 0.0163\n",
      "Epoch 39/50\n",
      "585/585 [==============================] - 0s 82us/sample - loss: 0.0098 - val_loss: 0.0166\n",
      "Epoch 40/50\n",
      "585/585 [==============================] - 0s 87us/sample - loss: 0.0091 - val_loss: 0.0193\n",
      "Epoch 41/50\n",
      "585/585 [==============================] - 0s 87us/sample - loss: 0.0085 - val_loss: 0.0164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "585/585 [==============================] - 0s 85us/sample - loss: 0.0105 - val_loss: 0.0173\n",
      "Epoch 43/50\n",
      "585/585 [==============================] - 0s 82us/sample - loss: 0.0093 - val_loss: 0.0181\n",
      "Epoch 44/50\n",
      "585/585 [==============================] - 0s 83us/sample - loss: 0.0081 - val_loss: 0.0161\n",
      "Epoch 45/50\n",
      "585/585 [==============================] - 0s 84us/sample - loss: 0.0089 - val_loss: 0.0162\n",
      "Epoch 46/50\n",
      "585/585 [==============================] - 0s 85us/sample - loss: 0.0088 - val_loss: 0.0190\n",
      "Epoch 47/50\n",
      "585/585 [==============================] - 0s 91us/sample - loss: 0.0085 - val_loss: 0.0166\n",
      "Epoch 48/50\n",
      "585/585 [==============================] - 0s 91us/sample - loss: 0.0110 - val_loss: 0.0174\n",
      "Epoch 49/50\n",
      "585/585 [==============================] - 0s 89us/sample - loss: 0.0091 - val_loss: 0.0174\n",
      "Epoch 50/50\n",
      "585/585 [==============================] - 0s 96us/sample - loss: 0.0084 - val_loss: 0.0161\n",
      "第185个数，还剩3938个没有训练\n",
      "inv_hat [1.0414504  1.04182681 1.04182681 1.04210853 1.0422962  1.04238995\n",
      " 1.04238995 1.04248367 1.04248367 1.04276444 1.04295147 1.04295147\n",
      " 1.04360447 1.04369759 1.04388368 1.04434798 1.04444072 1.04453342\n",
      " 1.04444072 1.04453342 1.04434798 1.04369759 1.04369759 1.01956452\n",
      " 1.01996772 1.02026989 1.02026989 1.02016925 1.02057207 1.02127663]\n",
      "Test RMSE: 0.005\n",
      "Train on 880 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "880/880 [==============================] - 0s 86us/sample - loss: 0.0079 - val_loss: 0.0030\n",
      "Epoch 2/50\n",
      "880/880 [==============================] - 0s 84us/sample - loss: 0.0095 - val_loss: 0.0041\n",
      "Epoch 3/50\n",
      "880/880 [==============================] - 0s 89us/sample - loss: 0.0184 - val_loss: 0.0287\n",
      "Epoch 4/50\n",
      "880/880 [==============================] - 0s 84us/sample - loss: 0.0140 - val_loss: 0.0026\n",
      "Epoch 5/50\n",
      "880/880 [==============================] - 0s 83us/sample - loss: 0.0120 - val_loss: 0.0063\n",
      "Epoch 6/50\n",
      "880/880 [==============================] - 0s 83us/sample - loss: 0.0141 - val_loss: 0.0164\n",
      "Epoch 7/50\n",
      "880/880 [==============================] - 0s 84us/sample - loss: 0.0174 - val_loss: 0.0057\n",
      "Epoch 8/50\n",
      "880/880 [==============================] - 0s 83us/sample - loss: 0.0081 - val_loss: 0.0017\n",
      "Epoch 9/50\n",
      "880/880 [==============================] - 0s 86us/sample - loss: 0.0078 - val_loss: 0.0017\n",
      "Epoch 10/50\n",
      "880/880 [==============================] - 0s 88us/sample - loss: 0.0084 - val_loss: 0.0023\n",
      "Epoch 11/50\n",
      "880/880 [==============================] - 0s 86us/sample - loss: 0.0090 - val_loss: 0.0021\n",
      "Epoch 12/50\n",
      "880/880 [==============================] - 0s 83us/sample - loss: 0.0094 - val_loss: 0.0026\n",
      "Epoch 13/50\n",
      "880/880 [==============================] - 0s 87us/sample - loss: 0.0089 - val_loss: 0.0022\n",
      "Epoch 14/50\n",
      "880/880 [==============================] - 0s 84us/sample - loss: 0.0087 - val_loss: 0.0020\n",
      "Epoch 15/50\n",
      "880/880 [==============================] - 0s 83us/sample - loss: 0.0080 - val_loss: 0.0021\n",
      "Epoch 16/50\n",
      "880/880 [==============================] - 0s 86us/sample - loss: 0.0078 - val_loss: 0.0017\n",
      "Epoch 17/50\n",
      "880/880 [==============================] - 0s 89us/sample - loss: 0.0087 - val_loss: 0.0020\n",
      "Epoch 18/50\n",
      "880/880 [==============================] - 0s 83us/sample - loss: 0.0116 - val_loss: 0.0085\n",
      "Epoch 19/50\n",
      "880/880 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0165\n",
      "Epoch 20/50\n",
      "880/880 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0031\n",
      "Epoch 21/50\n",
      "880/880 [==============================] - 0s 80us/sample - loss: 0.0120 - val_loss: 0.0152\n",
      "Epoch 22/50\n",
      "880/880 [==============================] - 0s 82us/sample - loss: 0.0133 - val_loss: 0.0051\n",
      "Epoch 23/50\n",
      "880/880 [==============================] - 0s 82us/sample - loss: 0.0150 - val_loss: 0.0070\n",
      "Epoch 24/50\n",
      "880/880 [==============================] - 0s 80us/sample - loss: 0.0095 - val_loss: 0.0029\n",
      "Epoch 25/50\n",
      "880/880 [==============================] - 0s 84us/sample - loss: 0.0159 - val_loss: 0.0121\n",
      "Epoch 26/50\n",
      "880/880 [==============================] - 0s 86us/sample - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 27/50\n",
      "880/880 [==============================] - 0s 83us/sample - loss: 0.0138 - val_loss: 0.0051\n",
      "Epoch 28/50\n",
      "880/880 [==============================] - 0s 84us/sample - loss: 0.0083 - val_loss: 0.0037\n",
      "Epoch 29/50\n",
      "880/880 [==============================] - 0s 83us/sample - loss: 0.0145 - val_loss: 0.0164\n",
      "Epoch 30/50\n",
      "880/880 [==============================] - 0s 82us/sample - loss: 0.0132 - val_loss: 0.0093\n",
      "Epoch 31/50\n",
      "880/880 [==============================] - 0s 86us/sample - loss: 0.0120 - val_loss: 0.0051\n",
      "Epoch 32/50\n",
      "880/880 [==============================] - 0s 89us/sample - loss: 0.0094 - val_loss: 0.0017\n",
      "Epoch 33/50\n",
      "880/880 [==============================] - 0s 85us/sample - loss: 0.0155 - val_loss: 0.0076\n",
      "Epoch 34/50\n",
      "880/880 [==============================] - 0s 87us/sample - loss: 0.0106 - val_loss: 0.0058\n",
      "Epoch 35/50\n",
      "880/880 [==============================] - 0s 86us/sample - loss: 0.0140 - val_loss: 0.0074\n",
      "Epoch 36/50\n",
      "880/880 [==============================] - 0s 81us/sample - loss: 0.0094 - val_loss: 0.0021\n",
      "Epoch 37/50\n",
      "880/880 [==============================] - 0s 83us/sample - loss: 0.0144 - val_loss: 0.0082\n",
      "Epoch 38/50\n",
      "880/880 [==============================] - 0s 82us/sample - loss: 0.0110 - val_loss: 0.0081\n",
      "Epoch 39/50\n",
      "880/880 [==============================] - 0s 79us/sample - loss: 0.0128 - val_loss: 0.0060\n",
      "Epoch 40/50\n",
      "880/880 [==============================] - 0s 80us/sample - loss: 0.0090 - val_loss: 0.0020\n",
      "Epoch 41/50\n",
      "880/880 [==============================] - 0s 82us/sample - loss: 0.0145 - val_loss: 0.0071\n",
      "Epoch 42/50\n",
      "880/880 [==============================] - 0s 83us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 43/50\n",
      "880/880 [==============================] - 0s 85us/sample - loss: 0.0127 - val_loss: 0.0068\n",
      "Epoch 44/50\n",
      "880/880 [==============================] - 0s 85us/sample - loss: 0.0086 - val_loss: 0.0019\n",
      "Epoch 45/50\n",
      "880/880 [==============================] - 0s 84us/sample - loss: 0.0125 - val_loss: 0.0086\n",
      "Epoch 46/50\n",
      "880/880 [==============================] - 0s 82us/sample - loss: 0.0110 - val_loss: 0.0097\n",
      "Epoch 47/50\n",
      "880/880 [==============================] - 0s 86us/sample - loss: 0.0126 - val_loss: 0.0039\n",
      "Epoch 48/50\n",
      "880/880 [==============================] - 0s 85us/sample - loss: 0.0084 - val_loss: 0.0019\n",
      "Epoch 49/50\n",
      "880/880 [==============================] - 0s 85us/sample - loss: 0.0129 - val_loss: 0.0084\n",
      "Epoch 50/50\n",
      "880/880 [==============================] - 0s 82us/sample - loss: 0.0115 - val_loss: 0.0136\n",
      "第186个数，还剩3937个没有训练\n",
      "inv_hat [1.03860456 1.03850477 1.03850477 1.03860456 1.03880417 1.03870436\n",
      " 1.03870436 1.03870436 1.03900367 1.03890386 1.03910349 1.03920332\n",
      " 1.03930315 1.03950283 1.03950283 1.03970241 1.03960268 1.03960268\n",
      " 1.03940298 1.03930315 1.03920332 1.03900367 1.03880417 1.03880417\n",
      " 1.03890386 1.03900367 1.04120056 1.04229989 1.04229989 1.04229989]\n",
      "Test RMSE: 0.002\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0122 - val_loss: 0.0054\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0105 - val_loss: 0.0053\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0112 - val_loss: 0.0048\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0049\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0108 - val_loss: 0.0051\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0104 - val_loss: 0.0049\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0107 - val_loss: 0.0045\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0107 - val_loss: 0.0046\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0107 - val_loss: 0.0048\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0106 - val_loss: 0.0045\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0105 - val_loss: 0.0047\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0106 - val_loss: 0.0045\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0108 - val_loss: 0.0051\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0106 - val_loss: 0.0046\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0105 - val_loss: 0.0046\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0047\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0047\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0106 - val_loss: 0.0045\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0105 - val_loss: 0.0045\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0106 - val_loss: 0.0046\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0106 - val_loss: 0.0046\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0106 - val_loss: 0.0046\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0106 - val_loss: 0.0046\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0106 - val_loss: 0.0047\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0105 - val_loss: 0.0045\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0106 - val_loss: 0.0046\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0106 - val_loss: 0.0047\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0105 - val_loss: 0.0046\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0105 - val_loss: 0.0045\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0106 - val_loss: 0.0046\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0106 - val_loss: 0.0047\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0106 - val_loss: 0.0047\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0105 - val_loss: 0.0045\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0105 - val_loss: 0.0045\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0106 - val_loss: 0.0046\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0049\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0105 - val_loss: 0.0046\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0105 - val_loss: 0.0045\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0106 - val_loss: 0.0045\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0107 - val_loss: 0.0048\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0106 - val_loss: 0.0046\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0106 - val_loss: 0.0045\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0106 - val_loss: 0.0045\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0106 - val_loss: 0.0046\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0050\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0106 - val_loss: 0.0046\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0105 - val_loss: 0.0045\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0106 - val_loss: 0.0046\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0106 - val_loss: 0.0046\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0107 - val_loss: 0.0048\n",
      "第187个数，还剩3936个没有训练\n",
      "inv_hat [0.95784474 0.9346661  0.93683333 0.93634074 0.91801619 0.92312225\n",
      " 0.92321686 0.93969094 0.92880189 0.93959238 0.96495884 0.97534384\n",
      " 0.97445319 0.94807242 0.94540915 0.94422574 0.94984839 0.95557338\n",
      " 0.96041305 0.94333833 0.93565119 0.92861248 0.91952852 0.92123046\n",
      " 0.91385968 0.92340609 0.91414295 0.90716021 0.90320161 0.90357841]\n",
      "Test RMSE: 0.012\n",
      "Train on 488 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "488/488 [==============================] - 0s 83us/sample - loss: 0.0136 - val_loss: 0.0093\n",
      "Epoch 2/50\n",
      "488/488 [==============================] - 0s 87us/sample - loss: 0.0135 - val_loss: 0.0075\n",
      "Epoch 3/50\n",
      "488/488 [==============================] - 0s 85us/sample - loss: 0.0132 - val_loss: 0.0092\n",
      "Epoch 4/50\n",
      "488/488 [==============================] - 0s 84us/sample - loss: 0.0135 - val_loss: 0.0075\n",
      "Epoch 5/50\n",
      "488/488 [==============================] - 0s 85us/sample - loss: 0.0129 - val_loss: 0.0087\n",
      "Epoch 6/50\n",
      "488/488 [==============================] - 0s 85us/sample - loss: 0.0134 - val_loss: 0.0075\n",
      "Epoch 7/50\n",
      "488/488 [==============================] - 0s 85us/sample - loss: 0.0129 - val_loss: 0.0088\n",
      "Epoch 8/50\n",
      "488/488 [==============================] - 0s 97us/sample - loss: 0.0134 - val_loss: 0.0075\n",
      "Epoch 9/50\n",
      "488/488 [==============================] - 0s 84us/sample - loss: 0.0128 - val_loss: 0.0090\n",
      "Epoch 10/50\n",
      "488/488 [==============================] - 0s 83us/sample - loss: 0.0135 - val_loss: 0.0075\n",
      "Epoch 11/50\n",
      "488/488 [==============================] - 0s 83us/sample - loss: 0.0129 - val_loss: 0.0088\n",
      "Epoch 12/50\n",
      "488/488 [==============================] - 0s 84us/sample - loss: 0.0134 - val_loss: 0.0075\n",
      "Epoch 13/50\n",
      "488/488 [==============================] - 0s 83us/sample - loss: 0.0128 - val_loss: 0.0089\n",
      "Epoch 14/50\n",
      "488/488 [==============================] - 0s 81us/sample - loss: 0.0135 - val_loss: 0.0075\n",
      "Epoch 15/50\n",
      "488/488 [==============================] - 0s 85us/sample - loss: 0.0128 - val_loss: 0.0089\n",
      "Epoch 16/50\n",
      "488/488 [==============================] - 0s 85us/sample - loss: 0.0134 - val_loss: 0.0075\n",
      "Epoch 17/50\n",
      "488/488 [==============================] - 0s 89us/sample - loss: 0.0128 - val_loss: 0.0092\n",
      "Epoch 18/50\n",
      "488/488 [==============================] - 0s 87us/sample - loss: 0.0135 - val_loss: 0.0075\n",
      "Epoch 19/50\n",
      "488/488 [==============================] - 0s 87us/sample - loss: 0.0129 - val_loss: 0.0090\n",
      "Epoch 20/50\n",
      "488/488 [==============================] - 0s 86us/sample - loss: 0.0136 - val_loss: 0.0075\n",
      "Epoch 21/50\n",
      "488/488 [==============================] - 0s 84us/sample - loss: 0.0128 - val_loss: 0.0090\n",
      "Epoch 22/50\n",
      "488/488 [==============================] - 0s 86us/sample - loss: 0.0135 - val_loss: 0.0075\n",
      "Epoch 23/50\n",
      "488/488 [==============================] - 0s 88us/sample - loss: 0.0130 - val_loss: 0.0090\n",
      "Epoch 24/50\n",
      "488/488 [==============================] - 0s 86us/sample - loss: 0.0135 - val_loss: 0.0076\n",
      "Epoch 25/50\n",
      "488/488 [==============================] - 0s 88us/sample - loss: 0.0128 - val_loss: 0.0089\n",
      "Epoch 26/50\n",
      "488/488 [==============================] - 0s 87us/sample - loss: 0.0135 - val_loss: 0.0075\n",
      "Epoch 27/50\n",
      "488/488 [==============================] - 0s 87us/sample - loss: 0.0128 - val_loss: 0.0089\n",
      "Epoch 28/50\n",
      "488/488 [==============================] - 0s 88us/sample - loss: 0.0134 - val_loss: 0.0075\n",
      "Epoch 29/50\n",
      "488/488 [==============================] - 0s 84us/sample - loss: 0.0128 - val_loss: 0.0091\n",
      "Epoch 30/50\n",
      "488/488 [==============================] - 0s 88us/sample - loss: 0.0136 - val_loss: 0.0076\n",
      "Epoch 31/50\n",
      "488/488 [==============================] - 0s 89us/sample - loss: 0.0128 - val_loss: 0.0088\n",
      "Epoch 32/50\n",
      "488/488 [==============================] - 0s 89us/sample - loss: 0.0134 - val_loss: 0.0075\n",
      "Epoch 33/50\n",
      "488/488 [==============================] - 0s 89us/sample - loss: 0.0128 - val_loss: 0.0089\n",
      "Epoch 34/50\n",
      "488/488 [==============================] - 0s 87us/sample - loss: 0.0135 - val_loss: 0.0075\n",
      "Epoch 35/50\n",
      "488/488 [==============================] - 0s 87us/sample - loss: 0.0128 - val_loss: 0.0089\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - 0s 83us/sample - loss: 0.0135 - val_loss: 0.0076\n",
      "Epoch 37/50\n",
      "488/488 [==============================] - 0s 83us/sample - loss: 0.0128 - val_loss: 0.0091\n",
      "Epoch 38/50\n",
      "488/488 [==============================] - 0s 85us/sample - loss: 0.0135 - val_loss: 0.0075\n",
      "Epoch 39/50\n",
      "488/488 [==============================] - 0s 86us/sample - loss: 0.0128 - val_loss: 0.0089\n",
      "Epoch 40/50\n",
      "488/488 [==============================] - 0s 89us/sample - loss: 0.0135 - val_loss: 0.0075\n",
      "Epoch 41/50\n",
      "488/488 [==============================] - 0s 86us/sample - loss: 0.0128 - val_loss: 0.0088\n",
      "Epoch 42/50\n",
      "488/488 [==============================] - 0s 80us/sample - loss: 0.0134 - val_loss: 0.0075\n",
      "Epoch 43/50\n",
      "488/488 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0092\n",
      "Epoch 44/50\n",
      "488/488 [==============================] - 0s 82us/sample - loss: 0.0136 - val_loss: 0.0079\n",
      "Epoch 45/50\n",
      "488/488 [==============================] - 0s 84us/sample - loss: 0.0129 - val_loss: 0.0095\n",
      "Epoch 46/50\n",
      "488/488 [==============================] - 0s 84us/sample - loss: 0.0138 - val_loss: 0.0079\n",
      "Epoch 47/50\n",
      "488/488 [==============================] - 0s 84us/sample - loss: 0.0129 - val_loss: 0.0094\n",
      "Epoch 48/50\n",
      "488/488 [==============================] - 0s 84us/sample - loss: 0.0137 - val_loss: 0.0076\n",
      "Epoch 49/50\n",
      "488/488 [==============================] - 0s 86us/sample - loss: 0.0128 - val_loss: 0.0092\n",
      "Epoch 50/50\n",
      "488/488 [==============================] - 0s 85us/sample - loss: 0.0136 - val_loss: 0.0076\n",
      "第188个数，还剩3935个没有训练\n",
      "inv_hat [1.02304736 1.02265256 1.02255369 1.02265256 1.02265256 1.02265256\n",
      " 1.02265256 1.02265256 1.02285    1.02314595 1.02353963 1.02393247\n",
      " 1.02432419 1.02432419 1.02442198 1.02451971 1.02461738 1.02461738\n",
      " 1.02471498 1.02422632 1.02403052 1.02373617 1.02403052 1.02471498\n",
      " 1.02520182 1.025299   1.025299   1.025299   1.02558998 1.02674747]\n",
      "Test RMSE: 0.000\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0068 - val_loss: 0.0020\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0069 - val_loss: 0.0020\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0086 - val_loss: 0.0079\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0079 - val_loss: 0.0032\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0101 - val_loss: 0.0036\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0117 - val_loss: 0.0051\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0095 - val_loss: 0.0214\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0151 - val_loss: 0.0028\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0109 - val_loss: 0.0220\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0141 - val_loss: 0.0192\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0208 - val_loss: 0.0046\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0116 - val_loss: 0.0058\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0177 - val_loss: 0.0172\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0097 - val_loss: 0.0091\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0109 - val_loss: 0.0244\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0189 - val_loss: 0.0257\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0256 - val_loss: 0.0302\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0151 - val_loss: 0.0232\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0192 - val_loss: 0.0146\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0086 - val_loss: 0.0030\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0102 - val_loss: 0.0258\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0217 - val_loss: 0.0230\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0164 - val_loss: 0.0164\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0107 - val_loss: 0.0030\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0086 - val_loss: 0.0136\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0133 - val_loss: 0.0071\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0087 - val_loss: 0.0114\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0141 - val_loss: 0.0235\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0190 - val_loss: 0.0145\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0089 - val_loss: 0.0059\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0082 - val_loss: 0.0141\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0125 - val_loss: 0.0110\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0106 - val_loss: 0.0090\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0120 - val_loss: 0.0184\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0184 - val_loss: 0.0148\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0087 - val_loss: 0.0047\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0077 - val_loss: 0.0113\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0120 - val_loss: 0.0084\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0093 - val_loss: 0.0126\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0139 - val_loss: 0.0203\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0176 - val_loss: 0.0126\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0082 - val_loss: 0.0037\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0077 - val_loss: 0.0093\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0113 - val_loss: 0.0065\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0092 - val_loss: 0.0124\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0140 - val_loss: 0.0201\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0166 - val_loss: 0.0119\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0081 - val_loss: 0.0029\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0079 - val_loss: 0.0093\n",
      "第189个数，还剩3934个没有训练\n",
      "inv_hat [1.05811325 1.05750866 1.05811325 1.05811325 1.05781102 1.05750866\n",
      " 1.05740789 1.05750866 1.05831484 1.05841564 1.05902036 1.06063345\n",
      " 1.06123848 1.06154099 1.06174272 1.06315501 1.06315501 1.06325592\n",
      " 1.06144023 1.06123848 1.06043174 1.05992765 1.06063345 1.06224702\n",
      " 1.0624488  1.06234792 1.06285239 1.06325592 1.06406315 1.06618275]\n",
      "Test RMSE: 0.003\n",
      "Train on 697 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "697/697 [==============================] - 0s 81us/sample - loss: 0.0084 - val_loss: 0.0058\n",
      "Epoch 2/50\n",
      "697/697 [==============================] - 0s 79us/sample - loss: 0.0071 - val_loss: 0.0106\n",
      "Epoch 3/50\n",
      "697/697 [==============================] - 0s 78us/sample - loss: 0.0124 - val_loss: 0.0089\n",
      "Epoch 4/50\n",
      "697/697 [==============================] - 0s 77us/sample - loss: 0.0067 - val_loss: 0.0101\n",
      "Epoch 5/50\n",
      "697/697 [==============================] - 0s 80us/sample - loss: 0.0053 - val_loss: 0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "697/697 [==============================] - 0s 79us/sample - loss: 0.0068 - val_loss: 0.0071\n",
      "Epoch 7/50\n",
      "697/697 [==============================] - 0s 82us/sample - loss: 0.0075 - val_loss: 0.0078\n",
      "Epoch 8/50\n",
      "697/697 [==============================] - 0s 82us/sample - loss: 0.0078 - val_loss: 0.0056\n",
      "Epoch 9/50\n",
      "697/697 [==============================] - 0s 80us/sample - loss: 0.0089 - val_loss: 0.0076\n",
      "Epoch 10/50\n",
      "697/697 [==============================] - 0s 82us/sample - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 11/50\n",
      "697/697 [==============================] - 0s 80us/sample - loss: 0.0071 - val_loss: 0.0088\n",
      "Epoch 12/50\n",
      "697/697 [==============================] - 0s 78us/sample - loss: 0.0090 - val_loss: 0.0116\n",
      "Epoch 13/50\n",
      "697/697 [==============================] - 0s 79us/sample - loss: 0.0075 - val_loss: 0.0041\n",
      "Epoch 14/50\n",
      "697/697 [==============================] - 0s 77us/sample - loss: 0.0058 - val_loss: 0.0107\n",
      "Epoch 15/50\n",
      "697/697 [==============================] - 0s 79us/sample - loss: 0.0060 - val_loss: 0.0086\n",
      "Epoch 16/50\n",
      "697/697 [==============================] - 0s 80us/sample - loss: 0.0062 - val_loss: 0.0042\n",
      "Epoch 17/50\n",
      "697/697 [==============================] - 0s 79us/sample - loss: 0.0055 - val_loss: 0.0110\n",
      "Epoch 18/50\n",
      "697/697 [==============================] - 0s 78us/sample - loss: 0.0057 - val_loss: 0.0078\n",
      "Epoch 19/50\n",
      "697/697 [==============================] - 0s 78us/sample - loss: 0.0061 - val_loss: 0.0053\n",
      "Epoch 20/50\n",
      "697/697 [==============================] - 0s 79us/sample - loss: 0.0054 - val_loss: 0.0103\n",
      "Epoch 21/50\n",
      "697/697 [==============================] - 0s 81us/sample - loss: 0.0056 - val_loss: 0.0074\n",
      "Epoch 22/50\n",
      "697/697 [==============================] - 0s 79us/sample - loss: 0.0055 - val_loss: 0.0108\n",
      "Epoch 23/50\n",
      "697/697 [==============================] - 0s 78us/sample - loss: 0.0055 - val_loss: 0.0098\n",
      "Epoch 24/50\n",
      "697/697 [==============================] - 0s 80us/sample - loss: 0.0057 - val_loss: 0.0088\n",
      "Epoch 25/50\n",
      "697/697 [==============================] - 0s 81us/sample - loss: 0.0062 - val_loss: 0.0100\n",
      "Epoch 26/50\n",
      "697/697 [==============================] - 0s 78us/sample - loss: 0.0093 - val_loss: 0.0065\n",
      "Epoch 27/50\n",
      "697/697 [==============================] - 0s 81us/sample - loss: 0.0066 - val_loss: 0.0086\n",
      "Epoch 28/50\n",
      "697/697 [==============================] - 0s 82us/sample - loss: 0.0056 - val_loss: 0.0078\n",
      "Epoch 29/50\n",
      "697/697 [==============================] - 0s 82us/sample - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 30/50\n",
      "697/697 [==============================] - 0s 84us/sample - loss: 0.0075 - val_loss: 0.0122\n",
      "Epoch 31/50\n",
      "697/697 [==============================] - 0s 85us/sample - loss: 0.0084 - val_loss: 0.0077\n",
      "Epoch 32/50\n",
      "697/697 [==============================] - 0s 82us/sample - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 33/50\n",
      "697/697 [==============================] - 0s 80us/sample - loss: 0.0062 - val_loss: 0.0092\n",
      "Epoch 34/50\n",
      "697/697 [==============================] - 0s 79us/sample - loss: 0.0058 - val_loss: 0.0094\n",
      "Epoch 35/50\n",
      "697/697 [==============================] - 0s 82us/sample - loss: 0.0071 - val_loss: 0.0056\n",
      "Epoch 36/50\n",
      "697/697 [==============================] - 0s 81us/sample - loss: 0.0054 - val_loss: 0.0091\n",
      "Epoch 37/50\n",
      "697/697 [==============================] - 0s 78us/sample - loss: 0.0053 - val_loss: 0.0086\n",
      "Epoch 38/50\n",
      "697/697 [==============================] - 0s 81us/sample - loss: 0.0059 - val_loss: 0.0083\n",
      "Epoch 39/50\n",
      "697/697 [==============================] - 0s 83us/sample - loss: 0.0073 - val_loss: 0.0094\n",
      "Epoch 40/50\n",
      "697/697 [==============================] - 0s 79us/sample - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 41/50\n",
      "697/697 [==============================] - 0s 81us/sample - loss: 0.0078 - val_loss: 0.0058\n",
      "Epoch 42/50\n",
      "697/697 [==============================] - 0s 82us/sample - loss: 0.0071 - val_loss: 0.0061\n",
      "Epoch 43/50\n",
      "697/697 [==============================] - 0s 83us/sample - loss: 0.0068 - val_loss: 0.0086\n",
      "Epoch 44/50\n",
      "697/697 [==============================] - 0s 84us/sample - loss: 0.0064 - val_loss: 0.0066\n",
      "Epoch 45/50\n",
      "697/697 [==============================] - 0s 84us/sample - loss: 0.0090 - val_loss: 0.0059\n",
      "Epoch 46/50\n",
      "697/697 [==============================] - 0s 85us/sample - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 47/50\n",
      "697/697 [==============================] - 0s 87us/sample - loss: 0.0062 - val_loss: 0.0089\n",
      "Epoch 48/50\n",
      "697/697 [==============================] - 0s 87us/sample - loss: 0.0057 - val_loss: 0.0096\n",
      "Epoch 49/50\n",
      "697/697 [==============================] - 0s 86us/sample - loss: 0.0071 - val_loss: 0.0041\n",
      "Epoch 50/50\n",
      "697/697 [==============================] - 0s 81us/sample - loss: 0.0059 - val_loss: 0.0091\n",
      "第190个数，还剩3933个没有训练\n",
      "inv_hat [1.05265995 1.05265995 1.05265995 1.05265995 1.05265995 1.05265995\n",
      " 1.05360336 1.05360336 1.05360336 1.05360336 1.05360336 1.0545425\n",
      " 1.0545425  1.0545425  1.05547757 1.05547757 1.05547757 1.05547757\n",
      " 1.05547757 1.05547757 1.05547757 1.05547757 1.05360336 1.0545425\n",
      " 1.0545425  1.0545425  1.0545425  1.0545425  1.05547757 1.05547757]\n",
      "Test RMSE: 0.001\n",
      "Train on 1043 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1043/1043 [==============================] - 0s 81us/sample - loss: 0.0054 - val_loss: 0.0145\n",
      "Epoch 2/50\n",
      "1043/1043 [==============================] - 0s 83us/sample - loss: 0.0054 - val_loss: 0.0095\n",
      "Epoch 3/50\n",
      "1043/1043 [==============================] - 0s 85us/sample - loss: 0.0054 - val_loss: 0.0137\n",
      "Epoch 4/50\n",
      "1043/1043 [==============================] - 0s 85us/sample - loss: 0.0053 - val_loss: 0.0090\n",
      "Epoch 5/50\n",
      "1043/1043 [==============================] - 0s 84us/sample - loss: 0.0056 - val_loss: 0.0103\n",
      "Epoch 6/50\n",
      "1043/1043 [==============================] - 0s 87us/sample - loss: 0.0047 - val_loss: 0.0090\n",
      "Epoch 7/50\n",
      "1043/1043 [==============================] - 0s 82us/sample - loss: 0.0048 - val_loss: 0.0111\n",
      "Epoch 8/50\n",
      "1043/1043 [==============================] - 0s 78us/sample - loss: 0.0047 - val_loss: 0.0091\n",
      "Epoch 9/50\n",
      "1043/1043 [==============================] - 0s 77us/sample - loss: 0.0053 - val_loss: 0.0116\n",
      "Epoch 10/50\n",
      "1043/1043 [==============================] - 0s 76us/sample - loss: 0.0051 - val_loss: 0.0088\n",
      "Epoch 11/50\n",
      "1043/1043 [==============================] - 0s 80us/sample - loss: 0.0052 - val_loss: 0.0093\n",
      "Epoch 12/50\n",
      "1043/1043 [==============================] - 0s 76us/sample - loss: 0.0048 - val_loss: 0.0092\n",
      "Epoch 13/50\n",
      "1043/1043 [==============================] - 0s 82us/sample - loss: 0.0048 - val_loss: 0.0090\n",
      "Epoch 14/50\n",
      "1043/1043 [==============================] - 0s 78us/sample - loss: 0.0047 - val_loss: 0.0098\n",
      "Epoch 15/50\n",
      "1043/1043 [==============================] - 0s 79us/sample - loss: 0.0046 - val_loss: 0.0090\n",
      "Epoch 16/50\n",
      "1043/1043 [==============================] - 0s 79us/sample - loss: 0.0048 - val_loss: 0.0105\n",
      "Epoch 17/50\n",
      "1043/1043 [==============================] - 0s 78us/sample - loss: 0.0047 - val_loss: 0.0094\n",
      "Epoch 18/50\n",
      "1043/1043 [==============================] - 0s 80us/sample - loss: 0.0047 - val_loss: 0.0090\n",
      "Epoch 19/50\n",
      "1043/1043 [==============================] - 0s 78us/sample - loss: 0.0046 - val_loss: 0.0090\n",
      "Epoch 20/50\n",
      "1043/1043 [==============================] - 0s 83us/sample - loss: 0.0048 - val_loss: 0.0091\n",
      "Epoch 21/50\n",
      "1043/1043 [==============================] - 0s 81us/sample - loss: 0.0048 - val_loss: 0.0094\n",
      "Epoch 22/50\n",
      "1043/1043 [==============================] - 0s 81us/sample - loss: 0.0046 - val_loss: 0.0091\n",
      "Epoch 23/50\n",
      "1043/1043 [==============================] - 0s 83us/sample - loss: 0.0048 - val_loss: 0.0091\n",
      "Epoch 24/50\n",
      "1043/1043 [==============================] - 0s 83us/sample - loss: 0.0048 - val_loss: 0.0104\n",
      "Epoch 25/50\n",
      "1043/1043 [==============================] - 0s 81us/sample - loss: 0.0050 - val_loss: 0.0091\n",
      "Epoch 26/50\n",
      "1043/1043 [==============================] - 0s 81us/sample - loss: 0.0049 - val_loss: 0.0094\n",
      "Epoch 27/50\n",
      "1043/1043 [==============================] - 0s 86us/sample - loss: 0.0050 - val_loss: 0.0105\n",
      "Epoch 28/50\n",
      "1043/1043 [==============================] - 0s 85us/sample - loss: 0.0051 - val_loss: 0.0093\n",
      "Epoch 29/50\n",
      "1043/1043 [==============================] - 0s 83us/sample - loss: 0.0050 - val_loss: 0.0092\n",
      "Epoch 30/50\n",
      "1043/1043 [==============================] - 0s 81us/sample - loss: 0.0049 - val_loss: 0.0092\n",
      "Epoch 31/50\n",
      "1043/1043 [==============================] - 0s 78us/sample - loss: 0.0052 - val_loss: 0.0107\n",
      "Epoch 32/50\n",
      "1043/1043 [==============================] - 0s 80us/sample - loss: 0.0055 - val_loss: 0.0103\n",
      "Epoch 33/50\n",
      "1043/1043 [==============================] - 0s 84us/sample - loss: 0.0052 - val_loss: 0.0094\n",
      "Epoch 34/50\n",
      "1043/1043 [==============================] - 0s 83us/sample - loss: 0.0054 - val_loss: 0.0097\n",
      "Epoch 35/50\n",
      "1043/1043 [==============================] - 0s 79us/sample - loss: 0.0055 - val_loss: 0.0096\n",
      "Epoch 36/50\n",
      "1043/1043 [==============================] - 0s 83us/sample - loss: 0.0058 - val_loss: 0.0100\n",
      "Epoch 37/50\n",
      "1043/1043 [==============================] - 0s 81us/sample - loss: 0.0062 - val_loss: 0.0104\n",
      "Epoch 38/50\n",
      "1043/1043 [==============================] - 0s 82us/sample - loss: 0.0063 - val_loss: 0.0110\n",
      "Epoch 39/50\n",
      "1043/1043 [==============================] - 0s 80us/sample - loss: 0.0061 - val_loss: 0.0122\n",
      "Epoch 40/50\n",
      "1043/1043 [==============================] - 0s 85us/sample - loss: 0.0076 - val_loss: 0.0182\n",
      "Epoch 41/50\n",
      "1043/1043 [==============================] - 0s 81us/sample - loss: 0.0095 - val_loss: 0.0201\n",
      "Epoch 42/50\n",
      "1043/1043 [==============================] - 0s 79us/sample - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 43/50\n",
      "1043/1043 [==============================] - 0s 81us/sample - loss: 0.0121 - val_loss: 0.0110\n",
      "Epoch 44/50\n",
      "1043/1043 [==============================] - 0s 79us/sample - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 45/50\n",
      "1043/1043 [==============================] - 0s 84us/sample - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 46/50\n",
      "1043/1043 [==============================] - 0s 80us/sample - loss: 0.0089 - val_loss: 0.0096\n",
      "Epoch 47/50\n",
      "1043/1043 [==============================] - 0s 83us/sample - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 48/50\n",
      "1043/1043 [==============================] - 0s 80us/sample - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 49/50\n",
      "1043/1043 [==============================] - 0s 80us/sample - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 50/50\n",
      "1043/1043 [==============================] - 0s 81us/sample - loss: 0.0076 - val_loss: 0.0104\n",
      "第191个数，还剩3932个没有训练\n",
      "inv_hat [1.29549388 1.29549388 1.29549388 1.29549388 1.29549388 1.29549388\n",
      " 1.29549388 1.29647148 1.29744837 1.29744837 1.29744837 1.29939972\n",
      " 1.3003743  1.3003743  1.30134791 1.30232087 1.30232087 1.30329303\n",
      " 1.30134791 1.3003743  1.3003743  1.29577327 1.3003743  1.23459736\n",
      " 1.23459736 1.23459736 1.23561178 1.23561178 1.23662589 1.23865276]\n",
      "Test RMSE: 0.012\n",
      "Train on 740 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0096 - val_loss: 6.1236e-04\n",
      "Epoch 2/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0104 - val_loss: 0.0021\n",
      "Epoch 3/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0112 - val_loss: 9.0083e-04\n",
      "Epoch 4/50\n",
      "740/740 [==============================] - 0s 92us/sample - loss: 0.0087 - val_loss: 5.7776e-04\n",
      "Epoch 5/50\n",
      "740/740 [==============================] - 0s 87us/sample - loss: 0.0109 - val_loss: 0.0028\n",
      "Epoch 6/50\n",
      "740/740 [==============================] - 0s 87us/sample - loss: 0.0092 - val_loss: 0.0016\n",
      "Epoch 7/50\n",
      "740/740 [==============================] - 0s 88us/sample - loss: 0.0101 - val_loss: 0.0042\n",
      "Epoch 8/50\n",
      "740/740 [==============================] - 0s 87us/sample - loss: 0.0095 - val_loss: 0.0024\n",
      "Epoch 9/50\n",
      "740/740 [==============================] - 0s 82us/sample - loss: 0.0098 - val_loss: 0.0046\n",
      "Epoch 10/50\n",
      "740/740 [==============================] - 0s 81us/sample - loss: 0.0094 - val_loss: 0.0025\n",
      "Epoch 11/50\n",
      "740/740 [==============================] - 0s 81us/sample - loss: 0.0097 - val_loss: 0.0046\n",
      "Epoch 12/50\n",
      "740/740 [==============================] - 0s 79us/sample - loss: 0.0088 - val_loss: 0.0014\n",
      "Epoch 13/50\n",
      "740/740 [==============================] - 0s 78us/sample - loss: 0.0104 - val_loss: 0.0035\n",
      "Epoch 14/50\n",
      "740/740 [==============================] - 0s 79us/sample - loss: 0.0086 - val_loss: 0.0018\n",
      "Epoch 15/50\n",
      "740/740 [==============================] - 0s 81us/sample - loss: 0.0099 - val_loss: 0.0043\n",
      "Epoch 16/50\n",
      "740/740 [==============================] - 0s 82us/sample - loss: 0.0089 - val_loss: 0.0023\n",
      "Epoch 17/50\n",
      "740/740 [==============================] - 0s 82us/sample - loss: 0.0096 - val_loss: 0.0043\n",
      "Epoch 18/50\n",
      "740/740 [==============================] - 0s 83us/sample - loss: 0.0085 - val_loss: 0.0015\n",
      "Epoch 19/50\n",
      "740/740 [==============================] - 0s 82us/sample - loss: 0.0100 - val_loss: 0.0036\n",
      "Epoch 20/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0085 - val_loss: 0.0020\n",
      "Epoch 21/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0095 - val_loss: 0.0042\n",
      "Epoch 22/50\n",
      "740/740 [==============================] - 0s 88us/sample - loss: 0.0085 - val_loss: 0.0015\n",
      "Epoch 23/50\n",
      "740/740 [==============================] - 0s 91us/sample - loss: 0.0097 - val_loss: 0.0035\n",
      "Epoch 24/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0085 - val_loss: 0.0018\n",
      "Epoch 25/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0093 - val_loss: 0.0041\n",
      "Epoch 26/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0088 - val_loss: 0.0024\n",
      "Epoch 27/50\n",
      "740/740 [==============================] - 0s 82us/sample - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 28/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0084 - val_loss: 0.0014\n",
      "Epoch 29/50\n",
      "740/740 [==============================] - 0s 86us/sample - loss: 0.0096 - val_loss: 0.0033\n",
      "Epoch 30/50\n",
      "740/740 [==============================] - 0s 88us/sample - loss: 0.0083 - val_loss: 0.0017\n",
      "Epoch 31/50\n",
      "740/740 [==============================] - 0s 83us/sample - loss: 0.0091 - val_loss: 0.0040\n",
      "Epoch 32/50\n",
      "740/740 [==============================] - 0s 81us/sample - loss: 0.0086 - val_loss: 0.0023\n",
      "Epoch 33/50\n",
      "740/740 [==============================] - 0s 80us/sample - loss: 0.0088 - val_loss: 0.0042\n",
      "Epoch 34/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0083 - val_loss: 0.0014\n",
      "Epoch 35/50\n",
      "740/740 [==============================] - 0s 89us/sample - loss: 0.0094 - val_loss: 0.0032\n",
      "Epoch 36/50\n",
      "740/740 [==============================] - 0s 83us/sample - loss: 0.0082 - val_loss: 0.0017\n",
      "Epoch 37/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0090 - val_loss: 0.0039\n",
      "Epoch 38/50\n",
      "740/740 [==============================] - 0s 86us/sample - loss: 0.0085 - val_loss: 0.0022\n",
      "Epoch 39/50\n",
      "740/740 [==============================] - 0s 91us/sample - loss: 0.0087 - val_loss: 0.0039\n",
      "Epoch 40/50\n",
      "740/740 [==============================] - 0s 83us/sample - loss: 0.0081 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0092 - val_loss: 0.0032\n",
      "Epoch 42/50\n",
      "740/740 [==============================] - 0s 83us/sample - loss: 0.0081 - val_loss: 0.0017\n",
      "Epoch 43/50\n",
      "740/740 [==============================] - 0s 81us/sample - loss: 0.0088 - val_loss: 0.0038\n",
      "Epoch 44/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0084 - val_loss: 0.0022\n",
      "Epoch 45/50\n",
      "740/740 [==============================] - 0s 80us/sample - loss: 0.0086 - val_loss: 0.0038\n",
      "Epoch 46/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0079 - val_loss: 0.0012\n",
      "Epoch 47/50\n",
      "740/740 [==============================] - 0s 91us/sample - loss: 0.0092 - val_loss: 0.0031\n",
      "Epoch 48/50\n",
      "740/740 [==============================] - 0s 88us/sample - loss: 0.0080 - val_loss: 0.0018\n",
      "Epoch 49/50\n",
      "740/740 [==============================] - 0s 84us/sample - loss: 0.0087 - val_loss: 0.0037\n",
      "Epoch 50/50\n",
      "740/740 [==============================] - 0s 85us/sample - loss: 0.0079 - val_loss: 0.0013\n",
      "第192个数，还剩3931个没有训练\n",
      "inv_hat [1.73348325 1.73357613 1.73413452 1.73441348 1.73469252 1.73497141\n",
      " 1.73478552 1.73487848 1.73497141 1.7356221  1.73617976 1.73655142\n",
      " 1.73701578 1.73692289 1.73701578 1.73748013 1.7377586  1.73794433\n",
      " 1.7377586  1.73748013 1.73766575 1.73710866 1.73701578 1.7377586\n",
      " 1.73794433 1.73812995 1.73822272 1.73794433 1.73840831 1.73998527]\n",
      "Test RMSE: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0107 - val_loss: 0.0041\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0099 - val_loss: 0.0051\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0094 - val_loss: 0.0041\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0095 - val_loss: 0.0052\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0092 - val_loss: 0.0044\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0093 - val_loss: 0.0050\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0050\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0049\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0049\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0092 - val_loss: 0.0048\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0092 - val_loss: 0.0048\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0092 - val_loss: 0.0048\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0092 - val_loss: 0.0047\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0092 - val_loss: 0.0047\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0092 - val_loss: 0.0047\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0092 - val_loss: 0.0044\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0092 - val_loss: 0.0044\n",
      "第193个数，还剩3930个没有训练\n",
      "inv_hat [1.01447778 0.99184115 0.99233726 0.98965854 0.96755052 0.96002296\n",
      " 0.96230062 0.97280213 0.95843864 0.9663617  0.98420309 0.98093067\n",
      " 0.97835288 0.96606452 0.97042385 0.9634891  0.96814495 0.97319855\n",
      " 0.98906328 0.97379319 0.96566827 0.9532909  0.94141816 0.93805602\n",
      " 0.92935759 0.93449693 0.93568318 0.92945644 0.92668987 0.9274802 ]\n",
      "Test RMSE: 0.010\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0072\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 87us/sample - loss: 0.0095 - val_loss: 0.0028\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 87us/sample - loss: 0.0098 - val_loss: 0.0013\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0070\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0095 - val_loss: 0.0041\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0086 - val_loss: 0.0014\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0089 - val_loss: 0.0011\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0087 - val_loss: 0.0014\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0087 - val_loss: 0.0023\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - ETA: 0s - loss: 0.013 - 0s 82us/sample - loss: 0.0090 - val_loss: 0.0024\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0088 - val_loss: 0.0017\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0086 - val_loss: 0.0013\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0087 - val_loss: 0.0025\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0089 - val_loss: 0.0024\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0087 - val_loss: 0.0014\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0086 - val_loss: 0.0014\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0086 - val_loss: 0.0015\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0086 - val_loss: 0.0017\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0087 - val_loss: 0.0019\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0086 - val_loss: 0.0016\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0085 - val_loss: 9.9356e-04\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0085 - val_loss: 0.0010\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0085 - val_loss: 0.0011\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0089 - val_loss: 0.0021\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0022\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0088 - val_loss: 9.8966e-04\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0086 - val_loss: 0.0014\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0085 - val_loss: 9.8940e-04\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0085 - val_loss: 0.0011\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0086 - val_loss: 0.0011\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0090 - val_loss: 0.0015\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0090 - val_loss: 0.0012\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0087 - val_loss: 0.0011\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0086 - val_loss: 0.0010\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0087 - val_loss: 0.0011\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0088 - val_loss: 0.0012\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0087 - val_loss: 0.0010\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0086 - val_loss: 0.0010\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0086 - val_loss: 0.0017\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0091 - val_loss: 0.0036\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0092 - val_loss: 0.0028\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0088 - val_loss: 0.0015\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0089 - val_loss: 0.0026\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0091 - val_loss: 0.0027\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0089 - val_loss: 0.0018\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0087 - val_loss: 0.0017\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0090 - val_loss: 0.0025\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0091 - val_loss: 0.0021\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0086 - val_loss: 0.0010\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0085 - val_loss: 0.0011\n",
      "第194个数，还剩3929个没有训练\n",
      "inv_hat [0.60811118 0.60211706 0.60311597 0.60211706 0.60011939 0.60011939\n",
      " 0.60011939 0.60211706 0.60011939 0.60011939 0.60311597 0.60311597\n",
      " 0.60311597 0.60211706 0.60211706 0.60111822 0.60111822 0.60211706\n",
      " 0.60311597 0.60211706 0.60111822 0.60011939 0.59812183 0.59612452\n",
      " 0.59412731 0.59412731 0.59312883 0.59312883 0.59312883 0.59412731]\n",
      "Test RMSE: 0.002\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0065 - val_loss: 0.0120\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0069 - val_loss: 0.0160\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0068 - val_loss: 0.0093\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0071 - val_loss: 0.0167\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0070 - val_loss: 0.0086\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0068 - val_loss: 0.0134\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0081 - val_loss: 0.0083\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0073 - val_loss: 0.0065\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0072 - val_loss: 0.0084\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0082 - val_loss: 0.0116\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0094 - val_loss: 0.0135\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0081 - val_loss: 0.0088\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0092 - val_loss: 0.0106\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0113 - val_loss: 0.0245\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0087 - val_loss: 0.0187\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0079 - val_loss: 0.0208\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0073 - val_loss: 0.0180\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0074 - val_loss: 0.0150\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0077 - val_loss: 0.0106\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0082 - val_loss: 0.0058\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0063 - val_loss: 0.0092\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0062 - val_loss: 0.0091\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0062 - val_loss: 0.0094\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0062 - val_loss: 0.0103\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0067 - val_loss: 0.0087\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0068 - val_loss: 0.0074\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0073 - val_loss: 0.0066\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0088 - val_loss: 0.0133\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0077 - val_loss: 0.0084\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0090 - val_loss: 0.0133\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0089 - val_loss: 0.0162\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 87us/sample - loss: 0.0078 - val_loss: 0.0125\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0075 - val_loss: 0.0153\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0070 - val_loss: 0.0095\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0074 - val_loss: 0.0082\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0073 - val_loss: 0.0069\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0099 - val_loss: 0.0162\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0090 - val_loss: 0.0191\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0074 - val_loss: 0.0196\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0079 - val_loss: 0.0148\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0084 - val_loss: 0.0078\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0068 - val_loss: 0.0098\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0067 - val_loss: 0.0092\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0072 - val_loss: 0.0098\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0076 - val_loss: 0.0077\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0075 - val_loss: 0.0073\n",
      "第195个数，还剩3928个没有训练\n",
      "inv_hat [1.076915   1.07785157 1.07785157 1.076915   1.076915   1.076915\n",
      " 1.076915   1.07785157 1.07878587 1.07878587 1.07878587 1.08157427\n",
      " 1.08249876 1.08342087 1.08434044 1.08434044 1.08434044 1.08525738\n",
      " 1.08434044 1.08342087 1.08249876 1.08249876 1.08249876 1.08342087\n",
      " 1.08434044 1.08434044 1.08434044 1.08525738 1.08525738 1.08525738]\n",
      "Test RMSE: 0.001\n",
      "Train on 573 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0076 - val_loss: 0.0031\n",
      "Epoch 2/50\n",
      "573/573 [==============================] - 0s 85us/sample - loss: 0.0083 - val_loss: 0.0030\n",
      "Epoch 3/50\n",
      "573/573 [==============================] - 0s 83us/sample - loss: 0.0086 - val_loss: 0.0065\n",
      "Epoch 4/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0091 - val_loss: 0.0034\n",
      "Epoch 5/50\n",
      "573/573 [==============================] - 0s 78us/sample - loss: 0.0074 - val_loss: 0.0030\n",
      "Epoch 6/50\n",
      "573/573 [==============================] - 0s 79us/sample - loss: 0.0081 - val_loss: 0.0030\n",
      "Epoch 7/50\n",
      "573/573 [==============================] - 0s 80us/sample - loss: 0.0073 - val_loss: 0.0043\n",
      "Epoch 8/50\n",
      "573/573 [==============================] - 0s 79us/sample - loss: 0.0088 - val_loss: 0.0031\n",
      "Epoch 9/50\n",
      "573/573 [==============================] - 0s 79us/sample - loss: 0.0077 - val_loss: 0.0041\n",
      "Epoch 10/50\n",
      "573/573 [==============================] - 0s 80us/sample - loss: 0.0076 - val_loss: 0.0033\n",
      "Epoch 11/50\n",
      "573/573 [==============================] - 0s 83us/sample - loss: 0.0089 - val_loss: 0.0034\n",
      "Epoch 12/50\n",
      "573/573 [==============================] - 0s 80us/sample - loss: 0.0076 - val_loss: 0.0042\n",
      "Epoch 13/50\n",
      "573/573 [==============================] - 0s 82us/sample - loss: 0.0079 - val_loss: 0.0032\n",
      "Epoch 14/50\n",
      "573/573 [==============================] - 0s 86us/sample - loss: 0.0074 - val_loss: 0.0045\n",
      "Epoch 15/50\n",
      "573/573 [==============================] - 0s 84us/sample - loss: 0.0075 - val_loss: 0.0032\n",
      "Epoch 16/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0081 - val_loss: 0.0037\n",
      "Epoch 17/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0076 - val_loss: 0.0031\n",
      "Epoch 18/50\n",
      "573/573 [==============================] - 0s 80us/sample - loss: 0.0083 - val_loss: 0.0042\n",
      "Epoch 19/50\n",
      "573/573 [==============================] - 0s 82us/sample - loss: 0.0084 - val_loss: 0.0031\n",
      "Epoch 20/50\n",
      "573/573 [==============================] - 0s 79us/sample - loss: 0.0074 - val_loss: 0.0031\n",
      "Epoch 21/50\n",
      "573/573 [==============================] - 0s 77us/sample - loss: 0.0074 - val_loss: 0.0034\n",
      "Epoch 22/50\n",
      "573/573 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0045\n",
      "Epoch 23/50\n",
      "573/573 [==============================] - 0s 76us/sample - loss: 0.0082 - val_loss: 0.0030\n",
      "Epoch 24/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0073 - val_loss: 0.0030\n",
      "Epoch 25/50\n",
      "573/573 [==============================] - 0s 80us/sample - loss: 0.0078 - val_loss: 0.0041\n",
      "Epoch 26/50\n",
      "573/573 [==============================] - 0s 84us/sample - loss: 0.0077 - val_loss: 0.0055\n",
      "Epoch 27/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0082 - val_loss: 0.0033\n",
      "Epoch 28/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0078 - val_loss: 0.0032\n",
      "Epoch 29/50\n",
      "573/573 [==============================] - 0s 78us/sample - loss: 0.0077 - val_loss: 0.0032\n",
      "Epoch 30/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0075 - val_loss: 0.0053\n",
      "Epoch 31/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0081 - val_loss: 0.0031\n",
      "Epoch 32/50\n",
      "573/573 [==============================] - 0s 84us/sample - loss: 0.0075 - val_loss: 0.0030\n",
      "Epoch 33/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0077 - val_loss: 0.0031\n",
      "Epoch 34/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0072 - val_loss: 0.0031\n",
      "Epoch 35/50\n",
      "573/573 [==============================] - 0s 83us/sample - loss: 0.0081 - val_loss: 0.0040\n",
      "Epoch 36/50\n",
      "573/573 [==============================] - 0s 80us/sample - loss: 0.0077 - val_loss: 0.0032\n",
      "Epoch 37/50\n",
      "573/573 [==============================] - 0s 84us/sample - loss: 0.0079 - val_loss: 0.0034\n",
      "Epoch 38/50\n",
      "573/573 [==============================] - 0s 82us/sample - loss: 0.0080 - val_loss: 0.0036\n",
      "Epoch 39/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0072 - val_loss: 0.0030\n",
      "Epoch 40/50\n",
      "573/573 [==============================] - 0s 77us/sample - loss: 0.0074 - val_loss: 0.0050\n",
      "Epoch 41/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0081 - val_loss: 0.0032\n",
      "Epoch 42/50\n",
      "573/573 [==============================] - 0s 85us/sample - loss: 0.0078 - val_loss: 0.0033\n",
      "Epoch 43/50\n",
      "573/573 [==============================] - 0s 86us/sample - loss: 0.0077 - val_loss: 0.0033\n",
      "Epoch 44/50\n",
      "573/573 [==============================] - 0s 82us/sample - loss: 0.0074 - val_loss: 0.0052\n",
      "Epoch 45/50\n",
      "573/573 [==============================] - 0s 79us/sample - loss: 0.0078 - val_loss: 0.0031\n",
      "Epoch 46/50\n",
      "573/573 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0035\n",
      "Epoch 47/50\n",
      "573/573 [==============================] - 0s 79us/sample - loss: 0.0082 - val_loss: 0.0042\n",
      "Epoch 48/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0074 - val_loss: 0.0048\n",
      "Epoch 49/50\n",
      "573/573 [==============================] - 0s 75us/sample - loss: 0.0079 - val_loss: 0.0031\n",
      "Epoch 50/50\n",
      "573/573 [==============================] - 0s 76us/sample - loss: 0.0079 - val_loss: 0.0033\n",
      "第196个数，还剩3927个没有训练\n",
      "inv_hat [1.14838868 1.14838868 1.14934244 1.14838868 1.14838868 1.14838868\n",
      " 1.14838868 1.14934244 1.14934244 1.14934244 1.15029426 1.15029426\n",
      " 1.15124434 1.15124434 1.15124434 1.15219241 1.15313873 1.15313873\n",
      " 1.15219241 1.15219241 1.15124434 1.15124434 1.15124434 1.15219241\n",
      " 1.15313873 1.15313873 1.15313873 1.15313873 1.15313873 1.15502551]\n",
      "Test RMSE: 0.001\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0141 - val_loss: 0.0094\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0138 - val_loss: 0.0066\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0113 - val_loss: 0.0057\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0114 - val_loss: 0.0060\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0058\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0114 - val_loss: 0.0058\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0114 - val_loss: 0.0058\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0114 - val_loss: 0.0058\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0058\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0114 - val_loss: 0.0060\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0114 - val_loss: 0.0060\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0114 - val_loss: 0.0060\n",
      "第197个数，还剩3926个没有训练\n",
      "inv_hat [1.62802055 1.60926743 1.60886859 1.60787097 1.58692231 1.5804379\n",
      " 1.57574907 1.58871784 1.5774451  1.58532608 1.61934242 1.62592586\n",
      " 1.62083867 1.59340648 1.59510227 1.57814338 1.59141124 1.59480318\n",
      " 1.61924268 1.59799528 1.58372997 1.57674675 1.55629519 1.54452276\n",
      " 1.53185192 1.53694028 1.53813756 1.53464548 1.52806068 1.53534388]\n",
      "Test RMSE: 0.015\n",
      "Train on 672 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "672/672 [==============================] - 0s 88us/sample - loss: 0.0198 - val_loss: 0.0220\n",
      "Epoch 2/50\n",
      "672/672 [==============================] - 0s 84us/sample - loss: 0.0191 - val_loss: 0.0203\n",
      "Epoch 3/50\n",
      "672/672 [==============================] - 0s 83us/sample - loss: 0.0195 - val_loss: 0.0223\n",
      "Epoch 4/50\n",
      "672/672 [==============================] - 0s 90us/sample - loss: 0.0191 - val_loss: 0.0206\n",
      "Epoch 5/50\n",
      "672/672 [==============================] - 0s 87us/sample - loss: 0.0194 - val_loss: 0.0220\n",
      "Epoch 6/50\n",
      "672/672 [==============================] - 0s 87us/sample - loss: 0.0191 - val_loss: 0.0207\n",
      "Epoch 7/50\n",
      "672/672 [==============================] - 0s 84us/sample - loss: 0.0194 - val_loss: 0.0220\n",
      "Epoch 8/50\n",
      "672/672 [==============================] - 0s 90us/sample - loss: 0.0191 - val_loss: 0.0207\n",
      "Epoch 9/50\n",
      "672/672 [==============================] - 0s 83us/sample - loss: 0.0194 - val_loss: 0.0221\n",
      "Epoch 10/50\n",
      "672/672 [==============================] - 0s 83us/sample - loss: 0.0191 - val_loss: 0.0208\n",
      "Epoch 11/50\n",
      "672/672 [==============================] - 0s 87us/sample - loss: 0.0193 - val_loss: 0.0222\n",
      "Epoch 12/50\n",
      "672/672 [==============================] - 0s 88us/sample - loss: 0.0191 - val_loss: 0.0208\n",
      "Epoch 13/50\n",
      "672/672 [==============================] - 0s 81us/sample - loss: 0.0194 - val_loss: 0.0223\n",
      "Epoch 14/50\n",
      "672/672 [==============================] - 0s 84us/sample - loss: 0.0191 - val_loss: 0.0208\n",
      "Epoch 15/50\n",
      "672/672 [==============================] - 0s 87us/sample - loss: 0.0193 - val_loss: 0.0222\n",
      "Epoch 16/50\n",
      "672/672 [==============================] - 0s 86us/sample - loss: 0.0191 - val_loss: 0.0208\n",
      "Epoch 17/50\n",
      "672/672 [==============================] - 0s 80us/sample - loss: 0.0194 - val_loss: 0.0225\n",
      "Epoch 18/50\n",
      "672/672 [==============================] - 0s 82us/sample - loss: 0.0191 - val_loss: 0.0209\n",
      "Epoch 19/50\n",
      "672/672 [==============================] - 0s 90us/sample - loss: 0.0193 - val_loss: 0.0223\n",
      "Epoch 20/50\n",
      "672/672 [==============================] - 0s 83us/sample - loss: 0.0190 - val_loss: 0.0208\n",
      "Epoch 21/50\n",
      "672/672 [==============================] - 0s 84us/sample - loss: 0.0193 - val_loss: 0.0225\n",
      "Epoch 22/50\n",
      "672/672 [==============================] - 0s 84us/sample - loss: 0.0191 - val_loss: 0.0210\n",
      "Epoch 23/50\n",
      "672/672 [==============================] - 0s 87us/sample - loss: 0.0192 - val_loss: 0.0223\n",
      "Epoch 24/50\n",
      "672/672 [==============================] - 0s 80us/sample - loss: 0.0191 - val_loss: 0.0211\n",
      "Epoch 25/50\n",
      "672/672 [==============================] - 0s 83us/sample - loss: 0.0192 - val_loss: 0.0223\n",
      "Epoch 26/50\n",
      "672/672 [==============================] - 0s 84us/sample - loss: 0.0191 - val_loss: 0.0212\n",
      "Epoch 27/50\n",
      "672/672 [==============================] - 0s 85us/sample - loss: 0.0192 - val_loss: 0.0223\n",
      "Epoch 28/50\n",
      "672/672 [==============================] - 0s 88us/sample - loss: 0.0191 - val_loss: 0.0213\n",
      "Epoch 29/50\n",
      "672/672 [==============================] - 0s 86us/sample - loss: 0.0192 - val_loss: 0.0222\n",
      "Epoch 30/50\n",
      "672/672 [==============================] - 0s 88us/sample - loss: 0.0191 - val_loss: 0.0213\n",
      "Epoch 31/50\n",
      "672/672 [==============================] - 0s 87us/sample - loss: 0.0192 - val_loss: 0.0223\n",
      "Epoch 32/50\n",
      "672/672 [==============================] - 0s 88us/sample - loss: 0.0191 - val_loss: 0.0213\n",
      "Epoch 33/50\n",
      "672/672 [==============================] - 0s 83us/sample - loss: 0.0192 - val_loss: 0.0223\n",
      "Epoch 34/50\n",
      "672/672 [==============================] - 0s 81us/sample - loss: 0.0191 - val_loss: 0.0213\n",
      "Epoch 35/50\n",
      "672/672 [==============================] - 0s 83us/sample - loss: 0.0192 - val_loss: 0.0223\n",
      "Epoch 36/50\n",
      "672/672 [==============================] - 0s 85us/sample - loss: 0.0191 - val_loss: 0.0213\n",
      "Epoch 37/50\n",
      "672/672 [==============================] - 0s 80us/sample - loss: 0.0192 - val_loss: 0.0223\n",
      "Epoch 38/50\n",
      "672/672 [==============================] - 0s 79us/sample - loss: 0.0191 - val_loss: 0.0212\n",
      "Epoch 39/50\n",
      "672/672 [==============================] - 0s 82us/sample - loss: 0.0192 - val_loss: 0.0222\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672/672 [==============================] - 0s 87us/sample - loss: 0.0191 - val_loss: 0.0212\n",
      "Epoch 41/50\n",
      "672/672 [==============================] - 0s 86us/sample - loss: 0.0192 - val_loss: 0.0223\n",
      "Epoch 42/50\n",
      "672/672 [==============================] - 0s 89us/sample - loss: 0.0191 - val_loss: 0.0212\n",
      "Epoch 43/50\n",
      "672/672 [==============================] - 0s 91us/sample - loss: 0.0192 - val_loss: 0.0222\n",
      "Epoch 44/50\n",
      "672/672 [==============================] - 0s 87us/sample - loss: 0.0191 - val_loss: 0.0212\n",
      "Epoch 45/50\n",
      "672/672 [==============================] - 0s 86us/sample - loss: 0.0192 - val_loss: 0.0223\n",
      "Epoch 46/50\n",
      "672/672 [==============================] - 0s 83us/sample - loss: 0.0191 - val_loss: 0.0212\n",
      "Epoch 47/50\n",
      "672/672 [==============================] - 0s 81us/sample - loss: 0.0192 - val_loss: 0.0222\n",
      "Epoch 48/50\n",
      "672/672 [==============================] - 0s 82us/sample - loss: 0.0191 - val_loss: 0.0212\n",
      "Epoch 49/50\n",
      "672/672 [==============================] - 0s 84us/sample - loss: 0.0192 - val_loss: 0.0222\n",
      "Epoch 50/50\n",
      "672/672 [==============================] - 0s 84us/sample - loss: 0.0191 - val_loss: 0.0212\n",
      "第198个数，还剩3925个没有训练\n",
      "inv_hat [1.14712077 1.11337609 1.12329052 1.12031512 1.089634   1.09160918\n",
      " 1.106443   1.14612717 1.12924385 1.14612717 1.1718349  1.16697445\n",
      " 1.18842167 1.18353391 1.18451079 1.16794594 1.16891771 1.18353391\n",
      " 1.19233708 1.16988974 1.15308398 1.15208995 1.12725906 1.13619333\n",
      " 1.13122901 1.15109608 1.14513344 1.12924385 1.12229861 1.12229861]\n",
      "Test RMSE: 0.017\n",
      "Train on 587 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "587/587 [==============================] - 0s 92us/sample - loss: 0.0103 - val_loss: 0.0119\n",
      "Epoch 2/50\n",
      "587/587 [==============================] - 0s 90us/sample - loss: 0.0107 - val_loss: 0.0096\n",
      "Epoch 3/50\n",
      "587/587 [==============================] - 0s 91us/sample - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 4/50\n",
      "587/587 [==============================] - 0s 85us/sample - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 5/50\n",
      "587/587 [==============================] - 0s 92us/sample - loss: 0.0098 - val_loss: 0.0097\n",
      "Epoch 6/50\n",
      "587/587 [==============================] - 0s 89us/sample - loss: 0.0098 - val_loss: 0.0126\n",
      "Epoch 7/50\n",
      "587/587 [==============================] - 0s 90us/sample - loss: 0.0103 - val_loss: 0.0118\n",
      "Epoch 8/50\n",
      "587/587 [==============================] - 0s 90us/sample - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 9/50\n",
      "587/587 [==============================] - 0s 87us/sample - loss: 0.0107 - val_loss: 0.0092\n",
      "Epoch 10/50\n",
      "587/587 [==============================] - 0s 90us/sample - loss: 0.0106 - val_loss: 0.0123\n",
      "Epoch 11/50\n",
      "587/587 [==============================] - 0s 92us/sample - loss: 0.0117 - val_loss: 0.0104\n",
      "Epoch 12/50\n",
      "587/587 [==============================] - 0s 96us/sample - loss: 0.0099 - val_loss: 0.0094\n",
      "Epoch 13/50\n",
      "587/587 [==============================] - 0s 93us/sample - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 14/50\n",
      "587/587 [==============================] - 0s 87us/sample - loss: 0.0093 - val_loss: 0.0099\n",
      "Epoch 15/50\n",
      "587/587 [==============================] - 0s 91us/sample - loss: 0.0100 - val_loss: 0.0128\n",
      "Epoch 16/50\n",
      "587/587 [==============================] - 0s 89us/sample - loss: 0.0101 - val_loss: 0.0115\n",
      "Epoch 17/50\n",
      "587/587 [==============================] - 0s 89us/sample - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 18/50\n",
      "587/587 [==============================] - 0s 89us/sample - loss: 0.0117 - val_loss: 0.0126\n",
      "Epoch 19/50\n",
      "587/587 [==============================] - 0s 87us/sample - loss: 0.0094 - val_loss: 0.0104\n",
      "Epoch 20/50\n",
      "587/587 [==============================] - 0s 85us/sample - loss: 0.0098 - val_loss: 0.0095\n",
      "Epoch 21/50\n",
      "587/587 [==============================] - 0s 84us/sample - loss: 0.0096 - val_loss: 0.0112\n",
      "Epoch 22/50\n",
      "587/587 [==============================] - 0s 84us/sample - loss: 0.0108 - val_loss: 0.0098\n",
      "Epoch 23/50\n",
      "587/587 [==============================] - 0s 85us/sample - loss: 0.0095 - val_loss: 0.0105\n",
      "Epoch 24/50\n",
      "587/587 [==============================] - 0s 90us/sample - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 25/50\n",
      "587/587 [==============================] - 0s 88us/sample - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 26/50\n",
      "587/587 [==============================] - 0s 86us/sample - loss: 0.0097 - val_loss: 0.0130\n",
      "Epoch 27/50\n",
      "587/587 [==============================] - 0s 87us/sample - loss: 0.0103 - val_loss: 0.0095\n",
      "Epoch 28/50\n",
      "587/587 [==============================] - 0s 89us/sample - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 29/50\n",
      "587/587 [==============================] - 0s 90us/sample - loss: 0.0100 - val_loss: 0.0116\n",
      "Epoch 30/50\n",
      "587/587 [==============================] - 0s 95us/sample - loss: 0.0094 - val_loss: 0.0106\n",
      "Epoch 31/50\n",
      "587/587 [==============================] - 0s 88us/sample - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 32/50\n",
      "587/587 [==============================] - 0s 92us/sample - loss: 0.0098 - val_loss: 0.0112\n",
      "Epoch 33/50\n",
      "587/587 [==============================] - 0s 98us/sample - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 34/50\n",
      "587/587 [==============================] - 0s 95us/sample - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 35/50\n",
      "587/587 [==============================] - 0s 89us/sample - loss: 0.0099 - val_loss: 0.0094\n",
      "Epoch 36/50\n",
      "587/587 [==============================] - 0s 90us/sample - loss: 0.0105 - val_loss: 0.0130\n",
      "Epoch 37/50\n",
      "587/587 [==============================] - 0s 92us/sample - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 38/50\n",
      "587/587 [==============================] - 0s 89us/sample - loss: 0.0104 - val_loss: 0.0096\n",
      "Epoch 39/50\n",
      "587/587 [==============================] - 0s 90us/sample - loss: 0.0104 - val_loss: 0.0120\n",
      "Epoch 40/50\n",
      "587/587 [==============================] - 0s 85us/sample - loss: 0.0103 - val_loss: 0.0118\n",
      "Epoch 41/50\n",
      "587/587 [==============================] - 0s 90us/sample - loss: 0.0098 - val_loss: 0.0090\n",
      "Epoch 42/50\n",
      "587/587 [==============================] - 0s 86us/sample - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 43/50\n",
      "587/587 [==============================] - 0s 86us/sample - loss: 0.0097 - val_loss: 0.0121\n",
      "Epoch 44/50\n",
      "587/587 [==============================] - 0s 86us/sample - loss: 0.0101 - val_loss: 0.0095\n",
      "Epoch 45/50\n",
      "587/587 [==============================] - 0s 88us/sample - loss: 0.0092 - val_loss: 0.0090\n",
      "Epoch 46/50\n",
      "587/587 [==============================] - 0s 84us/sample - loss: 0.0095 - val_loss: 0.0110\n",
      "Epoch 47/50\n",
      "587/587 [==============================] - 0s 86us/sample - loss: 0.0099 - val_loss: 0.0120\n",
      "Epoch 48/50\n",
      "587/587 [==============================] - 0s 86us/sample - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 49/50\n",
      "587/587 [==============================] - 0s 85us/sample - loss: 0.0098 - val_loss: 0.0095\n",
      "Epoch 50/50\n",
      "587/587 [==============================] - 0s 93us/sample - loss: 0.0107 - val_loss: 0.0138\n",
      "第199个数，还剩3924个没有训练\n",
      "inv_hat [1.07208736 1.07108852 1.07208736 1.07208736 1.07108852 1.07008815\n",
      " 1.07008815 1.07108852 1.07108852 1.07208736 1.07507455 1.07606689\n",
      " 1.07606689 1.07408044 1.07308475 1.07308475 1.07408044 1.07408044\n",
      " 1.07408044 1.07208736 1.07108852 1.07008815 1.06908642 1.06908642\n",
      " 1.06707938 1.06808355 1.06808355 1.06808355 1.06707938 1.06908642]\n",
      "Test RMSE: 0.002\n",
      "Train on 514 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "514/514 [==============================] - 0s 94us/sample - loss: 0.0132 - val_loss: 0.0296\n",
      "Epoch 2/50\n",
      "514/514 [==============================] - 0s 92us/sample - loss: 0.0100 - val_loss: 0.0279\n",
      "Epoch 3/50\n",
      "514/514 [==============================] - 0s 91us/sample - loss: 0.0106 - val_loss: 0.0279\n",
      "Epoch 4/50\n",
      "514/514 [==============================] - 0s 94us/sample - loss: 0.0098 - val_loss: 0.0278\n",
      "Epoch 5/50\n",
      "514/514 [==============================] - 0s 89us/sample - loss: 0.0110 - val_loss: 0.0283\n",
      "Epoch 6/50\n",
      "514/514 [==============================] - 0s 94us/sample - loss: 0.0097 - val_loss: 0.0279\n",
      "Epoch 7/50\n",
      "514/514 [==============================] - 0s 93us/sample - loss: 0.0108 - val_loss: 0.0282\n",
      "Epoch 8/50\n",
      "514/514 [==============================] - 0s 90us/sample - loss: 0.0098 - val_loss: 0.0278\n",
      "Epoch 9/50\n",
      "514/514 [==============================] - 0s 89us/sample - loss: 0.0111 - val_loss: 0.0284\n",
      "Epoch 10/50\n",
      "514/514 [==============================] - 0s 88us/sample - loss: 0.0097 - val_loss: 0.0278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "514/514 [==============================] - 0s 85us/sample - loss: 0.0103 - val_loss: 0.0280\n",
      "Epoch 12/50\n",
      "514/514 [==============================] - 0s 86us/sample - loss: 0.0096 - val_loss: 0.0278\n",
      "Epoch 13/50\n",
      "514/514 [==============================] - 0s 89us/sample - loss: 0.0107 - val_loss: 0.0283\n",
      "Epoch 14/50\n",
      "514/514 [==============================] - 0s 90us/sample - loss: 0.0095 - val_loss: 0.0278\n",
      "Epoch 15/50\n",
      "514/514 [==============================] - 0s 89us/sample - loss: 0.0105 - val_loss: 0.0282\n",
      "Epoch 16/50\n",
      "514/514 [==============================] - 0s 85us/sample - loss: 0.0095 - val_loss: 0.0278\n",
      "Epoch 17/50\n",
      "514/514 [==============================] - 0s 84us/sample - loss: 0.0100 - val_loss: 0.0279\n",
      "Epoch 18/50\n",
      "514/514 [==============================] - 0s 84us/sample - loss: 0.0099 - val_loss: 0.0279\n",
      "Epoch 19/50\n",
      "514/514 [==============================] - 0s 89us/sample - loss: 0.0094 - val_loss: 0.0279\n",
      "Epoch 20/50\n",
      "514/514 [==============================] - 0s 92us/sample - loss: 0.0095 - val_loss: 0.0280\n",
      "Epoch 21/50\n",
      "514/514 [==============================] - 0s 91us/sample - loss: 0.0095 - val_loss: 0.0279\n",
      "Epoch 22/50\n",
      "514/514 [==============================] - 0s 86us/sample - loss: 0.0103 - val_loss: 0.0281\n",
      "Epoch 23/50\n",
      "514/514 [==============================] - 0s 88us/sample - loss: 0.0094 - val_loss: 0.0279\n",
      "Epoch 24/50\n",
      "514/514 [==============================] - 0s 87us/sample - loss: 0.0100 - val_loss: 0.0279\n",
      "Epoch 25/50\n",
      "514/514 [==============================] - 0s 91us/sample - loss: 0.0098 - val_loss: 0.0279\n",
      "Epoch 26/50\n",
      "514/514 [==============================] - 0s 86us/sample - loss: 0.0098 - val_loss: 0.0279\n",
      "Epoch 27/50\n",
      "514/514 [==============================] - 0s 89us/sample - loss: 0.0095 - val_loss: 0.0279\n",
      "Epoch 28/50\n",
      "514/514 [==============================] - 0s 90us/sample - loss: 0.0100 - val_loss: 0.0281\n",
      "Epoch 29/50\n",
      "514/514 [==============================] - 0s 84us/sample - loss: 0.0094 - val_loss: 0.0279\n",
      "Epoch 30/50\n",
      "514/514 [==============================] - 0s 88us/sample - loss: 0.0101 - val_loss: 0.0281\n",
      "Epoch 31/50\n",
      "514/514 [==============================] - 0s 98us/sample - loss: 0.0096 - val_loss: 0.0279\n",
      "Epoch 32/50\n",
      "514/514 [==============================] - 0s 101us/sample - loss: 0.0098 - val_loss: 0.0280\n",
      "Epoch 33/50\n",
      "514/514 [==============================] - 0s 97us/sample - loss: 0.0098 - val_loss: 0.0280\n",
      "Epoch 34/50\n",
      "514/514 [==============================] - 0s 91us/sample - loss: 0.0096 - val_loss: 0.0280\n",
      "Epoch 35/50\n",
      "514/514 [==============================] - 0s 89us/sample - loss: 0.0098 - val_loss: 0.0280\n",
      "Epoch 36/50\n",
      "514/514 [==============================] - 0s 84us/sample - loss: 0.0098 - val_loss: 0.0280\n",
      "Epoch 37/50\n",
      "514/514 [==============================] - 0s 89us/sample - loss: 0.0097 - val_loss: 0.0280\n",
      "Epoch 38/50\n",
      "514/514 [==============================] - 0s 85us/sample - loss: 0.0096 - val_loss: 0.0280\n",
      "Epoch 39/50\n",
      "514/514 [==============================] - 0s 85us/sample - loss: 0.0098 - val_loss: 0.0280\n",
      "Epoch 40/50\n",
      "514/514 [==============================] - 0s 87us/sample - loss: 0.0097 - val_loss: 0.0280\n",
      "Epoch 41/50\n",
      "514/514 [==============================] - 0s 91us/sample - loss: 0.0097 - val_loss: 0.0280\n",
      "Epoch 42/50\n",
      "514/514 [==============================] - 0s 90us/sample - loss: 0.0097 - val_loss: 0.0280\n",
      "Epoch 43/50\n",
      "514/514 [==============================] - 0s 90us/sample - loss: 0.0097 - val_loss: 0.0282\n",
      "Epoch 44/50\n",
      "514/514 [==============================] - 0s 89us/sample - loss: 0.0096 - val_loss: 0.0280\n",
      "Epoch 45/50\n",
      "514/514 [==============================] - 0s 88us/sample - loss: 0.0099 - val_loss: 0.0280\n",
      "Epoch 46/50\n",
      "514/514 [==============================] - 0s 91us/sample - loss: 0.0102 - val_loss: 0.0284\n",
      "Epoch 47/50\n",
      "514/514 [==============================] - 0s 90us/sample - loss: 0.0097 - val_loss: 0.0279\n",
      "Epoch 48/50\n",
      "514/514 [==============================] - 0s 100us/sample - loss: 0.0103 - val_loss: 0.0282\n",
      "Epoch 49/50\n",
      "514/514 [==============================] - 0s 89us/sample - loss: 0.0096 - val_loss: 0.0281\n",
      "Epoch 50/50\n",
      "514/514 [==============================] - 0s 88us/sample - loss: 0.0095 - val_loss: 0.0281\n",
      "第200个数，还剩3923个没有训练\n",
      "inv_hat [1.077634   1.07724384 1.07724384 1.07656049 1.07724384 1.08016529\n",
      " 1.0791928  1.08162132 1.08249324 1.07948472 1.07773154 1.07391929\n",
      " 1.06969733 1.06792524 1.07665816 1.07362528 1.07616978 1.0839438\n",
      " 1.08307398 1.07205585 1.07068062 1.07499629 1.08045669 1.0791928\n",
      " 1.08471597 1.08923028 1.08942141 1.09171011 1.08808136 1.09190037]\n",
      "Test RMSE: 0.004\n",
      "Train on 904 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "904/904 [==============================] - 0s 80us/sample - loss: 0.0056 - val_loss: 6.9532e-04\n",
      "Epoch 2/50\n",
      "904/904 [==============================] - 0s 77us/sample - loss: 0.0100 - val_loss: 0.0032\n",
      "Epoch 3/50\n",
      "904/904 [==============================] - 0s 77us/sample - loss: 0.0181 - val_loss: 0.0178\n",
      "Epoch 4/50\n",
      "904/904 [==============================] - 0s 76us/sample - loss: 0.0137 - val_loss: 0.0057\n",
      "Epoch 5/50\n",
      "904/904 [==============================] - 0s 77us/sample - loss: 0.0195 - val_loss: 0.0102\n",
      "Epoch 6/50\n",
      "904/904 [==============================] - 0s 80us/sample - loss: 0.0101 - val_loss: 0.0014\n",
      "Epoch 7/50\n",
      "904/904 [==============================] - 0s 76us/sample - loss: 0.0142 - val_loss: 0.0117\n",
      "Epoch 8/50\n",
      "904/904 [==============================] - 0s 80us/sample - loss: 0.0128 - val_loss: 0.0055\n",
      "Epoch 9/50\n",
      "904/904 [==============================] - 0s 77us/sample - loss: 0.0168 - val_loss: 0.0101\n",
      "Epoch 10/50\n",
      "904/904 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0045\n",
      "Epoch 11/50\n",
      "904/904 [==============================] - 0s 80us/sample - loss: 0.0155 - val_loss: 0.0100\n",
      "Epoch 12/50\n",
      "904/904 [==============================] - 0s 85us/sample - loss: 0.0119 - val_loss: 0.0049\n",
      "Epoch 13/50\n",
      "904/904 [==============================] - 0s 82us/sample - loss: 0.0151 - val_loss: 0.0087\n",
      "Epoch 14/50\n",
      "904/904 [==============================] - 0s 82us/sample - loss: 0.0109 - val_loss: 0.0044\n",
      "Epoch 15/50\n",
      "904/904 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0087\n",
      "Epoch 16/50\n",
      "904/904 [==============================] - 0s 80us/sample - loss: 0.0113 - val_loss: 0.0048\n",
      "Epoch 17/50\n",
      "904/904 [==============================] - 0s 81us/sample - loss: 0.0138 - val_loss: 0.0077\n",
      "Epoch 18/50\n",
      "904/904 [==============================] - 0s 87us/sample - loss: 0.0105 - val_loss: 0.0037\n",
      "Epoch 19/50\n",
      "904/904 [==============================] - 0s 86us/sample - loss: 0.0135 - val_loss: 0.0091\n",
      "Epoch 20/50\n",
      "904/904 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0039\n",
      "Epoch 21/50\n",
      "904/904 [==============================] - 0s 81us/sample - loss: 0.0134 - val_loss: 0.0077\n",
      "Epoch 22/50\n",
      "904/904 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0038\n",
      "Epoch 23/50\n",
      "904/904 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0079\n",
      "Epoch 24/50\n",
      "904/904 [==============================] - 0s 85us/sample - loss: 0.0106 - val_loss: 0.0042\n",
      "Epoch 25/50\n",
      "904/904 [==============================] - 0s 82us/sample - loss: 0.0128 - val_loss: 0.0070\n",
      "Epoch 26/50\n",
      "904/904 [==============================] - 0s 85us/sample - loss: 0.0098 - val_loss: 0.0037\n",
      "Epoch 27/50\n",
      "904/904 [==============================] - 0s 84us/sample - loss: 0.0123 - val_loss: 0.0074\n",
      "Epoch 28/50\n",
      "904/904 [==============================] - 0s 83us/sample - loss: 0.0103 - val_loss: 0.0039\n",
      "Epoch 29/50\n",
      "904/904 [==============================] - 0s 83us/sample - loss: 0.0123 - val_loss: 0.0068\n",
      "Epoch 30/50\n",
      "904/904 [==============================] - 0s 82us/sample - loss: 0.0096 - val_loss: 0.0034\n",
      "Epoch 31/50\n",
      "904/904 [==============================] - 0s 88us/sample - loss: 0.0119 - val_loss: 0.0071\n",
      "Epoch 32/50\n",
      "904/904 [==============================] - 0s 84us/sample - loss: 0.0099 - val_loss: 0.0036\n",
      "Epoch 33/50\n",
      "904/904 [==============================] - 0s 81us/sample - loss: 0.0119 - val_loss: 0.0068\n",
      "Epoch 34/50\n",
      "904/904 [==============================] - 0s 79us/sample - loss: 0.0095 - val_loss: 0.0032\n",
      "Epoch 35/50\n",
      "904/904 [==============================] - 0s 78us/sample - loss: 0.0116 - val_loss: 0.0070\n",
      "Epoch 36/50\n",
      "904/904 [==============================] - 0s 80us/sample - loss: 0.0097 - val_loss: 0.0033\n",
      "Epoch 37/50\n",
      "904/904 [==============================] - 0s 84us/sample - loss: 0.0116 - val_loss: 0.0066\n",
      "Epoch 38/50\n",
      "904/904 [==============================] - 0s 88us/sample - loss: 0.0092 - val_loss: 0.0030\n",
      "Epoch 39/50\n",
      "904/904 [==============================] - 0s 80us/sample - loss: 0.0113 - val_loss: 0.0069\n",
      "Epoch 40/50\n",
      "904/904 [==============================] - 0s 80us/sample - loss: 0.0096 - val_loss: 0.0033\n",
      "Epoch 41/50\n",
      "904/904 [==============================] - 0s 82us/sample - loss: 0.0115 - val_loss: 0.0063\n",
      "Epoch 42/50\n",
      "904/904 [==============================] - 0s 84us/sample - loss: 0.0090 - val_loss: 0.0031\n",
      "Epoch 43/50\n",
      "904/904 [==============================] - 0s 82us/sample - loss: 0.0112 - val_loss: 0.0065\n",
      "Epoch 44/50\n",
      "904/904 [==============================] - 0s 83us/sample - loss: 0.0094 - val_loss: 0.0033\n",
      "Epoch 45/50\n",
      "904/904 [==============================] - 0s 89us/sample - loss: 0.0111 - val_loss: 0.0061\n",
      "Epoch 46/50\n",
      "904/904 [==============================] - 0s 84us/sample - loss: 0.0091 - val_loss: 0.0031\n",
      "Epoch 47/50\n",
      "904/904 [==============================] - 0s 81us/sample - loss: 0.0106 - val_loss: 0.0055\n",
      "Epoch 48/50\n",
      "904/904 [==============================] - 0s 82us/sample - loss: 0.0091 - val_loss: 0.0035\n",
      "Epoch 49/50\n",
      "904/904 [==============================] - 0s 80us/sample - loss: 0.0106 - val_loss: 0.0057\n",
      "Epoch 50/50\n",
      "904/904 [==============================] - 0s 79us/sample - loss: 0.0094 - val_loss: 0.0034\n",
      "第201个数，还剩3922个没有训练\n",
      "inv_hat [0.99901889 0.99901889 0.99901889 0.99911757 0.99921613 1.00010417\n",
      " 1.00010417 1.00010417 1.00020286 1.00000548 1.00010417 1.00020286\n",
      " 1.00030155 1.00030155 1.00030155 1.00020286 1.00030155 1.00030155\n",
      " 1.00020286 1.00020286 1.00040024 1.00040024 1.00069619 1.00138693\n",
      " 1.00128835 1.00168302 1.00158433 1.00158433 1.00178172 1.0020777 ]\n",
      "Test RMSE: 0.001\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0116 - val_loss: 0.0125\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0121 - val_loss: 0.0103\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0114 - val_loss: 0.0084\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0112 - val_loss: 0.0081\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 87us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0111 - val_loss: 0.0080\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0080\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0080\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0111 - val_loss: 0.0080\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 87us/sample - loss: 0.0111 - val_loss: 0.0080\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0080\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0111 - val_loss: 0.0080\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0080\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "第202个数，还剩3921个没有训练\n",
      "inv_hat [1.10126142 1.07190652 1.07538711 1.0734976  1.04328985 1.04051007\n",
      " 1.04209849 1.05799027 1.03892189 1.05043989 1.08334508 1.08443959\n",
      " 1.08075844 1.05540686 1.0553076  1.04110568 1.04785766 1.05063859\n",
      " 1.06564297 1.04398487 1.03921961 1.03058581 1.01699905 1.01779214\n",
      " 1.00570204 1.01243969 1.00490956 0.99966053 0.99104824 0.99421541]\n",
      "Test RMSE: 0.014\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0109 - val_loss: 0.0090\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0094\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0094\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0109 - val_loss: 0.0090\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0094\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0110 - val_loss: 0.0093\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0091\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0095\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0091\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0091\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0109 - val_loss: 0.0091\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0108 - val_loss: 0.0091\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0094\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0094\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0094\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0109 - val_loss: 0.0094\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0094\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0109 - val_loss: 0.0093\n",
      "第203个数，还剩3920个没有训练\n",
      "inv_hat [1.32921802 1.30101407 1.30220596 1.29733874 1.27061181 1.26763044\n",
      " 1.26693472 1.28114512 1.26484751 1.27776672 1.31650766 1.31918892\n",
      " 1.31472011 1.27717052 1.27220189 1.26077227 1.26733221 1.26782907\n",
      " 1.28631161 1.26375414 1.25739256 1.24745096 1.23024635 1.2245763\n",
      " 1.21154207 1.22348193 1.21681601 1.21024838 1.20268434 1.2087556 ]\n",
      "Test RMSE: 0.016\n",
      "Train on 537 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "537/537 [==============================] - 0s 86us/sample - loss: 0.0082 - val_loss: 0.0047\n",
      "Epoch 2/50\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.0146 - val_loss: 0.0181\n",
      "Epoch 3/50\n",
      "537/537 [==============================] - 0s 86us/sample - loss: 0.0149 - val_loss: 0.0041\n",
      "Epoch 4/50\n",
      "537/537 [==============================] - 0s 89us/sample - loss: 0.0071 - val_loss: 0.0014\n",
      "Epoch 5/50\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.0143 - val_loss: 0.0096\n",
      "Epoch 6/50\n",
      "537/537 [==============================] - 0s 88us/sample - loss: 0.0075 - val_loss: 0.0013\n",
      "Epoch 7/50\n",
      "537/537 [==============================] - 0s 86us/sample - loss: 0.0075 - val_loss: 0.0029\n",
      "Epoch 8/50\n",
      "537/537 [==============================] - 0s 88us/sample - loss: 0.0183 - val_loss: 0.0057\n",
      "Epoch 9/50\n",
      "537/537 [==============================] - 0s 89us/sample - loss: 0.0129 - val_loss: 0.0020\n",
      "Epoch 10/50\n",
      "537/537 [==============================] - 0s 88us/sample - loss: 0.0108 - val_loss: 0.0148\n",
      "Epoch 11/50\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.0073 - val_loss: 0.0040\n",
      "Epoch 12/50\n",
      "537/537 [==============================] - 0s 83us/sample - loss: 0.0088 - val_loss: 0.0011\n",
      "Epoch 13/50\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.0115 - val_loss: 0.0015\n",
      "Epoch 14/50\n",
      "537/537 [==============================] - 0s 90us/sample - loss: 0.0131 - val_loss: 0.0058\n",
      "Epoch 15/50\n",
      "537/537 [==============================] - 0s 85us/sample - loss: 0.0097 - val_loss: 0.0088\n",
      "Epoch 16/50\n",
      "537/537 [==============================] - 0s 81us/sample - loss: 0.0087 - val_loss: 0.0040\n",
      "Epoch 17/50\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.0074 - val_loss: 0.0032\n",
      "Epoch 18/50\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.0121 - val_loss: 0.0050\n",
      "Epoch 19/50\n",
      "537/537 [==============================] - 0s 89us/sample - loss: 0.0081 - val_loss: 0.0048\n",
      "Epoch 20/50\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.0071 - val_loss: 0.0020\n",
      "Epoch 21/50\n",
      "537/537 [==============================] - 0s 88us/sample - loss: 0.0070 - val_loss: 0.0033\n",
      "Epoch 22/50\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.0135 - val_loss: 0.0045\n",
      "Epoch 23/50\n",
      "537/537 [==============================] - 0s 86us/sample - loss: 0.0110 - val_loss: 0.0038\n",
      "Epoch 24/50\n",
      "537/537 [==============================] - 0s 87us/sample - loss: 0.0091 - val_loss: 0.0109\n",
      "Epoch 25/50\n",
      "537/537 [==============================] - 0s 90us/sample - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 26/50\n",
      "537/537 [==============================] - 0s 87us/sample - loss: 0.0119 - val_loss: 0.0040\n",
      "Epoch 27/50\n",
      "537/537 [==============================] - 0s 91us/sample - loss: 0.0138 - val_loss: 0.0011\n",
      "Epoch 28/50\n",
      "537/537 [==============================] - 0s 87us/sample - loss: 0.0102 - val_loss: 0.0037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "537/537 [==============================] - 0s 86us/sample - loss: 0.0146 - val_loss: 0.0027\n",
      "Epoch 30/50\n",
      "537/537 [==============================] - 0s 83us/sample - loss: 0.0095 - val_loss: 0.0028\n",
      "Epoch 31/50\n",
      "537/537 [==============================] - 0s 83us/sample - loss: 0.0091 - val_loss: 0.0083\n",
      "Epoch 32/50\n",
      "537/537 [==============================] - 0s 81us/sample - loss: 0.0080 - val_loss: 0.0036\n",
      "Epoch 33/50\n",
      "537/537 [==============================] - 0s 85us/sample - loss: 0.0067 - val_loss: 0.0018\n",
      "Epoch 34/50\n",
      "537/537 [==============================] - 0s 79us/sample - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 35/50\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.0122 - val_loss: 0.0043\n",
      "Epoch 36/50\n",
      "537/537 [==============================] - 0s 86us/sample - loss: 0.0078 - val_loss: 0.0071\n",
      "Epoch 37/50\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.0067 - val_loss: 0.0030\n",
      "Epoch 38/50\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.0107 - val_loss: 0.0052\n",
      "Epoch 39/50\n",
      "537/537 [==============================] - 0s 85us/sample - loss: 0.0137 - val_loss: 0.0030\n",
      "Epoch 40/50\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.0130 - val_loss: 0.0056\n",
      "Epoch 41/50\n",
      "537/537 [==============================] - 0s 85us/sample - loss: 0.0079 - val_loss: 0.0011\n",
      "Epoch 42/50\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 43/50\n",
      "537/537 [==============================] - 0s 90us/sample - loss: 0.0085 - val_loss: 0.0049\n",
      "Epoch 44/50\n",
      "537/537 [==============================] - 0s 83us/sample - loss: 0.0090 - val_loss: 0.0033\n",
      "Epoch 45/50\n",
      "537/537 [==============================] - 0s 92us/sample - loss: 0.0163 - val_loss: 0.0026\n",
      "Epoch 46/50\n",
      "537/537 [==============================] - 0s 86us/sample - loss: 0.0123 - val_loss: 0.0096\n",
      "Epoch 47/50\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.0098 - val_loss: 0.0011\n",
      "Epoch 48/50\n",
      "537/537 [==============================] - 0s 87us/sample - loss: 0.0076 - val_loss: 0.0015\n",
      "Epoch 49/50\n",
      "537/537 [==============================] - 0s 89us/sample - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 50/50\n",
      "537/537 [==============================] - 0s 85us/sample - loss: 0.0078 - val_loss: 0.0031\n",
      "第204个数，还剩3919个没有训练\n",
      "inv_hat [1.0498969  1.0498969  1.0498969  1.0498969  1.0498969  1.0498969\n",
      " 1.0498969  1.0498969  1.0498969  1.0498969  1.0498969  1.0498969\n",
      " 1.0498969  1.0498969  1.0498969  1.0498969  1.0498969  1.0498969\n",
      " 1.05084015 1.05084015 1.05084015 1.05084015 1.05084015 1.05084015\n",
      " 1.05084015 1.05084015 1.05084015 1.05084015 1.05084015 1.05084015]\n",
      "Test RMSE: 0.000\n",
      "Train on 770 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "770/770 [==============================] - 0s 85us/sample - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 2/50\n",
      "770/770 [==============================] - 0s 81us/sample - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 3/50\n",
      "770/770 [==============================] - 0s 80us/sample - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 4/50\n",
      "770/770 [==============================] - 0s 77us/sample - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 5/50\n",
      "770/770 [==============================] - 0s 79us/sample - loss: 0.0050 - val_loss: 0.0030\n",
      "Epoch 6/50\n",
      "770/770 [==============================] - 0s 81us/sample - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 7/50\n",
      "770/770 [==============================] - 0s 79us/sample - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 8/50\n",
      "770/770 [==============================] - 0s 79us/sample - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 9/50\n",
      "770/770 [==============================] - 0s 76us/sample - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 10/50\n",
      "770/770 [==============================] - 0s 77us/sample - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 11/50\n",
      "770/770 [==============================] - 0s 83us/sample - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 12/50\n",
      "770/770 [==============================] - 0s 87us/sample - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 13/50\n",
      "770/770 [==============================] - 0s 79us/sample - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 14/50\n",
      "770/770 [==============================] - 0s 80us/sample - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 15/50\n",
      "770/770 [==============================] - 0s 75us/sample - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 16/50\n",
      "770/770 [==============================] - 0s 77us/sample - loss: 0.0059 - val_loss: 0.0037\n",
      "Epoch 17/50\n",
      "770/770 [==============================] - 0s 78us/sample - loss: 0.0038 - val_loss: 0.0065\n",
      "Epoch 18/50\n",
      "770/770 [==============================] - 0s 81us/sample - loss: 0.0042 - val_loss: 0.0058\n",
      "Epoch 19/50\n",
      "770/770 [==============================] - 0s 81us/sample - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 20/50\n",
      "770/770 [==============================] - 0s 84us/sample - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 21/50\n",
      "770/770 [==============================] - 0s 88us/sample - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 22/50\n",
      "770/770 [==============================] - 0s 81us/sample - loss: 0.0058 - val_loss: 0.0029\n",
      "Epoch 23/50\n",
      "770/770 [==============================] - 0s 80us/sample - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 24/50\n",
      "770/770 [==============================] - 0s 87us/sample - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 25/50\n",
      "770/770 [==============================] - 0s 81us/sample - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 26/50\n",
      "770/770 [==============================] - 0s 88us/sample - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 27/50\n",
      "770/770 [==============================] - 0s 84us/sample - loss: 0.0038 - val_loss: 0.0054\n",
      "Epoch 28/50\n",
      "770/770 [==============================] - 0s 82us/sample - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 29/50\n",
      "770/770 [==============================] - 0s 82us/sample - loss: 0.0036 - val_loss: 0.0061\n",
      "Epoch 30/50\n",
      "770/770 [==============================] - 0s 82us/sample - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 31/50\n",
      "770/770 [==============================] - 0s 85us/sample - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 32/50\n",
      "770/770 [==============================] - 0s 79us/sample - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 33/50\n",
      "770/770 [==============================] - 0s 81us/sample - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 34/50\n",
      "770/770 [==============================] - 0s 82us/sample - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 35/50\n",
      "770/770 [==============================] - 0s 79us/sample - loss: 0.0068 - val_loss: 0.0038\n",
      "Epoch 36/50\n",
      "770/770 [==============================] - 0s 84us/sample - loss: 0.0041 - val_loss: 0.0082\n",
      "Epoch 37/50\n",
      "770/770 [==============================] - 0s 87us/sample - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 38/50\n",
      "770/770 [==============================] - 0s 82us/sample - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 39/50\n",
      "770/770 [==============================] - 0s 84us/sample - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 40/50\n",
      "770/770 [==============================] - 0s 80us/sample - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 41/50\n",
      "770/770 [==============================] - 0s 79us/sample - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 42/50\n",
      "770/770 [==============================] - 0s 81us/sample - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 43/50\n",
      "770/770 [==============================] - 0s 81us/sample - loss: 0.0040 - val_loss: 0.0056\n",
      "Epoch 44/50\n",
      "770/770 [==============================] - 0s 79us/sample - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 45/50\n",
      "770/770 [==============================] - 0s 79us/sample - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 46/50\n",
      "770/770 [==============================] - 0s 79us/sample - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 47/50\n",
      "770/770 [==============================] - 0s 78us/sample - loss: 0.0041 - val_loss: 0.0056\n",
      "Epoch 48/50\n",
      "770/770 [==============================] - 0s 84us/sample - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 49/50\n",
      "770/770 [==============================] - 0s 81us/sample - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 50/50\n",
      "770/770 [==============================] - 0s 81us/sample - loss: 0.0044 - val_loss: 0.0054\n",
      "第205个数，还剩3918个没有训练\n",
      "inv_hat [1.33338373 1.33357996 1.33433228 1.33433228 1.33433228 1.33433228\n",
      " 1.33433228 1.3352793  1.3352793  1.3352793  1.33622496 1.33716915\n",
      " 1.33716915 1.33811181 1.33811181 1.33811181 1.33905308 1.33905308\n",
      " 1.33905308 1.33837125 1.33811181 1.33716915 1.33716915 1.33811181\n",
      " 1.33811181 1.33905308 1.33811181 1.33811181 1.33905308 1.33999274]\n",
      "Test RMSE: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 629 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "629/629 [==============================] - 0s 86us/sample - loss: 0.0079 - val_loss: 0.0078\n",
      "Epoch 2/50\n",
      "629/629 [==============================] - 0s 83us/sample - loss: 0.0080 - val_loss: 0.0076\n",
      "Epoch 3/50\n",
      "629/629 [==============================] - 0s 79us/sample - loss: 0.0078 - val_loss: 0.0066\n",
      "Epoch 4/50\n",
      "629/629 [==============================] - 0s 79us/sample - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 5/50\n",
      "629/629 [==============================] - 0s 88us/sample - loss: 0.0079 - val_loss: 0.0061\n",
      "Epoch 6/50\n",
      "629/629 [==============================] - 0s 81us/sample - loss: 0.0077 - val_loss: 0.0060\n",
      "Epoch 7/50\n",
      "629/629 [==============================] - 0s 86us/sample - loss: 0.0077 - val_loss: 0.0073\n",
      "Epoch 8/50\n",
      "629/629 [==============================] - 0s 84us/sample - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 9/50\n",
      "629/629 [==============================] - 0s 84us/sample - loss: 0.0079 - val_loss: 0.0070\n",
      "Epoch 10/50\n",
      "629/629 [==============================] - 0s 82us/sample - loss: 0.0083 - val_loss: 0.0075\n",
      "Epoch 11/50\n",
      "629/629 [==============================] - 0s 79us/sample - loss: 0.0083 - val_loss: 0.0057\n",
      "Epoch 12/50\n",
      "629/629 [==============================] - 0s 82us/sample - loss: 0.0077 - val_loss: 0.0068\n",
      "Epoch 13/50\n",
      "629/629 [==============================] - 0s 83us/sample - loss: 0.0077 - val_loss: 0.0057\n",
      "Epoch 14/50\n",
      "629/629 [==============================] - 0s 82us/sample - loss: 0.0076 - val_loss: 0.0056\n",
      "Epoch 15/50\n",
      "629/629 [==============================] - 0s 83us/sample - loss: 0.0075 - val_loss: 0.0054\n",
      "Epoch 16/50\n",
      "629/629 [==============================] - 0s 87us/sample - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 17/50\n",
      "629/629 [==============================] - 0s 85us/sample - loss: 0.0077 - val_loss: 0.0078\n",
      "Epoch 18/50\n",
      "629/629 [==============================] - 0s 85us/sample - loss: 0.0080 - val_loss: 0.0056\n",
      "Epoch 19/50\n",
      "629/629 [==============================] - 0s 89us/sample - loss: 0.0080 - val_loss: 0.0086\n",
      "Epoch 20/50\n",
      "629/629 [==============================] - 0s 84us/sample - loss: 0.0097 - val_loss: 0.0072\n",
      "Epoch 21/50\n",
      "629/629 [==============================] - 0s 81us/sample - loss: 0.0092 - val_loss: 0.0085\n",
      "Epoch 22/50\n",
      "629/629 [==============================] - 0s 79us/sample - loss: 0.0091 - val_loss: 0.0075\n",
      "Epoch 23/50\n",
      "629/629 [==============================] - 0s 79us/sample - loss: 0.0088 - val_loss: 0.0064\n",
      "Epoch 24/50\n",
      "629/629 [==============================] - 0s 82us/sample - loss: 0.0082 - val_loss: 0.0090\n",
      "Epoch 25/50\n",
      "629/629 [==============================] - 0s 81us/sample - loss: 0.0094 - val_loss: 0.0063\n",
      "Epoch 26/50\n",
      "629/629 [==============================] - 0s 81us/sample - loss: 0.0076 - val_loss: 0.0061\n",
      "Epoch 27/50\n",
      "629/629 [==============================] - 0s 79us/sample - loss: 0.0074 - val_loss: 0.0054\n",
      "Epoch 28/50\n",
      "629/629 [==============================] - 0s 80us/sample - loss: 0.0075 - val_loss: 0.0055\n",
      "Epoch 29/50\n",
      "629/629 [==============================] - 0s 84us/sample - loss: 0.0079 - val_loss: 0.0065\n",
      "Epoch 30/50\n",
      "629/629 [==============================] - 0s 82us/sample - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 31/50\n",
      "629/629 [==============================] - 0s 84us/sample - loss: 0.0086 - val_loss: 0.0076\n",
      "Epoch 32/50\n",
      "629/629 [==============================] - 0s 86us/sample - loss: 0.0082 - val_loss: 0.0110\n",
      "Epoch 33/50\n",
      "629/629 [==============================] - 0s 80us/sample - loss: 0.0099 - val_loss: 0.0068\n",
      "Epoch 34/50\n",
      "629/629 [==============================] - 0s 83us/sample - loss: 0.0091 - val_loss: 0.0059\n",
      "Epoch 35/50\n",
      "629/629 [==============================] - 0s 82us/sample - loss: 0.0095 - val_loss: 0.0094\n",
      "Epoch 36/50\n",
      "629/629 [==============================] - 0s 83us/sample - loss: 0.0091 - val_loss: 0.0070\n",
      "Epoch 37/50\n",
      "629/629 [==============================] - 0s 83us/sample - loss: 0.0089 - val_loss: 0.0065\n",
      "Epoch 38/50\n",
      "629/629 [==============================] - 0s 85us/sample - loss: 0.0094 - val_loss: 0.0097\n",
      "Epoch 39/50\n",
      "629/629 [==============================] - 0s 84us/sample - loss: 0.0089 - val_loss: 0.0061\n",
      "Epoch 40/50\n",
      "629/629 [==============================] - 0s 81us/sample - loss: 0.0083 - val_loss: 0.0073\n",
      "Epoch 41/50\n",
      "629/629 [==============================] - 0s 81us/sample - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 42/50\n",
      "629/629 [==============================] - 0s 81us/sample - loss: 0.0077 - val_loss: 0.0087\n",
      "Epoch 43/50\n",
      "629/629 [==============================] - 0s 83us/sample - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 44/50\n",
      "629/629 [==============================] - 0s 82us/sample - loss: 0.0077 - val_loss: 0.0054\n",
      "Epoch 45/50\n",
      "629/629 [==============================] - 0s 84us/sample - loss: 0.0077 - val_loss: 0.0065\n",
      "Epoch 46/50\n",
      "629/629 [==============================] - 0s 80us/sample - loss: 0.0083 - val_loss: 0.0071\n",
      "Epoch 47/50\n",
      "629/629 [==============================] - 0s 76us/sample - loss: 0.0087 - val_loss: 0.0077\n",
      "Epoch 48/50\n",
      "629/629 [==============================] - 0s 76us/sample - loss: 0.0089 - val_loss: 0.0082\n",
      "Epoch 49/50\n",
      "629/629 [==============================] - 0s 78us/sample - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 50/50\n",
      "629/629 [==============================] - 0s 85us/sample - loss: 0.0087 - val_loss: 0.0082\n",
      "第206个数，还剩3917个没有训练\n",
      "inv_hat [1.01443364 1.01443364 1.01443364 1.01542968 1.01542968 1.01542968\n",
      " 1.01542968 1.01443364 1.01542968 1.01542968 1.01542968 1.01542968\n",
      " 1.01642727 1.01642727 1.01642727 1.017426   1.017426   1.017426\n",
      " 1.017426   1.01642727 1.01642727 1.01642727 1.01542968 1.01642727\n",
      " 1.017426   1.017426   1.017426   1.017426   1.017426   1.01842595]\n",
      "Test RMSE: 0.001\n",
      "Train on 1184 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1184/1184 [==============================] - 0s 83us/sample - loss: 0.0110 - val_loss: 0.0314\n",
      "Epoch 2/50\n",
      "1184/1184 [==============================] - 0s 78us/sample - loss: 0.0078 - val_loss: 0.0309\n",
      "Epoch 3/50\n",
      "1184/1184 [==============================] - 0s 81us/sample - loss: 0.0076 - val_loss: 0.0301\n",
      "Epoch 4/50\n",
      "1184/1184 [==============================] - 0s 79us/sample - loss: 0.0076 - val_loss: 0.0304\n",
      "Epoch 5/50\n",
      "1184/1184 [==============================] - 0s 77us/sample - loss: 0.0073 - val_loss: 0.0297\n",
      "Epoch 6/50\n",
      "1184/1184 [==============================] - 0s 78us/sample - loss: 0.0077 - val_loss: 0.0304\n",
      "Epoch 7/50\n",
      "1184/1184 [==============================] - 0s 78us/sample - loss: 0.0073 - val_loss: 0.0297\n",
      "Epoch 8/50\n",
      "1184/1184 [==============================] - 0s 79us/sample - loss: 0.0077 - val_loss: 0.0315\n",
      "Epoch 9/50\n",
      "1184/1184 [==============================] - 0s 76us/sample - loss: 0.0075 - val_loss: 0.0307\n",
      "Epoch 10/50\n",
      "1184/1184 [==============================] - 0s 81us/sample - loss: 0.0072 - val_loss: 0.0307\n",
      "Epoch 11/50\n",
      "1184/1184 [==============================] - 0s 82us/sample - loss: 0.0072 - val_loss: 0.0306\n",
      "Epoch 12/50\n",
      "1184/1184 [==============================] - 0s 79us/sample - loss: 0.0072 - val_loss: 0.0309\n",
      "Epoch 13/50\n",
      "1184/1184 [==============================] - 0s 77us/sample - loss: 0.0073 - val_loss: 0.0304\n",
      "Epoch 14/50\n",
      "1184/1184 [==============================] - 0s 80us/sample - loss: 0.0071 - val_loss: 0.0303\n",
      "Epoch 15/50\n",
      "1184/1184 [==============================] - 0s 80us/sample - loss: 0.0072 - val_loss: 0.0299\n",
      "Epoch 16/50\n",
      "1184/1184 [==============================] - 0s 79us/sample - loss: 0.0072 - val_loss: 0.0298\n",
      "Epoch 17/50\n",
      "1184/1184 [==============================] - 0s 79us/sample - loss: 0.0072 - val_loss: 0.0296\n",
      "Epoch 18/50\n",
      "1184/1184 [==============================] - 0s 80us/sample - loss: 0.0075 - val_loss: 0.0301\n",
      "Epoch 19/50\n",
      "1184/1184 [==============================] - 0s 86us/sample - loss: 0.0072 - val_loss: 0.0297\n",
      "Epoch 20/50\n",
      "1184/1184 [==============================] - 0s 82us/sample - loss: 0.0078 - val_loss: 0.0322\n",
      "Epoch 21/50\n",
      "1184/1184 [==============================] - 0s 79us/sample - loss: 0.0079 - val_loss: 0.0301\n",
      "Epoch 22/50\n",
      "1184/1184 [==============================] - 0s 80us/sample - loss: 0.0072 - val_loss: 0.0297\n",
      "Epoch 23/50\n",
      "1184/1184 [==============================] - 0s 85us/sample - loss: 0.0075 - val_loss: 0.0298\n",
      "Epoch 24/50\n",
      "1184/1184 [==============================] - 0s 82us/sample - loss: 0.0076 - val_loss: 0.0299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "1184/1184 [==============================] - 0s 83us/sample - loss: 0.0071 - val_loss: 0.0297\n",
      "Epoch 26/50\n",
      "1184/1184 [==============================] - 0s 76us/sample - loss: 0.0073 - val_loss: 0.0300\n",
      "Epoch 27/50\n",
      "1184/1184 [==============================] - 0s 76us/sample - loss: 0.0076 - val_loss: 0.0296\n",
      "Epoch 28/50\n",
      "1184/1184 [==============================] - 0s 78us/sample - loss: 0.0073 - val_loss: 0.0297\n",
      "Epoch 29/50\n",
      "1184/1184 [==============================] - 0s 77us/sample - loss: 0.0077 - val_loss: 0.0305\n",
      "Epoch 30/50\n",
      "1184/1184 [==============================] - 0s 81us/sample - loss: 0.0072 - val_loss: 0.0304\n",
      "Epoch 31/50\n",
      "1184/1184 [==============================] - 0s 76us/sample - loss: 0.0071 - val_loss: 0.0301\n",
      "Epoch 32/50\n",
      "1184/1184 [==============================] - 0s 81us/sample - loss: 0.0072 - val_loss: 0.0308\n",
      "Epoch 33/50\n",
      "1184/1184 [==============================] - 0s 81us/sample - loss: 0.0073 - val_loss: 0.0303\n",
      "Epoch 34/50\n",
      "1184/1184 [==============================] - 0s 79us/sample - loss: 0.0071 - val_loss: 0.0300\n",
      "Epoch 35/50\n",
      "1184/1184 [==============================] - 0s 80us/sample - loss: 0.0072 - val_loss: 0.0299\n",
      "Epoch 36/50\n",
      "1184/1184 [==============================] - 0s 84us/sample - loss: 0.0072 - val_loss: 0.0306\n",
      "Epoch 37/50\n",
      "1184/1184 [==============================] - 0s 80us/sample - loss: 0.0073 - val_loss: 0.0300\n",
      "Epoch 38/50\n",
      "1184/1184 [==============================] - 0s 78us/sample - loss: 0.0072 - val_loss: 0.0298\n",
      "Epoch 39/50\n",
      "1184/1184 [==============================] - 0s 77us/sample - loss: 0.0073 - val_loss: 0.0299\n",
      "Epoch 40/50\n",
      "1184/1184 [==============================] - 0s 77us/sample - loss: 0.0071 - val_loss: 0.0299\n",
      "Epoch 41/50\n",
      "1184/1184 [==============================] - 0s 78us/sample - loss: 0.0073 - val_loss: 0.0295\n",
      "Epoch 42/50\n",
      "1184/1184 [==============================] - 0s 77us/sample - loss: 0.0076 - val_loss: 0.0303\n",
      "Epoch 43/50\n",
      "1184/1184 [==============================] - 0s 79us/sample - loss: 0.0071 - val_loss: 0.0299\n",
      "Epoch 44/50\n",
      "1184/1184 [==============================] - 0s 76us/sample - loss: 0.0071 - val_loss: 0.0305\n",
      "Epoch 45/50\n",
      "1184/1184 [==============================] - 0s 77us/sample - loss: 0.0073 - val_loss: 0.0306\n",
      "Epoch 46/50\n",
      "1184/1184 [==============================] - 0s 77us/sample - loss: 0.0076 - val_loss: 0.0305\n",
      "Epoch 47/50\n",
      "1184/1184 [==============================] - 0s 78us/sample - loss: 0.0073 - val_loss: 0.0298\n",
      "Epoch 48/50\n",
      "1184/1184 [==============================] - 0s 76us/sample - loss: 0.0073 - val_loss: 0.0298\n",
      "Epoch 49/50\n",
      "1184/1184 [==============================] - 0s 77us/sample - loss: 0.0071 - val_loss: 0.0308\n",
      "Epoch 50/50\n",
      "1184/1184 [==============================] - 0s 80us/sample - loss: 0.0072 - val_loss: 0.0301\n",
      "第207个数，还剩3916个没有训练\n",
      "inv_hat [1.04407545 1.04407545 1.04407545 1.04407545 1.04407545 1.04507852\n",
      " 1.04507852 1.04507852 1.04507852 1.04507852 1.04507852 1.04607949\n",
      " 1.04607949 1.04607949 1.04607949 1.04607949 1.04607949 1.04707805\n",
      " 1.04707805 1.00004926 1.00004926 1.00104348 1.00104348 1.00104348\n",
      " 1.00104348 1.00104348 1.00104348 1.00203886 1.00203886 1.00203886]\n",
      "Test RMSE: 0.009\n",
      "Train on 799 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "799/799 [==============================] - 0s 83us/sample - loss: 0.0131 - val_loss: 0.0095\n",
      "Epoch 2/50\n",
      "799/799 [==============================] - 0s 81us/sample - loss: 0.0183 - val_loss: 0.0167\n",
      "Epoch 3/50\n",
      "799/799 [==============================] - 0s 81us/sample - loss: 0.0124 - val_loss: 0.0071\n",
      "Epoch 4/50\n",
      "799/799 [==============================] - 0s 82us/sample - loss: 0.0125 - val_loss: 0.0070\n",
      "Epoch 5/50\n",
      "799/799 [==============================] - 0s 84us/sample - loss: 0.0125 - val_loss: 0.0079\n",
      "Epoch 6/50\n",
      "799/799 [==============================] - 0s 84us/sample - loss: 0.0123 - val_loss: 0.0080\n",
      "Epoch 7/50\n",
      "799/799 [==============================] - 0s 81us/sample - loss: 0.0124 - val_loss: 0.0080\n",
      "Epoch 8/50\n",
      "799/799 [==============================] - 0s 78us/sample - loss: 0.0123 - val_loss: 0.0083\n",
      "Epoch 9/50\n",
      "799/799 [==============================] - 0s 81us/sample - loss: 0.0123 - val_loss: 0.0084\n",
      "Epoch 10/50\n",
      "799/799 [==============================] - 0s 80us/sample - loss: 0.0123 - val_loss: 0.0083\n",
      "Epoch 11/50\n",
      "799/799 [==============================] - 0s 82us/sample - loss: 0.0122 - val_loss: 0.0083\n",
      "Epoch 12/50\n",
      "799/799 [==============================] - 0s 89us/sample - loss: 0.0123 - val_loss: 0.0085\n",
      "Epoch 13/50\n",
      "799/799 [==============================] - 0s 86us/sample - loss: 0.0124 - val_loss: 0.0085\n",
      "Epoch 14/50\n",
      "799/799 [==============================] - 0s 83us/sample - loss: 0.0123 - val_loss: 0.0085\n",
      "Epoch 15/50\n",
      "799/799 [==============================] - 0s 88us/sample - loss: 0.0122 - val_loss: 0.0085\n",
      "Epoch 16/50\n",
      "799/799 [==============================] - 0s 85us/sample - loss: 0.0123 - val_loss: 0.0085\n",
      "Epoch 17/50\n",
      "799/799 [==============================] - 0s 82us/sample - loss: 0.0123 - val_loss: 0.0084\n",
      "Epoch 18/50\n",
      "799/799 [==============================] - 0s 82us/sample - loss: 0.0122 - val_loss: 0.0084\n",
      "Epoch 19/50\n",
      "799/799 [==============================] - 0s 81us/sample - loss: 0.0122 - val_loss: 0.0085\n",
      "Epoch 20/50\n",
      "799/799 [==============================] - 0s 81us/sample - loss: 0.0123 - val_loss: 0.0085\n",
      "Epoch 21/50\n",
      "799/799 [==============================] - 0s 82us/sample - loss: 0.0123 - val_loss: 0.0085\n",
      "Epoch 22/50\n",
      "799/799 [==============================] - 0s 87us/sample - loss: 0.0122 - val_loss: 0.0086\n",
      "Epoch 23/50\n",
      "799/799 [==============================] - 0s 85us/sample - loss: 0.0123 - val_loss: 0.0085\n",
      "Epoch 24/50\n",
      "799/799 [==============================] - 0s 83us/sample - loss: 0.0125 - val_loss: 0.0084\n",
      "Epoch 25/50\n",
      "799/799 [==============================] - 0s 81us/sample - loss: 0.0122 - val_loss: 0.0085\n",
      "Epoch 26/50\n",
      "799/799 [==============================] - 0s 88us/sample - loss: 0.0122 - val_loss: 0.0091\n",
      "Epoch 27/50\n",
      "799/799 [==============================] - 0s 85us/sample - loss: 0.0123 - val_loss: 0.0086\n",
      "Epoch 28/50\n",
      "799/799 [==============================] - 0s 81us/sample - loss: 0.0124 - val_loss: 0.0083\n",
      "Epoch 29/50\n",
      "799/799 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0085\n",
      "Epoch 30/50\n",
      "799/799 [==============================] - 0s 81us/sample - loss: 0.0122 - val_loss: 0.0090\n",
      "Epoch 31/50\n",
      "799/799 [==============================] - 0s 80us/sample - loss: 0.0124 - val_loss: 0.0088\n",
      "Epoch 32/50\n",
      "799/799 [==============================] - 0s 84us/sample - loss: 0.0124 - val_loss: 0.0085\n",
      "Epoch 33/50\n",
      "799/799 [==============================] - 0s 84us/sample - loss: 0.0122 - val_loss: 0.0086\n",
      "Epoch 34/50\n",
      "799/799 [==============================] - 0s 86us/sample - loss: 0.0122 - val_loss: 0.0090\n",
      "Epoch 35/50\n",
      "799/799 [==============================] - ETA: 0s - loss: 0.012 - 0s 84us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 36/50\n",
      "799/799 [==============================] - 0s 89us/sample - loss: 0.0123 - val_loss: 0.0086\n",
      "Epoch 37/50\n",
      "799/799 [==============================] - 0s 88us/sample - loss: 0.0123 - val_loss: 0.0086\n",
      "Epoch 38/50\n",
      "799/799 [==============================] - 0s 85us/sample - loss: 0.0122 - val_loss: 0.0086\n",
      "Epoch 39/50\n",
      "799/799 [==============================] - 0s 86us/sample - loss: 0.0122 - val_loss: 0.0086\n",
      "Epoch 40/50\n",
      "799/799 [==============================] - 0s 88us/sample - loss: 0.0123 - val_loss: 0.0084\n",
      "Epoch 41/50\n",
      "799/799 [==============================] - 0s 86us/sample - loss: 0.0123 - val_loss: 0.0086\n",
      "Epoch 42/50\n",
      "799/799 [==============================] - 0s 85us/sample - loss: 0.0122 - val_loss: 0.0086\n",
      "Epoch 43/50\n",
      "799/799 [==============================] - 0s 85us/sample - loss: 0.0122 - val_loss: 0.0085\n",
      "Epoch 44/50\n",
      "799/799 [==============================] - 0s 83us/sample - loss: 0.0123 - val_loss: 0.0085\n",
      "Epoch 45/50\n",
      "799/799 [==============================] - 0s 83us/sample - loss: 0.0123 - val_loss: 0.0087\n",
      "Epoch 46/50\n",
      "799/799 [==============================] - 0s 85us/sample - loss: 0.0123 - val_loss: 0.0087\n",
      "Epoch 47/50\n",
      "799/799 [==============================] - 0s 84us/sample - loss: 0.0122 - val_loss: 0.0085\n",
      "Epoch 48/50\n",
      "799/799 [==============================] - 0s 84us/sample - loss: 0.0122 - val_loss: 0.0085\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799/799 [==============================] - 0s 83us/sample - loss: 0.0123 - val_loss: 0.0085\n",
      "Epoch 50/50\n",
      "799/799 [==============================] - 0s 83us/sample - loss: 0.0123 - val_loss: 0.0086\n",
      "第208个数，还剩3915个没有训练\n",
      "inv_hat [0.62107467 0.61060232 0.61440397 0.61060232 0.59924276 0.59924276\n",
      " 0.60113117 0.60680814 0.59924276 0.60302157 0.61345286 0.6153556\n",
      " 0.61345286 0.60207615 0.60018672 0.59547182 0.59924276 0.59924276\n",
      " 0.60680814 0.59735634 0.59453034 0.58889201 0.58140293 0.57953586\n",
      " 0.57394754 0.57953586 0.57953586 0.57487757 0.57301805 0.57394754]\n",
      "Test RMSE: 0.007\n",
      "Train on 832 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "832/832 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0164\n",
      "Epoch 2/50\n",
      "832/832 [==============================] - 0s 81us/sample - loss: 0.0132 - val_loss: 0.0204\n",
      "Epoch 3/50\n",
      "832/832 [==============================] - 0s 79us/sample - loss: 0.0138 - val_loss: 0.0172\n",
      "Epoch 4/50\n",
      "832/832 [==============================] - 0s 83us/sample - loss: 0.0122 - val_loss: 0.0164\n",
      "Epoch 5/50\n",
      "832/832 [==============================] - 0s 82us/sample - loss: 0.0128 - val_loss: 0.0163\n",
      "Epoch 6/50\n",
      "832/832 [==============================] - 0s 81us/sample - loss: 0.0133 - val_loss: 0.0214\n",
      "Epoch 7/50\n",
      "832/832 [==============================] - 0s 82us/sample - loss: 0.0143 - val_loss: 0.0173\n",
      "Epoch 8/50\n",
      "832/832 [==============================] - 0s 82us/sample - loss: 0.0122 - val_loss: 0.0164\n",
      "Epoch 9/50\n",
      "832/832 [==============================] - 0s 88us/sample - loss: 0.0128 - val_loss: 0.0162\n",
      "Epoch 10/50\n",
      "832/832 [==============================] - 0s 84us/sample - loss: 0.0132 - val_loss: 0.0211\n",
      "Epoch 11/50\n",
      "832/832 [==============================] - 0s 83us/sample - loss: 0.0144 - val_loss: 0.0173\n",
      "Epoch 12/50\n",
      "832/832 [==============================] - 0s 78us/sample - loss: 0.0123 - val_loss: 0.0164\n",
      "Epoch 13/50\n",
      "832/832 [==============================] - 0s 79us/sample - loss: 0.0127 - val_loss: 0.0170\n",
      "Epoch 14/50\n",
      "832/832 [==============================] - 0s 80us/sample - loss: 0.0128 - val_loss: 0.0194\n",
      "Epoch 15/50\n",
      "832/832 [==============================] - 0s 82us/sample - loss: 0.0129 - val_loss: 0.0170\n",
      "Epoch 16/50\n",
      "832/832 [==============================] - 0s 81us/sample - loss: 0.0124 - val_loss: 0.0164\n",
      "Epoch 17/50\n",
      "832/832 [==============================] - 0s 81us/sample - loss: 0.0125 - val_loss: 0.0174\n",
      "Epoch 18/50\n",
      "832/832 [==============================] - 0s 84us/sample - loss: 0.0130 - val_loss: 0.0191\n",
      "Epoch 19/50\n",
      "832/832 [==============================] - 0s 81us/sample - loss: 0.0127 - val_loss: 0.0166\n",
      "Epoch 20/50\n",
      "832/832 [==============================] - 0s 77us/sample - loss: 0.0126 - val_loss: 0.0162\n",
      "Epoch 21/50\n",
      "832/832 [==============================] - 0s 77us/sample - loss: 0.0128 - val_loss: 0.0173\n",
      "Epoch 22/50\n",
      "832/832 [==============================] - 0s 79us/sample - loss: 0.0134 - val_loss: 0.0200\n",
      "Epoch 23/50\n",
      "832/832 [==============================] - 0s 80us/sample - loss: 0.0132 - val_loss: 0.0163\n",
      "Epoch 24/50\n",
      "832/832 [==============================] - 0s 86us/sample - loss: 0.0127 - val_loss: 0.0163\n",
      "Epoch 25/50\n",
      "832/832 [==============================] - 0s 83us/sample - loss: 0.0124 - val_loss: 0.0175\n",
      "Epoch 26/50\n",
      "832/832 [==============================] - 0s 85us/sample - loss: 0.0133 - val_loss: 0.0192\n",
      "Epoch 27/50\n",
      "832/832 [==============================] - 0s 82us/sample - loss: 0.0130 - val_loss: 0.0163\n",
      "Epoch 28/50\n",
      "832/832 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0162\n",
      "Epoch 29/50\n",
      "832/832 [==============================] - 0s 81us/sample - loss: 0.0130 - val_loss: 0.0197\n",
      "Epoch 30/50\n",
      "832/832 [==============================] - 0s 83us/sample - loss: 0.0140 - val_loss: 0.0186\n",
      "Epoch 31/50\n",
      "832/832 [==============================] - 0s 82us/sample - loss: 0.0124 - val_loss: 0.0164\n",
      "Epoch 32/50\n",
      "832/832 [==============================] - 0s 77us/sample - loss: 0.0132 - val_loss: 0.0161\n",
      "Epoch 33/50\n",
      "832/832 [==============================] - 0s 81us/sample - loss: 0.0127 - val_loss: 0.0197\n",
      "Epoch 34/50\n",
      "832/832 [==============================] - 0s 86us/sample - loss: 0.0144 - val_loss: 0.0183\n",
      "Epoch 35/50\n",
      "832/832 [==============================] - 0s 78us/sample - loss: 0.0125 - val_loss: 0.0164\n",
      "Epoch 36/50\n",
      "832/832 [==============================] - 0s 77us/sample - loss: 0.0132 - val_loss: 0.0162\n",
      "Epoch 37/50\n",
      "832/832 [==============================] - 0s 81us/sample - loss: 0.0133 - val_loss: 0.0210\n",
      "Epoch 38/50\n",
      "832/832 [==============================] - 0s 86us/sample - loss: 0.0146 - val_loss: 0.0175\n",
      "Epoch 39/50\n",
      "832/832 [==============================] - 0s 80us/sample - loss: 0.0123 - val_loss: 0.0162\n",
      "Epoch 40/50\n",
      "832/832 [==============================] - 0s 78us/sample - loss: 0.0128 - val_loss: 0.0168\n",
      "Epoch 41/50\n",
      "832/832 [==============================] - 0s 79us/sample - loss: 0.0126 - val_loss: 0.0192\n",
      "Epoch 42/50\n",
      "832/832 [==============================] - 0s 75us/sample - loss: 0.0128 - val_loss: 0.0170\n",
      "Epoch 43/50\n",
      "832/832 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0162\n",
      "Epoch 44/50\n",
      "832/832 [==============================] - 0s 81us/sample - loss: 0.0125 - val_loss: 0.0171\n",
      "Epoch 45/50\n",
      "832/832 [==============================] - 0s 82us/sample - loss: 0.0131 - val_loss: 0.0196\n",
      "Epoch 46/50\n",
      "832/832 [==============================] - 0s 85us/sample - loss: 0.0131 - val_loss: 0.0163\n",
      "Epoch 47/50\n",
      "832/832 [==============================] - 0s 86us/sample - loss: 0.0127 - val_loss: 0.0162\n",
      "Epoch 48/50\n",
      "832/832 [==============================] - 0s 85us/sample - loss: 0.0123 - val_loss: 0.0175\n",
      "Epoch 49/50\n",
      "832/832 [==============================] - 0s 87us/sample - loss: 0.0130 - val_loss: 0.0190\n",
      "Epoch 50/50\n",
      "832/832 [==============================] - 0s 85us/sample - loss: 0.0126 - val_loss: 0.0165\n",
      "第209个数，还剩3914个没有训练\n",
      "inv_hat [1.1603847  1.15361041 1.15652165 1.15458208 1.14971076 1.14971076\n",
      " 1.14873285 1.151663   1.14677329 1.14775367 1.15652165 1.15748948\n",
      " 1.15458208 1.14873285 1.14480929 1.14086816 1.14284086 1.14382567\n",
      " 1.14775367 1.14185497 1.14185497 1.1388914  1.1349263  1.13194318\n",
      " 1.12795463 1.13094724 1.13094724 1.12995041 1.12695562 1.12795463]\n",
      "Test RMSE: 0.004\n",
      "Train on 825 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0186 - val_loss: 0.0059\n",
      "Epoch 2/50\n",
      "825/825 [==============================] - 0s 85us/sample - loss: 0.0183 - val_loss: 0.0056\n",
      "Epoch 3/50\n",
      "825/825 [==============================] - 0s 85us/sample - loss: 0.0182 - val_loss: 0.0057\n",
      "Epoch 4/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0182 - val_loss: 0.0056\n",
      "Epoch 5/50\n",
      "825/825 [==============================] - 0s 80us/sample - loss: 0.0182 - val_loss: 0.0055\n",
      "Epoch 6/50\n",
      "825/825 [==============================] - 0s 78us/sample - loss: 0.0182 - val_loss: 0.0055\n",
      "Epoch 7/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0181 - val_loss: 0.0059\n",
      "Epoch 8/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0183 - val_loss: 0.0055\n",
      "Epoch 9/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0183 - val_loss: 0.0057\n",
      "Epoch 10/50\n",
      "825/825 [==============================] - 0s 87us/sample - loss: 0.0181 - val_loss: 0.0058\n",
      "Epoch 11/50\n",
      "825/825 [==============================] - 0s 85us/sample - loss: 0.0182 - val_loss: 0.0054\n",
      "Epoch 12/50\n",
      "825/825 [==============================] - 0s 81us/sample - loss: 0.0183 - val_loss: 0.0058\n",
      "Epoch 13/50\n",
      "825/825 [==============================] - 0s 79us/sample - loss: 0.0182 - val_loss: 0.0058\n",
      "Epoch 14/50\n",
      "825/825 [==============================] - 0s 81us/sample - loss: 0.0183 - val_loss: 0.0054\n",
      "Epoch 15/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0183 - val_loss: 0.0061\n",
      "Epoch 16/50\n",
      "825/825 [==============================] - 0s 85us/sample - loss: 0.0182 - val_loss: 0.0054\n",
      "Epoch 17/50\n",
      "825/825 [==============================] - 0s 79us/sample - loss: 0.0182 - val_loss: 0.0057\n",
      "Epoch 18/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0182 - val_loss: 0.0059\n",
      "Epoch 19/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0183 - val_loss: 0.0054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "825/825 [==============================] - 0s 80us/sample - loss: 0.0183 - val_loss: 0.0057\n",
      "Epoch 21/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0182 - val_loss: 0.0059\n",
      "Epoch 22/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0182 - val_loss: 0.0054\n",
      "Epoch 23/50\n",
      "825/825 [==============================] - 0s 85us/sample - loss: 0.0183 - val_loss: 0.0057\n",
      "Epoch 24/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0182 - val_loss: 0.0059\n",
      "Epoch 25/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0182 - val_loss: 0.0054\n",
      "Epoch 26/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0183 - val_loss: 0.0057\n",
      "Epoch 27/50\n",
      "825/825 [==============================] - 0s 85us/sample - loss: 0.0182 - val_loss: 0.0061\n",
      "Epoch 28/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0182 - val_loss: 0.0053\n",
      "Epoch 29/50\n",
      "825/825 [==============================] - 0s 80us/sample - loss: 0.0184 - val_loss: 0.0059\n",
      "Epoch 30/50\n",
      "825/825 [==============================] - 0s 78us/sample - loss: 0.0182 - val_loss: 0.0059\n",
      "Epoch 31/50\n",
      "825/825 [==============================] - 0s 79us/sample - loss: 0.0183 - val_loss: 0.0054\n",
      "Epoch 32/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0184 - val_loss: 0.0059\n",
      "Epoch 33/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0182 - val_loss: 0.0058\n",
      "Epoch 34/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0183 - val_loss: 0.0053\n",
      "Epoch 35/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0184 - val_loss: 0.0058\n",
      "Epoch 36/50\n",
      "825/825 [==============================] - 0s 88us/sample - loss: 0.0182 - val_loss: 0.0060\n",
      "Epoch 37/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0183 - val_loss: 0.0053\n",
      "Epoch 38/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0184 - val_loss: 0.0062\n",
      "Epoch 39/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0182 - val_loss: 0.0061\n",
      "Epoch 40/50\n",
      "825/825 [==============================] - 0s 84us/sample - loss: 0.0183 - val_loss: 0.0054\n",
      "Epoch 41/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0185 - val_loss: 0.0061\n",
      "Epoch 42/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0182 - val_loss: 0.0059\n",
      "Epoch 43/50\n",
      "825/825 [==============================] - 0s 80us/sample - loss: 0.0183 - val_loss: 0.0053\n",
      "Epoch 44/50\n",
      "825/825 [==============================] - 0s 82us/sample - loss: 0.0184 - val_loss: 0.0060\n",
      "Epoch 45/50\n",
      "825/825 [==============================] - 0s 80us/sample - loss: 0.0182 - val_loss: 0.0060\n",
      "Epoch 46/50\n",
      "825/825 [==============================] - 0s 80us/sample - loss: 0.0183 - val_loss: 0.0053\n",
      "Epoch 47/50\n",
      "825/825 [==============================] - 0s 83us/sample - loss: 0.0185 - val_loss: 0.0063\n",
      "Epoch 48/50\n",
      "825/825 [==============================] - 0s 80us/sample - loss: 0.0182 - val_loss: 0.0060\n",
      "Epoch 49/50\n",
      "825/825 [==============================] - 0s 79us/sample - loss: 0.0183 - val_loss: 0.0053\n",
      "Epoch 50/50\n",
      "825/825 [==============================] - 0s 81us/sample - loss: 0.0185 - val_loss: 0.0064\n",
      "第210个数，还剩3913个没有训练\n",
      "inv_hat [0.78447128 0.77688927 0.77641077 0.77564556 0.76811299 0.76725766\n",
      " 0.76877866 0.77134953 0.76659279 0.76934949 0.77717642 0.77832565\n",
      " 0.77698494 0.77201688 0.77308576 0.77135299 0.77298943 0.77347112\n",
      " 0.77646093 0.77067969 0.76904589 0.76693432 0.7643472  0.76492173\n",
      " 0.76310333 0.76530485 0.76386868 0.7626252  0.76023718 0.76033263]\n",
      "Test RMSE: 0.004\n",
      "Train on 1093 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1093/1093 [==============================] - 0s 85us/sample - loss: 0.0119 - val_loss: 0.0087\n",
      "Epoch 2/50\n",
      "1093/1093 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0087\n",
      "Epoch 3/50\n",
      "1093/1093 [==============================] - 0s 80us/sample - loss: 0.0123 - val_loss: 0.0062\n",
      "Epoch 4/50\n",
      "1093/1093 [==============================] - 0s 81us/sample - loss: 0.0099 - val_loss: 0.0053\n",
      "Epoch 5/50\n",
      "1093/1093 [==============================] - 0s 81us/sample - loss: 0.0099 - val_loss: 0.0038\n",
      "Epoch 6/50\n",
      "1093/1093 [==============================] - 0s 78us/sample - loss: 0.0106 - val_loss: 0.0043\n",
      "Epoch 7/50\n",
      "1093/1093 [==============================] - 0s 86us/sample - loss: 0.0106 - val_loss: 0.0066\n",
      "Epoch 8/50\n",
      "1093/1093 [==============================] - 0s 81us/sample - loss: 0.0104 - val_loss: 0.0041\n",
      "Epoch 9/50\n",
      "1093/1093 [==============================] - 0s 78us/sample - loss: 0.0092 - val_loss: 0.0036\n",
      "Epoch 10/50\n",
      "1093/1093 [==============================] - 0s 78us/sample - loss: 0.0093 - val_loss: 0.0038\n",
      "Epoch 11/50\n",
      "1093/1093 [==============================] - 0s 78us/sample - loss: 0.0095 - val_loss: 0.0049\n",
      "Epoch 12/50\n",
      "1093/1093 [==============================] - 0s 77us/sample - loss: 0.0105 - val_loss: 0.0068\n",
      "Epoch 13/50\n",
      "1093/1093 [==============================] - 0s 80us/sample - loss: 0.0107 - val_loss: 0.0050\n",
      "Epoch 14/50\n",
      "1093/1093 [==============================] - 0s 80us/sample - loss: 0.0099 - val_loss: 0.0053\n",
      "Epoch 15/50\n",
      "1093/1093 [==============================] - 0s 85us/sample - loss: 0.0104 - val_loss: 0.0044\n",
      "Epoch 16/50\n",
      "1093/1093 [==============================] - 0s 82us/sample - loss: 0.0106 - val_loss: 0.0050\n",
      "Epoch 17/50\n",
      "1093/1093 [==============================] - 0s 83us/sample - loss: 0.0096 - val_loss: 0.0036\n",
      "Epoch 18/50\n",
      "1093/1093 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0046\n",
      "Epoch 19/50\n",
      "1093/1093 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0043\n",
      "Epoch 20/50\n",
      "1093/1093 [==============================] - 0s 80us/sample - loss: 0.0095 - val_loss: 0.0043\n",
      "Epoch 21/50\n",
      "1093/1093 [==============================] - 0s 82us/sample - loss: 0.0096 - val_loss: 0.0050\n",
      "Epoch 22/50\n",
      "1093/1093 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0091\n",
      "Epoch 23/50\n",
      "1093/1093 [==============================] - 0s 79us/sample - loss: 0.0112 - val_loss: 0.0076\n",
      "Epoch 24/50\n",
      "1093/1093 [==============================] - 0s 82us/sample - loss: 0.0105 - val_loss: 0.0060\n",
      "Epoch 25/50\n",
      "1093/1093 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0048\n",
      "Epoch 26/50\n",
      "1093/1093 [==============================] - 0s 84us/sample - loss: 0.0095 - val_loss: 0.0050\n",
      "Epoch 27/50\n",
      "1093/1093 [==============================] - 0s 85us/sample - loss: 0.0096 - val_loss: 0.0048\n",
      "Epoch 28/50\n",
      "1093/1093 [==============================] - 0s 84us/sample - loss: 0.0104 - val_loss: 0.0062\n",
      "Epoch 29/50\n",
      "1093/1093 [==============================] - 0s 85us/sample - loss: 0.0098 - val_loss: 0.0051\n",
      "Epoch 30/50\n",
      "1093/1093 [==============================] - 0s 85us/sample - loss: 0.0097 - val_loss: 0.0040\n",
      "Epoch 31/50\n",
      "1093/1093 [==============================] - 0s 92us/sample - loss: 0.0100 - val_loss: 0.0041\n",
      "Epoch 32/50\n",
      "1093/1093 [==============================] - 0s 84us/sample - loss: 0.0102 - val_loss: 0.0050\n",
      "Epoch 33/50\n",
      "1093/1093 [==============================] - 0s 79us/sample - loss: 0.0096 - val_loss: 0.0048\n",
      "Epoch 34/50\n",
      "1093/1093 [==============================] - 0s 79us/sample - loss: 0.0095 - val_loss: 0.0047\n",
      "Epoch 35/50\n",
      "1093/1093 [==============================] - 0s 78us/sample - loss: 0.0102 - val_loss: 0.0047\n",
      "Epoch 36/50\n",
      "1093/1093 [==============================] - 0s 78us/sample - loss: 0.0097 - val_loss: 0.0043\n",
      "Epoch 37/50\n",
      "1093/1093 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0041\n",
      "Epoch 38/50\n",
      "1093/1093 [==============================] - 0s 82us/sample - loss: 0.0091 - val_loss: 0.0036\n",
      "Epoch 39/50\n",
      "1093/1093 [==============================] - 0s 82us/sample - loss: 0.0092 - val_loss: 0.0038\n",
      "Epoch 40/50\n",
      "1093/1093 [==============================] - 0s 81us/sample - loss: 0.0092 - val_loss: 0.0044\n",
      "Epoch 41/50\n",
      "1093/1093 [==============================] - 0s 82us/sample - loss: 0.0094 - val_loss: 0.0039\n",
      "Epoch 42/50\n",
      "1093/1093 [==============================] - 0s 83us/sample - loss: 0.0092 - val_loss: 0.0037\n",
      "Epoch 43/50\n",
      "1093/1093 [==============================] - 0s 83us/sample - loss: 0.0092 - val_loss: 0.0044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "1093/1093 [==============================] - 0s 83us/sample - loss: 0.0094 - val_loss: 0.0042\n",
      "Epoch 45/50\n",
      "1093/1093 [==============================] - 0s 78us/sample - loss: 0.0095 - val_loss: 0.0046\n",
      "Epoch 46/50\n",
      "1093/1093 [==============================] - 0s 83us/sample - loss: 0.0100 - val_loss: 0.0040\n",
      "Epoch 47/50\n",
      "1093/1093 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0038\n",
      "Epoch 48/50\n",
      "1093/1093 [==============================] - 0s 81us/sample - loss: 0.0094 - val_loss: 0.0045\n",
      "Epoch 49/50\n",
      "1093/1093 [==============================] - 0s 80us/sample - loss: 0.0099 - val_loss: 0.0049\n",
      "Epoch 50/50\n",
      "1093/1093 [==============================] - 0s 80us/sample - loss: 0.0099 - val_loss: 0.0040\n",
      "第211个数，还剩3912个没有训练\n",
      "inv_hat [1.02404492 1.02404492 1.02404492 1.02404492 1.02404492 1.02505\n",
      " 1.02505    1.02505    1.02505    1.02505    1.02605496 1.02605496\n",
      " 1.02605496 1.02605496 1.02705781 1.02705781 1.02705781 1.02705781\n",
      " 1.02705781 1.02805703 1.02805703 1.02805703 1.02805703 1.02906079\n",
      " 1.02906079 1.02906079 1.02906079 1.03006545 1.03006545 1.03006545]\n",
      "Test RMSE: 0.000\n",
      "Train on 547 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "547/547 [==============================] - 0s 78us/sample - loss: 0.0101 - val_loss: 0.0167\n",
      "Epoch 2/50\n",
      "547/547 [==============================] - 0s 83us/sample - loss: 0.0105 - val_loss: 0.0160\n",
      "Epoch 3/50\n",
      "547/547 [==============================] - 0s 88us/sample - loss: 0.0101 - val_loss: 0.0165\n",
      "Epoch 4/50\n",
      "547/547 [==============================] - 0s 84us/sample - loss: 0.0102 - val_loss: 0.0160\n",
      "Epoch 5/50\n",
      "547/547 [==============================] - 0s 86us/sample - loss: 0.0101 - val_loss: 0.0161\n",
      "Epoch 6/50\n",
      "547/547 [==============================] - 0s 89us/sample - loss: 0.0100 - val_loss: 0.0161\n",
      "Epoch 7/50\n",
      "547/547 [==============================] - 0s 82us/sample - loss: 0.0101 - val_loss: 0.0160\n",
      "Epoch 8/50\n",
      "547/547 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0161\n",
      "Epoch 9/50\n",
      "547/547 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0160\n",
      "Epoch 10/50\n",
      "547/547 [==============================] - 0s 79us/sample - loss: 0.0100 - val_loss: 0.0161\n",
      "Epoch 11/50\n",
      "547/547 [==============================] - 0s 82us/sample - loss: 0.0100 - val_loss: 0.0160\n",
      "Epoch 12/50\n",
      "547/547 [==============================] - 0s 83us/sample - loss: 0.0100 - val_loss: 0.0161\n",
      "Epoch 13/50\n",
      "547/547 [==============================] - 0s 81us/sample - loss: 0.0100 - val_loss: 0.0161\n",
      "Epoch 14/50\n",
      "547/547 [==============================] - 0s 83us/sample - loss: 0.0100 - val_loss: 0.0161\n",
      "Epoch 15/50\n",
      "547/547 [==============================] - 0s 92us/sample - loss: 0.0100 - val_loss: 0.0161\n",
      "Epoch 16/50\n",
      "547/547 [==============================] - 0s 86us/sample - loss: 0.0100 - val_loss: 0.0161\n",
      "Epoch 17/50\n",
      "547/547 [==============================] - 0s 78us/sample - loss: 0.0100 - val_loss: 0.0161\n",
      "Epoch 18/50\n",
      "547/547 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0161\n",
      "Epoch 19/50\n",
      "547/547 [==============================] - 0s 81us/sample - loss: 0.0100 - val_loss: 0.0162\n",
      "Epoch 20/50\n",
      "547/547 [==============================] - 0s 78us/sample - loss: 0.0100 - val_loss: 0.0161\n",
      "Epoch 21/50\n",
      "547/547 [==============================] - 0s 86us/sample - loss: 0.0099 - val_loss: 0.0162\n",
      "Epoch 22/50\n",
      "547/547 [==============================] - 0s 81us/sample - loss: 0.0100 - val_loss: 0.0161\n",
      "Epoch 23/50\n",
      "547/547 [==============================] - 0s 83us/sample - loss: 0.0099 - val_loss: 0.0163\n",
      "Epoch 24/50\n",
      "547/547 [==============================] - 0s 88us/sample - loss: 0.0100 - val_loss: 0.0161\n",
      "Epoch 25/50\n",
      "547/547 [==============================] - 0s 80us/sample - loss: 0.0099 - val_loss: 0.0163\n",
      "Epoch 26/50\n",
      "547/547 [==============================] - 0s 84us/sample - loss: 0.0100 - val_loss: 0.0162\n",
      "Epoch 27/50\n",
      "547/547 [==============================] - 0s 80us/sample - loss: 0.0099 - val_loss: 0.0163\n",
      "Epoch 28/50\n",
      "547/547 [==============================] - 0s 81us/sample - loss: 0.0100 - val_loss: 0.0162\n",
      "Epoch 29/50\n",
      "547/547 [==============================] - 0s 82us/sample - loss: 0.0099 - val_loss: 0.0162\n",
      "Epoch 30/50\n",
      "547/547 [==============================] - 0s 84us/sample - loss: 0.0099 - val_loss: 0.0163\n",
      "Epoch 31/50\n",
      "547/547 [==============================] - 0s 86us/sample - loss: 0.0099 - val_loss: 0.0162\n",
      "Epoch 32/50\n",
      "547/547 [==============================] - 0s 86us/sample - loss: 0.0099 - val_loss: 0.0163\n",
      "Epoch 33/50\n",
      "547/547 [==============================] - 0s 86us/sample - loss: 0.0099 - val_loss: 0.0163\n",
      "Epoch 34/50\n",
      "547/547 [==============================] - 0s 85us/sample - loss: 0.0099 - val_loss: 0.0163\n",
      "Epoch 35/50\n",
      "547/547 [==============================] - 0s 82us/sample - loss: 0.0099 - val_loss: 0.0163\n",
      "Epoch 36/50\n",
      "547/547 [==============================] - 0s 85us/sample - loss: 0.0099 - val_loss: 0.0164\n",
      "Epoch 37/50\n",
      "547/547 [==============================] - 0s 85us/sample - loss: 0.0100 - val_loss: 0.0162\n",
      "Epoch 38/50\n",
      "547/547 [==============================] - 0s 84us/sample - loss: 0.0099 - val_loss: 0.0164\n",
      "Epoch 39/50\n",
      "547/547 [==============================] - 0s 83us/sample - loss: 0.0100 - val_loss: 0.0162\n",
      "Epoch 40/50\n",
      "547/547 [==============================] - 0s 83us/sample - loss: 0.0098 - val_loss: 0.0164\n",
      "Epoch 41/50\n",
      "547/547 [==============================] - 0s 81us/sample - loss: 0.0100 - val_loss: 0.0162\n",
      "Epoch 42/50\n",
      "547/547 [==============================] - 0s 83us/sample - loss: 0.0098 - val_loss: 0.0166\n",
      "Epoch 43/50\n",
      "547/547 [==============================] - 0s 83us/sample - loss: 0.0100 - val_loss: 0.0162\n",
      "Epoch 44/50\n",
      "547/547 [==============================] - 0s 82us/sample - loss: 0.0099 - val_loss: 0.0165\n",
      "Epoch 45/50\n",
      "547/547 [==============================] - 0s 86us/sample - loss: 0.0100 - val_loss: 0.0162\n",
      "Epoch 46/50\n",
      "547/547 [==============================] - 0s 90us/sample - loss: 0.0098 - val_loss: 0.0165\n",
      "Epoch 47/50\n",
      "547/547 [==============================] - 0s 103us/sample - loss: 0.0100 - val_loss: 0.0162\n",
      "Epoch 48/50\n",
      "547/547 [==============================] - 0s 89us/sample - loss: 0.0099 - val_loss: 0.0165\n",
      "Epoch 49/50\n",
      "547/547 [==============================] - 0s 89us/sample - loss: 0.0100 - val_loss: 0.0162\n",
      "Epoch 50/50\n",
      "547/547 [==============================] - 0s 90us/sample - loss: 0.0098 - val_loss: 0.0165\n",
      "第212个数，还剩3911个没有训练\n",
      "inv_hat [1.02668516 1.02759129 1.0279934  1.02809385 1.02819416 1.02849525\n",
      " 1.02879605 1.02919657 1.02949671 1.02969651 1.03019573 1.03089306\n",
      " 1.03178689 1.03208423 1.03267774 1.03346689 1.03356535 1.03376216\n",
      " 1.03297402 1.01560512 1.01529958 1.0146889  1.01479068 1.01529958\n",
      " 1.01560512 1.01601252 1.01601252 1.01591063 1.01621633 1.01733745]\n",
      "Test RMSE: 0.003\n",
      "Train on 830 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "830/830 [==============================] - 0s 85us/sample - loss: 0.0232 - val_loss: 0.0152\n",
      "Epoch 2/50\n",
      "830/830 [==============================] - 0s 82us/sample - loss: 0.0236 - val_loss: 0.0160\n",
      "Epoch 3/50\n",
      "830/830 [==============================] - 0s 91us/sample - loss: 0.0229 - val_loss: 0.0151\n",
      "Epoch 4/50\n",
      "830/830 [==============================] - 0s 86us/sample - loss: 0.0233 - val_loss: 0.0168\n",
      "Epoch 5/50\n",
      "830/830 [==============================] - 0s 85us/sample - loss: 0.0228 - val_loss: 0.0155\n",
      "Epoch 6/50\n",
      "830/830 [==============================] - 0s 81us/sample - loss: 0.0231 - val_loss: 0.0169\n",
      "Epoch 7/50\n",
      "830/830 [==============================] - 0s 78us/sample - loss: 0.0228 - val_loss: 0.0159\n",
      "Epoch 8/50\n",
      "830/830 [==============================] - 0s 85us/sample - loss: 0.0231 - val_loss: 0.0168\n",
      "Epoch 9/50\n",
      "830/830 [==============================] - 0s 84us/sample - loss: 0.0228 - val_loss: 0.0159\n",
      "Epoch 10/50\n",
      "830/830 [==============================] - 0s 80us/sample - loss: 0.0230 - val_loss: 0.0167\n",
      "Epoch 11/50\n",
      "830/830 [==============================] - 0s 82us/sample - loss: 0.0228 - val_loss: 0.0159\n",
      "Epoch 12/50\n",
      "830/830 [==============================] - 0s 82us/sample - loss: 0.0230 - val_loss: 0.0167\n",
      "Epoch 13/50\n",
      "830/830 [==============================] - 0s 81us/sample - loss: 0.0228 - val_loss: 0.0159\n",
      "Epoch 14/50\n",
      "830/830 [==============================] - 0s 83us/sample - loss: 0.0230 - val_loss: 0.0165\n",
      "Epoch 15/50\n",
      "830/830 [==============================] - 0s 85us/sample - loss: 0.0228 - val_loss: 0.0159\n",
      "Epoch 16/50\n",
      "830/830 [==============================] - 0s 82us/sample - loss: 0.0229 - val_loss: 0.0164\n",
      "Epoch 17/50\n",
      "830/830 [==============================] - 0s 85us/sample - loss: 0.0228 - val_loss: 0.0160\n",
      "Epoch 18/50\n",
      "830/830 [==============================] - 0s 79us/sample - loss: 0.0229 - val_loss: 0.0164\n",
      "Epoch 19/50\n",
      "830/830 [==============================] - 0s 79us/sample - loss: 0.0228 - val_loss: 0.0159\n",
      "Epoch 20/50\n",
      "830/830 [==============================] - 0s 88us/sample - loss: 0.0230 - val_loss: 0.0164\n",
      "Epoch 21/50\n",
      "830/830 [==============================] - 0s 81us/sample - loss: 0.0228 - val_loss: 0.0159\n",
      "Epoch 22/50\n",
      "830/830 [==============================] - 0s 87us/sample - loss: 0.0229 - val_loss: 0.0163\n",
      "Epoch 23/50\n",
      "830/830 [==============================] - 0s 79us/sample - loss: 0.0228 - val_loss: 0.0159\n",
      "Epoch 24/50\n",
      "830/830 [==============================] - 0s 82us/sample - loss: 0.0229 - val_loss: 0.0164\n",
      "Epoch 25/50\n",
      "830/830 [==============================] - 0s 79us/sample - loss: 0.0228 - val_loss: 0.0159\n",
      "Epoch 26/50\n",
      "830/830 [==============================] - 0s 81us/sample - loss: 0.0229 - val_loss: 0.0164\n",
      "Epoch 27/50\n",
      "830/830 [==============================] - 0s 83us/sample - loss: 0.0228 - val_loss: 0.0159\n",
      "Epoch 28/50\n",
      "830/830 [==============================] - 0s 84us/sample - loss: 0.0229 - val_loss: 0.0164\n",
      "Epoch 29/50\n",
      "830/830 [==============================] - 0s 80us/sample - loss: 0.0228 - val_loss: 0.0158\n",
      "Epoch 30/50\n",
      "830/830 [==============================] - 0s 81us/sample - loss: 0.0229 - val_loss: 0.0164\n",
      "Epoch 31/50\n",
      "830/830 [==============================] - 0s 88us/sample - loss: 0.0228 - val_loss: 0.0158\n",
      "Epoch 32/50\n",
      "830/830 [==============================] - 0s 84us/sample - loss: 0.0229 - val_loss: 0.0163\n",
      "Epoch 33/50\n",
      "830/830 [==============================] - 0s 84us/sample - loss: 0.0228 - val_loss: 0.0157\n",
      "Epoch 34/50\n",
      "830/830 [==============================] - 0s 82us/sample - loss: 0.0229 - val_loss: 0.0163\n",
      "Epoch 35/50\n",
      "830/830 [==============================] - 0s 86us/sample - loss: 0.0228 - val_loss: 0.0157\n",
      "Epoch 36/50\n",
      "830/830 [==============================] - 0s 86us/sample - loss: 0.0229 - val_loss: 0.0162\n",
      "Epoch 37/50\n",
      "830/830 [==============================] - 0s 85us/sample - loss: 0.0228 - val_loss: 0.0157\n",
      "Epoch 38/50\n",
      "830/830 [==============================] - 0s 81us/sample - loss: 0.0229 - val_loss: 0.0162\n",
      "Epoch 39/50\n",
      "830/830 [==============================] - 0s 81us/sample - loss: 0.0228 - val_loss: 0.0156\n",
      "Epoch 40/50\n",
      "830/830 [==============================] - 0s 81us/sample - loss: 0.0230 - val_loss: 0.0163\n",
      "Epoch 41/50\n",
      "830/830 [==============================] - 0s 77us/sample - loss: 0.0228 - val_loss: 0.0156\n",
      "Epoch 42/50\n",
      "830/830 [==============================] - 0s 79us/sample - loss: 0.0230 - val_loss: 0.0162\n",
      "Epoch 43/50\n",
      "830/830 [==============================] - 0s 75us/sample - loss: 0.0228 - val_loss: 0.0156\n",
      "Epoch 44/50\n",
      "830/830 [==============================] - 0s 78us/sample - loss: 0.0229 - val_loss: 0.0161\n",
      "Epoch 45/50\n",
      "830/830 [==============================] - 0s 81us/sample - loss: 0.0228 - val_loss: 0.0156\n",
      "Epoch 46/50\n",
      "830/830 [==============================] - 0s 83us/sample - loss: 0.0229 - val_loss: 0.0161\n",
      "Epoch 47/50\n",
      "830/830 [==============================] - 0s 86us/sample - loss: 0.0228 - val_loss: 0.0155\n",
      "Epoch 48/50\n",
      "830/830 [==============================] - 0s 81us/sample - loss: 0.0229 - val_loss: 0.0161\n",
      "Epoch 49/50\n",
      "830/830 [==============================] - 0s 78us/sample - loss: 0.0228 - val_loss: 0.0155\n",
      "Epoch 50/50\n",
      "830/830 [==============================] - 0s 77us/sample - loss: 0.0229 - val_loss: 0.0161\n",
      "第213个数，还剩3910个没有训练\n",
      "inv_hat [0.69343562 0.67509149 0.67843474 0.67804121 0.65446385 0.65436662\n",
      " 0.65631194 0.66587486 0.65320047 0.65679864 0.67371628 0.6756811\n",
      " 0.67214563 0.6614776  0.66167279 0.65368628 0.65845435 0.6601116\n",
      " 0.66793033 0.65611733 0.65368628 0.64941623 0.64322585 0.64419142\n",
      " 0.6395624  0.64477106 0.63879239 0.63802274 0.6329348  0.63456468]\n",
      "Test RMSE: 0.009\n",
      "Train on 482 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "482/482 [==============================] - 0s 90us/sample - loss: 0.0096 - val_loss: 0.0089\n",
      "Epoch 2/50\n",
      "482/482 [==============================] - 0s 89us/sample - loss: 0.0087 - val_loss: 0.0101\n",
      "Epoch 3/50\n",
      "482/482 [==============================] - 0s 84us/sample - loss: 0.0084 - val_loss: 0.0114\n",
      "Epoch 4/50\n",
      "482/482 [==============================] - 0s 85us/sample - loss: 0.0087 - val_loss: 0.0113\n",
      "Epoch 5/50\n",
      "482/482 [==============================] - 0s 88us/sample - loss: 0.0084 - val_loss: 0.0116\n",
      "Epoch 6/50\n",
      "482/482 [==============================] - 0s 87us/sample - loss: 0.0090 - val_loss: 0.0150\n",
      "Epoch 7/50\n",
      "482/482 [==============================] - 0s 88us/sample - loss: 0.0110 - val_loss: 0.0153\n",
      "Epoch 8/50\n",
      "482/482 [==============================] - 0s 88us/sample - loss: 0.0104 - val_loss: 0.0136\n",
      "Epoch 9/50\n",
      "482/482 [==============================] - 0s 82us/sample - loss: 0.0109 - val_loss: 0.0176\n",
      "Epoch 10/50\n",
      "482/482 [==============================] - 0s 88us/sample - loss: 0.0103 - val_loss: 0.0131\n",
      "Epoch 11/50\n",
      "482/482 [==============================] - 0s 85us/sample - loss: 0.0105 - val_loss: 0.0177\n",
      "Epoch 12/50\n",
      "482/482 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0152\n",
      "Epoch 13/50\n",
      "482/482 [==============================] - 0s 81us/sample - loss: 0.0104 - val_loss: 0.0167\n",
      "Epoch 14/50\n",
      "482/482 [==============================] - 0s 87us/sample - loss: 0.0093 - val_loss: 0.0156\n",
      "Epoch 15/50\n",
      "482/482 [==============================] - 0s 87us/sample - loss: 0.0114 - val_loss: 0.0189\n",
      "Epoch 16/50\n",
      "482/482 [==============================] - 0s 89us/sample - loss: 0.0101 - val_loss: 0.0128\n",
      "Epoch 17/50\n",
      "482/482 [==============================] - 0s 81us/sample - loss: 0.0112 - val_loss: 0.0218\n",
      "Epoch 18/50\n",
      "482/482 [==============================] - 0s 86us/sample - loss: 0.0090 - val_loss: 0.0121\n",
      "Epoch 19/50\n",
      "482/482 [==============================] - 0s 82us/sample - loss: 0.0090 - val_loss: 0.0177\n",
      "Epoch 20/50\n",
      "482/482 [==============================] - 0s 78us/sample - loss: 0.0082 - val_loss: 0.0135\n",
      "Epoch 21/50\n",
      "482/482 [==============================] - 0s 84us/sample - loss: 0.0086 - val_loss: 0.0136\n",
      "Epoch 22/50\n",
      "482/482 [==============================] - 0s 86us/sample - loss: 0.0095 - val_loss: 0.0177\n",
      "Epoch 23/50\n",
      "482/482 [==============================] - 0s 79us/sample - loss: 0.0096 - val_loss: 0.0132\n",
      "Epoch 24/50\n",
      "482/482 [==============================] - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0214\n",
      "Epoch 25/50\n",
      "482/482 [==============================] - 0s 84us/sample - loss: 0.0090 - val_loss: 0.0120\n",
      "Epoch 26/50\n",
      "482/482 [==============================] - 0s 89us/sample - loss: 0.0089 - val_loss: 0.0174\n",
      "Epoch 27/50\n",
      "482/482 [==============================] - 0s 85us/sample - loss: 0.0082 - val_loss: 0.0137\n",
      "Epoch 28/50\n",
      "482/482 [==============================] - 0s 88us/sample - loss: 0.0085 - val_loss: 0.0134\n",
      "Epoch 29/50\n",
      "482/482 [==============================] - 0s 89us/sample - loss: 0.0090 - val_loss: 0.0170\n",
      "Epoch 30/50\n",
      "482/482 [==============================] - 0s 85us/sample - loss: 0.0090 - val_loss: 0.0131\n",
      "Epoch 31/50\n",
      "482/482 [==============================] - 0s 87us/sample - loss: 0.0101 - val_loss: 0.0194\n",
      "Epoch 32/50\n",
      "482/482 [==============================] - 0s 87us/sample - loss: 0.0091 - val_loss: 0.0124\n",
      "Epoch 33/50\n",
      "482/482 [==============================] - 0s 89us/sample - loss: 0.0093 - val_loss: 0.0186\n",
      "Epoch 34/50\n",
      "482/482 [==============================] - 0s 87us/sample - loss: 0.0086 - val_loss: 0.0129\n",
      "Epoch 35/50\n",
      "482/482 [==============================] - 0s 85us/sample - loss: 0.0090 - val_loss: 0.0188\n",
      "Epoch 36/50\n",
      "482/482 [==============================] - 0s 85us/sample - loss: 0.0090 - val_loss: 0.0129\n",
      "Epoch 37/50\n",
      "482/482 [==============================] - 0s 87us/sample - loss: 0.0092 - val_loss: 0.0193\n",
      "Epoch 38/50\n",
      "482/482 [==============================] - 0s 82us/sample - loss: 0.0087 - val_loss: 0.0131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "482/482 [==============================] - 0s 85us/sample - loss: 0.0092 - val_loss: 0.0190\n",
      "Epoch 40/50\n",
      "482/482 [==============================] - 0s 85us/sample - loss: 0.0082 - val_loss: 0.0139\n",
      "Epoch 41/50\n",
      "482/482 [==============================] - 0s 86us/sample - loss: 0.0082 - val_loss: 0.0141\n",
      "Epoch 42/50\n",
      "482/482 [==============================] - 0s 89us/sample - loss: 0.0081 - val_loss: 0.0161\n",
      "Epoch 43/50\n",
      "482/482 [==============================] - 0s 88us/sample - loss: 0.0083 - val_loss: 0.0132\n",
      "Epoch 44/50\n",
      "482/482 [==============================] - 0s 87us/sample - loss: 0.0083 - val_loss: 0.0137\n",
      "Epoch 45/50\n",
      "482/482 [==============================] - 0s 84us/sample - loss: 0.0085 - val_loss: 0.0131\n",
      "Epoch 46/50\n",
      "482/482 [==============================] - 0s 87us/sample - loss: 0.0087 - val_loss: 0.0150\n",
      "Epoch 47/50\n",
      "482/482 [==============================] - 0s 87us/sample - loss: 0.0084 - val_loss: 0.0131\n",
      "Epoch 48/50\n",
      "482/482 [==============================] - 0s 85us/sample - loss: 0.0092 - val_loss: 0.0178\n",
      "Epoch 49/50\n",
      "482/482 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0124\n",
      "Epoch 50/50\n",
      "482/482 [==============================] - 0s 78us/sample - loss: 0.0092 - val_loss: 0.0185\n",
      "第214个数，还剩3909个没有训练\n",
      "inv_hat [1.08639685 1.08639685 1.08639685 1.08639685 1.08541859 1.08541859\n",
      " 1.08541859 1.08327939 1.08327939 1.08327939 1.08327939 1.08327939\n",
      " 1.08229813 1.08229813 1.08229813 1.08229813 1.08131555 1.08131555\n",
      " 1.08131555 1.08131555 1.08033177 1.08088372 1.08186932 1.08285369\n",
      " 1.08481803 1.08579803 1.08677646 1.09164328 1.09261122 1.09357742]\n",
      "Test RMSE: 0.004\n",
      "Train on 848 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "848/848 [==============================] - 0s 73us/sample - loss: 0.0070 - val_loss: 0.0031\n",
      "Epoch 2/50\n",
      "848/848 [==============================] - 0s 73us/sample - loss: 0.0070 - val_loss: 0.0033\n",
      "Epoch 3/50\n",
      "848/848 [==============================] - 0s 76us/sample - loss: 0.0069 - val_loss: 0.0018\n",
      "Epoch 4/50\n",
      "848/848 [==============================] - 0s 78us/sample - loss: 0.0060 - val_loss: 0.0022\n",
      "Epoch 5/50\n",
      "848/848 [==============================] - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 6/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0066 - val_loss: 0.0029\n",
      "Epoch 7/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0063 - val_loss: 0.0038\n",
      "Epoch 8/50\n",
      "848/848 [==============================] - 0s 77us/sample - loss: 0.0069 - val_loss: 0.0035\n",
      "Epoch 9/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0064 - val_loss: 0.0027\n",
      "Epoch 10/50\n",
      "848/848 [==============================] - 0s 77us/sample - loss: 0.0064 - val_loss: 0.0029\n",
      "Epoch 11/50\n",
      "848/848 [==============================] - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0038\n",
      "Epoch 12/50\n",
      "848/848 [==============================] - 0s 81us/sample - loss: 0.0065 - val_loss: 0.0028\n",
      "Epoch 13/50\n",
      "848/848 [==============================] - 0s 86us/sample - loss: 0.0061 - val_loss: 0.0027\n",
      "Epoch 14/50\n",
      "848/848 [==============================] - 0s 81us/sample - loss: 0.0063 - val_loss: 0.0030\n",
      "Epoch 15/50\n",
      "848/848 [==============================] - 0s 75us/sample - loss: 0.0063 - val_loss: 0.0028\n",
      "Epoch 16/50\n",
      "848/848 [==============================] - 0s 74us/sample - loss: 0.0064 - val_loss: 0.0025\n",
      "Epoch 17/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0061 - val_loss: 0.0017\n",
      "Epoch 18/50\n",
      "848/848 [==============================] - 0s 78us/sample - loss: 0.0058 - val_loss: 0.0018\n",
      "Epoch 19/50\n",
      "848/848 [==============================] - 0s 83us/sample - loss: 0.0059 - val_loss: 0.0021\n",
      "Epoch 20/50\n",
      "848/848 [==============================] - 0s 86us/sample - loss: 0.0059 - val_loss: 0.0018\n",
      "Epoch 21/50\n",
      "848/848 [==============================] - 0s 81us/sample - loss: 0.0058 - val_loss: 0.0024\n",
      "Epoch 22/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0062 - val_loss: 0.0024\n",
      "Epoch 23/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0063 - val_loss: 0.0022\n",
      "Epoch 24/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0062 - val_loss: 0.0023\n",
      "Epoch 25/50\n",
      "848/848 [==============================] - 0s 81us/sample - loss: 0.0062 - val_loss: 0.0022\n",
      "Epoch 26/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0062 - val_loss: 0.0021\n",
      "Epoch 27/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0062 - val_loss: 0.0022\n",
      "Epoch 28/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0062 - val_loss: 0.0022\n",
      "Epoch 29/50\n",
      "848/848 [==============================] - 0s 77us/sample - loss: 0.0062 - val_loss: 0.0022\n",
      "Epoch 30/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0062 - val_loss: 0.0022\n",
      "Epoch 31/50\n",
      "848/848 [==============================] - 0s 81us/sample - loss: 0.0062 - val_loss: 0.0022\n",
      "Epoch 32/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0061 - val_loss: 0.0023\n",
      "Epoch 33/50\n",
      "848/848 [==============================] - 0s 77us/sample - loss: 0.0062 - val_loss: 0.0021\n",
      "Epoch 34/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0061 - val_loss: 0.0023\n",
      "Epoch 35/50\n",
      "848/848 [==============================] - 0s 82us/sample - loss: 0.0062 - val_loss: 0.0021\n",
      "Epoch 36/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0061 - val_loss: 0.0023\n",
      "Epoch 37/50\n",
      "848/848 [==============================] - 0s 81us/sample - loss: 0.0062 - val_loss: 0.0021\n",
      "Epoch 38/50\n",
      "848/848 [==============================] - 0s 81us/sample - loss: 0.0062 - val_loss: 0.0020\n",
      "Epoch 39/50\n",
      "848/848 [==============================] - 0s 75us/sample - loss: 0.0059 - val_loss: 0.0019\n",
      "Epoch 40/50\n",
      "848/848 [==============================] - 0s 77us/sample - loss: 0.0059 - val_loss: 0.0022\n",
      "Epoch 41/50\n",
      "848/848 [==============================] - 0s 77us/sample - loss: 0.0062 - val_loss: 0.0023\n",
      "Epoch 42/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0065 - val_loss: 0.0017\n",
      "Epoch 43/50\n",
      "848/848 [==============================] - 0s 81us/sample - loss: 0.0061 - val_loss: 0.0016\n",
      "Epoch 44/50\n",
      "848/848 [==============================] - 0s 79us/sample - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 45/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 46/50\n",
      "848/848 [==============================] - 0s 84us/sample - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 47/50\n",
      "848/848 [==============================] - 0s 78us/sample - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 48/50\n",
      "848/848 [==============================] - 0s 82us/sample - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 49/50\n",
      "848/848 [==============================] - 0s 80us/sample - loss: 0.0057 - val_loss: 0.0016\n",
      "Epoch 50/50\n",
      "848/848 [==============================] - 0s 82us/sample - loss: 0.0057 - val_loss: 0.0016\n",
      "第215个数，还剩3908个没有训练\n",
      "inv_hat [1.02120329 1.02130324 1.02140331 1.02160348 1.02170357 1.02200391\n",
      " 1.02220405 1.0223042  1.02240435 1.02250412 1.02290255 1.02300221\n",
      " 1.02320156 1.02330124 1.02340094 1.02379971 1.02389945 1.02399921\n",
      " 1.02409897 1.0242984  1.02459781 1.02479746 1.02489718 1.02499703\n",
      " 1.02509689 1.02549642 1.02559633 1.02569612 1.02589599 1.02599593]\n",
      "Test RMSE: 0.000\n",
      "Train on 811 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "811/811 [==============================] - 0s 81us/sample - loss: 0.0053 - val_loss: 0.0357\n",
      "Epoch 2/50\n",
      "811/811 [==============================] - 0s 85us/sample - loss: 0.0053 - val_loss: 0.0351\n",
      "Epoch 3/50\n",
      "811/811 [==============================] - 0s 82us/sample - loss: 0.0053 - val_loss: 0.0358\n",
      "Epoch 4/50\n",
      "811/811 [==============================] - 0s 85us/sample - loss: 0.0054 - val_loss: 0.0361\n",
      "Epoch 5/50\n",
      "811/811 [==============================] - 0s 88us/sample - loss: 0.0054 - val_loss: 0.0364\n",
      "Epoch 6/50\n",
      "811/811 [==============================] - 0s 81us/sample - loss: 0.0052 - val_loss: 0.0355\n",
      "Epoch 7/50\n",
      "811/811 [==============================] - 0s 84us/sample - loss: 0.0053 - val_loss: 0.0354\n",
      "Epoch 8/50\n",
      "811/811 [==============================] - 0s 85us/sample - loss: 0.0054 - val_loss: 0.0352\n",
      "Epoch 9/50\n",
      "811/811 [==============================] - 0s 83us/sample - loss: 0.0052 - val_loss: 0.0356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "811/811 [==============================] - 0s 81us/sample - loss: 0.0053 - val_loss: 0.0351\n",
      "Epoch 11/50\n",
      "811/811 [==============================] - 0s 81us/sample - loss: 0.0052 - val_loss: 0.0358\n",
      "Epoch 12/50\n",
      "811/811 [==============================] - 0s 89us/sample - loss: 0.0052 - val_loss: 0.0358\n",
      "Epoch 13/50\n",
      "811/811 [==============================] - 0s 85us/sample - loss: 0.0054 - val_loss: 0.0361\n",
      "Epoch 14/50\n",
      "811/811 [==============================] - 0s 83us/sample - loss: 0.0051 - val_loss: 0.0353\n",
      "Epoch 15/50\n",
      "811/811 [==============================] - 0s 81us/sample - loss: 0.0053 - val_loss: 0.0350\n",
      "Epoch 16/50\n",
      "811/811 [==============================] - ETA: 0s - loss: 0.005 - 0s 82us/sample - loss: 0.0051 - val_loss: 0.0359\n",
      "Epoch 17/50\n",
      "811/811 [==============================] - 0s 82us/sample - loss: 0.0051 - val_loss: 0.0356\n",
      "Epoch 18/50\n",
      "811/811 [==============================] - 0s 82us/sample - loss: 0.0052 - val_loss: 0.0358\n",
      "Epoch 19/50\n",
      "811/811 [==============================] - 0s 82us/sample - loss: 0.0051 - val_loss: 0.0356\n",
      "Epoch 20/50\n",
      "811/811 [==============================] - 0s 82us/sample - loss: 0.0051 - val_loss: 0.0354\n",
      "Epoch 21/50\n",
      "811/811 [==============================] - 0s 84us/sample - loss: 0.0052 - val_loss: 0.0359\n",
      "Epoch 22/50\n",
      "811/811 [==============================] - 0s 82us/sample - loss: 0.0052 - val_loss: 0.0357\n",
      "Epoch 23/50\n",
      "811/811 [==============================] - 0s 84us/sample - loss: 0.0052 - val_loss: 0.0350\n",
      "Epoch 24/50\n",
      "811/811 [==============================] - 0s 84us/sample - loss: 0.0052 - val_loss: 0.0354\n",
      "Epoch 25/50\n",
      "811/811 [==============================] - 0s 80us/sample - loss: 0.0052 - val_loss: 0.0354\n",
      "Epoch 26/50\n",
      "811/811 [==============================] - ETA: 0s - loss: 0.005 - 0s 82us/sample - loss: 0.0053 - val_loss: 0.0359\n",
      "Epoch 27/50\n",
      "811/811 [==============================] - 0s 79us/sample - loss: 0.0055 - val_loss: 0.0362\n",
      "Epoch 28/50\n",
      "811/811 [==============================] - 0s 80us/sample - loss: 0.0057 - val_loss: 0.0365\n",
      "Epoch 29/50\n",
      "811/811 [==============================] - 0s 82us/sample - loss: 0.0053 - val_loss: 0.0360\n",
      "Epoch 30/50\n",
      "811/811 [==============================] - 0s 84us/sample - loss: 0.0053 - val_loss: 0.0359\n",
      "Epoch 31/50\n",
      "811/811 [==============================] - ETA: 0s - loss: 0.005 - 0s 85us/sample - loss: 0.0051 - val_loss: 0.0357\n",
      "Epoch 32/50\n",
      "811/811 [==============================] - 0s 84us/sample - loss: 0.0052 - val_loss: 0.0360\n",
      "Epoch 33/50\n",
      "811/811 [==============================] - 0s 83us/sample - loss: 0.0051 - val_loss: 0.0353\n",
      "Epoch 34/50\n",
      "811/811 [==============================] - 0s 87us/sample - loss: 0.0054 - val_loss: 0.0353\n",
      "Epoch 35/50\n",
      "811/811 [==============================] - 0s 88us/sample - loss: 0.0052 - val_loss: 0.0357\n",
      "Epoch 36/50\n",
      "811/811 [==============================] - 0s 83us/sample - loss: 0.0052 - val_loss: 0.0359\n",
      "Epoch 37/50\n",
      "811/811 [==============================] - 0s 88us/sample - loss: 0.0052 - val_loss: 0.0356\n",
      "Epoch 38/50\n",
      "811/811 [==============================] - 0s 87us/sample - loss: 0.0054 - val_loss: 0.0362\n",
      "Epoch 39/50\n",
      "811/811 [==============================] - 0s 83us/sample - loss: 0.0051 - val_loss: 0.0358\n",
      "Epoch 40/50\n",
      "811/811 [==============================] - 0s 81us/sample - loss: 0.0051 - val_loss: 0.0356\n",
      "Epoch 41/50\n",
      "811/811 [==============================] - 0s 82us/sample - loss: 0.0053 - val_loss: 0.0353\n",
      "Epoch 42/50\n",
      "811/811 [==============================] - 0s 79us/sample - loss: 0.0052 - val_loss: 0.0364\n",
      "Epoch 43/50\n",
      "811/811 [==============================] - 0s 86us/sample - loss: 0.0051 - val_loss: 0.0356\n",
      "Epoch 44/50\n",
      "811/811 [==============================] - 0s 82us/sample - loss: 0.0051 - val_loss: 0.0355\n",
      "Epoch 45/50\n",
      "811/811 [==============================] - 0s 82us/sample - loss: 0.0051 - val_loss: 0.0354\n",
      "Epoch 46/50\n",
      "811/811 [==============================] - 0s 87us/sample - loss: 0.0051 - val_loss: 0.0354\n",
      "Epoch 47/50\n",
      "811/811 [==============================] - 0s 84us/sample - loss: 0.0050 - val_loss: 0.0355\n",
      "Epoch 48/50\n",
      "811/811 [==============================] - 0s 88us/sample - loss: 0.0051 - val_loss: 0.0358\n",
      "Epoch 49/50\n",
      "811/811 [==============================] - 0s 87us/sample - loss: 0.0052 - val_loss: 0.0358\n",
      "Epoch 50/50\n",
      "811/811 [==============================] - 0s 82us/sample - loss: 0.0051 - val_loss: 0.0356\n",
      "第216个数，还剩3907个没有训练\n",
      "inv_hat [1.0512018  1.0512991  1.05149346 1.05159063 1.05178485 1.05217264\n",
      " 1.05236633 1.05246311 1.05265653 1.05275317 1.05323559 1.05333196\n",
      " 1.05352456 1.05362068 1.05381301 1.05419709 1.05438875 1.05448446\n",
      " 1.0546748  1.0547699  1.00019284 1.00039113 1.00049031 1.00068861\n",
      " 1.00078785 1.00128423 1.00138359 1.00158236 1.00168177 1.00188065]\n",
      "Test RMSE: 0.010\n",
      "Train on 529 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "529/529 [==============================] - 0s 91us/sample - loss: 0.0049 - val_loss: 0.0097\n",
      "Epoch 2/50\n",
      "529/529 [==============================] - 0s 88us/sample - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 3/50\n",
      "529/529 [==============================] - 0s 91us/sample - loss: 0.0051 - val_loss: 0.0072\n",
      "Epoch 4/50\n",
      "529/529 [==============================] - 0s 87us/sample - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 5/50\n",
      "529/529 [==============================] - 0s 87us/sample - loss: 0.0031 - val_loss: 0.0079\n",
      "Epoch 6/50\n",
      "529/529 [==============================] - 0s 85us/sample - loss: 0.0030 - val_loss: 0.0070\n",
      "Epoch 7/50\n",
      "529/529 [==============================] - 0s 84us/sample - loss: 0.0034 - val_loss: 0.0063\n",
      "Epoch 8/50\n",
      "529/529 [==============================] - 0s 85us/sample - loss: 0.0032 - val_loss: 0.0069\n",
      "Epoch 9/50\n",
      "529/529 [==============================] - 0s 87us/sample - loss: 0.0037 - val_loss: 0.0080\n",
      "Epoch 10/50\n",
      "529/529 [==============================] - 0s 89us/sample - loss: 0.0038 - val_loss: 0.0062\n",
      "Epoch 11/50\n",
      "529/529 [==============================] - 0s 87us/sample - loss: 0.0053 - val_loss: 0.0081\n",
      "Epoch 12/50\n",
      "529/529 [==============================] - 0s 83us/sample - loss: 0.0075 - val_loss: 0.0072\n",
      "Epoch 13/50\n",
      "529/529 [==============================] - 0s 83us/sample - loss: 0.0034 - val_loss: 0.0072\n",
      "Epoch 14/50\n",
      "529/529 [==============================] - 0s 85us/sample - loss: 0.0041 - val_loss: 0.0069\n",
      "Epoch 15/50\n",
      "529/529 [==============================] - 0s 86us/sample - loss: 0.0034 - val_loss: 0.0062\n",
      "Epoch 16/50\n",
      "529/529 [==============================] - 0s 83us/sample - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 17/50\n",
      "529/529 [==============================] - 0s 91us/sample - loss: 0.0046 - val_loss: 0.0084\n",
      "Epoch 18/50\n",
      "529/529 [==============================] - 0s 87us/sample - loss: 0.0041 - val_loss: 0.0077\n",
      "Epoch 19/50\n",
      "529/529 [==============================] - 0s 91us/sample - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 20/50\n",
      "529/529 [==============================] - 0s 87us/sample - loss: 0.0036 - val_loss: 0.0074\n",
      "Epoch 21/50\n",
      "529/529 [==============================] - 0s 85us/sample - loss: 0.0033 - val_loss: 0.0075\n",
      "Epoch 22/50\n",
      "529/529 [==============================] - 0s 86us/sample - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 23/50\n",
      "529/529 [==============================] - 0s 82us/sample - loss: 0.0038 - val_loss: 0.0076\n",
      "Epoch 24/50\n",
      "529/529 [==============================] - 0s 84us/sample - loss: 0.0039 - val_loss: 0.0077\n",
      "Epoch 25/50\n",
      "529/529 [==============================] - 0s 86us/sample - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 26/50\n",
      "529/529 [==============================] - 0s 90us/sample - loss: 0.0035 - val_loss: 0.0077\n",
      "Epoch 27/50\n",
      "529/529 [==============================] - 0s 88us/sample - loss: 0.0034 - val_loss: 0.0076\n",
      "Epoch 28/50\n",
      "529/529 [==============================] - 0s 86us/sample - loss: 0.0047 - val_loss: 0.0059\n",
      "Epoch 29/50\n",
      "529/529 [==============================] - 0s 84us/sample - loss: 0.0034 - val_loss: 0.0073\n",
      "Epoch 30/50\n",
      "529/529 [==============================] - 0s 85us/sample - loss: 0.0054 - val_loss: 0.0093\n",
      "Epoch 31/50\n",
      "529/529 [==============================] - 0s 85us/sample - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 32/50\n",
      "529/529 [==============================] - 0s 82us/sample - loss: 0.0032 - val_loss: 0.0075\n",
      "Epoch 33/50\n",
      "529/529 [==============================] - 0s 83us/sample - loss: 0.0032 - val_loss: 0.0072\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529/529 [==============================] - 0s 84us/sample - loss: 0.0037 - val_loss: 0.0065\n",
      "Epoch 35/50\n",
      "529/529 [==============================] - 0s 85us/sample - loss: 0.0030 - val_loss: 0.0076\n",
      "Epoch 36/50\n",
      "529/529 [==============================] - 0s 96us/sample - loss: 0.0042 - val_loss: 0.0079\n",
      "Epoch 37/50\n",
      "529/529 [==============================] - 0s 87us/sample - loss: 0.0037 - val_loss: 0.0061\n",
      "Epoch 38/50\n",
      "529/529 [==============================] - 0s 86us/sample - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 39/50\n",
      "529/529 [==============================] - 0s 85us/sample - loss: 0.0042 - val_loss: 0.0084\n",
      "Epoch 40/50\n",
      "529/529 [==============================] - 0s 87us/sample - loss: 0.0033 - val_loss: 0.0064\n",
      "Epoch 41/50\n",
      "529/529 [==============================] - 0s 82us/sample - loss: 0.0042 - val_loss: 0.0061\n",
      "Epoch 42/50\n",
      "529/529 [==============================] - 0s 86us/sample - loss: 0.0041 - val_loss: 0.0079\n",
      "Epoch 43/50\n",
      "529/529 [==============================] - 0s 85us/sample - loss: 0.0040 - val_loss: 0.0070\n",
      "Epoch 44/50\n",
      "529/529 [==============================] - 0s 89us/sample - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 45/50\n",
      "529/529 [==============================] - 0s 85us/sample - loss: 0.0035 - val_loss: 0.0079\n",
      "Epoch 46/50\n",
      "529/529 [==============================] - 0s 85us/sample - loss: 0.0032 - val_loss: 0.0066\n",
      "Epoch 47/50\n",
      "529/529 [==============================] - 0s 87us/sample - loss: 0.0035 - val_loss: 0.0070\n",
      "Epoch 48/50\n",
      "529/529 [==============================] - 0s 90us/sample - loss: 0.0032 - val_loss: 0.0072\n",
      "Epoch 49/50\n",
      "529/529 [==============================] - 0s 82us/sample - loss: 0.0037 - val_loss: 0.0075\n",
      "Epoch 50/50\n",
      "529/529 [==============================] - 0s 86us/sample - loss: 0.0043 - val_loss: 0.0057\n",
      "第217个数，还剩3906个没有训练\n",
      "inv_hat [1.10326759 1.10443202 1.10462587 1.10404423 1.1039472  1.10375308\n",
      " 1.1039472  1.10452894 1.10578704 1.10636668 1.10694549 1.10896559\n",
      " 1.10963695 1.11023269 1.11097657 1.11259768 1.1127879  1.11307325\n",
      " 1.11068981 1.11002008 1.10915755 1.10963695 1.11107212 1.11259768\n",
      " 1.11240725 1.11240725 1.11297814 1.11335828 1.11430722 1.11591528]\n",
      "Test RMSE: 0.001\n",
      "Train on 557 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "557/557 [==============================] - 0s 83us/sample - loss: 0.0235 - val_loss: 0.0235\n",
      "Epoch 2/50\n",
      "557/557 [==============================] - 0s 82us/sample - loss: 0.0239 - val_loss: 0.0237\n",
      "Epoch 3/50\n",
      "557/557 [==============================] - 0s 78us/sample - loss: 0.0236 - val_loss: 0.0235\n",
      "Epoch 4/50\n",
      "557/557 [==============================] - 0s 79us/sample - loss: 0.0235 - val_loss: 0.0237\n",
      "Epoch 5/50\n",
      "557/557 [==============================] - 0s 82us/sample - loss: 0.0234 - val_loss: 0.0234\n",
      "Epoch 6/50\n",
      "557/557 [==============================] - 0s 84us/sample - loss: 0.0234 - val_loss: 0.0239\n",
      "Epoch 7/50\n",
      "557/557 [==============================] - 0s 82us/sample - loss: 0.0234 - val_loss: 0.0233\n",
      "Epoch 8/50\n",
      "557/557 [==============================] - 0s 83us/sample - loss: 0.0235 - val_loss: 0.0237\n",
      "Epoch 9/50\n",
      "557/557 [==============================] - 0s 82us/sample - loss: 0.0233 - val_loss: 0.0234\n",
      "Epoch 10/50\n",
      "557/557 [==============================] - 0s 84us/sample - loss: 0.0233 - val_loss: 0.0238\n",
      "Epoch 11/50\n",
      "557/557 [==============================] - 0s 81us/sample - loss: 0.0233 - val_loss: 0.0234\n",
      "Epoch 12/50\n",
      "557/557 [==============================] - 0s 79us/sample - loss: 0.0233 - val_loss: 0.0238\n",
      "Epoch 13/50\n",
      "557/557 [==============================] - 0s 79us/sample - loss: 0.0233 - val_loss: 0.0235\n",
      "Epoch 14/50\n",
      "557/557 [==============================] - 0s 79us/sample - loss: 0.0233 - val_loss: 0.0238\n",
      "Epoch 15/50\n",
      "557/557 [==============================] - 0s 81us/sample - loss: 0.0233 - val_loss: 0.0235\n",
      "Epoch 16/50\n",
      "557/557 [==============================] - 0s 79us/sample - loss: 0.0233 - val_loss: 0.0235\n",
      "Epoch 17/50\n",
      "557/557 [==============================] - 0s 77us/sample - loss: 0.0232 - val_loss: 0.0235\n",
      "Epoch 18/50\n",
      "557/557 [==============================] - 0s 82us/sample - loss: 0.0232 - val_loss: 0.0234\n",
      "Epoch 19/50\n",
      "557/557 [==============================] - 0s 82us/sample - loss: 0.0233 - val_loss: 0.0239\n",
      "Epoch 20/50\n",
      "557/557 [==============================] - 0s 80us/sample - loss: 0.0234 - val_loss: 0.0232\n",
      "Epoch 21/50\n",
      "557/557 [==============================] - 0s 82us/sample - loss: 0.0235 - val_loss: 0.0238\n",
      "Epoch 22/50\n",
      "557/557 [==============================] - 0s 84us/sample - loss: 0.0233 - val_loss: 0.0236\n",
      "Epoch 23/50\n",
      "557/557 [==============================] - 0s 80us/sample - loss: 0.0232 - val_loss: 0.0234\n",
      "Epoch 24/50\n",
      "557/557 [==============================] - 0s 80us/sample - loss: 0.0233 - val_loss: 0.0239\n",
      "Epoch 25/50\n",
      "557/557 [==============================] - 0s 81us/sample - loss: 0.0233 - val_loss: 0.0233\n",
      "Epoch 26/50\n",
      "557/557 [==============================] - 0s 80us/sample - loss: 0.0234 - val_loss: 0.0238\n",
      "Epoch 27/50\n",
      "557/557 [==============================] - 0s 80us/sample - loss: 0.0233 - val_loss: 0.0236\n",
      "Epoch 28/50\n",
      "557/557 [==============================] - 0s 78us/sample - loss: 0.0232 - val_loss: 0.0233\n",
      "Epoch 29/50\n",
      "557/557 [==============================] - 0s 80us/sample - loss: 0.0234 - val_loss: 0.0239\n",
      "Epoch 30/50\n",
      "557/557 [==============================] - 0s 83us/sample - loss: 0.0233 - val_loss: 0.0232\n",
      "Epoch 31/50\n",
      "557/557 [==============================] - 0s 87us/sample - loss: 0.0235 - val_loss: 0.0238\n",
      "Epoch 32/50\n",
      "557/557 [==============================] - 0s 82us/sample - loss: 0.0233 - val_loss: 0.0235\n",
      "Epoch 33/50\n",
      "557/557 [==============================] - 0s 79us/sample - loss: 0.0232 - val_loss: 0.0238\n",
      "Epoch 34/50\n",
      "557/557 [==============================] - 0s 83us/sample - loss: 0.0233 - val_loss: 0.0235\n",
      "Epoch 35/50\n",
      "557/557 [==============================] - 0s 78us/sample - loss: 0.0232 - val_loss: 0.0235\n",
      "Epoch 36/50\n",
      "557/557 [==============================] - 0s 80us/sample - loss: 0.0232 - val_loss: 0.0235\n",
      "Epoch 37/50\n",
      "557/557 [==============================] - 0s 79us/sample - loss: 0.0232 - val_loss: 0.0235\n",
      "Epoch 38/50\n",
      "557/557 [==============================] - 0s 79us/sample - loss: 0.0232 - val_loss: 0.0234\n",
      "Epoch 39/50\n",
      "557/557 [==============================] - 0s 79us/sample - loss: 0.0233 - val_loss: 0.0239\n",
      "Epoch 40/50\n",
      "557/557 [==============================] - 0s 80us/sample - loss: 0.0233 - val_loss: 0.0232\n",
      "Epoch 41/50\n",
      "557/557 [==============================] - 0s 77us/sample - loss: 0.0235 - val_loss: 0.0239\n",
      "Epoch 42/50\n",
      "557/557 [==============================] - 0s 77us/sample - loss: 0.0233 - val_loss: 0.0232\n",
      "Epoch 43/50\n",
      "557/557 [==============================] - 0s 79us/sample - loss: 0.0235 - val_loss: 0.0239\n",
      "Epoch 44/50\n",
      "557/557 [==============================] - 0s 78us/sample - loss: 0.0233 - val_loss: 0.0233\n",
      "Epoch 45/50\n",
      "557/557 [==============================] - 0s 77us/sample - loss: 0.0234 - val_loss: 0.0238\n",
      "Epoch 46/50\n",
      "557/557 [==============================] - 0s 79us/sample - loss: 0.0233 - val_loss: 0.0236\n",
      "Epoch 47/50\n",
      "557/557 [==============================] - 0s 87us/sample - loss: 0.0232 - val_loss: 0.0234\n",
      "Epoch 48/50\n",
      "557/557 [==============================] - 0s 86us/sample - loss: 0.0233 - val_loss: 0.0240\n",
      "Epoch 49/50\n",
      "557/557 [==============================] - 0s 85us/sample - loss: 0.0234 - val_loss: 0.0232\n",
      "Epoch 50/50\n",
      "557/557 [==============================] - 0s 82us/sample - loss: 0.0237 - val_loss: 0.0238\n",
      "第218个数，还剩3905个没有训练\n",
      "inv_hat [1.02938088 1.00931342 1.00852471 1.0082289  0.98750463 0.98926575\n",
      " 0.99191005 1.00487888 0.995048   1.00005732 1.02522223 1.0321548\n",
      " 1.0389948  1.01681582 1.01424751 1.01010244 1.02146222 1.02334194\n",
      " 1.02621217 1.01237182 1.00143412 0.99455746 0.98496338 0.97959839\n",
      " 0.97444336 0.98125508 0.98408442 0.9805727  0.97590079 0.9792088 ]\n",
      "Test RMSE: 0.011\n",
      "Train on 886 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "886/886 [==============================] - 0s 86us/sample - loss: 0.0109 - val_loss: 0.0090\n",
      "Epoch 2/50\n",
      "886/886 [==============================] - 0s 82us/sample - loss: 0.0110 - val_loss: 0.0095\n",
      "Epoch 3/50\n",
      "886/886 [==============================] - 0s 79us/sample - loss: 0.0113 - val_loss: 0.0150\n",
      "Epoch 4/50\n",
      "886/886 [==============================] - 0s 85us/sample - loss: 0.0119 - val_loss: 0.0093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "886/886 [==============================] - 0s 82us/sample - loss: 0.0118 - val_loss: 0.0090\n",
      "Epoch 6/50\n",
      "886/886 [==============================] - 0s 78us/sample - loss: 0.0095 - val_loss: 0.0090\n",
      "Epoch 7/50\n",
      "886/886 [==============================] - 0s 79us/sample - loss: 0.0102 - val_loss: 0.0090\n",
      "Epoch 8/50\n",
      "886/886 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0128\n",
      "Epoch 9/50\n",
      "886/886 [==============================] - 0s 79us/sample - loss: 0.0127 - val_loss: 0.0097\n",
      "Epoch 10/50\n",
      "886/886 [==============================] - 0s 87us/sample - loss: 0.0130 - val_loss: 0.0119\n",
      "Epoch 11/50\n",
      "886/886 [==============================] - 0s 86us/sample - loss: 0.0150 - val_loss: 0.0114\n",
      "Epoch 12/50\n",
      "886/886 [==============================] - 0s 83us/sample - loss: 0.0229 - val_loss: 0.0293\n",
      "Epoch 13/50\n",
      "886/886 [==============================] - 0s 82us/sample - loss: 0.0108 - val_loss: 0.0090\n",
      "Epoch 14/50\n",
      "886/886 [==============================] - 0s 89us/sample - loss: 0.0110 - val_loss: 0.0106\n",
      "Epoch 15/50\n",
      "886/886 [==============================] - 0s 87us/sample - loss: 0.0123 - val_loss: 0.0103\n",
      "Epoch 16/50\n",
      "886/886 [==============================] - 0s 82us/sample - loss: 0.0108 - val_loss: 0.0116\n",
      "Epoch 17/50\n",
      "886/886 [==============================] - 0s 84us/sample - loss: 0.0133 - val_loss: 0.0100\n",
      "Epoch 18/50\n",
      "886/886 [==============================] - 0s 85us/sample - loss: 0.0153 - val_loss: 0.0099\n",
      "Epoch 19/50\n",
      "886/886 [==============================] - 0s 83us/sample - loss: 0.0179 - val_loss: 0.0089\n",
      "Epoch 20/50\n",
      "886/886 [==============================] - 0s 85us/sample - loss: 0.0143 - val_loss: 0.0113\n",
      "Epoch 21/50\n",
      "886/886 [==============================] - 0s 79us/sample - loss: 0.0155 - val_loss: 0.0092\n",
      "Epoch 22/50\n",
      "886/886 [==============================] - 0s 80us/sample - loss: 0.0159 - val_loss: 0.0133\n",
      "Epoch 23/50\n",
      "886/886 [==============================] - 0s 80us/sample - loss: 0.0148 - val_loss: 0.0096\n",
      "Epoch 24/50\n",
      "886/886 [==============================] - 0s 86us/sample - loss: 0.0139 - val_loss: 0.0106\n",
      "Epoch 25/50\n",
      "886/886 [==============================] - 0s 86us/sample - loss: 0.0150 - val_loss: 0.0093\n",
      "Epoch 26/50\n",
      "886/886 [==============================] - 0s 83us/sample - loss: 0.0154 - val_loss: 0.0125\n",
      "Epoch 27/50\n",
      "886/886 [==============================] - 0s 80us/sample - loss: 0.0147 - val_loss: 0.0092\n",
      "Epoch 28/50\n",
      "886/886 [==============================] - 0s 78us/sample - loss: 0.0142 - val_loss: 0.0112\n",
      "Epoch 29/50\n",
      "886/886 [==============================] - 0s 80us/sample - loss: 0.0146 - val_loss: 0.0093\n",
      "Epoch 30/50\n",
      "886/886 [==============================] - 0s 79us/sample - loss: 0.0151 - val_loss: 0.0123\n",
      "Epoch 31/50\n",
      "886/886 [==============================] - 0s 79us/sample - loss: 0.0145 - val_loss: 0.0092\n",
      "Epoch 32/50\n",
      "886/886 [==============================] - 0s 79us/sample - loss: 0.0139 - val_loss: 0.0114\n",
      "Epoch 33/50\n",
      "886/886 [==============================] - 0s 82us/sample - loss: 0.0140 - val_loss: 0.0094\n",
      "Epoch 34/50\n",
      "886/886 [==============================] - 0s 79us/sample - loss: 0.0148 - val_loss: 0.0118\n",
      "Epoch 35/50\n",
      "886/886 [==============================] - 0s 82us/sample - loss: 0.0145 - val_loss: 0.0091\n",
      "Epoch 36/50\n",
      "886/886 [==============================] - 0s 83us/sample - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 37/50\n",
      "886/886 [==============================] - 0s 91us/sample - loss: 0.0135 - val_loss: 0.0094\n",
      "Epoch 38/50\n",
      "886/886 [==============================] - 0s 83us/sample - loss: 0.0145 - val_loss: 0.0115\n",
      "Epoch 39/50\n",
      "886/886 [==============================] - 0s 83us/sample - loss: 0.0148 - val_loss: 0.0093\n",
      "Epoch 40/50\n",
      "886/886 [==============================] - 0s 88us/sample - loss: 0.0138 - val_loss: 0.0121\n",
      "Epoch 41/50\n",
      "886/886 [==============================] - 0s 85us/sample - loss: 0.0127 - val_loss: 0.0093\n",
      "Epoch 42/50\n",
      "886/886 [==============================] - 0s 81us/sample - loss: 0.0148 - val_loss: 0.0121\n",
      "Epoch 43/50\n",
      "886/886 [==============================] - 0s 83us/sample - loss: 0.0143 - val_loss: 0.0093\n",
      "Epoch 44/50\n",
      "886/886 [==============================] - 0s 81us/sample - loss: 0.0134 - val_loss: 0.0113\n",
      "Epoch 45/50\n",
      "886/886 [==============================] - 0s 82us/sample - loss: 0.0128 - val_loss: 0.0095\n",
      "Epoch 46/50\n",
      "886/886 [==============================] - 0s 84us/sample - loss: 0.0146 - val_loss: 0.0121\n",
      "Epoch 47/50\n",
      "886/886 [==============================] - 0s 81us/sample - loss: 0.0138 - val_loss: 0.0092\n",
      "Epoch 48/50\n",
      "886/886 [==============================] - 0s 86us/sample - loss: 0.0130 - val_loss: 0.0108\n",
      "Epoch 49/50\n",
      "886/886 [==============================] - 0s 85us/sample - loss: 0.0134 - val_loss: 0.0094\n",
      "Epoch 50/50\n",
      "886/886 [==============================] - 0s 85us/sample - loss: 0.0139 - val_loss: 0.0113\n",
      "第219个数，还剩3904个没有训练\n",
      "inv_hat [1.15510642 1.15501073 1.15501073 1.15501073 1.15491501 1.15491501\n",
      " 1.15481932 1.15481932 1.15481932 1.15481932 1.15472359 1.15414933\n",
      " 1.15127526 1.1431122  1.14378542 1.13820347 1.13781825 1.14138052\n",
      " 1.14753322 1.14205409 1.14195785 1.14003291 1.13762559 1.12866189\n",
      " 1.12509438 1.12663707 1.12875829 1.130301   1.1299153  1.13184346]\n",
      "Test RMSE: 0.003\n",
      "Train on 1142 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1142/1142 [==============================] - 0s 78us/sample - loss: 0.0145 - val_loss: 0.0090\n",
      "Epoch 2/50\n",
      "1142/1142 [==============================] - 0s 74us/sample - loss: 0.0133 - val_loss: 0.0114\n",
      "Epoch 3/50\n",
      "1142/1142 [==============================] - 0s 77us/sample - loss: 0.0130 - val_loss: 0.0092\n",
      "Epoch 4/50\n",
      "1142/1142 [==============================] - 0s 76us/sample - loss: 0.0128 - val_loss: 0.0089\n",
      "Epoch 5/50\n",
      "1142/1142 [==============================] - 0s 77us/sample - loss: 0.0129 - val_loss: 0.0094\n",
      "Epoch 6/50\n",
      "1142/1142 [==============================] - 0s 75us/sample - loss: 0.0129 - val_loss: 0.0103\n",
      "Epoch 7/50\n",
      "1142/1142 [==============================] - 0s 77us/sample - loss: 0.0129 - val_loss: 0.0095\n",
      "Epoch 8/50\n",
      "1142/1142 [==============================] - 0s 76us/sample - loss: 0.0128 - val_loss: 0.0091\n",
      "Epoch 9/50\n",
      "1142/1142 [==============================] - 0s 81us/sample - loss: 0.0128 - val_loss: 0.0091\n",
      "Epoch 10/50\n",
      "1142/1142 [==============================] - 0s 77us/sample - loss: 0.0129 - val_loss: 0.0098\n",
      "Epoch 11/50\n",
      "1142/1142 [==============================] - 0s 74us/sample - loss: 0.0129 - val_loss: 0.0098\n",
      "Epoch 12/50\n",
      "1142/1142 [==============================] - 0s 73us/sample - loss: 0.0129 - val_loss: 0.0093\n",
      "Epoch 13/50\n",
      "1142/1142 [==============================] - 0s 75us/sample - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 14/50\n",
      "1142/1142 [==============================] - 0s 73us/sample - loss: 0.0128 - val_loss: 0.0094\n",
      "Epoch 15/50\n",
      "1142/1142 [==============================] - 0s 75us/sample - loss: 0.0129 - val_loss: 0.0096\n",
      "Epoch 16/50\n",
      "1142/1142 [==============================] - 0s 78us/sample - loss: 0.0129 - val_loss: 0.0098\n",
      "Epoch 17/50\n",
      "1142/1142 [==============================] - 0s 79us/sample - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 18/50\n",
      "1142/1142 [==============================] - 0s 80us/sample - loss: 0.0129 - val_loss: 0.0095\n",
      "Epoch 19/50\n",
      "1142/1142 [==============================] - 0s 77us/sample - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 20/50\n",
      "1142/1142 [==============================] - 0s 73us/sample - loss: 0.0129 - val_loss: 0.0096\n",
      "Epoch 21/50\n",
      "1142/1142 [==============================] - 0s 75us/sample - loss: 0.0129 - val_loss: 0.0094\n",
      "Epoch 22/50\n",
      "1142/1142 [==============================] - 0s 75us/sample - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 23/50\n",
      "1142/1142 [==============================] - 0s 74us/sample - loss: 0.0129 - val_loss: 0.0098\n",
      "Epoch 24/50\n",
      "1142/1142 [==============================] - 0s 73us/sample - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 25/50\n",
      "1142/1142 [==============================] - 0s 77us/sample - loss: 0.0129 - val_loss: 0.0096\n",
      "Epoch 26/50\n",
      "1142/1142 [==============================] - 0s 79us/sample - loss: 0.0129 - val_loss: 0.0100\n",
      "Epoch 27/50\n",
      "1142/1142 [==============================] - 0s 74us/sample - loss: 0.0129 - val_loss: 0.0096\n",
      "Epoch 28/50\n",
      "1142/1142 [==============================] - 0s 76us/sample - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 29/50\n",
      "1142/1142 [==============================] - 0s 73us/sample - loss: 0.0128 - val_loss: 0.0094\n",
      "Epoch 30/50\n",
      "1142/1142 [==============================] - 0s 83us/sample - loss: 0.0128 - val_loss: 0.0095\n",
      "Epoch 31/50\n",
      "1142/1142 [==============================] - 0s 76us/sample - loss: 0.0129 - val_loss: 0.0096\n",
      "Epoch 32/50\n",
      "1142/1142 [==============================] - 0s 76us/sample - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 33/50\n",
      "1142/1142 [==============================] - 0s 78us/sample - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 34/50\n",
      "1142/1142 [==============================] - 0s 76us/sample - loss: 0.0129 - val_loss: 0.0096\n",
      "Epoch 35/50\n",
      "1142/1142 [==============================] - 0s 74us/sample - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 36/50\n",
      "1142/1142 [==============================] - 0s 80us/sample - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 37/50\n",
      "1142/1142 [==============================] - 0s 83us/sample - loss: 0.0129 - val_loss: 0.0096\n",
      "Epoch 38/50\n",
      "1142/1142 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 39/50\n",
      "1142/1142 [==============================] - 0s 83us/sample - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 40/50\n",
      "1142/1142 [==============================] - 0s 80us/sample - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 41/50\n",
      "1142/1142 [==============================] - 0s 78us/sample - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 42/50\n",
      "1142/1142 [==============================] - 0s 80us/sample - loss: 0.0129 - val_loss: 0.0096\n",
      "Epoch 43/50\n",
      "1142/1142 [==============================] - 0s 77us/sample - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 44/50\n",
      "1142/1142 [==============================] - 0s 80us/sample - loss: 0.0129 - val_loss: 0.0096\n",
      "Epoch 45/50\n",
      "1142/1142 [==============================] - 0s 78us/sample - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 46/50\n",
      "1142/1142 [==============================] - 0s 77us/sample - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 47/50\n",
      "1142/1142 [==============================] - 0s 75us/sample - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 48/50\n",
      "1142/1142 [==============================] - 0s 75us/sample - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 49/50\n",
      "1142/1142 [==============================] - 0s 76us/sample - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 50/50\n",
      "1142/1142 [==============================] - 0s 77us/sample - loss: 0.0129 - val_loss: 0.0097\n",
      "第220个数，还剩3903个没有训练\n",
      "inv_hat [1.37685042 1.32231089 1.31928341 1.31928341 1.27996218 1.26687193\n",
      " 1.26385249 1.29003772 1.26687193 1.28197685 1.32937603 1.32937603\n",
      " 1.32432933 1.2890299  1.2930614  1.27391935 1.27694051 1.2779477\n",
      " 1.3031433  1.27089874 1.25680926 1.24574752 1.22666047 1.22666047\n",
      " 1.21361622 1.22264539 1.21662527 1.2035914  1.19357504 1.19758049]\n",
      "Test RMSE: 0.021\n",
      "Train on 737 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "737/737 [==============================] - 0s 89us/sample - loss: 0.0161 - val_loss: 0.0255\n",
      "Epoch 2/50\n",
      "737/737 [==============================] - 0s 85us/sample - loss: 0.0168 - val_loss: 0.0244\n",
      "Epoch 3/50\n",
      "737/737 [==============================] - 0s 82us/sample - loss: 0.0162 - val_loss: 0.0262\n",
      "Epoch 4/50\n",
      "737/737 [==============================] - 0s 87us/sample - loss: 0.0169 - val_loss: 0.0243\n",
      "Epoch 5/50\n",
      "737/737 [==============================] - 0s 84us/sample - loss: 0.0158 - val_loss: 0.0273\n",
      "Epoch 6/50\n",
      "737/737 [==============================] - 0s 89us/sample - loss: 0.0169 - val_loss: 0.0243\n",
      "Epoch 7/50\n",
      "737/737 [==============================] - 0s 86us/sample - loss: 0.0154 - val_loss: 0.0271\n",
      "Epoch 8/50\n",
      "737/737 [==============================] - 0s 79us/sample - loss: 0.0165 - val_loss: 0.0242\n",
      "Epoch 9/50\n",
      "737/737 [==============================] - 0s 79us/sample - loss: 0.0158 - val_loss: 0.0279\n",
      "Epoch 10/50\n",
      "737/737 [==============================] - 0s 81us/sample - loss: 0.0169 - val_loss: 0.0243\n",
      "Epoch 11/50\n",
      "737/737 [==============================] - 0s 84us/sample - loss: 0.0154 - val_loss: 0.0267\n",
      "Epoch 12/50\n",
      "737/737 [==============================] - 0s 83us/sample - loss: 0.0164 - val_loss: 0.0242\n",
      "Epoch 13/50\n",
      "737/737 [==============================] - 0s 84us/sample - loss: 0.0157 - val_loss: 0.0281\n",
      "Epoch 14/50\n",
      "737/737 [==============================] - 0s 86us/sample - loss: 0.0167 - val_loss: 0.0245\n",
      "Epoch 15/50\n",
      "737/737 [==============================] - 0s 86us/sample - loss: 0.0152 - val_loss: 0.0255\n",
      "Epoch 16/50\n",
      "737/737 [==============================] - 0s 80us/sample - loss: 0.0154 - val_loss: 0.0245\n",
      "Epoch 17/50\n",
      "737/737 [==============================] - 0s 80us/sample - loss: 0.0154 - val_loss: 0.0244\n",
      "Epoch 18/50\n",
      "737/737 [==============================] - 0s 82us/sample - loss: 0.0161 - val_loss: 0.0242\n",
      "Epoch 19/50\n",
      "737/737 [==============================] - 0s 82us/sample - loss: 0.0154 - val_loss: 0.0259\n",
      "Epoch 20/50\n",
      "737/737 [==============================] - 0s 79us/sample - loss: 0.0158 - val_loss: 0.0258\n",
      "Epoch 21/50\n",
      "737/737 [==============================] - 0s 84us/sample - loss: 0.0157 - val_loss: 0.0243\n",
      "Epoch 22/50\n",
      "737/737 [==============================] - 0s 82us/sample - loss: 0.0153 - val_loss: 0.0244\n",
      "Epoch 23/50\n",
      "737/737 [==============================] - 0s 84us/sample - loss: 0.0150 - val_loss: 0.0254\n",
      "Epoch 24/50\n",
      "737/737 [==============================] - 0s 85us/sample - loss: 0.0151 - val_loss: 0.0249\n",
      "Epoch 25/50\n",
      "737/737 [==============================] - 0s 82us/sample - loss: 0.0151 - val_loss: 0.0250\n",
      "Epoch 26/50\n",
      "737/737 [==============================] - 0s 82us/sample - loss: 0.0160 - val_loss: 0.0242\n",
      "Epoch 27/50\n",
      "737/737 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0249\n",
      "Epoch 28/50\n",
      "737/737 [==============================] - 0s 78us/sample - loss: 0.0150 - val_loss: 0.0253\n",
      "Epoch 29/50\n",
      "737/737 [==============================] - 0s 78us/sample - loss: 0.0151 - val_loss: 0.0247\n",
      "Epoch 30/50\n",
      "737/737 [==============================] - 0s 84us/sample - loss: 0.0156 - val_loss: 0.0241\n",
      "Epoch 31/50\n",
      "737/737 [==============================] - 0s 84us/sample - loss: 0.0157 - val_loss: 0.0257\n",
      "Epoch 32/50\n",
      "737/737 [==============================] - 0s 80us/sample - loss: 0.0156 - val_loss: 0.0260\n",
      "Epoch 33/50\n",
      "737/737 [==============================] - 0s 82us/sample - loss: 0.0160 - val_loss: 0.0241\n",
      "Epoch 34/50\n",
      "737/737 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0257\n",
      "Epoch 35/50\n",
      "737/737 [==============================] - 0s 83us/sample - loss: 0.0150 - val_loss: 0.0255\n",
      "Epoch 36/50\n",
      "737/737 [==============================] - 0s 79us/sample - loss: 0.0149 - val_loss: 0.0248\n",
      "Epoch 37/50\n",
      "737/737 [==============================] - 0s 82us/sample - loss: 0.0155 - val_loss: 0.0243\n",
      "Epoch 38/50\n",
      "737/737 [==============================] - 0s 84us/sample - loss: 0.0155 - val_loss: 0.0263\n",
      "Epoch 39/50\n",
      "737/737 [==============================] - 0s 83us/sample - loss: 0.0154 - val_loss: 0.0267\n",
      "Epoch 40/50\n",
      "737/737 [==============================] - 0s 79us/sample - loss: 0.0155 - val_loss: 0.0251\n",
      "Epoch 41/50\n",
      "737/737 [==============================] - 0s 81us/sample - loss: 0.0153 - val_loss: 0.0243\n",
      "Epoch 42/50\n",
      "737/737 [==============================] - 0s 85us/sample - loss: 0.0156 - val_loss: 0.0267\n",
      "Epoch 43/50\n",
      "737/737 [==============================] - 0s 83us/sample - loss: 0.0158 - val_loss: 0.0272\n",
      "Epoch 44/50\n",
      "737/737 [==============================] - 0s 84us/sample - loss: 0.0160 - val_loss: 0.0242\n",
      "Epoch 45/50\n",
      "737/737 [==============================] - 0s 88us/sample - loss: 0.0161 - val_loss: 0.0286\n",
      "Epoch 46/50\n",
      "737/737 [==============================] - 0s 89us/sample - loss: 0.0159 - val_loss: 0.0250\n",
      "Epoch 47/50\n",
      "737/737 [==============================] - 0s 85us/sample - loss: 0.0158 - val_loss: 0.0291\n",
      "Epoch 48/50\n",
      "737/737 [==============================] - 0s 89us/sample - loss: 0.0160 - val_loss: 0.0253\n",
      "Epoch 49/50\n",
      "737/737 [==============================] - 0s 86us/sample - loss: 0.0150 - val_loss: 0.0246\n",
      "Epoch 50/50\n",
      "737/737 [==============================] - 0s 87us/sample - loss: 0.0152 - val_loss: 0.0262\n",
      "第221个数，还剩3902个没有训练\n",
      "inv_hat [0.99839281 0.99354788 0.99354788 0.99354788 0.98877918 0.98783612\n",
      " 0.98783612 0.98972604 0.98783612 0.99067644 0.9964468  0.99741854\n",
      " 0.9954777  0.9916303  0.9925875  0.99067644 0.9916303  0.9925875\n",
      " 0.99741854 0.99354788 0.9925875  0.99067644 0.98877918 0.98689693\n",
      " 0.98503072 0.98596176 0.98503072 0.98596176 0.9841039  0.98596176]\n",
      "Test RMSE: 0.003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1172 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1172/1172 [==============================] - 0s 81us/sample - loss: 0.0105 - val_loss: 0.0057\n",
      "Epoch 2/50\n",
      "1172/1172 [==============================] - 0s 81us/sample - loss: 0.0105 - val_loss: 0.0055\n",
      "Epoch 3/50\n",
      "1172/1172 [==============================] - 0s 85us/sample - loss: 0.0104 - val_loss: 0.0055\n",
      "Epoch 4/50\n",
      "1172/1172 [==============================] - 0s 78us/sample - loss: 0.0106 - val_loss: 0.0055\n",
      "Epoch 5/50\n",
      "1172/1172 [==============================] - 0s 77us/sample - loss: 0.0102 - val_loss: 0.0055\n",
      "Epoch 6/50\n",
      "1172/1172 [==============================] - 0s 85us/sample - loss: 0.0107 - val_loss: 0.0056\n",
      "Epoch 7/50\n",
      "1172/1172 [==============================] - 0s 76us/sample - loss: 0.0101 - val_loss: 0.0054\n",
      "Epoch 8/50\n",
      "1172/1172 [==============================] - 0s 79us/sample - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 9/50\n",
      "1172/1172 [==============================] - 0s 81us/sample - loss: 0.0107 - val_loss: 0.0059\n",
      "Epoch 10/50\n",
      "1172/1172 [==============================] - 0s 83us/sample - loss: 0.0105 - val_loss: 0.0057\n",
      "Epoch 11/50\n",
      "1172/1172 [==============================] - 0s 82us/sample - loss: 0.0097 - val_loss: 0.0054\n",
      "Epoch 12/50\n",
      "1172/1172 [==============================] - 0s 82us/sample - loss: 0.0093 - val_loss: 0.0055\n",
      "Epoch 13/50\n",
      "1172/1172 [==============================] - 0s 79us/sample - loss: 0.0101 - val_loss: 0.0056\n",
      "Epoch 14/50\n",
      "1172/1172 [==============================] - 0s 80us/sample - loss: 0.0106 - val_loss: 0.0060\n",
      "Epoch 15/50\n",
      "1172/1172 [==============================] - 0s 85us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 16/50\n",
      "1172/1172 [==============================] - 0s 83us/sample - loss: 0.0094 - val_loss: 0.0054\n",
      "Epoch 17/50\n",
      "1172/1172 [==============================] - 0s 84us/sample - loss: 0.0097 - val_loss: 0.0054\n",
      "Epoch 18/50\n",
      "1172/1172 [==============================] - 0s 84us/sample - loss: 0.0103 - val_loss: 0.0059\n",
      "Epoch 19/50\n",
      "1172/1172 [==============================] - 0s 84us/sample - loss: 0.0100 - val_loss: 0.0058\n",
      "Epoch 20/50\n",
      "1172/1172 [==============================] - 0s 81us/sample - loss: 0.0096 - val_loss: 0.0054\n",
      "Epoch 21/50\n",
      "1172/1172 [==============================] - 0s 84us/sample - loss: 0.0095 - val_loss: 0.0054\n",
      "Epoch 22/50\n",
      "1172/1172 [==============================] - 0s 80us/sample - loss: 0.0096 - val_loss: 0.0054\n",
      "Epoch 23/50\n",
      "1172/1172 [==============================] - 0s 79us/sample - loss: 0.0100 - val_loss: 0.0059\n",
      "Epoch 24/50\n",
      "1172/1172 [==============================] - 0s 89us/sample - loss: 0.0104 - val_loss: 0.0062\n",
      "Epoch 25/50\n",
      "1172/1172 [==============================] - 0s 82us/sample - loss: 0.0095 - val_loss: 0.0054\n",
      "Epoch 26/50\n",
      "1172/1172 [==============================] - 0s 83us/sample - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 27/50\n",
      "1172/1172 [==============================] - 0s 84us/sample - loss: 0.0096 - val_loss: 0.0054\n",
      "Epoch 28/50\n",
      "1172/1172 [==============================] - 0s 80us/sample - loss: 0.0090 - val_loss: 0.0055\n",
      "Epoch 29/50\n",
      "1172/1172 [==============================] - 0s 85us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 30/50\n",
      "1172/1172 [==============================] - 0s 86us/sample - loss: 0.0096 - val_loss: 0.0055\n",
      "Epoch 31/50\n",
      "1172/1172 [==============================] - 0s 83us/sample - loss: 0.0095 - val_loss: 0.0055\n",
      "Epoch 32/50\n",
      "1172/1172 [==============================] - 0s 80us/sample - loss: 0.0102 - val_loss: 0.0062\n",
      "Epoch 33/50\n",
      "1172/1172 [==============================] - 0s 78us/sample - loss: 0.0098 - val_loss: 0.0056\n",
      "Epoch 34/50\n",
      "1172/1172 [==============================] - 0s 78us/sample - loss: 0.0091 - val_loss: 0.0055\n",
      "Epoch 35/50\n",
      "1172/1172 [==============================] - 0s 78us/sample - loss: 0.0095 - val_loss: 0.0054\n",
      "Epoch 36/50\n",
      "1172/1172 [==============================] - 0s 77us/sample - loss: 0.0096 - val_loss: 0.0055\n",
      "Epoch 37/50\n",
      "1172/1172 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0059\n",
      "Epoch 38/50\n",
      "1172/1172 [==============================] - 0s 83us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 39/50\n",
      "1172/1172 [==============================] - 0s 83us/sample - loss: 0.0091 - val_loss: 0.0054\n",
      "Epoch 40/50\n",
      "1172/1172 [==============================] - 0s 85us/sample - loss: 0.0090 - val_loss: 0.0056\n",
      "Epoch 41/50\n",
      "1172/1172 [==============================] - 0s 85us/sample - loss: 0.0095 - val_loss: 0.0055\n",
      "Epoch 42/50\n",
      "1172/1172 [==============================] - 0s 82us/sample - loss: 0.0090 - val_loss: 0.0059\n",
      "Epoch 43/50\n",
      "1172/1172 [==============================] - 0s 82us/sample - loss: 0.0098 - val_loss: 0.0054\n",
      "Epoch 44/50\n",
      "1172/1172 [==============================] - 0s 80us/sample - loss: 0.0090 - val_loss: 0.0055\n",
      "Epoch 45/50\n",
      "1172/1172 [==============================] - 0s 77us/sample - loss: 0.0096 - val_loss: 0.0054\n",
      "Epoch 46/50\n",
      "1172/1172 [==============================] - 0s 76us/sample - loss: 0.0094 - val_loss: 0.0054\n",
      "Epoch 47/50\n",
      "1172/1172 [==============================] - 0s 83us/sample - loss: 0.0097 - val_loss: 0.0057\n",
      "Epoch 48/50\n",
      "1172/1172 [==============================] - 0s 80us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 49/50\n",
      "1172/1172 [==============================] - 0s 82us/sample - loss: 0.0093 - val_loss: 0.0054\n",
      "Epoch 50/50\n",
      "1172/1172 [==============================] - 0s 85us/sample - loss: 0.0090 - val_loss: 0.0056\n",
      "第222个数，还剩3901个没有训练\n",
      "inv_hat [1.60158568 1.56466207 1.56565976 1.56266655 1.52775319 1.51479021\n",
      " 1.51877855 1.53473441 1.5117992  1.52476142 1.55268963 1.54770156\n",
      " 1.54371144 1.52376429 1.53074505 1.51977565 1.52675589 1.53473441\n",
      " 1.55767789 1.53473441 1.52276709 1.50482086 1.48688123 1.48189933\n",
      " 1.46894921 1.47691802 1.47891042 1.46894921 1.46496556 1.46496556]\n",
      "Test RMSE: 0.016\n",
      "Train on 1158 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1158/1158 [==============================] - 0s 84us/sample - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 2/50\n",
      "1158/1158 [==============================] - 0s 86us/sample - loss: 0.0073 - val_loss: 0.0085\n",
      "Epoch 3/50\n",
      "1158/1158 [==============================] - 0s 83us/sample - loss: 0.0071 - val_loss: 0.0091\n",
      "Epoch 4/50\n",
      "1158/1158 [==============================] - 0s 86us/sample - loss: 0.0087 - val_loss: 0.0205\n",
      "Epoch 5/50\n",
      "1158/1158 [==============================] - 0s 84us/sample - loss: 0.0125 - val_loss: 0.0091\n",
      "Epoch 6/50\n",
      "1158/1158 [==============================] - 0s 83us/sample - loss: 0.0092 - val_loss: 0.0065\n",
      "Epoch 7/50\n",
      "1158/1158 [==============================] - 0s 79us/sample - loss: 0.0081 - val_loss: 0.0063\n",
      "Epoch 8/50\n",
      "1158/1158 [==============================] - 0s 78us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 9/50\n",
      "1158/1158 [==============================] - 0s 79us/sample - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 10/50\n",
      "1158/1158 [==============================] - 0s 85us/sample - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 11/50\n",
      "1158/1158 [==============================] - 0s 86us/sample - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 12/50\n",
      "1158/1158 [==============================] - 0s 84us/sample - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 13/50\n",
      "1158/1158 [==============================] - 0s 90us/sample - loss: 0.0079 - val_loss: 0.0117\n",
      "Epoch 14/50\n",
      "1158/1158 [==============================] - 0s 76us/sample - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 15/50\n",
      "1158/1158 [==============================] - 0s 77us/sample - loss: 0.0075 - val_loss: 0.0077\n",
      "Epoch 16/50\n",
      "1158/1158 [==============================] - 0s 77us/sample - loss: 0.0073 - val_loss: 0.0103\n",
      "Epoch 17/50\n",
      "1158/1158 [==============================] - 0s 76us/sample - loss: 0.0076 - val_loss: 0.0097\n",
      "Epoch 18/50\n",
      "1158/1158 [==============================] - 0s 76us/sample - loss: 0.0078 - val_loss: 0.0112\n",
      "Epoch 19/50\n",
      "1158/1158 [==============================] - 0s 76us/sample - loss: 0.0080 - val_loss: 0.0084\n",
      "Epoch 20/50\n",
      "1158/1158 [==============================] - 0s 77us/sample - loss: 0.0073 - val_loss: 0.0082\n",
      "Epoch 21/50\n",
      "1158/1158 [==============================] - 0s 82us/sample - loss: 0.0075 - val_loss: 0.0097\n",
      "Epoch 22/50\n",
      "1158/1158 [==============================] - 0s 89us/sample - loss: 0.0076 - val_loss: 0.0077\n",
      "Epoch 23/50\n",
      "1158/1158 [==============================] - 0s 84us/sample - loss: 0.0085 - val_loss: 0.0096\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1158/1158 [==============================] - 0s 81us/sample - loss: 0.0079 - val_loss: 0.0090\n",
      "Epoch 25/50\n",
      "1158/1158 [==============================] - 0s 82us/sample - loss: 0.0083 - val_loss: 0.0073\n",
      "Epoch 26/50\n",
      "1158/1158 [==============================] - 0s 77us/sample - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 27/50\n",
      "1158/1158 [==============================] - 0s 78us/sample - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 28/50\n",
      "1158/1158 [==============================] - 0s 84us/sample - loss: 0.0072 - val_loss: 0.0089\n",
      "Epoch 29/50\n",
      "1158/1158 [==============================] - 0s 84us/sample - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 30/50\n",
      "1158/1158 [==============================] - 0s 80us/sample - loss: 0.0084 - val_loss: 0.0096\n",
      "Epoch 31/50\n",
      "1158/1158 [==============================] - 0s 83us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 32/50\n",
      "1158/1158 [==============================] - 0s 82us/sample - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 33/50\n",
      "1158/1158 [==============================] - 0s 80us/sample - loss: 0.0080 - val_loss: 0.0132\n",
      "Epoch 34/50\n",
      "1158/1158 [==============================] - 0s 79us/sample - loss: 0.0103 - val_loss: 0.0086\n",
      "Epoch 35/50\n",
      "1158/1158 [==============================] - 0s 81us/sample - loss: 0.0083 - val_loss: 0.0070\n",
      "Epoch 36/50\n",
      "1158/1158 [==============================] - 0s 83us/sample - loss: 0.0077 - val_loss: 0.0066\n",
      "Epoch 37/50\n",
      "1158/1158 [==============================] - 0s 82us/sample - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 38/50\n",
      "1158/1158 [==============================] - 0s 83us/sample - loss: 0.0074 - val_loss: 0.0094\n",
      "Epoch 39/50\n",
      "1158/1158 [==============================] - 0s 84us/sample - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 40/50\n",
      "1158/1158 [==============================] - 0s 83us/sample - loss: 0.0079 - val_loss: 0.0135\n",
      "Epoch 41/50\n",
      "1158/1158 [==============================] - 0s 76us/sample - loss: 0.0103 - val_loss: 0.0074\n",
      "Epoch 42/50\n",
      "1158/1158 [==============================] - 0s 79us/sample - loss: 0.0080 - val_loss: 0.0065\n",
      "Epoch 43/50\n",
      "1158/1158 [==============================] - 0s 77us/sample - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 44/50\n",
      "1158/1158 [==============================] - 0s 78us/sample - loss: 0.0066 - val_loss: 0.0080\n",
      "Epoch 45/50\n",
      "1158/1158 [==============================] - 0s 81us/sample - loss: 0.0083 - val_loss: 0.0093\n",
      "Epoch 46/50\n",
      "1158/1158 [==============================] - 0s 80us/sample - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 47/50\n",
      "1158/1158 [==============================] - 0s 78us/sample - loss: 0.0074 - val_loss: 0.0106\n",
      "Epoch 48/50\n",
      "1158/1158 [==============================] - 0s 81us/sample - loss: 0.0077 - val_loss: 0.0109\n",
      "Epoch 49/50\n",
      "1158/1158 [==============================] - 0s 78us/sample - loss: 0.0077 - val_loss: 0.0099\n",
      "Epoch 50/50\n",
      "1158/1158 [==============================] - 0s 78us/sample - loss: 0.0075 - val_loss: 0.0079\n",
      "第223个数，还剩3900个没有训练\n",
      "inv_hat [1.02794764 1.02893844 1.02992921 1.02992921 1.03092023 1.0319113\n",
      " 1.0319113  1.03290269 1.03389433 1.03389433 1.03389433 1.03488615\n",
      " 1.03488615 1.03488615 1.03488615 1.0358784  1.03488615 1.03418094\n",
      " 1.03518472 1.03518472 1.03518472 1.03518472 1.03366231 1.03366231\n",
      " 1.03366231 1.03366231 1.03366231 1.03366231 1.03366231 1.03366231]\n",
      "Test RMSE: 0.001\n",
      "Train on 580 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "580/580 [==============================] - 0s 92us/sample - loss: 0.0154 - val_loss: 0.0469\n",
      "Epoch 2/50\n",
      "580/580 [==============================] - 0s 95us/sample - loss: 0.0163 - val_loss: 0.0437\n",
      "Epoch 3/50\n",
      "580/580 [==============================] - 0s 90us/sample - loss: 0.0141 - val_loss: 0.0465\n",
      "Epoch 4/50\n",
      "580/580 [==============================] - 0s 90us/sample - loss: 0.0161 - val_loss: 0.0437\n",
      "Epoch 5/50\n",
      "580/580 [==============================] - 0s 89us/sample - loss: 0.0134 - val_loss: 0.0458\n",
      "Epoch 6/50\n",
      "580/580 [==============================] - 0s 89us/sample - loss: 0.0152 - val_loss: 0.0439\n",
      "Epoch 7/50\n",
      "580/580 [==============================] - 0s 86us/sample - loss: 0.0124 - val_loss: 0.0463\n",
      "Epoch 8/50\n",
      "580/580 [==============================] - 0s 84us/sample - loss: 0.0157 - val_loss: 0.0439\n",
      "Epoch 9/50\n",
      "580/580 [==============================] - 0s 88us/sample - loss: 0.0140 - val_loss: 0.0465\n",
      "Epoch 10/50\n",
      "580/580 [==============================] - 0s 89us/sample - loss: 0.0156 - val_loss: 0.0439\n",
      "Epoch 11/50\n",
      "580/580 [==============================] - 0s 91us/sample - loss: 0.0134 - val_loss: 0.0453\n",
      "Epoch 12/50\n",
      "580/580 [==============================] - 0s 89us/sample - loss: 0.0140 - val_loss: 0.0450\n",
      "Epoch 13/50\n",
      "580/580 [==============================] - 0s 87us/sample - loss: 0.0137 - val_loss: 0.0447\n",
      "Epoch 14/50\n",
      "580/580 [==============================] - 0s 85us/sample - loss: 0.0125 - val_loss: 0.0446\n",
      "Epoch 15/50\n",
      "580/580 [==============================] - 0s 87us/sample - loss: 0.0129 - val_loss: 0.0445\n",
      "Epoch 16/50\n",
      "580/580 [==============================] - 0s 83us/sample - loss: 0.0134 - val_loss: 0.0445\n",
      "Epoch 17/50\n",
      "580/580 [==============================] - 0s 90us/sample - loss: 0.0126 - val_loss: 0.0451\n",
      "Epoch 18/50\n",
      "580/580 [==============================] - 0s 88us/sample - loss: 0.0136 - val_loss: 0.0453\n",
      "Epoch 19/50\n",
      "580/580 [==============================] - 0s 86us/sample - loss: 0.0138 - val_loss: 0.0443\n",
      "Epoch 20/50\n",
      "580/580 [==============================] - 0s 87us/sample - loss: 0.0135 - val_loss: 0.0449\n",
      "Epoch 21/50\n",
      "580/580 [==============================] - 0s 87us/sample - loss: 0.0124 - val_loss: 0.0455\n",
      "Epoch 22/50\n",
      "580/580 [==============================] - 0s 83us/sample - loss: 0.0138 - val_loss: 0.0447\n",
      "Epoch 23/50\n",
      "580/580 [==============================] - 0s 86us/sample - loss: 0.0122 - val_loss: 0.0453\n",
      "Epoch 24/50\n",
      "580/580 [==============================] - 0s 87us/sample - loss: 0.0129 - val_loss: 0.0449\n",
      "Epoch 25/50\n",
      "580/580 [==============================] - 0s 90us/sample - loss: 0.0134 - val_loss: 0.0442\n",
      "Epoch 26/50\n",
      "580/580 [==============================] - 0s 92us/sample - loss: 0.0151 - val_loss: 0.0458\n",
      "Epoch 27/50\n",
      "580/580 [==============================] - 0s 89us/sample - loss: 0.0140 - val_loss: 0.0438\n",
      "Epoch 28/50\n",
      "580/580 [==============================] - 0s 88us/sample - loss: 0.0141 - val_loss: 0.0452\n",
      "Epoch 29/50\n",
      "580/580 [==============================] - 0s 90us/sample - loss: 0.0135 - val_loss: 0.0453\n",
      "Epoch 30/50\n",
      "580/580 [==============================] - 0s 88us/sample - loss: 0.0138 - val_loss: 0.0439\n",
      "Epoch 31/50\n",
      "580/580 [==============================] - 0s 85us/sample - loss: 0.0142 - val_loss: 0.0456\n",
      "Epoch 32/50\n",
      "580/580 [==============================] - 0s 91us/sample - loss: 0.0139 - val_loss: 0.0442\n",
      "Epoch 33/50\n",
      "580/580 [==============================] - 0s 86us/sample - loss: 0.0136 - val_loss: 0.0452\n",
      "Epoch 34/50\n",
      "580/580 [==============================] - 0s 85us/sample - loss: 0.0128 - val_loss: 0.0461\n",
      "Epoch 35/50\n",
      "580/580 [==============================] - 0s 98us/sample - loss: 0.0151 - val_loss: 0.0439\n",
      "Epoch 36/50\n",
      "580/580 [==============================] - 0s 90us/sample - loss: 0.0139 - val_loss: 0.0461\n",
      "Epoch 37/50\n",
      "580/580 [==============================] - 0s 83us/sample - loss: 0.0152 - val_loss: 0.0440\n",
      "Epoch 38/50\n",
      "580/580 [==============================] - 0s 84us/sample - loss: 0.0126 - val_loss: 0.0454\n",
      "Epoch 39/50\n",
      "580/580 [==============================] - 0s 84us/sample - loss: 0.0141 - val_loss: 0.0444\n",
      "Epoch 40/50\n",
      "580/580 [==============================] - 0s 83us/sample - loss: 0.0123 - val_loss: 0.0457\n",
      "Epoch 41/50\n",
      "580/580 [==============================] - 0s 90us/sample - loss: 0.0138 - val_loss: 0.0441\n",
      "Epoch 42/50\n",
      "580/580 [==============================] - 0s 86us/sample - loss: 0.0147 - val_loss: 0.0456\n",
      "Epoch 43/50\n",
      "580/580 [==============================] - 0s 91us/sample - loss: 0.0132 - val_loss: 0.0446\n",
      "Epoch 44/50\n",
      "580/580 [==============================] - 0s 88us/sample - loss: 0.0132 - val_loss: 0.0442\n",
      "Epoch 45/50\n",
      "580/580 [==============================] - 0s 89us/sample - loss: 0.0142 - val_loss: 0.0461\n",
      "Epoch 46/50\n",
      "580/580 [==============================] - 0s 93us/sample - loss: 0.0148 - val_loss: 0.0440\n",
      "Epoch 47/50\n",
      "580/580 [==============================] - 0s 92us/sample - loss: 0.0128 - val_loss: 0.0455\n",
      "Epoch 48/50\n",
      "580/580 [==============================] - 0s 91us/sample - loss: 0.0144 - val_loss: 0.0438\n",
      "Epoch 49/50\n",
      "580/580 [==============================] - 0s 93us/sample - loss: 0.0135 - val_loss: 0.0454\n",
      "Epoch 50/50\n",
      "580/580 [==============================] - 0s 94us/sample - loss: 0.0144 - val_loss: 0.0441\n",
      "第224个数，还剩3899个没有训练\n",
      "inv_hat [1.04290657 1.02887225 1.03014261 1.02779876 1.01486356 1.01197733\n",
      " 1.01585786 1.02516987 1.01705019 1.02448203 1.03966074 1.04103766\n",
      " 1.04241477 1.03278613 1.03121887 1.02965384 1.03131678 1.02984936\n",
      " 1.03425715 1.0220089  1.01873797 1.01267437 1.007791   1.01257478\n",
      " 1.00998465 1.01724887 1.01466461 1.00948615 1.00579567 1.00799052]\n",
      "Test RMSE: 0.007\n",
      "Train on 874 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "874/874 [==============================] - 0s 90us/sample - loss: 0.0145 - val_loss: 0.0081\n",
      "Epoch 2/50\n",
      "874/874 [==============================] - 0s 83us/sample - loss: 0.0150 - val_loss: 0.0072\n",
      "Epoch 3/50\n",
      "874/874 [==============================] - 0s 85us/sample - loss: 0.0147 - val_loss: 0.0072\n",
      "Epoch 4/50\n",
      "874/874 [==============================] - 0s 82us/sample - loss: 0.0149 - val_loss: 0.0071\n",
      "Epoch 5/50\n",
      "874/874 [==============================] - 0s 89us/sample - loss: 0.0144 - val_loss: 0.0085\n",
      "Epoch 6/50\n",
      "874/874 [==============================] - 0s 87us/sample - loss: 0.0155 - val_loss: 0.0088\n",
      "Epoch 7/50\n",
      "874/874 [==============================] - 0s 83us/sample - loss: 0.0152 - val_loss: 0.0086\n",
      "Epoch 8/50\n",
      "874/874 [==============================] - 0s 83us/sample - loss: 0.0149 - val_loss: 0.0072\n",
      "Epoch 9/50\n",
      "874/874 [==============================] - 0s 87us/sample - loss: 0.0145 - val_loss: 0.0071\n",
      "Epoch 10/50\n",
      "874/874 [==============================] - 0s 85us/sample - loss: 0.0143 - val_loss: 0.0075\n",
      "Epoch 11/50\n",
      "874/874 [==============================] - 0s 83us/sample - loss: 0.0148 - val_loss: 0.0076\n",
      "Epoch 12/50\n",
      "874/874 [==============================] - 0s 87us/sample - loss: 0.0145 - val_loss: 0.0075\n",
      "Epoch 13/50\n",
      "874/874 [==============================] - 0s 86us/sample - loss: 0.0149 - val_loss: 0.0083\n",
      "Epoch 14/50\n",
      "874/874 [==============================] - 0s 83us/sample - loss: 0.0146 - val_loss: 0.0082\n",
      "Epoch 15/50\n",
      "874/874 [==============================] - 0s 85us/sample - loss: 0.0144 - val_loss: 0.0073\n",
      "Epoch 16/50\n",
      "874/874 [==============================] - 0s 84us/sample - loss: 0.0143 - val_loss: 0.0074\n",
      "Epoch 17/50\n",
      "874/874 [==============================] - 0s 84us/sample - loss: 0.0146 - val_loss: 0.0070\n",
      "Epoch 18/50\n",
      "874/874 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0072\n",
      "Epoch 19/50\n",
      "874/874 [==============================] - 0s 84us/sample - loss: 0.0143 - val_loss: 0.0072\n",
      "Epoch 20/50\n",
      "874/874 [==============================] - 0s 90us/sample - loss: 0.0144 - val_loss: 0.0071\n",
      "Epoch 21/50\n",
      "874/874 [==============================] - 0s 83us/sample - loss: 0.0144 - val_loss: 0.0070\n",
      "Epoch 22/50\n",
      "874/874 [==============================] - 0s 84us/sample - loss: 0.0144 - val_loss: 0.0070\n",
      "Epoch 23/50\n",
      "874/874 [==============================] - 0s 84us/sample - loss: 0.0142 - val_loss: 0.0072\n",
      "Epoch 24/50\n",
      "874/874 [==============================] - 0s 82us/sample - loss: 0.0147 - val_loss: 0.0078\n",
      "Epoch 25/50\n",
      "874/874 [==============================] - 0s 84us/sample - loss: 0.0143 - val_loss: 0.0076\n",
      "Epoch 26/50\n",
      "874/874 [==============================] - 0s 84us/sample - loss: 0.0149 - val_loss: 0.0081\n",
      "Epoch 27/50\n",
      "874/874 [==============================] - 0s 82us/sample - loss: 0.0147 - val_loss: 0.0070\n",
      "Epoch 28/50\n",
      "874/874 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0069\n",
      "Epoch 29/50\n",
      "874/874 [==============================] - 0s 80us/sample - loss: 0.0142 - val_loss: 0.0070\n",
      "Epoch 30/50\n",
      "874/874 [==============================] - 0s 84us/sample - loss: 0.0142 - val_loss: 0.0070\n",
      "Epoch 31/50\n",
      "874/874 [==============================] - 0s 85us/sample - loss: 0.0141 - val_loss: 0.0069\n",
      "Epoch 32/50\n",
      "874/874 [==============================] - 0s 83us/sample - loss: 0.0140 - val_loss: 0.0072\n",
      "Epoch 33/50\n",
      "874/874 [==============================] - 0s 79us/sample - loss: 0.0142 - val_loss: 0.0069\n",
      "Epoch 34/50\n",
      "874/874 [==============================] - 0s 82us/sample - loss: 0.0145 - val_loss: 0.0082\n",
      "Epoch 35/50\n",
      "874/874 [==============================] - 0s 82us/sample - loss: 0.0143 - val_loss: 0.0074\n",
      "Epoch 36/50\n",
      "874/874 [==============================] - 0s 83us/sample - loss: 0.0145 - val_loss: 0.0069\n",
      "Epoch 37/50\n",
      "874/874 [==============================] - 0s 82us/sample - loss: 0.0141 - val_loss: 0.0070\n",
      "Epoch 38/50\n",
      "874/874 [==============================] - 0s 82us/sample - loss: 0.0141 - val_loss: 0.0073\n",
      "Epoch 39/50\n",
      "874/874 [==============================] - 0s 80us/sample - loss: 0.0145 - val_loss: 0.0073\n",
      "Epoch 40/50\n",
      "874/874 [==============================] - 0s 83us/sample - loss: 0.0140 - val_loss: 0.0069\n",
      "Epoch 41/50\n",
      "874/874 [==============================] - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0072\n",
      "Epoch 42/50\n",
      "874/874 [==============================] - 0s 79us/sample - loss: 0.0143 - val_loss: 0.0072\n",
      "Epoch 43/50\n",
      "874/874 [==============================] - 0s 83us/sample - loss: 0.0141 - val_loss: 0.0072\n",
      "Epoch 44/50\n",
      "874/874 [==============================] - 0s 84us/sample - loss: 0.0144 - val_loss: 0.0069\n",
      "Epoch 45/50\n",
      "874/874 [==============================] - 0s 79us/sample - loss: 0.0140 - val_loss: 0.0071\n",
      "Epoch 46/50\n",
      "874/874 [==============================] - 0s 80us/sample - loss: 0.0139 - val_loss: 0.0071\n",
      "Epoch 47/50\n",
      "874/874 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0071\n",
      "Epoch 48/50\n",
      "874/874 [==============================] - 0s 82us/sample - loss: 0.0143 - val_loss: 0.0072\n",
      "Epoch 49/50\n",
      "874/874 [==============================] - 0s 81us/sample - loss: 0.0141 - val_loss: 0.0069\n",
      "Epoch 50/50\n",
      "874/874 [==============================] - 0s 84us/sample - loss: 0.0140 - val_loss: 0.0070\n",
      "第225个数，还剩3898个没有训练\n",
      "inv_hat [1.01400681 1.01400681 1.0150038  1.0150038  1.0150038  1.0150038\n",
      " 1.0150038  1.01600456 1.01600456 1.01600456 1.01600456 1.01600456\n",
      " 1.01600456 1.01600456 1.01600456 1.01701278 1.01701278 1.01701278\n",
      " 1.01701278 1.01701278 1.01701278 1.0180191  1.0180191  1.0180191\n",
      " 1.0180191  1.0180191  1.0180191  1.0180191  1.01902098 1.01902098]\n",
      "Test RMSE: 0.000\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0122 - val_loss: 0.0047\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0047\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0047\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0047\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0047\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0122 - val_loss: 0.0047\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0122 - val_loss: 0.0047\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0122 - val_loss: 0.0046\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0047\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0122 - val_loss: 0.0047\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0121 - val_loss: 0.0047\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0047\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0121 - val_loss: 0.0047\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0047\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0121 - val_loss: 0.0048\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0049\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0121 - val_loss: 0.0047\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0121 - val_loss: 0.0047\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0122 - val_loss: 0.0047\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0121 - val_loss: 0.0047\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0122 - val_loss: 0.0047\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0049\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0047\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0047\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0122 - val_loss: 0.0048\n",
      "第226个数，还剩3897个没有训练\n",
      "inv_hat [1.23083172 1.21596757 1.21695791 1.21299683 1.20309951 1.20211017\n",
      " 1.1991428  1.20606787 1.19518754 1.1991428  1.22092039 1.21794844\n",
      " 1.20804715 1.1922219  1.1922219  1.18332977 1.18728093 1.1912336\n",
      " 1.2040888  1.19716499 1.19815392 1.18925706 1.18234214 1.17543154\n",
      " 1.16753911 1.16951163 1.16753911 1.16556694 1.1596526  1.16162363]\n",
      "Test RMSE: 0.009\n",
      "Train on 962 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "962/962 [==============================] - 0s 78us/sample - loss: 0.0146 - val_loss: 0.0048\n",
      "Epoch 2/50\n",
      "962/962 [==============================] - 0s 79us/sample - loss: 0.0141 - val_loss: 0.0047\n",
      "Epoch 3/50\n",
      "962/962 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0047\n",
      "Epoch 4/50\n",
      "962/962 [==============================] - 0s 80us/sample - loss: 0.0117 - val_loss: 0.0066\n",
      "Epoch 5/50\n",
      "962/962 [==============================] - 0s 82us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 6/50\n",
      "962/962 [==============================] - 0s 84us/sample - loss: 0.0114 - val_loss: 0.0066\n",
      "Epoch 7/50\n",
      "962/962 [==============================] - 0s 83us/sample - loss: 0.0112 - val_loss: 0.0057\n",
      "Epoch 8/50\n",
      "962/962 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0054\n",
      "Epoch 9/50\n",
      "962/962 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0056\n",
      "Epoch 10/50\n",
      "962/962 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0059\n",
      "Epoch 11/50\n",
      "962/962 [==============================] - 0s 86us/sample - loss: 0.0111 - val_loss: 0.0061\n",
      "Epoch 12/50\n",
      "962/962 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0058\n",
      "Epoch 13/50\n",
      "962/962 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0058\n",
      "Epoch 14/50\n",
      "962/962 [==============================] - 0s 84us/sample - loss: 0.0111 - val_loss: 0.0057\n",
      "Epoch 15/50\n",
      "962/962 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0059\n",
      "Epoch 16/50\n",
      "962/962 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0058\n",
      "Epoch 17/50\n",
      "962/962 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0058\n",
      "Epoch 18/50\n",
      "962/962 [==============================] - 0s 83us/sample - loss: 0.0111 - val_loss: 0.0058\n",
      "Epoch 19/50\n",
      "962/962 [==============================] - 0s 84us/sample - loss: 0.0111 - val_loss: 0.0057\n",
      "Epoch 20/50\n",
      "962/962 [==============================] - 0s 84us/sample - loss: 0.0111 - val_loss: 0.0056\n",
      "Epoch 21/50\n",
      "962/962 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0057\n",
      "Epoch 22/50\n",
      "962/962 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0058\n",
      "Epoch 23/50\n",
      "962/962 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0057\n",
      "Epoch 24/50\n",
      "962/962 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0057\n",
      "Epoch 25/50\n",
      "962/962 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0057\n",
      "Epoch 26/50\n",
      "962/962 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0057\n",
      "Epoch 27/50\n",
      "962/962 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0056\n",
      "Epoch 28/50\n",
      "962/962 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0057\n",
      "Epoch 29/50\n",
      "962/962 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0057\n",
      "Epoch 30/50\n",
      "962/962 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0057\n",
      "Epoch 31/50\n",
      "962/962 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0057\n",
      "Epoch 32/50\n",
      "962/962 [==============================] - 0s 87us/sample - loss: 0.0111 - val_loss: 0.0057\n",
      "Epoch 33/50\n",
      "962/962 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0057\n",
      "Epoch 34/50\n",
      "962/962 [==============================] - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0056\n",
      "Epoch 35/50\n",
      "962/962 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0056\n",
      "Epoch 36/50\n",
      "962/962 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0058\n",
      "Epoch 37/50\n",
      "962/962 [==============================] - 0s 83us/sample - loss: 0.0111 - val_loss: 0.0058\n",
      "Epoch 38/50\n",
      "962/962 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0056\n",
      "Epoch 39/50\n",
      "962/962 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0056\n",
      "Epoch 40/50\n",
      "962/962 [==============================] - 0s 84us/sample - loss: 0.0111 - val_loss: 0.0055\n",
      "Epoch 41/50\n",
      "962/962 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0056\n",
      "Epoch 42/50\n",
      "962/962 [==============================] - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0056\n",
      "Epoch 43/50\n",
      "962/962 [==============================] - 0s 83us/sample - loss: 0.0111 - val_loss: 0.0054\n",
      "Epoch 44/50\n",
      "962/962 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0057\n",
      "Epoch 45/50\n",
      "962/962 [==============================] - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0058\n",
      "Epoch 46/50\n",
      "962/962 [==============================] - 0s 77us/sample - loss: 0.0111 - val_loss: 0.0058\n",
      "Epoch 47/50\n",
      "962/962 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0058\n",
      "Epoch 48/50\n",
      "962/962 [==============================] - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0058\n",
      "Epoch 49/50\n",
      "962/962 [==============================] - 0s 83us/sample - loss: 0.0111 - val_loss: 0.0057\n",
      "Epoch 50/50\n",
      "962/962 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0056\n",
      "第227个数，还剩3896个没有训练\n",
      "inv_hat [0.68311181 0.66259534 0.66357057 0.66064541 0.64118638 0.64021539\n",
      " 0.64118638 0.65090671 0.6382739  0.64798865 0.67137874 0.67528694\n",
      " 0.67919802 0.66454594 0.65869625 0.65285299 0.66064541 0.65674775\n",
      " 0.66649727 0.65285299 0.64604422 0.64410048 0.63633327 0.63730349\n",
      " 0.63051569 0.63924453 0.63924453 0.63342361 0.62954679 0.62567307]\n",
      "Test RMSE: 0.011\n",
      "Train on 1109 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1109/1109 [==============================] - 0s 83us/sample - loss: 0.0101 - val_loss: 0.0064\n",
      "Epoch 2/50\n",
      "1109/1109 [==============================] - 0s 79us/sample - loss: 0.0095 - val_loss: 0.0053\n",
      "Epoch 3/50\n",
      "1109/1109 [==============================] - 0s 84us/sample - loss: 0.0092 - val_loss: 0.0061\n",
      "Epoch 4/50\n",
      "1109/1109 [==============================] - 0s 79us/sample - loss: 0.0083 - val_loss: 0.0058\n",
      "Epoch 5/50\n",
      "1109/1109 [==============================] - 0s 82us/sample - loss: 0.0096 - val_loss: 0.0071\n",
      "Epoch 6/50\n",
      "1109/1109 [==============================] - 0s 82us/sample - loss: 0.0091 - val_loss: 0.0067\n",
      "Epoch 7/50\n",
      "1109/1109 [==============================] - 0s 78us/sample - loss: 0.0124 - val_loss: 0.0054\n",
      "Epoch 8/50\n",
      "1109/1109 [==============================] - 0s 78us/sample - loss: 0.0137 - val_loss: 0.0086\n",
      "Epoch 9/50\n",
      "1109/1109 [==============================] - 0s 79us/sample - loss: 0.0115 - val_loss: 0.0060\n",
      "Epoch 10/50\n",
      "1109/1109 [==============================] - 0s 80us/sample - loss: 0.0094 - val_loss: 0.0056\n",
      "Epoch 11/50\n",
      "1109/1109 [==============================] - 0s 76us/sample - loss: 0.0107 - val_loss: 0.0059\n",
      "Epoch 12/50\n",
      "1109/1109 [==============================] - 0s 84us/sample - loss: 0.0120 - val_loss: 0.0079\n",
      "Epoch 13/50\n",
      "1109/1109 [==============================] - 0s 84us/sample - loss: 0.0105 - val_loss: 0.0062\n",
      "Epoch 14/50\n",
      "1109/1109 [==============================] - 0s 85us/sample - loss: 0.0082 - val_loss: 0.0053\n",
      "Epoch 15/50\n",
      "1109/1109 [==============================] - 0s 85us/sample - loss: 0.0084 - val_loss: 0.0053\n",
      "Epoch 16/50\n",
      "1109/1109 [==============================] - 0s 83us/sample - loss: 0.0088 - val_loss: 0.0054\n",
      "Epoch 17/50\n",
      "1109/1109 [==============================] - 0s 84us/sample - loss: 0.0093 - val_loss: 0.0054\n",
      "Epoch 18/50\n",
      "1109/1109 [==============================] - 0s 82us/sample - loss: 0.0097 - val_loss: 0.0063\n",
      "Epoch 19/50\n",
      "1109/1109 [==============================] - 0s 80us/sample - loss: 0.0101 - val_loss: 0.0057\n",
      "Epoch 20/50\n",
      "1109/1109 [==============================] - 0s 82us/sample - loss: 0.0081 - val_loss: 0.0055\n",
      "Epoch 21/50\n",
      "1109/1109 [==============================] - 0s 80us/sample - loss: 0.0077 - val_loss: 0.0053\n",
      "Epoch 22/50\n",
      "1109/1109 [==============================] - 0s 79us/sample - loss: 0.0079 - val_loss: 0.0053\n",
      "Epoch 23/50\n",
      "1109/1109 [==============================] - 0s 78us/sample - loss: 0.0084 - val_loss: 0.0053\n",
      "Epoch 24/50\n",
      "1109/1109 [==============================] - 0s 80us/sample - loss: 0.0091 - val_loss: 0.0054\n",
      "Epoch 25/50\n",
      "1109/1109 [==============================] - 0s 80us/sample - loss: 0.0091 - val_loss: 0.0057\n",
      "Epoch 26/50\n",
      "1109/1109 [==============================] - 0s 82us/sample - loss: 0.0104 - val_loss: 0.0062\n",
      "Epoch 27/50\n",
      "1109/1109 [==============================] - 0s 80us/sample - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 28/50\n",
      "1109/1109 [==============================] - 0s 76us/sample - loss: 0.0080 - val_loss: 0.0053\n",
      "Epoch 29/50\n",
      "1109/1109 [==============================] - 0s 79us/sample - loss: 0.0075 - val_loss: 0.0056\n",
      "Epoch 30/50\n",
      "1109/1109 [==============================] - 0s 77us/sample - loss: 0.0081 - val_loss: 0.0057\n",
      "Epoch 31/50\n",
      "1109/1109 [==============================] - 0s 83us/sample - loss: 0.0077 - val_loss: 0.0054\n",
      "Epoch 32/50\n",
      "1109/1109 [==============================] - 0s 81us/sample - loss: 0.0082 - val_loss: 0.0055\n",
      "Epoch 33/50\n",
      "1109/1109 [==============================] - 0s 83us/sample - loss: 0.0081 - val_loss: 0.0053\n",
      "Epoch 34/50\n",
      "1109/1109 [==============================] - 0s 86us/sample - loss: 0.0089 - val_loss: 0.0054\n",
      "Epoch 35/50\n",
      "1109/1109 [==============================] - 0s 84us/sample - loss: 0.0091 - val_loss: 0.0057\n",
      "Epoch 36/50\n",
      "1109/1109 [==============================] - 0s 81us/sample - loss: 0.0093 - val_loss: 0.0059\n",
      "Epoch 37/50\n",
      "1109/1109 [==============================] - 0s 78us/sample - loss: 0.0079 - val_loss: 0.0055\n",
      "Epoch 38/50\n",
      "1109/1109 [==============================] - 0s 79us/sample - loss: 0.0077 - val_loss: 0.0054\n",
      "Epoch 39/50\n",
      "1109/1109 [==============================] - 0s 83us/sample - loss: 0.0075 - val_loss: 0.0054\n",
      "Epoch 40/50\n",
      "1109/1109 [==============================] - 0s 84us/sample - loss: 0.0075 - val_loss: 0.0056\n",
      "Epoch 41/50\n",
      "1109/1109 [==============================] - 0s 81us/sample - loss: 0.0076 - val_loss: 0.0054\n",
      "Epoch 42/50\n",
      "1109/1109 [==============================] - 0s 80us/sample - loss: 0.0076 - val_loss: 0.0062\n",
      "Epoch 43/50\n",
      "1109/1109 [==============================] - 0s 77us/sample - loss: 0.0079 - val_loss: 0.0055\n",
      "Epoch 44/50\n",
      "1109/1109 [==============================] - 0s 81us/sample - loss: 0.0075 - val_loss: 0.0059\n",
      "Epoch 45/50\n",
      "1109/1109 [==============================] - 0s 81us/sample - loss: 0.0078 - val_loss: 0.0056\n",
      "Epoch 46/50\n",
      "1109/1109 [==============================] - 0s 81us/sample - loss: 0.0075 - val_loss: 0.0060\n",
      "Epoch 47/50\n",
      "1109/1109 [==============================] - 0s 79us/sample - loss: 0.0079 - val_loss: 0.0057\n",
      "Epoch 48/50\n",
      "1109/1109 [==============================] - 0s 78us/sample - loss: 0.0075 - val_loss: 0.0059\n",
      "Epoch 49/50\n",
      "1109/1109 [==============================] - 0s 78us/sample - loss: 0.0081 - val_loss: 0.0054\n",
      "Epoch 50/50\n",
      "1109/1109 [==============================] - 0s 79us/sample - loss: 0.0078 - val_loss: 0.0053\n",
      "第228个数，还剩3895个没有训练\n",
      "inv_hat [1.16207257 1.1542291  1.15814893 1.1561906  1.14827944 1.14728785\n",
      " 1.14827944 1.14827944 1.14728785 1.14827944 1.15026256 1.15224574\n",
      " 1.1542291  1.14629643 1.14332196 1.14431347 1.14629643 1.14629643\n",
      " 1.14927105 1.14530488 1.14530488 1.14629643 1.14431347 1.14530488\n",
      " 1.14530488 1.14530488 1.14629643 1.14629643 1.14827944 1.14927105]\n",
      "Test RMSE: 0.003\n",
      "Train on 706 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "706/706 [==============================] - 0s 75us/sample - loss: 0.0117 - val_loss: 0.0308\n",
      "Epoch 2/50\n",
      "706/706 [==============================] - 0s 78us/sample - loss: 0.0145 - val_loss: 0.0230\n",
      "Epoch 3/50\n",
      "706/706 [==============================] - 0s 81us/sample - loss: 0.0114 - val_loss: 0.0244\n",
      "Epoch 4/50\n",
      "706/706 [==============================] - 0s 76us/sample - loss: 0.0110 - val_loss: 0.0253\n",
      "Epoch 5/50\n",
      "706/706 [==============================] - 0s 78us/sample - loss: 0.0124 - val_loss: 0.0223\n",
      "Epoch 6/50\n",
      "706/706 [==============================] - 0s 80us/sample - loss: 0.0115 - val_loss: 0.0222\n",
      "Epoch 7/50\n",
      "706/706 [==============================] - 0s 82us/sample - loss: 0.0117 - val_loss: 0.0253\n",
      "Epoch 8/50\n",
      "706/706 [==============================] - 0s 90us/sample - loss: 0.0114 - val_loss: 0.0255\n",
      "Epoch 9/50\n",
      "706/706 [==============================] - 0s 80us/sample - loss: 0.0120 - val_loss: 0.0228\n",
      "Epoch 10/50\n",
      "706/706 [==============================] - 0s 80us/sample - loss: 0.0113 - val_loss: 0.0224\n",
      "Epoch 11/50\n",
      "706/706 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "706/706 [==============================] - 0s 82us/sample - loss: 0.0105 - val_loss: 0.0259\n",
      "Epoch 13/50\n",
      "706/706 [==============================] - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0250\n",
      "Epoch 14/50\n",
      "706/706 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0228\n",
      "Epoch 15/50\n",
      "706/706 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0222\n",
      "Epoch 16/50\n",
      "706/706 [==============================] - 0s 77us/sample - loss: 0.0126 - val_loss: 0.0268\n",
      "Epoch 17/50\n",
      "706/706 [==============================] - 0s 80us/sample - loss: 0.0121 - val_loss: 0.0242\n",
      "Epoch 18/50\n",
      "706/706 [==============================] - 0s 80us/sample - loss: 0.0103 - val_loss: 0.0233\n",
      "Epoch 19/50\n",
      "706/706 [==============================] - 0s 80us/sample - loss: 0.0108 - val_loss: 0.0232\n",
      "Epoch 20/50\n",
      "706/706 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0257\n",
      "Epoch 21/50\n",
      "706/706 [==============================] - 0s 79us/sample - loss: 0.0112 - val_loss: 0.0268\n",
      "Epoch 22/50\n",
      "706/706 [==============================] - 0s 81us/sample - loss: 0.0120 - val_loss: 0.0235\n",
      "Epoch 23/50\n",
      "706/706 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0232\n",
      "Epoch 24/50\n",
      "706/706 [==============================] - 0s 78us/sample - loss: 0.0112 - val_loss: 0.0251\n",
      "Epoch 25/50\n",
      "706/706 [==============================] - 0s 77us/sample - loss: 0.0108 - val_loss: 0.0270\n",
      "Epoch 26/50\n",
      "706/706 [==============================] - 0s 82us/sample - loss: 0.0117 - val_loss: 0.0242\n",
      "Epoch 27/50\n",
      "706/706 [==============================] - 0s 80us/sample - loss: 0.0103 - val_loss: 0.0233\n",
      "Epoch 28/50\n",
      "706/706 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0223\n",
      "Epoch 29/50\n",
      "706/706 [==============================] - 0s 78us/sample - loss: 0.0125 - val_loss: 0.0258\n",
      "Epoch 30/50\n",
      "706/706 [==============================] - 0s 75us/sample - loss: 0.0109 - val_loss: 0.0254\n",
      "Epoch 31/50\n",
      "706/706 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0237\n",
      "Epoch 32/50\n",
      "706/706 [==============================] - 0s 82us/sample - loss: 0.0107 - val_loss: 0.0229\n",
      "Epoch 33/50\n",
      "706/706 [==============================] - 0s 81us/sample - loss: 0.0118 - val_loss: 0.0251\n",
      "Epoch 34/50\n",
      "706/706 [==============================] - 0s 83us/sample - loss: 0.0105 - val_loss: 0.0259\n",
      "Epoch 35/50\n",
      "706/706 [==============================] - 0s 81us/sample - loss: 0.0107 - val_loss: 0.0255\n",
      "Epoch 36/50\n",
      "706/706 [==============================] - 0s 84us/sample - loss: 0.0108 - val_loss: 0.0237\n",
      "Epoch 37/50\n",
      "706/706 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0232\n",
      "Epoch 38/50\n",
      "706/706 [==============================] - 0s 75us/sample - loss: 0.0115 - val_loss: 0.0259\n",
      "Epoch 39/50\n",
      "706/706 [==============================] - 0s 80us/sample - loss: 0.0107 - val_loss: 0.0264\n",
      "Epoch 40/50\n",
      "706/706 [==============================] - 0s 84us/sample - loss: 0.0112 - val_loss: 0.0243\n",
      "Epoch 41/50\n",
      "706/706 [==============================] - 0s 86us/sample - loss: 0.0104 - val_loss: 0.0230\n",
      "Epoch 42/50\n",
      "706/706 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0239\n",
      "Epoch 43/50\n",
      "706/706 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0258\n",
      "Epoch 44/50\n",
      "706/706 [==============================] - 0s 83us/sample - loss: 0.0108 - val_loss: 0.0284\n",
      "Epoch 45/50\n",
      "706/706 [==============================] - 0s 83us/sample - loss: 0.0117 - val_loss: 0.0249\n",
      "Epoch 46/50\n",
      "706/706 [==============================] - 0s 80us/sample - loss: 0.0103 - val_loss: 0.0241\n",
      "Epoch 47/50\n",
      "706/706 [==============================] - 0s 82us/sample - loss: 0.0107 - val_loss: 0.0226\n",
      "Epoch 48/50\n",
      "706/706 [==============================] - 0s 83us/sample - loss: 0.0121 - val_loss: 0.0250\n",
      "Epoch 49/50\n",
      "706/706 [==============================] - 0s 77us/sample - loss: 0.0103 - val_loss: 0.0254\n",
      "Epoch 50/50\n",
      "706/706 [==============================] - 0s 79us/sample - loss: 0.0104 - val_loss: 0.0265\n",
      "第229个数，还剩3894个没有训练\n",
      "inv_hat [0.90572925 0.89009679 0.89399476 0.88912346 0.87458463 0.87651605\n",
      " 0.87361983 0.88329363 0.87555007 0.88426405 0.90083288 0.90279032\n",
      " 0.89887707 0.88426405 0.88232379 0.87651605 0.87844973 0.8803857\n",
      " 0.89301954 0.88135447 0.88232379 0.87265564 0.86400625 0.85161299\n",
      " 0.84311192 0.84311192 0.83935651 0.83468334 0.83282088 0.83748439]\n",
      "Test RMSE: 0.010\n",
      "Train on 671 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "671/671 [==============================] - 0s 81us/sample - loss: 0.0166 - val_loss: 0.0079\n",
      "Epoch 2/50\n",
      "671/671 [==============================] - 0s 84us/sample - loss: 0.0162 - val_loss: 0.0069\n",
      "Epoch 3/50\n",
      "671/671 [==============================] - 0s 90us/sample - loss: 0.0157 - val_loss: 0.0074\n",
      "Epoch 4/50\n",
      "671/671 [==============================] - 0s 87us/sample - loss: 0.0153 - val_loss: 0.0064\n",
      "Epoch 5/50\n",
      "671/671 [==============================] - 0s 82us/sample - loss: 0.0149 - val_loss: 0.0055\n",
      "Epoch 6/50\n",
      "671/671 [==============================] - 0s 86us/sample - loss: 0.0148 - val_loss: 0.0055\n",
      "Epoch 7/50\n",
      "671/671 [==============================] - 0s 84us/sample - loss: 0.0145 - val_loss: 0.0060\n",
      "Epoch 8/50\n",
      "671/671 [==============================] - 0s 87us/sample - loss: 0.0145 - val_loss: 0.0053\n",
      "Epoch 9/50\n",
      "671/671 [==============================] - 0s 88us/sample - loss: 0.0146 - val_loss: 0.0061\n",
      "Epoch 10/50\n",
      "671/671 [==============================] - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0053\n",
      "Epoch 11/50\n",
      "671/671 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0057\n",
      "Epoch 12/50\n",
      "671/671 [==============================] - 0s 85us/sample - loss: 0.0142 - val_loss: 0.0062\n",
      "Epoch 13/50\n",
      "671/671 [==============================] - 0s 86us/sample - loss: 0.0143 - val_loss: 0.0053\n",
      "Epoch 14/50\n",
      "671/671 [==============================] - 0s 84us/sample - loss: 0.0140 - val_loss: 0.0056\n",
      "Epoch 15/50\n",
      "671/671 [==============================] - 0s 85us/sample - loss: 0.0141 - val_loss: 0.0057\n",
      "Epoch 16/50\n",
      "671/671 [==============================] - 0s 87us/sample - loss: 0.0140 - val_loss: 0.0060\n",
      "Epoch 17/50\n",
      "671/671 [==============================] - 0s 87us/sample - loss: 0.0141 - val_loss: 0.0055\n",
      "Epoch 18/50\n",
      "671/671 [==============================] - 0s 88us/sample - loss: 0.0140 - val_loss: 0.0057\n",
      "Epoch 19/50\n",
      "671/671 [==============================] - 0s 84us/sample - loss: 0.0140 - val_loss: 0.0053\n",
      "Epoch 20/50\n",
      "671/671 [==============================] - 0s 84us/sample - loss: 0.0142 - val_loss: 0.0056\n",
      "Epoch 21/50\n",
      "671/671 [==============================] - 0s 86us/sample - loss: 0.0140 - val_loss: 0.0054\n",
      "Epoch 22/50\n",
      "671/671 [==============================] - 0s 84us/sample - loss: 0.0140 - val_loss: 0.0057\n",
      "Epoch 23/50\n",
      "671/671 [==============================] - 0s 82us/sample - loss: 0.0141 - val_loss: 0.0054\n",
      "Epoch 24/50\n",
      "671/671 [==============================] - 0s 82us/sample - loss: 0.0138 - val_loss: 0.0056\n",
      "Epoch 25/50\n",
      "671/671 [==============================] - 0s 84us/sample - loss: 0.0139 - val_loss: 0.0053\n",
      "Epoch 26/50\n",
      "671/671 [==============================] - 0s 86us/sample - loss: 0.0139 - val_loss: 0.0060\n",
      "Epoch 27/50\n",
      "671/671 [==============================] - 0s 80us/sample - loss: 0.0142 - val_loss: 0.0059\n",
      "Epoch 28/50\n",
      "671/671 [==============================] - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0053\n",
      "Epoch 29/50\n",
      "671/671 [==============================] - 0s 86us/sample - loss: 0.0139 - val_loss: 0.0057\n",
      "Epoch 30/50\n",
      "671/671 [==============================] - 0s 86us/sample - loss: 0.0141 - val_loss: 0.0056\n",
      "Epoch 31/50\n",
      "671/671 [==============================] - 0s 85us/sample - loss: 0.0140 - val_loss: 0.0059\n",
      "Epoch 32/50\n",
      "671/671 [==============================] - 0s 86us/sample - loss: 0.0140 - val_loss: 0.0055\n",
      "Epoch 33/50\n",
      "671/671 [==============================] - 0s 84us/sample - loss: 0.0139 - val_loss: 0.0056\n",
      "Epoch 34/50\n",
      "671/671 [==============================] - 0s 84us/sample - loss: 0.0140 - val_loss: 0.0052\n",
      "Epoch 35/50\n",
      "671/671 [==============================] - 0s 83us/sample - loss: 0.0138 - val_loss: 0.0054\n",
      "Epoch 36/50\n",
      "671/671 [==============================] - 0s 87us/sample - loss: 0.0139 - val_loss: 0.0053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "671/671 [==============================] - 0s 87us/sample - loss: 0.0138 - val_loss: 0.0053\n",
      "Epoch 38/50\n",
      "671/671 [==============================] - 0s 85us/sample - loss: 0.0138 - val_loss: 0.0056\n",
      "Epoch 39/50\n",
      "671/671 [==============================] - 0s 83us/sample - loss: 0.0138 - val_loss: 0.0053\n",
      "Epoch 40/50\n",
      "671/671 [==============================] - 0s 82us/sample - loss: 0.0139 - val_loss: 0.0059\n",
      "Epoch 41/50\n",
      "671/671 [==============================] - 0s 88us/sample - loss: 0.0139 - val_loss: 0.0053\n",
      "Epoch 42/50\n",
      "671/671 [==============================] - 0s 89us/sample - loss: 0.0137 - val_loss: 0.0056\n",
      "Epoch 43/50\n",
      "671/671 [==============================] - 0s 90us/sample - loss: 0.0138 - val_loss: 0.0053\n",
      "Epoch 44/50\n",
      "671/671 [==============================] - 0s 86us/sample - loss: 0.0139 - val_loss: 0.0057\n",
      "Epoch 45/50\n",
      "671/671 [==============================] - 0s 80us/sample - loss: 0.0140 - val_loss: 0.0053\n",
      "Epoch 46/50\n",
      "671/671 [==============================] - 0s 82us/sample - loss: 0.0140 - val_loss: 0.0053\n",
      "Epoch 47/50\n",
      "671/671 [==============================] - 0s 85us/sample - loss: 0.0137 - val_loss: 0.0057\n",
      "Epoch 48/50\n",
      "671/671 [==============================] - 0s 86us/sample - loss: 0.0138 - val_loss: 0.0058\n",
      "Epoch 49/50\n",
      "671/671 [==============================] - 0s 85us/sample - loss: 0.0138 - val_loss: 0.0053\n",
      "Epoch 50/50\n",
      "671/671 [==============================] - 0s 83us/sample - loss: 0.0136 - val_loss: 0.0054\n",
      "第230个数，还剩3893个没有训练\n",
      "inv_hat [1.01299713 1.01299713 1.01399026 1.01399026 1.01399026 1.01399026\n",
      " 1.01399026 1.01399026 1.01498761 1.01498761 1.01498761 1.01498761\n",
      " 1.01498761 1.01498761 1.01498761 1.01498761 1.01599002 1.01599002\n",
      " 1.01599002 1.01599002 1.01599002 1.01599002 1.01599002 1.016999\n",
      " 1.016999   1.016999   1.016999   1.016999   1.016999   1.016999  ]\n",
      "Test RMSE: 0.000\n",
      "Train on 601 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "601/601 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0102\n",
      "Epoch 2/50\n",
      "601/601 [==============================] - 0s 89us/sample - loss: 0.0254 - val_loss: 0.0085\n",
      "Epoch 3/50\n",
      "601/601 [==============================] - 0s 89us/sample - loss: 0.0148 - val_loss: 0.0278\n",
      "Epoch 4/50\n",
      "601/601 [==============================] - 0s 87us/sample - loss: 0.0071 - val_loss: 0.0096\n",
      "Epoch 5/50\n",
      "601/601 [==============================] - 0s 85us/sample - loss: 0.0065 - val_loss: 0.0102\n",
      "Epoch 6/50\n",
      "601/601 [==============================] - 0s 86us/sample - loss: 0.0057 - val_loss: 0.0101\n",
      "Epoch 7/50\n",
      "601/601 [==============================] - 0s 87us/sample - loss: 0.0055 - val_loss: 0.0085\n",
      "Epoch 8/50\n",
      "601/601 [==============================] - 0s 85us/sample - loss: 0.0062 - val_loss: 0.0082\n",
      "Epoch 9/50\n",
      "601/601 [==============================] - 0s 85us/sample - loss: 0.0069 - val_loss: 0.0104\n",
      "Epoch 10/50\n",
      "601/601 [==============================] - 0s 86us/sample - loss: 0.0076 - val_loss: 0.0116\n",
      "Epoch 11/50\n",
      "601/601 [==============================] - 0s 89us/sample - loss: 0.0055 - val_loss: 0.0084\n",
      "Epoch 12/50\n",
      "601/601 [==============================] - 0s 84us/sample - loss: 0.0088 - val_loss: 0.0153\n",
      "Epoch 13/50\n",
      "601/601 [==============================] - 0s 85us/sample - loss: 0.0057 - val_loss: 0.0092\n",
      "Epoch 14/50\n",
      "601/601 [==============================] - 0s 81us/sample - loss: 0.0081 - val_loss: 0.0145\n",
      "Epoch 15/50\n",
      "601/601 [==============================] - 0s 84us/sample - loss: 0.0075 - val_loss: 0.0084\n",
      "Epoch 16/50\n",
      "601/601 [==============================] - 0s 81us/sample - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 17/50\n",
      "601/601 [==============================] - 0s 87us/sample - loss: 0.0067 - val_loss: 0.0114\n",
      "Epoch 18/50\n",
      "601/601 [==============================] - 0s 85us/sample - loss: 0.0072 - val_loss: 0.0083\n",
      "Epoch 19/50\n",
      "601/601 [==============================] - 0s 82us/sample - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 20/50\n",
      "601/601 [==============================] - 0s 80us/sample - loss: 0.0066 - val_loss: 0.0123\n",
      "Epoch 21/50\n",
      "601/601 [==============================] - 0s 81us/sample - loss: 0.0073 - val_loss: 0.0090\n",
      "Epoch 22/50\n",
      "601/601 [==============================] - 0s 84us/sample - loss: 0.0057 - val_loss: 0.0116\n",
      "Epoch 23/50\n",
      "601/601 [==============================] - 0s 84us/sample - loss: 0.0080 - val_loss: 0.0138\n",
      "Epoch 24/50\n",
      "601/601 [==============================] - 0s 89us/sample - loss: 0.0072 - val_loss: 0.0082\n",
      "Epoch 25/50\n",
      "601/601 [==============================] - 0s 82us/sample - loss: 0.0087 - val_loss: 0.0096\n",
      "Epoch 26/50\n",
      "601/601 [==============================] - 0s 81us/sample - loss: 0.0062 - val_loss: 0.0116\n",
      "Epoch 27/50\n",
      "601/601 [==============================] - 0s 81us/sample - loss: 0.0082 - val_loss: 0.0106\n",
      "Epoch 28/50\n",
      "601/601 [==============================] - 0s 86us/sample - loss: 0.0057 - val_loss: 0.0113\n",
      "Epoch 29/50\n",
      "601/601 [==============================] - 0s 87us/sample - loss: 0.0058 - val_loss: 0.0103\n",
      "Epoch 30/50\n",
      "601/601 [==============================] - 0s 92us/sample - loss: 0.0058 - val_loss: 0.0102\n",
      "Epoch 31/50\n",
      "601/601 [==============================] - 0s 85us/sample - loss: 0.0060 - val_loss: 0.0083\n",
      "Epoch 32/50\n",
      "601/601 [==============================] - 0s 83us/sample - loss: 0.0053 - val_loss: 0.0097\n",
      "Epoch 33/50\n",
      "601/601 [==============================] - 0s 85us/sample - loss: 0.0067 - val_loss: 0.0100\n",
      "Epoch 34/50\n",
      "601/601 [==============================] - 0s 85us/sample - loss: 0.0073 - val_loss: 0.0089\n",
      "Epoch 35/50\n",
      "601/601 [==============================] - 0s 83us/sample - loss: 0.0059 - val_loss: 0.0093\n",
      "Epoch 36/50\n",
      "601/601 [==============================] - 0s 84us/sample - loss: 0.0087 - val_loss: 0.0135\n",
      "Epoch 37/50\n",
      "601/601 [==============================] - 0s 81us/sample - loss: 0.0065 - val_loss: 0.0084\n",
      "Epoch 38/50\n",
      "601/601 [==============================] - 0s 85us/sample - loss: 0.0083 - val_loss: 0.0095\n",
      "Epoch 39/50\n",
      "601/601 [==============================] - 0s 85us/sample - loss: 0.0058 - val_loss: 0.0088\n",
      "Epoch 40/50\n",
      "601/601 [==============================] - 0s 84us/sample - loss: 0.0062 - val_loss: 0.0090\n",
      "Epoch 41/50\n",
      "601/601 [==============================] - 0s 83us/sample - loss: 0.0078 - val_loss: 0.0095\n",
      "Epoch 42/50\n",
      "601/601 [==============================] - 0s 85us/sample - loss: 0.0062 - val_loss: 0.0115\n",
      "Epoch 43/50\n",
      "601/601 [==============================] - 0s 87us/sample - loss: 0.0063 - val_loss: 0.0084\n",
      "Epoch 44/50\n",
      "601/601 [==============================] - 0s 84us/sample - loss: 0.0054 - val_loss: 0.0086\n",
      "Epoch 45/50\n",
      "601/601 [==============================] - 0s 87us/sample - loss: 0.0058 - val_loss: 0.0087\n",
      "Epoch 46/50\n",
      "601/601 [==============================] - 0s 84us/sample - loss: 0.0056 - val_loss: 0.0087\n",
      "Epoch 47/50\n",
      "601/601 [==============================] - 0s 87us/sample - loss: 0.0052 - val_loss: 0.0087\n",
      "Epoch 48/50\n",
      "601/601 [==============================] - 0s 87us/sample - loss: 0.0058 - val_loss: 0.0083\n",
      "Epoch 49/50\n",
      "601/601 [==============================] - 0s 88us/sample - loss: 0.0059 - val_loss: 0.0085\n",
      "Epoch 50/50\n",
      "601/601 [==============================] - 0s 85us/sample - loss: 0.0052 - val_loss: 0.0097\n",
      "第231个数，还剩3892个没有训练\n",
      "inv_hat [1.09253168 1.09170175 1.09170175 1.09170175 1.08788011 1.08788011\n",
      " 1.08788011 1.08788011 1.08788011 1.08884001 1.08884001 1.08884001\n",
      " 1.08979702 1.09075087 1.09075087 1.09075087 1.09075087 1.09170175\n",
      " 1.09075087 1.09075087 1.09075087 1.09075087 1.09075087 1.09075087\n",
      " 1.09075087 1.09170175 1.09170175 1.09170175 1.08206031 1.08303706]\n",
      "Test RMSE: 0.002\n",
      "Train on 808 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "808/808 [==============================] - 0s 86us/sample - loss: 0.0312 - val_loss: 0.0154\n",
      "Epoch 2/50\n",
      "808/808 [==============================] - 0s 83us/sample - loss: 0.0215 - val_loss: 0.0101\n",
      "Epoch 3/50\n",
      "808/808 [==============================] - 0s 82us/sample - loss: 0.0202 - val_loss: 0.0124\n",
      "Epoch 4/50\n",
      "808/808 [==============================] - 0s 83us/sample - loss: 0.0202 - val_loss: 0.0112\n",
      "Epoch 5/50\n",
      "808/808 [==============================] - 0s 84us/sample - loss: 0.0199 - val_loss: 0.0097\n",
      "Epoch 6/50\n",
      "808/808 [==============================] - 0s 86us/sample - loss: 0.0198 - val_loss: 0.0095\n",
      "Epoch 7/50\n",
      "808/808 [==============================] - 0s 87us/sample - loss: 0.0197 - val_loss: 0.0096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "808/808 [==============================] - 0s 88us/sample - loss: 0.0198 - val_loss: 0.0102\n",
      "Epoch 9/50\n",
      "808/808 [==============================] - 0s 88us/sample - loss: 0.0197 - val_loss: 0.0097\n",
      "Epoch 10/50\n",
      "808/808 [==============================] - 0s 88us/sample - loss: 0.0197 - val_loss: 0.0101\n",
      "Epoch 11/50\n",
      "808/808 [==============================] - 0s 83us/sample - loss: 0.0197 - val_loss: 0.0100\n",
      "Epoch 12/50\n",
      "808/808 [==============================] - 0s 81us/sample - loss: 0.0197 - val_loss: 0.0103\n",
      "Epoch 13/50\n",
      "808/808 [==============================] - 0s 81us/sample - loss: 0.0196 - val_loss: 0.0098\n",
      "Epoch 14/50\n",
      "808/808 [==============================] - 0s 82us/sample - loss: 0.0197 - val_loss: 0.0103\n",
      "Epoch 15/50\n",
      "808/808 [==============================] - 0s 82us/sample - loss: 0.0196 - val_loss: 0.0102\n",
      "Epoch 16/50\n",
      "808/808 [==============================] - 0s 81us/sample - loss: 0.0196 - val_loss: 0.0103\n",
      "Epoch 17/50\n",
      "808/808 [==============================] - 0s 83us/sample - loss: 0.0196 - val_loss: 0.0101\n",
      "Epoch 18/50\n",
      "808/808 [==============================] - 0s 84us/sample - loss: 0.0196 - val_loss: 0.0107\n",
      "Epoch 19/50\n",
      "808/808 [==============================] - 0s 83us/sample - loss: 0.0195 - val_loss: 0.0099\n",
      "Epoch 20/50\n",
      "808/808 [==============================] - 0s 88us/sample - loss: 0.0196 - val_loss: 0.0106\n",
      "Epoch 21/50\n",
      "808/808 [==============================] - 0s 86us/sample - loss: 0.0195 - val_loss: 0.0102\n",
      "Epoch 22/50\n",
      "808/808 [==============================] - 0s 83us/sample - loss: 0.0196 - val_loss: 0.0107\n",
      "Epoch 23/50\n",
      "808/808 [==============================] - 0s 84us/sample - loss: 0.0195 - val_loss: 0.0103\n",
      "Epoch 24/50\n",
      "808/808 [==============================] - 0s 86us/sample - loss: 0.0196 - val_loss: 0.0106\n",
      "Epoch 25/50\n",
      "808/808 [==============================] - 0s 84us/sample - loss: 0.0195 - val_loss: 0.0106\n",
      "Epoch 26/50\n",
      "808/808 [==============================] - 0s 86us/sample - loss: 0.0195 - val_loss: 0.0113\n",
      "Epoch 27/50\n",
      "808/808 [==============================] - 0s 82us/sample - loss: 0.0196 - val_loss: 0.0108\n",
      "Epoch 28/50\n",
      "808/808 [==============================] - 0s 87us/sample - loss: 0.0195 - val_loss: 0.0106\n",
      "Epoch 29/50\n",
      "808/808 [==============================] - 0s 88us/sample - loss: 0.0195 - val_loss: 0.0105\n",
      "Epoch 30/50\n",
      "808/808 [==============================] - 0s 84us/sample - loss: 0.0195 - val_loss: 0.0106\n",
      "Epoch 31/50\n",
      "808/808 [==============================] - 0s 82us/sample - loss: 0.0195 - val_loss: 0.0106\n",
      "Epoch 32/50\n",
      "808/808 [==============================] - 0s 85us/sample - loss: 0.0195 - val_loss: 0.0114\n",
      "Epoch 33/50\n",
      "808/808 [==============================] - 0s 89us/sample - loss: 0.0196 - val_loss: 0.0109\n",
      "Epoch 34/50\n",
      "808/808 [==============================] - 0s 85us/sample - loss: 0.0195 - val_loss: 0.0106\n",
      "Epoch 35/50\n",
      "808/808 [==============================] - 0s 88us/sample - loss: 0.0195 - val_loss: 0.0111\n",
      "Epoch 36/50\n",
      "808/808 [==============================] - 0s 84us/sample - loss: 0.0195 - val_loss: 0.0105\n",
      "Epoch 37/50\n",
      "808/808 [==============================] - 0s 80us/sample - loss: 0.0195 - val_loss: 0.0104\n",
      "Epoch 38/50\n",
      "808/808 [==============================] - 0s 81us/sample - loss: 0.0195 - val_loss: 0.0112\n",
      "Epoch 39/50\n",
      "808/808 [==============================] - 0s 82us/sample - loss: 0.0196 - val_loss: 0.0106\n",
      "Epoch 40/50\n",
      "808/808 [==============================] - 0s 89us/sample - loss: 0.0195 - val_loss: 0.0106\n",
      "Epoch 41/50\n",
      "808/808 [==============================] - 0s 94us/sample - loss: 0.0195 - val_loss: 0.0106\n",
      "Epoch 42/50\n",
      "808/808 [==============================] - 0s 87us/sample - loss: 0.0195 - val_loss: 0.0108\n",
      "Epoch 43/50\n",
      "808/808 [==============================] - 0s 86us/sample - loss: 0.0195 - val_loss: 0.0103\n",
      "Epoch 44/50\n",
      "808/808 [==============================] - 0s 89us/sample - loss: 0.0196 - val_loss: 0.0115\n",
      "Epoch 45/50\n",
      "808/808 [==============================] - 0s 90us/sample - loss: 0.0195 - val_loss: 0.0108\n",
      "Epoch 46/50\n",
      "808/808 [==============================] - 0s 87us/sample - loss: 0.0195 - val_loss: 0.0106\n",
      "Epoch 47/50\n",
      "808/808 [==============================] - 0s 79us/sample - loss: 0.0195 - val_loss: 0.0111\n",
      "Epoch 48/50\n",
      "808/808 [==============================] - 0s 84us/sample - loss: 0.0196 - val_loss: 0.0108\n",
      "Epoch 49/50\n",
      "808/808 [==============================] - 0s 83us/sample - loss: 0.0195 - val_loss: 0.0105\n",
      "Epoch 50/50\n",
      "808/808 [==============================] - 0s 82us/sample - loss: 0.0195 - val_loss: 0.0112\n",
      "第232个数，还剩3891个没有训练\n",
      "inv_hat [1.2371448  1.22132805 1.22429385 1.22330527 1.2035282  1.19957087\n",
      " 1.2015496  1.21144067 1.19957087 1.20649569 1.22330527 1.22231673\n",
      " 1.21836211 1.2074848  1.21045172 1.20451745 1.20946283 1.21045172\n",
      " 1.2203395  1.21045172 1.21045172 1.20550652 1.20253897 1.20056021\n",
      " 1.19759181 1.19957087 1.19858132 1.19759181 1.19561251 1.19561251]\n",
      "Test RMSE: 0.008\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0071 - val_loss: 0.0035\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0040\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0037\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0090 - val_loss: 0.0038\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0076 - val_loss: 0.0062\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0075 - val_loss: 0.0037\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0082 - val_loss: 0.0040\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0073 - val_loss: 0.0058\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0067 - val_loss: 0.0038\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0066 - val_loss: 0.0039\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0067 - val_loss: 0.0037\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0038\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0072 - val_loss: 0.0056\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0066 - val_loss: 0.0035\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0064 - val_loss: 0.0038\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0063 - val_loss: 0.0036\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0063 - val_loss: 0.0038\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0062 - val_loss: 0.0035\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0062 - val_loss: 0.0037\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0062 - val_loss: 0.0035\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0062 - val_loss: 0.0034\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0065 - val_loss: 0.0038\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0068 - val_loss: 0.0037\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0078 - val_loss: 0.0039\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0070 - val_loss: 0.0053\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0064 - val_loss: 0.0038\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0063 - val_loss: 0.0037\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0063 - val_loss: 0.0038\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0065 - val_loss: 0.0045\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0065 - val_loss: 0.0038\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0067 - val_loss: 0.0038\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0080 - val_loss: 0.0038\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0065 - val_loss: 0.0035\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0063 - val_loss: 0.0039\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0064 - val_loss: 0.0038\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0068 - val_loss: 0.0037\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0071 - val_loss: 0.0039\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0065 - val_loss: 0.0038\n",
      "第233个数，还剩3890个没有训练\n",
      "inv_hat [1.08347009 1.08051019 1.08122466 1.07938736 1.07765208 1.07795835\n",
      " 1.07744803 1.0804081  1.07918318 1.08163288 1.08551123 1.08561331\n",
      " 1.08520502 1.08265358 1.08255149 1.08142871 1.0829597  1.08449062\n",
      " 1.08775636 1.08387828 1.08347009 1.07918318 1.07785626 1.0749982\n",
      " 1.07122147 1.07111938 1.07081323 1.07020083 1.07009874 1.07316093]\n",
      "Test RMSE: 0.002\n",
      "Train on 915 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "915/915 [==============================] - 0s 81us/sample - loss: 0.0119 - val_loss: 0.0048\n",
      "Epoch 2/50\n",
      "915/915 [==============================] - 0s 81us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 3/50\n",
      "915/915 [==============================] - 0s 76us/sample - loss: 0.0118 - val_loss: 0.0048\n",
      "Epoch 4/50\n",
      "915/915 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 5/50\n",
      "915/915 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 6/50\n",
      "915/915 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 7/50\n",
      "915/915 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 8/50\n",
      "915/915 [==============================] - 0s 83us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 9/50\n",
      "915/915 [==============================] - 0s 82us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 10/50\n",
      "915/915 [==============================] - 0s 82us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 11/50\n",
      "915/915 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 12/50\n",
      "915/915 [==============================] - 0s 76us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 13/50\n",
      "915/915 [==============================] - 0s 76us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 14/50\n",
      "915/915 [==============================] - 0s 75us/sample - loss: 0.0118 - val_loss: 0.0048\n",
      "Epoch 15/50\n",
      "915/915 [==============================] - 0s 75us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 16/50\n",
      "915/915 [==============================] - 0s 76us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 17/50\n",
      "915/915 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 18/50\n",
      "915/915 [==============================] - 0s 77us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 19/50\n",
      "915/915 [==============================] - 0s 76us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 20/50\n",
      "915/915 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 21/50\n",
      "915/915 [==============================] - 0s 77us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 22/50\n",
      "915/915 [==============================] - 0s 77us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 23/50\n",
      "915/915 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 24/50\n",
      "915/915 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 25/50\n",
      "915/915 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 26/50\n",
      "915/915 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 27/50\n",
      "915/915 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 28/50\n",
      "915/915 [==============================] - 0s 77us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 29/50\n",
      "915/915 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 30/50\n",
      "915/915 [==============================] - 0s 81us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 31/50\n",
      "915/915 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 32/50\n",
      "915/915 [==============================] - 0s 81us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 33/50\n",
      "915/915 [==============================] - 0s 83us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 34/50\n",
      "915/915 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 35/50\n",
      "915/915 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 36/50\n",
      "915/915 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 37/50\n",
      "915/915 [==============================] - 0s 82us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 38/50\n",
      "915/915 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 39/50\n",
      "915/915 [==============================] - 0s 75us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 40/50\n",
      "915/915 [==============================] - 0s 81us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 41/50\n",
      "915/915 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 42/50\n",
      "915/915 [==============================] - 0s 75us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 43/50\n",
      "915/915 [==============================] - 0s 77us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 44/50\n",
      "915/915 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 45/50\n",
      "915/915 [==============================] - 0s 88us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 46/50\n",
      "915/915 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 47/50\n",
      "915/915 [==============================] - 0s 84us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 48/50\n",
      "915/915 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0048\n",
      "Epoch 49/50\n",
      "915/915 [==============================] - 0s 77us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 50/50\n",
      "915/915 [==============================] - 0s 75us/sample - loss: 0.0118 - val_loss: 0.0047\n",
      "第234个数，还剩3889个没有训练\n",
      "inv_hat [0.73286549 0.71482477 0.71682715 0.71382375 0.69882575 0.69383362\n",
      " 0.69583007 0.70982123 0.70382154 0.71482477 0.73888833 0.73788423\n",
      " 0.73989258 0.72083357 0.72283753 0.7118222  0.71482477 0.71682715\n",
      " 0.72784985 0.71883012 0.71082166 0.70582087 0.69483172 0.69283564\n",
      " 0.68685087 0.69183783 0.69283564 0.68884519 0.68585391 0.68485716]\n",
      "Test RMSE: 0.009\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0143 - val_loss: 0.0125\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0143 - val_loss: 0.0116\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0143 - val_loss: 0.0119\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0141 - val_loss: 0.0122\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0141 - val_loss: 0.0117\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0141 - val_loss: 0.0116\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0140 - val_loss: 0.0121\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0140 - val_loss: 0.0117\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0140 - val_loss: 0.0120\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0140 - val_loss: 0.0120\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0140 - val_loss: 0.0117\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0140 - val_loss: 0.0117\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0140 - val_loss: 0.0120\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0140 - val_loss: 0.0120\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0120\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0140 - val_loss: 0.0120\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0121\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0140 - val_loss: 0.0118\n",
      "第235个数，还剩3888个没有训练\n",
      "inv_hat [1.02541483 1.00738894 1.00659768 1.00402672 0.98792739 0.98723629\n",
      " 0.98437358 0.99888762 0.99138288 1.00066612 1.02333241 1.02412561\n",
      " 1.02372903 1.00669658 1.00827918 1.00116025 1.0063009  1.01005997\n",
      " 1.02521652 1.01114856 1.00808134 0.99839365 0.98733498 0.98038268\n",
      " 0.97107793 0.97507978 0.97097786 0.96627598 0.96357509 0.96657609]\n",
      "Test RMSE: 0.010\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0108 - val_loss: 0.0063\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0109 - val_loss: 0.0068\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0086\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0115 - val_loss: 0.0086\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0109 - val_loss: 0.0068\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0108 - val_loss: 0.0064\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0069\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0090\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0080\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0108 - val_loss: 0.0066\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0108 - val_loss: 0.0064\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0109 - val_loss: 0.0070\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0115 - val_loss: 0.0090\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0113 - val_loss: 0.0079\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0107 - val_loss: 0.0065\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0108 - val_loss: 0.0064\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0110 - val_loss: 0.0072\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0114 - val_loss: 0.0085\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0112 - val_loss: 0.0077\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0107 - val_loss: 0.0065\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0108 - val_loss: 0.0065\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0073\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0113 - val_loss: 0.0078\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0072\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0108 - val_loss: 0.0066\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0108 - val_loss: 0.0067\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0113 - val_loss: 0.0079\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0068\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0108 - val_loss: 0.0066\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0070\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0112 - val_loss: 0.0075\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0072\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0108 - val_loss: 0.0067\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0068\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0073\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0112 - val_loss: 0.0076\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0068\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0108 - val_loss: 0.0067\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0069\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0074\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0072\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0068\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0109 - val_loss: 0.0069\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0111 - val_loss: 0.0071\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0111 - val_loss: 0.0072\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0071\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0070\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0071\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0071\n",
      "第236个数，还剩3887个没有训练\n",
      "inv_hat [2.10079547 2.05810325 2.06505165 2.05909579 2.02733699 2.02336799\n",
      " 2.02039112 2.04321516 2.02237573 2.04222276 2.08987196 2.09384412\n",
      " 2.08987196 2.04718493 2.04520019 2.02138332 2.03031407 2.03626824\n",
      " 2.06207358 2.03428335 2.02932174 2.0094771  1.98963555 1.97773217\n",
      " 1.9569037  1.96285445 1.95392855 1.94599484 1.9350865  1.94202802]\n",
      "Test RMSE: 0.021\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0138 - val_loss: 0.0083\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0136 - val_loss: 0.0081\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0133 - val_loss: 0.0081\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0133 - val_loss: 0.0083\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0134 - val_loss: 0.0084\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0136 - val_loss: 0.0090\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0139 - val_loss: 0.0094\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0141 - val_loss: 0.0097\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0140 - val_loss: 0.0099\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0139 - val_loss: 0.0097\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0137 - val_loss: 0.0095\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0135 - val_loss: 0.0093\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0133 - val_loss: 0.0090\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0132 - val_loss: 0.0089\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0132 - val_loss: 0.0088\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0131 - val_loss: 0.0086\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0085\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0130 - val_loss: 0.0083\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0129 - val_loss: 0.0083\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0129 - val_loss: 0.0083\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0129 - val_loss: 0.0083\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0082\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0129 - val_loss: 0.0082\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0128 - val_loss: 0.0081\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0128 - val_loss: 0.0081\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0127 - val_loss: 0.0081\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0127 - val_loss: 0.0080\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0127 - val_loss: 0.0080\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0127 - val_loss: 0.0081\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0127 - val_loss: 0.0081\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0127 - val_loss: 0.0080\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0127 - val_loss: 0.0080\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0127 - val_loss: 0.0081\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0127 - val_loss: 0.0081\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0127 - val_loss: 0.0081\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 88us/sample - loss: 0.0127 - val_loss: 0.0080\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0127 - val_loss: 0.0080\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0127 - val_loss: 0.0080\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0127 - val_loss: 0.0080\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0127 - val_loss: 0.0081\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0127 - val_loss: 0.0080\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0127 - val_loss: 0.0080\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0127 - val_loss: 0.0080\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0127 - val_loss: 0.0080\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0127 - val_loss: 0.0080\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0127 - val_loss: 0.0080\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0127 - val_loss: 0.0080\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0127 - val_loss: 0.0080\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0127 - val_loss: 0.0080\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0127 - val_loss: 0.0080\n",
      "第237个数，还剩3886个没有训练\n",
      "inv_hat [1.04457022 1.01861376 1.02553578 1.02256833 0.999857   0.99887116\n",
      " 0.99788533 1.01861376 1.00380203 1.01268564 1.04256191 1.04557444\n",
      " 1.04256191 1.01960225 1.01960225 1.01367339 1.01663727 1.02059075\n",
      " 1.03754249 1.0215795  1.01663727 1.00577526 0.99000399 0.98705069\n",
      " 0.97721561 0.98705069 0.98311494 0.9762329  0.97033962 0.97426788]\n",
      "Test RMSE: 0.013\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0090 - val_loss: 0.0027\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0089 - val_loss: 0.0025\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0092 - val_loss: 0.0024\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0095 - val_loss: 0.0024\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0095 - val_loss: 0.0024\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0090 - val_loss: 0.0024\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0085 - val_loss: 0.0025\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0083 - val_loss: 0.0026\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0084 - val_loss: 0.0029\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0085 - val_loss: 0.0031\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0088 - val_loss: 0.0036\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0091 - val_loss: 0.0040\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0092 - val_loss: 0.0047\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0083 - val_loss: 0.0032\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0082 - val_loss: 0.0029\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0082 - val_loss: 0.0026\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0086 - val_loss: 0.0024\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0091 - val_loss: 0.0025\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0099 - val_loss: 0.0033\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0097 - val_loss: 0.0028\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0087 - val_loss: 0.0024\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0083 - val_loss: 0.0026\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0082 - val_loss: 0.0028\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0082 - val_loss: 0.0029\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0082 - val_loss: 0.0028\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0082 - val_loss: 0.0029\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0082 - val_loss: 0.0028\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0082 - val_loss: 0.0029\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0082 - val_loss: 0.0028\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0082 - val_loss: 0.0029\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0082 - val_loss: 0.0027\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0082 - val_loss: 0.0028\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0082 - val_loss: 0.0027\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0082 - val_loss: 0.0028\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0082 - val_loss: 0.0028\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0082 - val_loss: 0.0029\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0083 - val_loss: 0.0027\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0082 - val_loss: 0.0028\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0083 - val_loss: 0.0026\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0082 - val_loss: 0.0028\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0082 - val_loss: 0.0027\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0082 - val_loss: 0.0029\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0082 - val_loss: 0.0028\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0082 - val_loss: 0.0029\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0083 - val_loss: 0.0028\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0082 - val_loss: 0.0029\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0083 - val_loss: 0.0027\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0083 - val_loss: 0.0028\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0083 - val_loss: 0.0026\n",
      "第238个数，还剩3885个没有训练\n",
      "inv_hat [0.74217402 0.72802396 0.72860501 0.72734614 0.7117699  0.7117699\n",
      " 0.71070667 0.71757152 0.70954698 0.71457358 0.73073585 0.73141394\n",
      " 0.72792714 0.71718464 0.71834539 0.71234991 0.71505701 0.71795845\n",
      " 0.72637788 0.71747476 0.71718464 0.71196322 0.70519941 0.70278501\n",
      " 0.69757228 0.70056437 0.69622134 0.69525647 0.69323073 0.69602831]\n",
      "Test RMSE: 0.007\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0106 - val_loss: 0.0116\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0116\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0124 - val_loss: 0.0128\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0128\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0107 - val_loss: 0.0159\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0113 - val_loss: 0.0155\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0128 - val_loss: 0.0127\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0111\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0120 - val_loss: 0.0112\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0122\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0137\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0107 - val_loss: 0.0139\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0107 - val_loss: 0.0142\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0110 - val_loss: 0.0128\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0116 - val_loss: 0.0115\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0104 - val_loss: 0.0115\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0109 - val_loss: 0.0134\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0105 - val_loss: 0.0135\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0105 - val_loss: 0.0137\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0106 - val_loss: 0.0116\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0103 - val_loss: 0.0116\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0132\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0105 - val_loss: 0.0136\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0105 - val_loss: 0.0136\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0125\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0106 - val_loss: 0.0116\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0103 - val_loss: 0.0117\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0106 - val_loss: 0.0125\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0106 - val_loss: 0.0130\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0105 - val_loss: 0.0135\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0105 - val_loss: 0.0133\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0123\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0109 - val_loss: 0.0116\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0105 - val_loss: 0.0117\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0103 - val_loss: 0.0116\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0105 - val_loss: 0.0122\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0106 - val_loss: 0.0132\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0105 - val_loss: 0.0137\n",
      "第239个数，还剩3884个没有训练\n",
      "inv_hat [1.31949126 1.29751376 1.30635112 1.30042697 1.28192908 1.28303588\n",
      " 1.27649455 1.29289087 1.28273392 1.29942248 1.3353122  1.33611245\n",
      " 1.33211064 1.29902068 1.2931924  1.27951403 1.28695879 1.29168461\n",
      " 1.3135756  1.29158397 1.28856771 1.27417908 1.25553974 1.24051113\n",
      " 1.22194301 1.2279582  1.22414813 1.21392906 1.20922374 1.22214354]\n",
      "Test RMSE: 0.017\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0065 - val_loss: 0.0023\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0063 - val_loss: 0.0026\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0020\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0061 - val_loss: 0.0021\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0064 - val_loss: 0.0028\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0066 - val_loss: 0.0021\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0063 - val_loss: 0.0022\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0064 - val_loss: 0.0021\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0063 - val_loss: 0.0023\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0063 - val_loss: 0.0021\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0063 - val_loss: 0.0025\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0065 - val_loss: 0.0024\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0064 - val_loss: 0.0027\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0065 - val_loss: 0.0025\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0064 - val_loss: 0.0032\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0072 - val_loss: 0.0045\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0071 - val_loss: 0.0034\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0068 - val_loss: 0.0038\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0079 - val_loss: 0.0042\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0039\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0070 - val_loss: 0.0038\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0065 - val_loss: 0.0029\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0062 - val_loss: 0.0029\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0065 - val_loss: 0.0031\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0066 - val_loss: 0.0042\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0071 - val_loss: 0.0039\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0073 - val_loss: 0.0039\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0073 - val_loss: 0.0036\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0068 - val_loss: 0.0035\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0065 - val_loss: 0.0034\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0067 - val_loss: 0.0037\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0070 - val_loss: 0.0036\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0071 - val_loss: 0.0032\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0064 - val_loss: 0.0031\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0070 - val_loss: 0.0033\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0066 - val_loss: 0.0033\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0065 - val_loss: 0.0031\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0066 - val_loss: 0.0033\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0067 - val_loss: 0.0032\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0066 - val_loss: 0.0033\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0066 - val_loss: 0.0032\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0066 - val_loss: 0.0031\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0066 - val_loss: 0.0032\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0066 - val_loss: 0.0032\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0066 - val_loss: 0.0031\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0068 - val_loss: 0.0030\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0064 - val_loss: 0.0027\n",
      "第240个数，还剩3883个没有训练\n",
      "inv_hat [1.17650301 1.1755166  1.17650301 1.1755166  1.17453021 1.17453021\n",
      " 1.1755166  1.17650301 1.17748934 1.17847581 1.17847581 1.18143524\n",
      " 1.18143524 1.18340831 1.18538149 1.18735481 1.18834156 1.18834156\n",
      " 1.18439482 1.18340831 1.18242169 1.18340831 1.18538149 1.18636817\n",
      " 1.18636817 1.18538149 1.18636817 1.18834156 1.19031511 1.19426277]\n",
      "Test RMSE: 0.002\n",
      "Train on 1088 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1088/1088 [==============================] - 0s 86us/sample - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 2/50\n",
      "1088/1088 [==============================] - 0s 80us/sample - loss: 0.0084 - val_loss: 0.0126\n",
      "Epoch 3/50\n",
      "1088/1088 [==============================] - 0s 82us/sample - loss: 0.0097 - val_loss: 0.0149\n",
      "Epoch 4/50\n",
      "1088/1088 [==============================] - 0s 83us/sample - loss: 0.0058 - val_loss: 0.0066\n",
      "Epoch 5/50\n",
      "1088/1088 [==============================] - 0s 80us/sample - loss: 0.0075 - val_loss: 0.0106\n",
      "Epoch 6/50\n",
      "1088/1088 [==============================] - 0s 84us/sample - loss: 0.0050 - val_loss: 0.0070\n",
      "Epoch 7/50\n",
      "1088/1088 [==============================] - 0s 81us/sample - loss: 0.0053 - val_loss: 0.0074\n",
      "Epoch 8/50\n",
      "1088/1088 [==============================] - 0s 80us/sample - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 9/50\n",
      "1088/1088 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0125\n",
      "Epoch 10/50\n",
      "1088/1088 [==============================] - 0s 85us/sample - loss: 0.0050 - val_loss: 0.0095\n",
      "Epoch 11/50\n",
      "1088/1088 [==============================] - 0s 81us/sample - loss: 0.0077 - val_loss: 0.0147\n",
      "Epoch 12/50\n",
      "1088/1088 [==============================] - 0s 82us/sample - loss: 0.0132 - val_loss: 0.0062\n",
      "Epoch 13/50\n",
      "1088/1088 [==============================] - 0s 82us/sample - loss: 0.0139 - val_loss: 0.0145\n",
      "Epoch 14/50\n",
      "1088/1088 [==============================] - 0s 81us/sample - loss: 0.0074 - val_loss: 0.0145\n",
      "Epoch 15/50\n",
      "1088/1088 [==============================] - 0s 80us/sample - loss: 0.0185 - val_loss: 0.0200\n",
      "Epoch 16/50\n",
      "1088/1088 [==============================] - 0s 79us/sample - loss: 0.0101 - val_loss: 0.0053\n",
      "Epoch 17/50\n",
      "1088/1088 [==============================] - 0s 82us/sample - loss: 0.0067 - val_loss: 0.0116\n",
      "Epoch 18/50\n",
      "1088/1088 [==============================] - 0s 83us/sample - loss: 0.0093 - val_loss: 0.0085\n",
      "Epoch 19/50\n",
      "1088/1088 [==============================] - 0s 85us/sample - loss: 0.0099 - val_loss: 0.0048\n",
      "Epoch 20/50\n",
      "1088/1088 [==============================] - 0s 85us/sample - loss: 0.0057 - val_loss: 0.0066\n",
      "Epoch 21/50\n",
      "1088/1088 [==============================] - 0s 81us/sample - loss: 0.0053 - val_loss: 0.0091\n",
      "Epoch 22/50\n",
      "1088/1088 [==============================] - 0s 82us/sample - loss: 0.0058 - val_loss: 0.0120\n",
      "Epoch 23/50\n",
      "1088/1088 [==============================] - 0s 85us/sample - loss: 0.0132 - val_loss: 0.0108\n",
      "Epoch 24/50\n",
      "1088/1088 [==============================] - 0s 84us/sample - loss: 0.0104 - val_loss: 0.0052\n",
      "Epoch 25/50\n",
      "1088/1088 [==============================] - 0s 80us/sample - loss: 0.0055 - val_loss: 0.0076\n",
      "Epoch 26/50\n",
      "1088/1088 [==============================] - 0s 78us/sample - loss: 0.0058 - val_loss: 0.0068\n",
      "Epoch 27/50\n",
      "1088/1088 [==============================] - 0s 83us/sample - loss: 0.0047 - val_loss: 0.0058\n",
      "Epoch 28/50\n",
      "1088/1088 [==============================] - 0s 77us/sample - loss: 0.0051 - val_loss: 0.0071\n",
      "Epoch 29/50\n",
      "1088/1088 [==============================] - 0s 81us/sample - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 30/50\n",
      "1088/1088 [==============================] - 0s 79us/sample - loss: 0.0046 - val_loss: 0.0066\n",
      "Epoch 31/50\n",
      "1088/1088 [==============================] - 0s 81us/sample - loss: 0.0045 - val_loss: 0.0077\n",
      "Epoch 32/50\n",
      "1088/1088 [==============================] - 0s 80us/sample - loss: 0.0048 - val_loss: 0.0062\n",
      "Epoch 33/50\n",
      "1088/1088 [==============================] - 0s 80us/sample - loss: 0.0049 - val_loss: 0.0075\n",
      "Epoch 34/50\n",
      "1088/1088 [==============================] - 0s 82us/sample - loss: 0.0047 - val_loss: 0.0084\n",
      "Epoch 35/50\n",
      "1088/1088 [==============================] - 0s 87us/sample - loss: 0.0055 - val_loss: 0.0080\n",
      "Epoch 36/50\n",
      "1088/1088 [==============================] - 0s 85us/sample - loss: 0.0055 - val_loss: 0.0084\n",
      "Epoch 37/50\n",
      "1088/1088 [==============================] - 0s 80us/sample - loss: 0.0061 - val_loss: 0.0104\n",
      "Epoch 38/50\n",
      "1088/1088 [==============================] - 0s 80us/sample - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 39/50\n",
      "1088/1088 [==============================] - 0s 82us/sample - loss: 0.0083 - val_loss: 0.0060\n",
      "Epoch 40/50\n",
      "1088/1088 [==============================] - 0s 82us/sample - loss: 0.0057 - val_loss: 0.0101\n",
      "Epoch 41/50\n",
      "1088/1088 [==============================] - 0s 82us/sample - loss: 0.0069 - val_loss: 0.0116\n",
      "Epoch 42/50\n",
      "1088/1088 [==============================] - 0s 88us/sample - loss: 0.0118 - val_loss: 0.0081\n",
      "Epoch 43/50\n",
      "1088/1088 [==============================] - 0s 78us/sample - loss: 0.0090 - val_loss: 0.0050\n",
      "Epoch 44/50\n",
      "1088/1088 [==============================] - 0s 84us/sample - loss: 0.0058 - val_loss: 0.0075\n",
      "Epoch 45/50\n",
      "1088/1088 [==============================] - 0s 81us/sample - loss: 0.0076 - val_loss: 0.0049\n",
      "Epoch 46/50\n",
      "1088/1088 [==============================] - 0s 84us/sample - loss: 0.0054 - val_loss: 0.0073\n",
      "Epoch 47/50\n",
      "1088/1088 [==============================] - 0s 79us/sample - loss: 0.0058 - val_loss: 0.0106\n",
      "Epoch 48/50\n",
      "1088/1088 [==============================] - 0s 80us/sample - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 49/50\n",
      "1088/1088 [==============================] - 0s 84us/sample - loss: 0.0096 - val_loss: 0.0049\n",
      "Epoch 50/50\n",
      "1088/1088 [==============================] - 0s 81us/sample - loss: 0.0053 - val_loss: 0.0071\n",
      "第241个数，还剩3882个没有训练\n",
      "inv_hat [1.15590887 1.15601044 1.15631493 1.15641648 1.15631493 1.15631493\n",
      " 1.15631493 1.15631493 1.15661956 1.15692411 1.15722876 1.15793962\n",
      " 1.15875213 1.15966635 1.16027586 1.16108866 1.16139342 1.1617999\n",
      " 1.16068218 1.16007263 1.15956475 1.12922871 1.12922871 1.12953001\n",
      " 1.1298314  1.1303337  1.1305347  1.1306351  1.13083614 1.13204282]\n",
      "Test RMSE: 0.006\n",
      "Train on 1176 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1176/1176 [==============================] - 0s 81us/sample - loss: 0.0073 - val_loss: 0.0014\n",
      "Epoch 2/50\n",
      "1176/1176 [==============================] - 0s 79us/sample - loss: 0.0190 - val_loss: 0.0015\n",
      "Epoch 3/50\n",
      "1176/1176 [==============================] - 0s 79us/sample - loss: 0.0169 - val_loss: 0.0164\n",
      "Epoch 4/50\n",
      "1176/1176 [==============================] - 0s 78us/sample - loss: 0.0056 - val_loss: 0.0026\n",
      "Epoch 5/50\n",
      "1176/1176 [==============================] - 0s 78us/sample - loss: 0.0208 - val_loss: 0.0076\n",
      "Epoch 6/50\n",
      "1176/1176 [==============================] - 0s 81us/sample - loss: 0.0128 - val_loss: 0.0047\n",
      "Epoch 7/50\n",
      "1176/1176 [==============================] - 0s 79us/sample - loss: 0.0101 - val_loss: 0.0045\n",
      "Epoch 8/50\n",
      "1176/1176 [==============================] - 0s 81us/sample - loss: 0.0168 - val_loss: 0.0078\n",
      "Epoch 9/50\n",
      "1176/1176 [==============================] - 0s 82us/sample - loss: 0.0159 - val_loss: 0.0042\n",
      "Epoch 10/50\n",
      "1176/1176 [==============================] - 0s 82us/sample - loss: 0.0161 - val_loss: 0.0103\n",
      "Epoch 11/50\n",
      "1176/1176 [==============================] - 0s 82us/sample - loss: 0.0152 - val_loss: 0.0071\n",
      "Epoch 12/50\n",
      "1176/1176 [==============================] - 0s 80us/sample - loss: 0.0080 - val_loss: 0.0025\n",
      "Epoch 13/50\n",
      "1176/1176 [==============================] - 0s 77us/sample - loss: 0.0099 - val_loss: 0.0051\n",
      "Epoch 14/50\n",
      "1176/1176 [==============================] - 0s 79us/sample - loss: 0.0223 - val_loss: 0.0016\n",
      "Epoch 15/50\n",
      "1176/1176 [==============================] - 0s 83us/sample - loss: 0.0078 - val_loss: 0.0044\n",
      "Epoch 16/50\n",
      "1176/1176 [==============================] - 0s 82us/sample - loss: 0.0090 - val_loss: 0.0015\n",
      "Epoch 17/50\n",
      "1176/1176 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0044\n",
      "Epoch 18/50\n",
      "1176/1176 [==============================] - 0s 83us/sample - loss: 0.0188 - val_loss: 0.0023\n",
      "Epoch 19/50\n",
      "1176/1176 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0065\n",
      "Epoch 20/50\n",
      "1176/1176 [==============================] - 0s 77us/sample - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 21/50\n",
      "1176/1176 [==============================] - 0s 77us/sample - loss: 0.0147 - val_loss: 0.0072\n",
      "Epoch 22/50\n",
      "1176/1176 [==============================] - 0s 80us/sample - loss: 0.0078 - val_loss: 0.0025\n",
      "Epoch 23/50\n",
      "1176/1176 [==============================] - 0s 82us/sample - loss: 0.0067 - val_loss: 0.0054\n",
      "Epoch 24/50\n",
      "1176/1176 [==============================] - 0s 78us/sample - loss: 0.0146 - val_loss: 0.0063\n",
      "Epoch 25/50\n",
      "1176/1176 [==============================] - 0s 80us/sample - loss: 0.0160 - val_loss: 0.0028\n",
      "Epoch 26/50\n",
      "1176/1176 [==============================] - 0s 78us/sample - loss: 0.0132 - val_loss: 0.0043\n",
      "Epoch 27/50\n",
      "1176/1176 [==============================] - 0s 80us/sample - loss: 0.0088 - val_loss: 0.0063\n",
      "Epoch 28/50\n",
      "1176/1176 [==============================] - 0s 83us/sample - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 29/50\n",
      "1176/1176 [==============================] - 0s 82us/sample - loss: 0.0152 - val_loss: 0.0032\n",
      "Epoch 30/50\n",
      "1176/1176 [==============================] - 0s 78us/sample - loss: 0.0149 - val_loss: 0.0126\n",
      "Epoch 31/50\n",
      "1176/1176 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0026\n",
      "Epoch 32/50\n",
      "1176/1176 [==============================] - 0s 79us/sample - loss: 0.0087 - val_loss: 0.0071\n",
      "Epoch 33/50\n",
      "1176/1176 [==============================] - 0s 81us/sample - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 34/50\n",
      "1176/1176 [==============================] - 0s 80us/sample - loss: 0.0163 - val_loss: 0.0066\n",
      "Epoch 35/50\n",
      "1176/1176 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0018\n",
      "Epoch 36/50\n",
      "1176/1176 [==============================] - 0s 80us/sample - loss: 0.0164 - val_loss: 0.0083\n",
      "Epoch 37/50\n",
      "1176/1176 [==============================] - 0s 83us/sample - loss: 0.0102 - val_loss: 0.0062\n",
      "Epoch 38/50\n",
      "1176/1176 [==============================] - 0s 78us/sample - loss: 0.0103 - val_loss: 0.0022\n",
      "Epoch 39/50\n",
      "1176/1176 [==============================] - 0s 83us/sample - loss: 0.0075 - val_loss: 0.0036\n",
      "Epoch 40/50\n",
      "1176/1176 [==============================] - 0s 83us/sample - loss: 0.0191 - val_loss: 0.0070\n",
      "Epoch 41/50\n",
      "1176/1176 [==============================] - 0s 83us/sample - loss: 0.0081 - val_loss: 0.0057\n",
      "Epoch 42/50\n",
      "1176/1176 [==============================] - 0s 84us/sample - loss: 0.0082 - val_loss: 0.0033\n",
      "Epoch 43/50\n",
      "1176/1176 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 44/50\n",
      "1176/1176 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0041\n",
      "Epoch 45/50\n",
      "1176/1176 [==============================] - 0s 80us/sample - loss: 0.0166 - val_loss: 0.0059\n",
      "Epoch 46/50\n",
      "1176/1176 [==============================] - 0s 79us/sample - loss: 0.0089 - val_loss: 0.0021\n",
      "Epoch 47/50\n",
      "1176/1176 [==============================] - 0s 81us/sample - loss: 0.0073 - val_loss: 0.0018\n",
      "Epoch 48/50\n",
      "1176/1176 [==============================] - 0s 82us/sample - loss: 0.0080 - val_loss: 0.0052\n",
      "Epoch 49/50\n",
      "1176/1176 [==============================] - 0s 81us/sample - loss: 0.0192 - val_loss: 0.0030\n",
      "Epoch 50/50\n",
      "1176/1176 [==============================] - 0s 79us/sample - loss: 0.0085 - val_loss: 0.0016\n",
      "第242个数，还剩3881个没有训练\n",
      "inv_hat [0.65736367 0.65687218 0.62595467 0.62575995 0.62546782 0.62527313\n",
      " 0.62546782 0.62566259 0.62575995 0.62556519 0.62663635 0.62692853\n",
      " 0.62722075 0.62741562 0.62751306 0.62800014 0.62770786 0.62770786\n",
      " 0.62653894 0.62595467 0.62498111 0.6244944  0.62498111 0.62537051\n",
      " 0.62478639 0.62439712 0.6244944  0.6244944  0.62527313 0.62624678]\n",
      "Test RMSE: 0.006\n",
      "Train on 862 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "862/862 [==============================] - 0s 77us/sample - loss: 0.0218 - val_loss: 0.0173\n",
      "Epoch 2/50\n",
      "862/862 [==============================] - 0s 79us/sample - loss: 0.0200 - val_loss: 0.0196\n",
      "Epoch 3/50\n",
      "862/862 [==============================] - 0s 75us/sample - loss: 0.0195 - val_loss: 0.0170\n",
      "Epoch 4/50\n",
      "862/862 [==============================] - 0s 78us/sample - loss: 0.0193 - val_loss: 0.0168\n",
      "Epoch 5/50\n",
      "862/862 [==============================] - 0s 80us/sample - loss: 0.0191 - val_loss: 0.0166\n",
      "Epoch 6/50\n",
      "862/862 [==============================] - 0s 82us/sample - loss: 0.0191 - val_loss: 0.0165\n",
      "Epoch 7/50\n",
      "862/862 [==============================] - 0s 79us/sample - loss: 0.0191 - val_loss: 0.0164\n",
      "Epoch 8/50\n",
      "862/862 [==============================] - 0s 77us/sample - loss: 0.0191 - val_loss: 0.0164\n",
      "Epoch 9/50\n",
      "862/862 [==============================] - 0s 78us/sample - loss: 0.0191 - val_loss: 0.0164\n",
      "Epoch 10/50\n",
      "862/862 [==============================] - 0s 74us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 11/50\n",
      "862/862 [==============================] - 0s 78us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 12/50\n",
      "862/862 [==============================] - 0s 79us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 13/50\n",
      "862/862 [==============================] - 0s 77us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 14/50\n",
      "862/862 [==============================] - 0s 76us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 15/50\n",
      "862/862 [==============================] - 0s 78us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 16/50\n",
      "862/862 [==============================] - 0s 78us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 17/50\n",
      "862/862 [==============================] - 0s 74us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 18/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.019 - 0s 76us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 19/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.019 - 0s 77us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 20/50\n",
      "862/862 [==============================] - 0s 79us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 21/50\n",
      "862/862 [==============================] - 0s 72us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 22/50\n",
      "862/862 [==============================] - 0s 74us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 23/50\n",
      "862/862 [==============================] - 0s 77us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 24/50\n",
      "862/862 [==============================] - 0s 73us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 25/50\n",
      "862/862 [==============================] - 0s 75us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 26/50\n",
      "862/862 [==============================] - 0s 76us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 27/50\n",
      "862/862 [==============================] - 0s 78us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 28/50\n",
      "862/862 [==============================] - 0s 77us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 29/50\n",
      "862/862 [==============================] - 0s 78us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 30/50\n",
      "862/862 [==============================] - 0s 76us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 31/50\n",
      "862/862 [==============================] - 0s 80us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "862/862 [==============================] - 0s 84us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 33/50\n",
      "862/862 [==============================] - 0s 80us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 34/50\n",
      "862/862 [==============================] - 0s 81us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 35/50\n",
      "862/862 [==============================] - 0s 82us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 36/50\n",
      "862/862 [==============================] - 0s 84us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 37/50\n",
      "862/862 [==============================] - 0s 80us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 38/50\n",
      "862/862 [==============================] - 0s 82us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 39/50\n",
      "862/862 [==============================] - 0s 80us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 40/50\n",
      "862/862 [==============================] - 0s 76us/sample - loss: 0.0192 - val_loss: 0.0163\n",
      "Epoch 41/50\n",
      "862/862 [==============================] - 0s 79us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 42/50\n",
      "862/862 [==============================] - 0s 83us/sample - loss: 0.0192 - val_loss: 0.0163\n",
      "Epoch 43/50\n",
      "862/862 [==============================] - 0s 81us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 44/50\n",
      "862/862 [==============================] - 0s 79us/sample - loss: 0.0192 - val_loss: 0.0163\n",
      "Epoch 45/50\n",
      "862/862 [==============================] - 0s 80us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 46/50\n",
      "862/862 [==============================] - 0s 79us/sample - loss: 0.0192 - val_loss: 0.0163\n",
      "Epoch 47/50\n",
      "862/862 [==============================] - 0s 78us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 48/50\n",
      "862/862 [==============================] - 0s 77us/sample - loss: 0.0192 - val_loss: 0.0163\n",
      "Epoch 49/50\n",
      "862/862 [==============================] - 0s 78us/sample - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 50/50\n",
      "862/862 [==============================] - 0s 77us/sample - loss: 0.0192 - val_loss: 0.0163\n",
      "第243个数，还剩3880个没有训练\n",
      "inv_hat [1.00097364 0.97997742 0.98197935 0.97897618 0.95593113 0.95793601\n",
      " 0.95893836 0.96996221 0.95793601 0.96595414 0.98998285 0.99498086\n",
      " 0.98798268 0.97196579 0.9809784  0.97697367 0.97897618 0.98197935\n",
      " 1.00097364 0.97674498 0.98080672 0.96996221 0.9599407  0.95392632\n",
      " 0.94791181 0.95392632 0.9388915  0.93588554 0.93087698 0.93488372]\n",
      "Test RMSE: 0.011\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0084 - val_loss: 0.0033\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0081 - val_loss: 0.0020\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0081 - val_loss: 0.0021\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0081 - val_loss: 0.0020\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0081 - val_loss: 0.0021\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0083 - val_loss: 0.0027\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0086 - val_loss: 0.0035\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0089 - val_loss: 0.0030\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0085 - val_loss: 0.0025\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0082 - val_loss: 0.0020\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0021\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0083 - val_loss: 0.0036\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0092 - val_loss: 0.0056\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0094 - val_loss: 0.0045\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0082 - val_loss: 0.0031\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0081 - val_loss: 0.0020\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0081 - val_loss: 0.0020\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0080 - val_loss: 0.0021\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0022\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0082 - val_loss: 0.0029\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0086 - val_loss: 0.0041\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0088 - val_loss: 0.0038\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0086 - val_loss: 0.0038\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0084 - val_loss: 0.0031\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0083 - val_loss: 0.0029\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0083 - val_loss: 0.0031\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0084 - val_loss: 0.0030\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0085 - val_loss: 0.0034\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0085 - val_loss: 0.0032\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0084 - val_loss: 0.0031\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0083 - val_loss: 0.0027\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0083 - val_loss: 0.0028\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0083 - val_loss: 0.0029\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0084 - val_loss: 0.0027\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0084 - val_loss: 0.0028\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0083 - val_loss: 0.0027\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0083 - val_loss: 0.0026\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0083 - val_loss: 0.0026\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0083 - val_loss: 0.0026\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0084 - val_loss: 0.0026\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0084 - val_loss: 0.0027\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0083 - val_loss: 0.0026\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0082 - val_loss: 0.0021\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0020\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0021\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0083 - val_loss: 0.0031\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0091 - val_loss: 0.0048\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0041\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0084 - val_loss: 0.0030\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0080 - val_loss: 0.0020\n",
      "第244个数，还剩3879个没有训练\n",
      "inv_hat [0.65702427 0.64907817 0.64808549 0.64610053 0.64014871 0.64014871\n",
      " 0.64114038 0.64610053 0.64213212 0.64411604 0.65007104 0.65106397\n",
      " 0.65106397 0.64907817 0.65007104 0.64808549 0.64808549 0.64610053\n",
      " 0.65106397 0.64808549 0.64510825 0.64312402 0.63915722 0.63717468\n",
      " 0.63618359 0.63816587 0.63816587 0.63717468 0.63420182 0.63321119]\n",
      "Test RMSE: 0.003\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0062 - val_loss: 0.0157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "1195/1195 [==============================] - ETA: 0s - loss: 0.006 - 0s 80us/sample - loss: 0.0061 - val_loss: 0.0152\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0061 - val_loss: 0.0162\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0063 - val_loss: 0.0167\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0071 - val_loss: 0.0170\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0082 - val_loss: 0.0155\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0067 - val_loss: 0.0161\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0065 - val_loss: 0.0164\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0070 - val_loss: 0.0163\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0070 - val_loss: 0.0163\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0068 - val_loss: 0.0163\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0069 - val_loss: 0.0161\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0068 - val_loss: 0.0161\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0068 - val_loss: 0.0160\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0067 - val_loss: 0.0159\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0067 - val_loss: 0.0160\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0067 - val_loss: 0.0159\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0067 - val_loss: 0.0158\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0066 - val_loss: 0.0157\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0066 - val_loss: 0.0157\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0066 - val_loss: 0.0157\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0066 - val_loss: 0.0156\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0067 - val_loss: 0.0156\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0065 - val_loss: 0.0153\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0065 - val_loss: 0.0154\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0064 - val_loss: 0.0150\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0061 - val_loss: 0.0145\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0064 - val_loss: 0.0143\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0077 - val_loss: 0.0144\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0093 - val_loss: 0.0152\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0071 - val_loss: 0.0143\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0066 - val_loss: 0.0144\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0073 - val_loss: 0.0145\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0160\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0066 - val_loss: 0.0143\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0145\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0066 - val_loss: 0.0143\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0078 - val_loss: 0.0147\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0085 - val_loss: 0.0153\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0066 - val_loss: 0.0146\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0062 - val_loss: 0.0147\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0143\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0066 - val_loss: 0.0144\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0073 - val_loss: 0.0145\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0078 - val_loss: 0.0148\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0070 - val_loss: 0.0145\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0065 - val_loss: 0.0146\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0065 - val_loss: 0.0145\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0069 - val_loss: 0.0144\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0074 - val_loss: 0.0147\n",
      "第245个数，还剩3878个没有训练\n",
      "inv_hat [1.08947518 1.0825451  1.0825451  1.08155575 1.07759918 1.07957728\n",
      " 1.07858817 1.0825451  1.07759918 1.08056642 1.08749446 1.08848467\n",
      " 1.0878042  1.08287568 1.08522864 1.08223201 1.0842296  1.08522864\n",
      " 1.08722707 1.08323081 1.08323081 1.0792366  1.00720961 1.00620503\n",
      " 1.00242732 1.00143459 0.99944844 0.99845514 0.99845514 1.00143459]\n",
      "Test RMSE: 0.014\n",
      "Train on 1185 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1185/1185 [==============================] - 0s 84us/sample - loss: 0.0075 - val_loss: 0.0040\n",
      "Epoch 2/50\n",
      "1185/1185 [==============================] - 0s 83us/sample - loss: 0.0077 - val_loss: 0.0050\n",
      "Epoch 3/50\n",
      "1185/1185 [==============================] - 0s 81us/sample - loss: 0.0066 - val_loss: 0.0040\n",
      "Epoch 4/50\n",
      "1185/1185 [==============================] - 0s 76us/sample - loss: 0.0064 - val_loss: 0.0041\n",
      "Epoch 5/50\n",
      "1185/1185 [==============================] - 0s 77us/sample - loss: 0.0063 - val_loss: 0.0040\n",
      "Epoch 6/50\n",
      "1185/1185 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0040\n",
      "Epoch 7/50\n",
      "1185/1185 [==============================] - 0s 78us/sample - loss: 0.0063 - val_loss: 0.0042\n",
      "Epoch 8/50\n",
      "1185/1185 [==============================] - 0s 77us/sample - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 9/50\n",
      "1185/1185 [==============================] - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 10/50\n",
      "1185/1185 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0040\n",
      "Epoch 11/50\n",
      "1185/1185 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0040\n",
      "Epoch 12/50\n",
      "1185/1185 [==============================] - 0s 80us/sample - loss: 0.0065 - val_loss: 0.0040\n",
      "Epoch 13/50\n",
      "1185/1185 [==============================] - 0s 75us/sample - loss: 0.0064 - val_loss: 0.0040\n",
      "Epoch 14/50\n",
      "1185/1185 [==============================] - 0s 76us/sample - loss: 0.0065 - val_loss: 0.0040\n",
      "Epoch 15/50\n",
      "1185/1185 [==============================] - 0s 78us/sample - loss: 0.0063 - val_loss: 0.0040\n",
      "Epoch 16/50\n",
      "1185/1185 [==============================] - 0s 86us/sample - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 17/50\n",
      "1185/1185 [==============================] - 0s 80us/sample - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 18/50\n",
      "1185/1185 [==============================] - 0s 81us/sample - loss: 0.0065 - val_loss: 0.0041\n",
      "Epoch 19/50\n",
      "1185/1185 [==============================] - 0s 80us/sample - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 20/50\n",
      "1185/1185 [==============================] - 0s 78us/sample - loss: 0.0066 - val_loss: 0.0040\n",
      "Epoch 21/50\n",
      "1185/1185 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 22/50\n",
      "1185/1185 [==============================] - 0s 76us/sample - loss: 0.0065 - val_loss: 0.0041\n",
      "Epoch 23/50\n",
      "1185/1185 [==============================] - 0s 77us/sample - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 24/50\n",
      "1185/1185 [==============================] - 0s 80us/sample - loss: 0.0066 - val_loss: 0.0040\n",
      "Epoch 25/50\n",
      "1185/1185 [==============================] - 0s 79us/sample - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 26/50\n",
      "1185/1185 [==============================] - 0s 80us/sample - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 27/50\n",
      "1185/1185 [==============================] - 0s 80us/sample - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 28/50\n",
      "1185/1185 [==============================] - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 29/50\n",
      "1185/1185 [==============================] - 0s 74us/sample - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 30/50\n",
      "1185/1185 [==============================] - 0s 75us/sample - loss: 0.0065 - val_loss: 0.0039\n",
      "Epoch 31/50\n",
      "1185/1185 [==============================] - 0s 78us/sample - loss: 0.0063 - val_loss: 0.0040\n",
      "Epoch 32/50\n",
      "1185/1185 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 33/50\n",
      "1185/1185 [==============================] - 0s 81us/sample - loss: 0.0063 - val_loss: 0.0039\n",
      "Epoch 34/50\n",
      "1185/1185 [==============================] - 0s 84us/sample - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 35/50\n",
      "1185/1185 [==============================] - 0s 80us/sample - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 36/50\n",
      "1185/1185 [==============================] - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 37/50\n",
      "1185/1185 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 38/50\n",
      "1185/1185 [==============================] - 0s 75us/sample - loss: 0.0063 - val_loss: 0.0039\n",
      "Epoch 39/50\n",
      "1185/1185 [==============================] - 0s 76us/sample - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 40/50\n",
      "1185/1185 [==============================] - 0s 81us/sample - loss: 0.0063 - val_loss: 0.0039\n",
      "Epoch 41/50\n",
      "1185/1185 [==============================] - 0s 82us/sample - loss: 0.0063 - val_loss: 0.0039\n",
      "Epoch 42/50\n",
      "1185/1185 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 43/50\n",
      "1185/1185 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 44/50\n",
      "1185/1185 [==============================] - 0s 81us/sample - loss: 0.0066 - val_loss: 0.0039\n",
      "Epoch 45/50\n",
      "1185/1185 [==============================] - 0s 80us/sample - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 46/50\n",
      "1185/1185 [==============================] - 0s 75us/sample - loss: 0.0065 - val_loss: 0.0039\n",
      "Epoch 47/50\n",
      "1185/1185 [==============================] - 0s 77us/sample - loss: 0.0065 - val_loss: 0.0039\n",
      "Epoch 48/50\n",
      "1185/1185 [==============================] - 0s 76us/sample - loss: 0.0065 - val_loss: 0.0039\n",
      "Epoch 49/50\n",
      "1185/1185 [==============================] - 0s 76us/sample - loss: 0.0063 - val_loss: 0.0039\n",
      "Epoch 50/50\n",
      "1185/1185 [==============================] - 0s 74us/sample - loss: 0.0066 - val_loss: 0.0040\n",
      "第246个数，还剩3877个没有训练\n",
      "inv_hat [1.23576891 1.23037007 1.23095868 1.22948727 1.22576205 1.22546802\n",
      " 1.22684009 1.2288008  1.22723209 1.22850671 1.23439393 1.23488502\n",
      " 1.23429577 1.23174367 1.23184178 1.23066441 1.23066441 1.23105682\n",
      " 1.23243057 1.22948727 1.22742816 1.22429243 1.22203993 1.22086516\n",
      " 1.21675545 1.21792945 1.21753814 1.21665771 1.21685328 1.21832076]\n",
      "Test RMSE: 0.002\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0058 - val_loss: 7.0470e-04\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0073 - val_loss: 0.0047\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0108 - val_loss: 6.8126e-04\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0094 - val_loss: 0.0023\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0073 - val_loss: 0.0029\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0062 - val_loss: 0.0016\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0094 - val_loss: 7.6998e-04\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0180 - val_loss: 0.0241\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0094 - val_loss: 0.0012\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0076 - val_loss: 8.5218e-04\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0176 - val_loss: 0.0212\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0144 - val_loss: 0.0062\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0195 - val_loss: 0.0216\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0183 - val_loss: 0.0074\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0239 - val_loss: 0.0188\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0132 - val_loss: 0.0050\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0202 - val_loss: 0.0207\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0158 - val_loss: 0.0053\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0219 - val_loss: 0.0186\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0128 - val_loss: 0.0045\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0198 - val_loss: 0.0188\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0138 - val_loss: 0.0048\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0204 - val_loss: 0.0178\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0126 - val_loss: 0.0044\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0194 - val_loss: 0.0175\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0045\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0193 - val_loss: 0.0168\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0121 - val_loss: 0.0044\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0185 - val_loss: 0.0164\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0124 - val_loss: 0.0046\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0183 - val_loss: 0.0158\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0120 - val_loss: 0.0044\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0176 - val_loss: 0.0153\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0117 - val_loss: 0.0046\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0174 - val_loss: 0.0149\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0116 - val_loss: 0.0047\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0172 - val_loss: 0.0145\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0114 - val_loss: 0.0045\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0167 - val_loss: 0.0143\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0115 - val_loss: 0.0046\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0165 - val_loss: 0.0140\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0114 - val_loss: 0.0047\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0162 - val_loss: 0.0135\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0112 - val_loss: 0.0045\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0159 - val_loss: 0.0135\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0045\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0159 - val_loss: 0.0132\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0044\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0156 - val_loss: 0.0130\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0109 - val_loss: 0.0045\n",
      "第247个数，还剩3876个没有训练\n",
      "inv_hat [1.08081573 1.08081573 1.08081573 1.08081573 1.08081573 1.08081573\n",
      " 1.08081573 1.08081573 1.08081573 1.08081573 1.08081573 1.08177926\n",
      " 1.08177926 1.08177926 1.08177926 1.08274314 1.08274314 1.08274314\n",
      " 1.08177926 1.08177926 1.08177926 1.08177926 1.08177926 1.08177926\n",
      " 1.08274314 1.08274314 1.08274314 1.08274314 1.08274314 1.08467181]\n",
      "Test RMSE: 0.002\n",
      "Train on 724 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "724/724 [==============================] - 0s 84us/sample - loss: 0.0132 - val_loss: 0.0044\n",
      "Epoch 2/50\n",
      "724/724 [==============================] - 0s 81us/sample - loss: 0.0149 - val_loss: 0.0200\n",
      "Epoch 3/50\n",
      "724/724 [==============================] - 0s 82us/sample - loss: 0.0086 - val_loss: 0.0106\n",
      "Epoch 4/50\n",
      "724/724 [==============================] - 0s 82us/sample - loss: 0.0090 - val_loss: 0.0066\n",
      "Epoch 5/50\n",
      "724/724 [==============================] - 0s 94us/sample - loss: 0.0098 - val_loss: 0.0036\n",
      "Epoch 6/50\n",
      "724/724 [==============================] - 0s 81us/sample - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 7/50\n",
      "724/724 [==============================] - 0s 86us/sample - loss: 0.0059 - val_loss: 0.0037\n",
      "Epoch 8/50\n",
      "724/724 [==============================] - 0s 87us/sample - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 9/50\n",
      "724/724 [==============================] - 0s 86us/sample - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 10/50\n",
      "724/724 [==============================] - 0s 88us/sample - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 11/50\n",
      "724/724 [==============================] - 0s 92us/sample - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 12/50\n",
      "724/724 [==============================] - 0s 87us/sample - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 13/50\n",
      "724/724 [==============================] - 0s 89us/sample - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 14/50\n",
      "724/724 [==============================] - 0s 85us/sample - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 15/50\n",
      "724/724 [==============================] - 0s 86us/sample - loss: 0.0097 - val_loss: 0.0090\n",
      "Epoch 16/50\n",
      "724/724 [==============================] - 0s 89us/sample - loss: 0.0061 - val_loss: 0.0040\n",
      "Epoch 17/50\n",
      "724/724 [==============================] - 0s 91us/sample - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 18/50\n",
      "724/724 [==============================] - 0s 86us/sample - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 19/50\n",
      "724/724 [==============================] - 0s 86us/sample - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 20/50\n",
      "724/724 [==============================] - 0s 87us/sample - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 21/50\n",
      "724/724 [==============================] - 0s 84us/sample - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 22/50\n",
      "724/724 [==============================] - 0s 91us/sample - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 23/50\n",
      "724/724 [==============================] - 0s 84us/sample - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 24/50\n",
      "724/724 [==============================] - 0s 87us/sample - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 25/50\n",
      "724/724 [==============================] - 0s 86us/sample - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 26/50\n",
      "724/724 [==============================] - 0s 82us/sample - loss: 0.0079 - val_loss: 0.0054\n",
      "Epoch 27/50\n",
      "724/724 [==============================] - 0s 81us/sample - loss: 0.0067 - val_loss: 0.0038\n",
      "Epoch 28/50\n",
      "724/724 [==============================] - 0s 81us/sample - loss: 0.0055 - val_loss: 0.0035\n",
      "Epoch 29/50\n",
      "724/724 [==============================] - 0s 81us/sample - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 30/50\n",
      "724/724 [==============================] - 0s 84us/sample - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 31/50\n",
      "724/724 [==============================] - 0s 91us/sample - loss: 0.0069 - val_loss: 0.0041\n",
      "Epoch 32/50\n",
      "724/724 [==============================] - 0s 93us/sample - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 33/50\n",
      "724/724 [==============================] - 0s 87us/sample - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 34/50\n",
      "724/724 [==============================] - 0s 84us/sample - loss: 0.0065 - val_loss: 0.0039\n",
      "Epoch 35/50\n",
      "724/724 [==============================] - 0s 81us/sample - loss: 0.0067 - val_loss: 0.0038\n",
      "Epoch 36/50\n",
      "724/724 [==============================] - 0s 82us/sample - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 37/50\n",
      "724/724 [==============================] - 0s 82us/sample - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 38/50\n",
      "724/724 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 39/50\n",
      "724/724 [==============================] - 0s 80us/sample - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 40/50\n",
      "724/724 [==============================] - 0s 86us/sample - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 41/50\n",
      "724/724 [==============================] - 0s 84us/sample - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 42/50\n",
      "724/724 [==============================] - 0s 85us/sample - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 43/50\n",
      "724/724 [==============================] - 0s 86us/sample - loss: 0.0069 - val_loss: 0.0035\n",
      "Epoch 44/50\n",
      "724/724 [==============================] - 0s 86us/sample - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 45/50\n",
      "724/724 [==============================] - 0s 86us/sample - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 46/50\n",
      "724/724 [==============================] - 0s 93us/sample - loss: 0.0079 - val_loss: 0.0072\n",
      "Epoch 47/50\n",
      "724/724 [==============================] - 0s 88us/sample - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 48/50\n",
      "724/724 [==============================] - 0s 94us/sample - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 49/50\n",
      "724/724 [==============================] - 0s 86us/sample - loss: 0.0059 - val_loss: 0.0051\n",
      "Epoch 50/50\n",
      "724/724 [==============================] - 0s 85us/sample - loss: 0.0087 - val_loss: 0.0068\n",
      "第248个数，还剩3875个没有训练\n",
      "inv_hat [1.46637406 1.4669256  1.4669256  1.41116011 1.41116011 1.41116011\n",
      " 1.41116011 1.41116011 1.41014523 1.41116011 1.41116011 1.41116011\n",
      " 1.41217478 1.41217478 1.41217478 1.41318966 1.41318966 1.41318966\n",
      " 1.41318966 1.41318966 1.41217478 1.41116011 1.41116011 1.41116011\n",
      " 1.41217478 1.41217478 1.41217478 1.41318966 1.41318966 1.41521933]\n",
      "Test RMSE: 0.010\n",
      "Train on 588 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "588/588 [==============================] - 0s 90us/sample - loss: 0.0166 - val_loss: 0.0164\n",
      "Epoch 2/50\n",
      "588/588 [==============================] - 0s 87us/sample - loss: 0.0153 - val_loss: 0.0179\n",
      "Epoch 3/50\n",
      "588/588 [==============================] - 0s 88us/sample - loss: 0.0155 - val_loss: 0.0168\n",
      "Epoch 4/50\n",
      "588/588 [==============================] - 0s 90us/sample - loss: 0.0152 - val_loss: 0.0162\n",
      "Epoch 5/50\n",
      "588/588 [==============================] - 0s 88us/sample - loss: 0.0152 - val_loss: 0.0163\n",
      "Epoch 6/50\n",
      "588/588 [==============================] - 0s 90us/sample - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 7/50\n",
      "588/588 [==============================] - 0s 86us/sample - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 8/50\n",
      "588/588 [==============================] - 0s 87us/sample - loss: 0.0152 - val_loss: 0.0163\n",
      "Epoch 9/50\n",
      "588/588 [==============================] - 0s 85us/sample - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 10/50\n",
      "588/588 [==============================] - 0s 84us/sample - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 11/50\n",
      "588/588 [==============================] - 0s 83us/sample - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 12/50\n",
      "588/588 [==============================] - 0s 82us/sample - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 13/50\n",
      "588/588 [==============================] - 0s 85us/sample - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 14/50\n",
      "588/588 [==============================] - 0s 86us/sample - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 15/50\n",
      "588/588 [==============================] - 0s 88us/sample - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 16/50\n",
      "588/588 [==============================] - 0s 84us/sample - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 17/50\n",
      "588/588 [==============================] - 0s 87us/sample - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 18/50\n",
      "588/588 [==============================] - 0s 87us/sample - loss: 0.0152 - val_loss: 0.0164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "588/588 [==============================] - 0s 88us/sample - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 20/50\n",
      "588/588 [==============================] - 0s 87us/sample - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 21/50\n",
      "588/588 [==============================] - 0s 92us/sample - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 22/50\n",
      "588/588 [==============================] - 0s 85us/sample - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 23/50\n",
      "588/588 [==============================] - 0s 89us/sample - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 24/50\n",
      "588/588 [==============================] - 0s 89us/sample - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 25/50\n",
      "588/588 [==============================] - 0s 91us/sample - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 26/50\n",
      "588/588 [==============================] - 0s 87us/sample - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 27/50\n",
      "588/588 [==============================] - 0s 85us/sample - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 28/50\n",
      "588/588 [==============================] - 0s 87us/sample - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 29/50\n",
      "588/588 [==============================] - 0s 86us/sample - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 30/50\n",
      "588/588 [==============================] - 0s 91us/sample - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 31/50\n",
      "588/588 [==============================] - 0s 84us/sample - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 32/50\n",
      "588/588 [==============================] - 0s 81us/sample - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 33/50\n",
      "588/588 [==============================] - 0s 83us/sample - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 34/50\n",
      "588/588 [==============================] - 0s 86us/sample - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 35/50\n",
      "588/588 [==============================] - 0s 84us/sample - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 36/50\n",
      "588/588 [==============================] - 0s 88us/sample - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 37/50\n",
      "588/588 [==============================] - 0s 87us/sample - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 38/50\n",
      "588/588 [==============================] - 0s 85us/sample - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 39/50\n",
      "588/588 [==============================] - 0s 87us/sample - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 40/50\n",
      "588/588 [==============================] - 0s 82us/sample - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 41/50\n",
      "588/588 [==============================] - 0s 84us/sample - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 42/50\n",
      "588/588 [==============================] - 0s 85us/sample - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 43/50\n",
      "588/588 [==============================] - 0s 84us/sample - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 44/50\n",
      "588/588 [==============================] - 0s 87us/sample - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 45/50\n",
      "588/588 [==============================] - 0s 86us/sample - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 46/50\n",
      "588/588 [==============================] - 0s 98us/sample - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 47/50\n",
      "588/588 [==============================] - 0s 86us/sample - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 48/50\n",
      "588/588 [==============================] - 0s 84us/sample - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 49/50\n",
      "588/588 [==============================] - 0s 85us/sample - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 50/50\n",
      "588/588 [==============================] - 0s 88us/sample - loss: 0.0152 - val_loss: 0.0165\n",
      "第249个数，还剩3874个没有训练\n",
      "inv_hat [1.21204844 1.18116484 1.18315631 1.1821606  1.15827245 1.15926744\n",
      " 1.15329822 1.17519116 1.15528779 1.16722829 1.20208226 1.19510813\n",
      " 1.18813558 1.16225241 1.16324754 1.14733025 1.15727748 1.16324754\n",
      " 1.1861438  1.16822349 1.15827245 1.14235799 1.1294345  1.12844075\n",
      " 1.11751137 1.12148512 1.11850476 1.11254533 1.10063169 1.10063169]\n",
      "Test RMSE: 0.015\n",
      "Train on 590 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "590/590 [==============================] - 0s 87us/sample - loss: 0.0175 - val_loss: 0.0230\n",
      "Epoch 2/50\n",
      "590/590 [==============================] - 0s 88us/sample - loss: 0.0175 - val_loss: 0.0230\n",
      "Epoch 3/50\n",
      "590/590 [==============================] - 0s 88us/sample - loss: 0.0175 - val_loss: 0.0231\n",
      "Epoch 4/50\n",
      "590/590 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0231\n",
      "Epoch 5/50\n",
      "590/590 [==============================] - 0s 85us/sample - loss: 0.0175 - val_loss: 0.0232\n",
      "Epoch 6/50\n",
      "590/590 [==============================] - 0s 80us/sample - loss: 0.0175 - val_loss: 0.0233\n",
      "Epoch 7/50\n",
      "590/590 [==============================] - 0s 82us/sample - loss: 0.0175 - val_loss: 0.0233\n",
      "Epoch 8/50\n",
      "590/590 [==============================] - 0s 85us/sample - loss: 0.0175 - val_loss: 0.0234\n",
      "Epoch 9/50\n",
      "590/590 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0235\n",
      "Epoch 10/50\n",
      "590/590 [==============================] - 0s 86us/sample - loss: 0.0175 - val_loss: 0.0235\n",
      "Epoch 11/50\n",
      "590/590 [==============================] - 0s 84us/sample - loss: 0.0175 - val_loss: 0.0235\n",
      "Epoch 12/50\n",
      "590/590 [==============================] - 0s 86us/sample - loss: 0.0175 - val_loss: 0.0235\n",
      "Epoch 13/50\n",
      "590/590 [==============================] - 0s 88us/sample - loss: 0.0175 - val_loss: 0.0236\n",
      "Epoch 14/50\n",
      "590/590 [==============================] - 0s 87us/sample - loss: 0.0175 - val_loss: 0.0236\n",
      "Epoch 15/50\n",
      "590/590 [==============================] - 0s 85us/sample - loss: 0.0175 - val_loss: 0.0236\n",
      "Epoch 16/50\n",
      "590/590 [==============================] - 0s 84us/sample - loss: 0.0175 - val_loss: 0.0236\n",
      "Epoch 17/50\n",
      "590/590 [==============================] - 0s 84us/sample - loss: 0.0175 - val_loss: 0.0237\n",
      "Epoch 18/50\n",
      "590/590 [==============================] - 0s 88us/sample - loss: 0.0175 - val_loss: 0.0237\n",
      "Epoch 19/50\n",
      "590/590 [==============================] - 0s 88us/sample - loss: 0.0175 - val_loss: 0.0237\n",
      "Epoch 20/50\n",
      "590/590 [==============================] - 0s 85us/sample - loss: 0.0175 - val_loss: 0.0237\n",
      "Epoch 21/50\n",
      "590/590 [==============================] - 0s 89us/sample - loss: 0.0175 - val_loss: 0.0237\n",
      "Epoch 22/50\n",
      "590/590 [==============================] - 0s 86us/sample - loss: 0.0175 - val_loss: 0.0237\n",
      "Epoch 23/50\n",
      "590/590 [==============================] - 0s 91us/sample - loss: 0.0175 - val_loss: 0.0238\n",
      "Epoch 24/50\n",
      "590/590 [==============================] - 0s 86us/sample - loss: 0.0175 - val_loss: 0.0238\n",
      "Epoch 25/50\n",
      "590/590 [==============================] - 0s 90us/sample - loss: 0.0175 - val_loss: 0.0238\n",
      "Epoch 26/50\n",
      "590/590 [==============================] - 0s 88us/sample - loss: 0.0175 - val_loss: 0.0238\n",
      "Epoch 27/50\n",
      "590/590 [==============================] - 0s 87us/sample - loss: 0.0175 - val_loss: 0.0238\n",
      "Epoch 28/50\n",
      "590/590 [==============================] - 0s 85us/sample - loss: 0.0175 - val_loss: 0.0238\n",
      "Epoch 29/50\n",
      "590/590 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0239\n",
      "Epoch 30/50\n",
      "590/590 [==============================] - 0s 84us/sample - loss: 0.0175 - val_loss: 0.0238\n",
      "Epoch 31/50\n",
      "590/590 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0239\n",
      "Epoch 32/50\n",
      "590/590 [==============================] - 0s 86us/sample - loss: 0.0175 - val_loss: 0.0239\n",
      "Epoch 33/50\n",
      "590/590 [==============================] - 0s 89us/sample - loss: 0.0175 - val_loss: 0.0239\n",
      "Epoch 34/50\n",
      "590/590 [==============================] - 0s 88us/sample - loss: 0.0175 - val_loss: 0.0239\n",
      "Epoch 35/50\n",
      "590/590 [==============================] - 0s 81us/sample - loss: 0.0175 - val_loss: 0.0239\n",
      "Epoch 36/50\n",
      "590/590 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0239\n",
      "Epoch 37/50\n",
      "590/590 [==============================] - 0s 84us/sample - loss: 0.0175 - val_loss: 0.0240\n",
      "Epoch 38/50\n",
      "590/590 [==============================] - 0s 85us/sample - loss: 0.0175 - val_loss: 0.0240\n",
      "Epoch 39/50\n",
      "590/590 [==============================] - 0s 86us/sample - loss: 0.0175 - val_loss: 0.0240\n",
      "Epoch 40/50\n",
      "590/590 [==============================] - 0s 81us/sample - loss: 0.0175 - val_loss: 0.0240\n",
      "Epoch 41/50\n",
      "590/590 [==============================] - 0s 84us/sample - loss: 0.0175 - val_loss: 0.0241\n",
      "Epoch 42/50\n",
      "590/590 [==============================] - 0s 85us/sample - loss: 0.0175 - val_loss: 0.0241\n",
      "Epoch 43/50\n",
      "590/590 [==============================] - 0s 84us/sample - loss: 0.0175 - val_loss: 0.0241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "590/590 [==============================] - 0s 81us/sample - loss: 0.0175 - val_loss: 0.0241\n",
      "Epoch 45/50\n",
      "590/590 [==============================] - 0s 80us/sample - loss: 0.0175 - val_loss: 0.0242\n",
      "Epoch 46/50\n",
      "590/590 [==============================] - 0s 84us/sample - loss: 0.0175 - val_loss: 0.0242\n",
      "Epoch 47/50\n",
      "590/590 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0242\n",
      "Epoch 48/50\n",
      "590/590 [==============================] - 0s 85us/sample - loss: 0.0175 - val_loss: 0.0243\n",
      "Epoch 49/50\n",
      "590/590 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0243\n",
      "Epoch 50/50\n",
      "590/590 [==============================] - 0s 93us/sample - loss: 0.0175 - val_loss: 0.0243\n",
      "第250个数，还剩3873个没有训练\n",
      "inv_hat [1.0049972  0.97737121 0.98143529 0.98095139 0.95804731 0.95650334\n",
      " 0.96084639 0.97949975 0.96577131 0.97814517 1.00305456 1.00674626\n",
      " 1.00762099 0.99131499 0.99383567 0.98337141 0.98879527 0.99024884\n",
      " 1.00577448 0.98763263 0.98056425 0.97485642 0.95920542 0.96036375\n",
      " 0.9538986  0.9605568  0.95534555 0.95023398 0.93984135 0.94080215]\n",
      "Test RMSE: 0.013\n",
      "Train on 616 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "616/616 [==============================] - 0s 87us/sample - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 2/50\n",
      "616/616 [==============================] - 0s 86us/sample - loss: 0.0141 - val_loss: 0.0089\n",
      "Epoch 3/50\n",
      "616/616 [==============================] - 0s 85us/sample - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 4/50\n",
      "616/616 [==============================] - 0s 87us/sample - loss: 0.0129 - val_loss: 0.0083\n",
      "Epoch 5/50\n",
      "616/616 [==============================] - 0s 83us/sample - loss: 0.0093 - val_loss: 0.0082\n",
      "Epoch 6/50\n",
      "616/616 [==============================] - 0s 80us/sample - loss: 0.0105 - val_loss: 0.0081\n",
      "Epoch 7/50\n",
      "616/616 [==============================] - 0s 83us/sample - loss: 0.0083 - val_loss: 0.0089\n",
      "Epoch 8/50\n",
      "616/616 [==============================] - 0s 81us/sample - loss: 0.0101 - val_loss: 0.0078\n",
      "Epoch 9/50\n",
      "616/616 [==============================] - 0s 79us/sample - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 10/50\n",
      "616/616 [==============================] - 0s 80us/sample - loss: 0.0094 - val_loss: 0.0070\n",
      "Epoch 11/50\n",
      "616/616 [==============================] - 0s 86us/sample - loss: 0.0080 - val_loss: 0.0090\n",
      "Epoch 12/50\n",
      "616/616 [==============================] - 0s 84us/sample - loss: 0.0084 - val_loss: 0.0069\n",
      "Epoch 13/50\n",
      "616/616 [==============================] - 0s 85us/sample - loss: 0.0079 - val_loss: 0.0089\n",
      "Epoch 14/50\n",
      "616/616 [==============================] - 0s 85us/sample - loss: 0.0085 - val_loss: 0.0075\n",
      "Epoch 15/50\n",
      "616/616 [==============================] - 0s 77us/sample - loss: 0.0084 - val_loss: 0.0095\n",
      "Epoch 16/50\n",
      "616/616 [==============================] - 0s 78us/sample - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 17/50\n",
      "616/616 [==============================] - 0s 77us/sample - loss: 0.0079 - val_loss: 0.0090\n",
      "Epoch 18/50\n",
      "616/616 [==============================] - 0s 77us/sample - loss: 0.0082 - val_loss: 0.0075\n",
      "Epoch 19/50\n",
      "616/616 [==============================] - 0s 79us/sample - loss: 0.0084 - val_loss: 0.0095\n",
      "Epoch 20/50\n",
      "616/616 [==============================] - 0s 83us/sample - loss: 0.0083 - val_loss: 0.0071\n",
      "Epoch 21/50\n",
      "616/616 [==============================] - 0s 93us/sample - loss: 0.0082 - val_loss: 0.0097\n",
      "Epoch 22/50\n",
      "616/616 [==============================] - 0s 86us/sample - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 23/50\n",
      "616/616 [==============================] - 0s 85us/sample - loss: 0.0079 - val_loss: 0.0091\n",
      "Epoch 24/50\n",
      "616/616 [==============================] - 0s 89us/sample - loss: 0.0085 - val_loss: 0.0077\n",
      "Epoch 25/50\n",
      "616/616 [==============================] - 0s 82us/sample - loss: 0.0085 - val_loss: 0.0094\n",
      "Epoch 26/50\n",
      "616/616 [==============================] - 0s 81us/sample - loss: 0.0083 - val_loss: 0.0075\n",
      "Epoch 27/50\n",
      "616/616 [==============================] - 0s 79us/sample - loss: 0.0079 - val_loss: 0.0093\n",
      "Epoch 28/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.009 - 0s 76us/sample - loss: 0.0084 - val_loss: 0.0078\n",
      "Epoch 29/50\n",
      "616/616 [==============================] - 0s 79us/sample - loss: 0.0085 - val_loss: 0.0096\n",
      "Epoch 30/50\n",
      "616/616 [==============================] - 0s 79us/sample - loss: 0.0084 - val_loss: 0.0077\n",
      "Epoch 31/50\n",
      "616/616 [==============================] - 0s 82us/sample - loss: 0.0079 - val_loss: 0.0095\n",
      "Epoch 32/50\n",
      "616/616 [==============================] - 0s 83us/sample - loss: 0.0083 - val_loss: 0.0074\n",
      "Epoch 33/50\n",
      "616/616 [==============================] - 0s 84us/sample - loss: 0.0085 - val_loss: 0.0097\n",
      "Epoch 34/50\n",
      "616/616 [==============================] - 0s 80us/sample - loss: 0.0084 - val_loss: 0.0074\n",
      "Epoch 35/50\n",
      "616/616 [==============================] - 0s 78us/sample - loss: 0.0079 - val_loss: 0.0098\n",
      "Epoch 36/50\n",
      "616/616 [==============================] - 0s 82us/sample - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 37/50\n",
      "616/616 [==============================] - 0s 83us/sample - loss: 0.0081 - val_loss: 0.0106\n",
      "Epoch 38/50\n",
      "616/616 [==============================] - 0s 84us/sample - loss: 0.0086 - val_loss: 0.0069\n",
      "Epoch 39/50\n",
      "616/616 [==============================] - 0s 87us/sample - loss: 0.0079 - val_loss: 0.0089\n",
      "Epoch 40/50\n",
      "616/616 [==============================] - 0s 86us/sample - loss: 0.0079 - val_loss: 0.0086\n",
      "Epoch 41/50\n",
      "616/616 [==============================] - 0s 80us/sample - loss: 0.0079 - val_loss: 0.0087\n",
      "Epoch 42/50\n",
      "616/616 [==============================] - 0s 85us/sample - loss: 0.0079 - val_loss: 0.0103\n",
      "Epoch 43/50\n",
      "616/616 [==============================] - 0s 90us/sample - loss: 0.0080 - val_loss: 0.0084\n",
      "Epoch 44/50\n",
      "616/616 [==============================] - 0s 85us/sample - loss: 0.0078 - val_loss: 0.0091\n",
      "Epoch 45/50\n",
      "616/616 [==============================] - 0s 88us/sample - loss: 0.0078 - val_loss: 0.0088\n",
      "Epoch 46/50\n",
      "616/616 [==============================] - 0s 83us/sample - loss: 0.0078 - val_loss: 0.0097\n",
      "Epoch 47/50\n",
      "616/616 [==============================] - 0s 82us/sample - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 48/50\n",
      "616/616 [==============================] - 0s 82us/sample - loss: 0.0083 - val_loss: 0.0103\n",
      "Epoch 49/50\n",
      "616/616 [==============================] - 0s 81us/sample - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 50/50\n",
      "616/616 [==============================] - 0s 82us/sample - loss: 0.0078 - val_loss: 0.0092\n",
      "第251个数，还剩3872个没有训练\n",
      "inv_hat [0.15842157 0.15832261 0.15832261 0.15832261 0.15832261 0.15842157\n",
      " 0.15832261 0.15832261 0.15832261 0.15842157 0.15842157 0.15822385\n",
      " 0.15792676 0.15812521 0.15822385 0.15812521 0.15802594 0.15802594\n",
      " 0.15822385 0.15812521 0.15822385 0.15822385 0.15842157 0.15842157\n",
      " 0.15822385 0.15822385 0.15839326 0.1584915  0.15832261 0.15852074]\n",
      "Test RMSE: 0.000\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0063 - val_loss: 0.0184\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0050 - val_loss: 0.0156\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0049 - val_loss: 0.0153\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0043 - val_loss: 0.0164\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0039 - val_loss: 0.0162\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0036 - val_loss: 0.0155\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0035 - val_loss: 0.0152\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0032 - val_loss: 0.0151\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0034 - val_loss: 0.0150\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0032 - val_loss: 0.0150\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0032 - val_loss: 0.0152\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0035 - val_loss: 0.0153\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0031 - val_loss: 0.0149\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0032 - val_loss: 0.0150\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0036 - val_loss: 0.0150\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0031 - val_loss: 0.0153\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0034 - val_loss: 0.0151\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0036 - val_loss: 0.0150\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0032 - val_loss: 0.0151\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0034 - val_loss: 0.0149\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0033 - val_loss: 0.0150\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0035 - val_loss: 0.0150\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0038 - val_loss: 0.0160\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0051 - val_loss: 0.0149\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0049 - val_loss: 0.0166\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0062 - val_loss: 0.0150\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0063 - val_loss: 0.0153\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0080 - val_loss: 0.0163\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0065 - val_loss: 0.0156\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0047 - val_loss: 0.0156\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0059 - val_loss: 0.0154\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0063 - val_loss: 0.0154\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0059 - val_loss: 0.0153\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0048 - val_loss: 0.0155\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0051 - val_loss: 0.0160\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0062 - val_loss: 0.0156\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0052 - val_loss: 0.0153\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0045 - val_loss: 0.0154\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0045 - val_loss: 0.0157\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0048 - val_loss: 0.0153\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0044 - val_loss: 0.0155\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0048 - val_loss: 0.0156\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0052 - val_loss: 0.0155\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0047 - val_loss: 0.0153\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0043 - val_loss: 0.0156\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0046 - val_loss: 0.0156\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0048 - val_loss: 0.0156\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0049 - val_loss: 0.0153\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0042 - val_loss: 0.0154\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0042 - val_loss: 0.0156\n",
      "第252个数，还剩3871个没有训练\n",
      "inv_hat [1.33929826 1.34027393 1.34027393 1.34027393 1.33929826 1.3399882\n",
      " 1.33929826 1.34027393 1.34222338 1.34222338 1.34319711 1.34708458\n",
      " 1.34805471 1.34999265 1.34999265 1.3528941  1.3528941  1.3528941\n",
      " 1.34902407 1.34805471 1.34611384 1.34611384 1.34805471 1.34999265\n",
      " 1.35096058 1.34999265 1.35192765 1.22150214 1.22355124 1.2256    ]\n",
      "Test RMSE: 0.024\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0140 - val_loss: 0.0113\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0143 - val_loss: 0.0124\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0140 - val_loss: 0.0112\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0137 - val_loss: 0.0112\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0137 - val_loss: 0.0116\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0137 - val_loss: 0.0115\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0137 - val_loss: 0.0114\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0136 - val_loss: 0.0114\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0136 - val_loss: 0.0114\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0136 - val_loss: 0.0115\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0136 - val_loss: 0.0116\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0136 - val_loss: 0.0114\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0136 - val_loss: 0.0118\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0137 - val_loss: 0.0119\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0135 - val_loss: 0.0114\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0136 - val_loss: 0.0117\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0137 - val_loss: 0.0124\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0136 - val_loss: 0.0115\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0136 - val_loss: 0.0115\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0137 - val_loss: 0.0127\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0138 - val_loss: 0.0120\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0135 - val_loss: 0.0114\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0137 - val_loss: 0.0127\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0137 - val_loss: 0.0122\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0135 - val_loss: 0.0114\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0137 - val_loss: 0.0131\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0138 - val_loss: 0.0121\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0135 - val_loss: 0.0114\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0137 - val_loss: 0.0128\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0139 - val_loss: 0.0127\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0135 - val_loss: 0.0115\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0136 - val_loss: 0.0121\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0139 - val_loss: 0.0135\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0136 - val_loss: 0.0114\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0137 - val_loss: 0.0119\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0138 - val_loss: 0.0121\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0136 - val_loss: 0.0112\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0138 - val_loss: 0.0135\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0142 - val_loss: 0.0132\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0135 - val_loss: 0.0112\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0138 - val_loss: 0.0122\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0140 - val_loss: 0.0142\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0137 - val_loss: 0.0118\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0137 - val_loss: 0.0111\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0139 - val_loss: 0.0145\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0143 - val_loss: 0.0130\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0135 - val_loss: 0.0111\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0138 - val_loss: 0.0127\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0142 - val_loss: 0.0145\n",
      "第253个数，还剩3870个没有训练\n",
      "inv_hat [0.9085478  0.88790161 0.89183213 0.89084935 0.86530276 0.86233733\n",
      " 0.86629122 0.88200755 0.86530276 0.87218839 0.89084935 0.88986676\n",
      " 0.88888416 0.87611545 0.87807932 0.86826209 0.87709736 0.87611545\n",
      " 0.88888416 0.87611545 0.87317008 0.86530276 0.85739516 0.85838356\n",
      " 0.8494882  0.8564068  0.85344164 0.8494882  0.84059337 0.84355828]\n",
      "Test RMSE: 0.012\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0089\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0117 - val_loss: 0.0090\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0116 - val_loss: 0.0092\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "第254个数，还剩3869个没有训练\n",
      "inv_hat [0.77558089 0.75620604 0.76077447 0.76077447 0.74289834 0.73793256\n",
      " 0.7383298  0.74428872 0.73485361 0.74309694 0.76554177 0.7650452\n",
      " 0.76385333 0.74587766 0.74786394 0.73842913 0.74538119 0.7471688\n",
      " 0.75779508 0.74478524 0.74210382 0.73157588 0.72343039 0.72402643\n",
      " 0.7139916  0.7182642  0.71587952 0.71438908 0.70951966 0.71309726]\n",
      "Test RMSE: 0.009\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0113 - val_loss: 0.0086\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0116 - val_loss: 0.0089\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0114 - val_loss: 0.0087\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0114 - val_loss: 0.0087\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0114 - val_loss: 0.0087\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0113 - val_loss: 0.0088\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0086\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0087\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0114 - val_loss: 0.0087\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0114 - val_loss: 0.0087\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0113 - val_loss: 0.0088\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0113 - val_loss: 0.0088\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0088\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0113 - val_loss: 0.0088\n",
      "第255个数，还剩3868个没有训练\n",
      "inv_hat [1.57421831 1.53008404 1.53669941 1.53590957 1.49916856 1.49679707\n",
      " 1.50371349 1.53314506 1.51122119 1.53107149 1.57076271 1.5766867\n",
      " 1.57806893 1.552103   1.55615103 1.53936547 1.54815362 1.5504246\n",
      " 1.57510696 1.54617886 1.53492231 1.52573934 1.50074946 1.50252782\n",
      " 1.49215259 1.50282429 1.49452438 1.48632133 1.46961237 1.47109581]\n",
      "Test RMSE: 0.020\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0059 - val_loss: 0.0021\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0061 - val_loss: 0.0026\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0065 - val_loss: 0.0024\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0062 - val_loss: 0.0027\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0070 - val_loss: 0.0021\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0065 - val_loss: 0.0027\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0083 - val_loss: 0.0038\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0029\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0068 - val_loss: 0.0030\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0065 - val_loss: 0.0038\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0087 - val_loss: 0.0049\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0077 - val_loss: 0.0034\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0063 - val_loss: 0.0030\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0074 - val_loss: 0.0049\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0071 - val_loss: 0.0040\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0076 - val_loss: 0.0038\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0074 - val_loss: 0.0032\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0066 - val_loss: 0.0032\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0066 - val_loss: 0.0034\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0070 - val_loss: 0.0035\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0074 - val_loss: 0.0030\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0066 - val_loss: 0.0030\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0065 - val_loss: 0.0029\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0067 - val_loss: 0.0032\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0071 - val_loss: 0.0034\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0071 - val_loss: 0.0030\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0065 - val_loss: 0.0026\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0063 - val_loss: 0.0029\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0068 - val_loss: 0.0024\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0062 - val_loss: 0.0023\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0069 - val_loss: 0.0034\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0065 - val_loss: 0.0024\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0062 - val_loss: 0.0028\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0069 - val_loss: 0.0031\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0064 - val_loss: 0.0025\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0062 - val_loss: 0.0029\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0067 - val_loss: 0.0031\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0068 - val_loss: 0.0033\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0067 - val_loss: 0.0027\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0064 - val_loss: 0.0027\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0067 - val_loss: 0.0029\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0027\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0066 - val_loss: 0.0028\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0063 - val_loss: 0.0025\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0063 - val_loss: 0.0029\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0067 - val_loss: 0.0029\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0063 - val_loss: 0.0023\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0063 - val_loss: 0.0027\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0062 - val_loss: 0.0027\n",
      "第256个数，还剩3867个没有训练\n",
      "inv_hat [1.14146772 1.14146772 1.14246037 1.14146772 1.14047506 1.14047506\n",
      " 1.14047506 1.14146772 1.14345286 1.14345286 1.14345286 1.14642917\n",
      " 1.14642917 1.14841279 1.15138689 1.15237806 1.15336909 1.15336909\n",
      " 1.14940427 1.14841279 1.14742106 1.14841279 1.15039572 1.15138689\n",
      " 1.15138689 1.15039572 1.15138689 1.15237806 1.1553506  1.15931201]\n",
      "Test RMSE: 0.002\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0135 - val_loss: 0.0097\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0132 - val_loss: 0.0080\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0131 - val_loss: 0.0095\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0131 - val_loss: 0.0090\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0129 - val_loss: 0.0082\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0130 - val_loss: 0.0092\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0130 - val_loss: 0.0088\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0086\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0130 - val_loss: 0.0093\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0129 - val_loss: 0.0086\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0129 - val_loss: 0.0088\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0129 - val_loss: 0.0089\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0129 - val_loss: 0.0091\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0129 - val_loss: 0.0086\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0129 - val_loss: 0.0090\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0129 - val_loss: 0.0088\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0129 - val_loss: 0.0089\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0129 - val_loss: 0.0090\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0129 - val_loss: 0.0089\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0129 - val_loss: 0.0087\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0130 - val_loss: 0.0091\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0129 - val_loss: 0.0088\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0129 - val_loss: 0.0087\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0129 - val_loss: 0.0090\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0088\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0129 - val_loss: 0.0089\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0129 - val_loss: 0.0088\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0129 - val_loss: 0.0091\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0129 - val_loss: 0.0088\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0129 - val_loss: 0.0087\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0129 - val_loss: 0.0089\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0129 - val_loss: 0.0089\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0129 - val_loss: 0.0089\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0129 - val_loss: 0.0086\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0130 - val_loss: 0.0090\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0087\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0086\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0129 - val_loss: 0.0089\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0129 - val_loss: 0.0088\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0129 - val_loss: 0.0087\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0129 - val_loss: 0.0089\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0129 - val_loss: 0.0088\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0129 - val_loss: 0.0085\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0130 - val_loss: 0.0090\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0129 - val_loss: 0.0087\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0129 - val_loss: 0.0085\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0130 - val_loss: 0.0090\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0130 - val_loss: 0.0087\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0129 - val_loss: 0.0085\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0129 - val_loss: 0.0089\n",
      "第257个数，还剩3866个没有训练\n",
      "inv_hat [1.37490207 1.34212598 1.34908391 1.34411426 1.31725131 1.30629404\n",
      " 1.31625559 1.33417036 1.31127562 1.32322485 1.37986259 1.38581333\n",
      " 1.3907708  1.36596944 1.36398384 1.35703221 1.35405204 1.35703221\n",
      " 1.36497662 1.34212598 1.31525968 1.31027938 1.28235959 1.29233685\n",
      " 1.28435555 1.30529747 1.30430083 1.29034197 1.2793651  1.27736849]\n",
      "Test RMSE: 0.020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 671 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "671/671 [==============================] - 0s 85us/sample - loss: 0.0214 - val_loss: 0.0111\n",
      "Epoch 2/50\n",
      "671/671 [==============================] - 0s 85us/sample - loss: 0.0215 - val_loss: 0.0161\n",
      "Epoch 3/50\n",
      "671/671 [==============================] - 0s 82us/sample - loss: 0.0247 - val_loss: 0.0109\n",
      "Epoch 4/50\n",
      "671/671 [==============================] - 0s 80us/sample - loss: 0.0230 - val_loss: 0.0146\n",
      "Epoch 5/50\n",
      "671/671 [==============================] - 0s 80us/sample - loss: 0.0236 - val_loss: 0.0154\n",
      "Epoch 6/50\n",
      "671/671 [==============================] - 0s 80us/sample - loss: 0.0236 - val_loss: 0.0112\n",
      "Epoch 7/50\n",
      "671/671 [==============================] - 0s 80us/sample - loss: 0.0214 - val_loss: 0.0109\n",
      "Epoch 8/50\n",
      "671/671 [==============================] - 0s 82us/sample - loss: 0.0213 - val_loss: 0.0112\n",
      "Epoch 9/50\n",
      "671/671 [==============================] - 0s 85us/sample - loss: 0.0213 - val_loss: 0.0121\n",
      "Epoch 10/50\n",
      "671/671 [==============================] - 0s 83us/sample - loss: 0.0215 - val_loss: 0.0110\n",
      "Epoch 11/50\n",
      "671/671 [==============================] - 0s 86us/sample - loss: 0.0213 - val_loss: 0.0108\n",
      "Epoch 12/50\n",
      "671/671 [==============================] - 0s 83us/sample - loss: 0.0213 - val_loss: 0.0109\n",
      "Epoch 13/50\n",
      "671/671 [==============================] - 0s 82us/sample - loss: 0.0212 - val_loss: 0.0107\n",
      "Epoch 14/50\n",
      "671/671 [==============================] - 0s 83us/sample - loss: 0.0214 - val_loss: 0.0114\n",
      "Epoch 15/50\n",
      "671/671 [==============================] - 0s 81us/sample - loss: 0.0214 - val_loss: 0.0110\n",
      "Epoch 16/50\n",
      "671/671 [==============================] - 0s 81us/sample - loss: 0.0215 - val_loss: 0.0113\n",
      "Epoch 17/50\n",
      "671/671 [==============================] - 0s 81us/sample - loss: 0.0215 - val_loss: 0.0112\n",
      "Epoch 18/50\n",
      "671/671 [==============================] - 0s 80us/sample - loss: 0.0213 - val_loss: 0.0112\n",
      "Epoch 19/50\n",
      "671/671 [==============================] - 0s 87us/sample - loss: 0.0218 - val_loss: 0.0111\n",
      "Epoch 20/50\n",
      "671/671 [==============================] - 0s 82us/sample - loss: 0.0216 - val_loss: 0.0111\n",
      "Epoch 21/50\n",
      "671/671 [==============================] - 0s 79us/sample - loss: 0.0212 - val_loss: 0.0108\n",
      "Epoch 22/50\n",
      "671/671 [==============================] - 0s 80us/sample - loss: 0.0212 - val_loss: 0.0120\n",
      "Epoch 23/50\n",
      "671/671 [==============================] - 0s 82us/sample - loss: 0.0214 - val_loss: 0.0108\n",
      "Epoch 24/50\n",
      "671/671 [==============================] - 0s 81us/sample - loss: 0.0215 - val_loss: 0.0113\n",
      "Epoch 25/50\n",
      "671/671 [==============================] - 0s 80us/sample - loss: 0.0215 - val_loss: 0.0111\n",
      "Epoch 26/50\n",
      "671/671 [==============================] - 0s 82us/sample - loss: 0.0212 - val_loss: 0.0112\n",
      "Epoch 27/50\n",
      "671/671 [==============================] - 0s 82us/sample - loss: 0.0218 - val_loss: 0.0112\n",
      "Epoch 28/50\n",
      "671/671 [==============================] - 0s 80us/sample - loss: 0.0216 - val_loss: 0.0112\n",
      "Epoch 29/50\n",
      "671/671 [==============================] - 0s 84us/sample - loss: 0.0212 - val_loss: 0.0109\n",
      "Epoch 30/50\n",
      "671/671 [==============================] - 0s 79us/sample - loss: 0.0212 - val_loss: 0.0116\n",
      "Epoch 31/50\n",
      "671/671 [==============================] - 0s 82us/sample - loss: 0.0214 - val_loss: 0.0110\n",
      "Epoch 32/50\n",
      "671/671 [==============================] - 0s 81us/sample - loss: 0.0214 - val_loss: 0.0111\n",
      "Epoch 33/50\n",
      "671/671 [==============================] - 0s 81us/sample - loss: 0.0213 - val_loss: 0.0108\n",
      "Epoch 34/50\n",
      "671/671 [==============================] - 0s 83us/sample - loss: 0.0212 - val_loss: 0.0110\n",
      "Epoch 35/50\n",
      "671/671 [==============================] - 0s 83us/sample - loss: 0.0214 - val_loss: 0.0112\n",
      "Epoch 36/50\n",
      "671/671 [==============================] - 0s 80us/sample - loss: 0.0213 - val_loss: 0.0111\n",
      "Epoch 37/50\n",
      "671/671 [==============================] - 0s 83us/sample - loss: 0.0214 - val_loss: 0.0114\n",
      "Epoch 38/50\n",
      "671/671 [==============================] - 0s 80us/sample - loss: 0.0214 - val_loss: 0.0111\n",
      "Epoch 39/50\n",
      "671/671 [==============================] - 0s 86us/sample - loss: 0.0212 - val_loss: 0.0109\n",
      "Epoch 40/50\n",
      "671/671 [==============================] - 0s 85us/sample - loss: 0.0212 - val_loss: 0.0116\n",
      "Epoch 41/50\n",
      "671/671 [==============================] - 0s 85us/sample - loss: 0.0213 - val_loss: 0.0111\n",
      "Epoch 42/50\n",
      "671/671 [==============================] - 0s 87us/sample - loss: 0.0214 - val_loss: 0.0110\n",
      "Epoch 43/50\n",
      "671/671 [==============================] - 0s 88us/sample - loss: 0.0212 - val_loss: 0.0109\n",
      "Epoch 44/50\n",
      "671/671 [==============================] - 0s 89us/sample - loss: 0.0211 - val_loss: 0.0107\n",
      "Epoch 45/50\n",
      "671/671 [==============================] - 0s 87us/sample - loss: 0.0213 - val_loss: 0.0113\n",
      "Epoch 46/50\n",
      "671/671 [==============================] - 0s 90us/sample - loss: 0.0213 - val_loss: 0.0110\n",
      "Epoch 47/50\n",
      "671/671 [==============================] - 0s 87us/sample - loss: 0.0214 - val_loss: 0.0111\n",
      "Epoch 48/50\n",
      "671/671 [==============================] - 0s 86us/sample - loss: 0.0212 - val_loss: 0.0108\n",
      "Epoch 49/50\n",
      "671/671 [==============================] - 0s 83us/sample - loss: 0.0212 - val_loss: 0.0107\n",
      "Epoch 50/50\n",
      "671/671 [==============================] - 0s 82us/sample - loss: 0.0214 - val_loss: 0.0116\n",
      "第258个数，还剩3865个没有训练\n",
      "inv_hat [1.03635616 1.03434935 1.03334676 1.03334676 1.03134386 1.03134386\n",
      " 1.03334676 1.03535244 1.03334676 1.03334676 1.03635616 1.03635616\n",
      " 1.03836481 1.03535244 1.03635616 1.03635616 1.03635616 1.03836481\n",
      " 1.03936969 1.03736024 1.03635616 1.03535244 1.03234488 1.03234488\n",
      " 1.03134386 1.03334676 1.03234488 1.03234488 1.02834606 1.03034359]\n",
      "Test RMSE: 0.002\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0132 - val_loss: 0.0081\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0136 - val_loss: 0.0074\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0157 - val_loss: 0.0106\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0146 - val_loss: 0.0069\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0132 - val_loss: 0.0066\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0134 - val_loss: 0.0071\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0142 - val_loss: 0.0072\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0137 - val_loss: 0.0065\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0134 - val_loss: 0.0065\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0135 - val_loss: 0.0067\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0138 - val_loss: 0.0070\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0137 - val_loss: 0.0066\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0133 - val_loss: 0.0065\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0135 - val_loss: 0.0069\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0137 - val_loss: 0.0069\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0136 - val_loss: 0.0067\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0133 - val_loss: 0.0065\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0134 - val_loss: 0.0070\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0135 - val_loss: 0.0071\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0135 - val_loss: 0.0067\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0134 - val_loss: 0.0066\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0135 - val_loss: 0.0071\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0136 - val_loss: 0.0072\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0133 - val_loss: 0.0065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0133 - val_loss: 0.0068\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0137 - val_loss: 0.0077\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0137 - val_loss: 0.0066\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0132 - val_loss: 0.0065\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0133 - val_loss: 0.0071\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0136 - val_loss: 0.0073\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0138 - val_loss: 0.0072\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0134 - val_loss: 0.0065\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0133 - val_loss: 0.0066\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0136 - val_loss: 0.0072\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0134 - val_loss: 0.0066\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0134 - val_loss: 0.0066\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0135 - val_loss: 0.0069\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0135 - val_loss: 0.0069\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0134 - val_loss: 0.0066\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0134 - val_loss: 0.0068\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0135 - val_loss: 0.0069\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0135 - val_loss: 0.0068\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0134 - val_loss: 0.0067\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0134 - val_loss: 0.0068\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0135 - val_loss: 0.0068\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0135 - val_loss: 0.0067\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0134 - val_loss: 0.0066\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0132 - val_loss: 0.0066\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0136 - val_loss: 0.0074\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0137 - val_loss: 0.0071\n",
      "第259个数，还剩3864个没有训练\n",
      "inv_hat [0.43800284 0.42796962 0.42796962 0.42796962 0.42096225 0.41996234\n",
      " 0.42096225 0.42696775 0.42096225 0.4249648  0.43699836 0.43800284\n",
      " 0.43900752 0.42596615 0.42296295 0.42096225 0.42296295 0.42096225\n",
      " 0.42696775 0.41796337 0.41197372 0.40898307 0.40400522 0.40400522\n",
      " 0.40301066 0.40898307 0.40997964 0.40599537 0.40400522 0.40301066]\n",
      "Test RMSE: 0.006\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0083 - val_loss: 0.0020\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0082 - val_loss: 0.0019\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0084 - val_loss: 0.0022\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0091 - val_loss: 0.0061\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0097 - val_loss: 0.0069\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0101 - val_loss: 0.0080\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0088 - val_loss: 0.0027\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0078 - val_loss: 0.0018\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0078 - val_loss: 0.0018\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0079 - val_loss: 0.0018\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0087 - val_loss: 0.0066\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0112 - val_loss: 0.0127\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0147 - val_loss: 0.0045\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0090 - val_loss: 0.0023\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0102 - val_loss: 0.0058\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0088 - val_loss: 0.0025\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0099 - val_loss: 0.0115\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0136 - val_loss: 0.0041\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0087 - val_loss: 0.0022\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0095 - val_loss: 0.0047\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0084 - val_loss: 0.0026\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0115 - val_loss: 0.0056\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0091 - val_loss: 0.0022\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0079 - val_loss: 0.0019\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0086 - val_loss: 0.0062\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0100 - val_loss: 0.0067\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0098 - val_loss: 0.0037\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0080 - val_loss: 0.0021\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0085 - val_loss: 0.0042\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0101 - val_loss: 0.0093\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0128 - val_loss: 0.0024\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0083 - val_loss: 0.0041\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0103 - val_loss: 0.0032\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0097 - val_loss: 0.0095\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0150 - val_loss: 0.0019\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0106 - val_loss: 0.0018\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0085 - val_loss: 0.0059\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0102 - val_loss: 0.0020\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0147 - val_loss: 0.0022\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0090 - val_loss: 0.0019\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0085 - val_loss: 0.0039\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0084 - val_loss: 0.0018\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0090 - val_loss: 0.0054\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0103 - val_loss: 0.0023\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0079 - val_loss: 0.0035\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0081 - val_loss: 0.0029\n",
      "第260个数，还剩3863个没有训练\n",
      "inv_hat [1.03006614 1.03056858 1.03056858 1.03087016 1.03107113 1.03127222\n",
      " 1.03137277 1.03147333 1.03157388 1.03197604 1.0321772  1.03247872\n",
      " 1.03278033 1.03358462 1.03378577 1.03459037 1.03489211 1.03529464\n",
      " 1.03499274 1.03469087 1.03428856 1.03418797 1.03438916 1.03459037\n",
      " 1.03549582 1.03559648 1.0357978  1.0357978  1.03599915 1.0368045 ]\n",
      "Test RMSE: 0.000\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0095 - val_loss: 0.0034\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0095 - val_loss: 0.0049\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0094 - val_loss: 0.0042\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0094 - val_loss: 0.0043\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0094 - val_loss: 0.0042\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0094 - val_loss: 0.0042\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0042\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0094 - val_loss: 0.0043\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0094 - val_loss: 0.0042\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0094 - val_loss: 0.0041\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0094 - val_loss: 0.0042\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0094 - val_loss: 0.0042\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0094 - val_loss: 0.0042\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0042\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0094 - val_loss: 0.0042\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0042\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0094 - val_loss: 0.0041\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0094 - val_loss: 0.0042\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0094 - val_loss: 0.0042\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0094 - val_loss: 0.0041\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0094 - val_loss: 0.0040\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0094 - val_loss: 0.0042\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0094 - val_loss: 0.0041\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0094 - val_loss: 0.0040\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0094 - val_loss: 0.0041\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0094 - val_loss: 0.0041\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0094 - val_loss: 0.0040\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0094 - val_loss: 0.0040\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0094 - val_loss: 0.0041\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0094 - val_loss: 0.0040\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0094 - val_loss: 0.0040\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0041\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0040\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0094 - val_loss: 0.0039\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0094 - val_loss: 0.0039\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0039\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0094 - val_loss: 0.0040\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0094 - val_loss: 0.0039\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0094 - val_loss: 0.0038\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0094 - val_loss: 0.0039\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0094 - val_loss: 0.0040\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0094 - val_loss: 0.0039\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0094 - val_loss: 0.0038\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0094 - val_loss: 0.0038\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0094 - val_loss: 0.0039\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0094 - val_loss: 0.0039\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0094 - val_loss: 0.0039\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0094 - val_loss: 0.0038\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0094 - val_loss: 0.0038\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0094 - val_loss: 0.0039\n",
      "第261个数，还剩3862个没有训练\n",
      "inv_hat [0.38601915 0.37593772 0.37671949 0.37574234 0.37008158 0.36637922\n",
      " 0.36589246 0.37193467 0.36589246 0.36793748 0.37330091 0.37417955\n",
      " 0.37193467 0.36881441 0.37281289 0.37173953 0.37134935 0.37252013\n",
      " 0.38092511 0.37623087 0.37818587 0.37554696 0.37193467 0.36842462\n",
      " 0.36608716 0.36696347 0.36336269 0.36248759 0.36034972 0.36239039]\n",
      "Test RMSE: 0.004\n",
      "Train on 1029 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1029/1029 [==============================] - 0s 84us/sample - loss: 0.0083 - val_loss: 0.0170\n",
      "Epoch 2/50\n",
      "1029/1029 [==============================] - 0s 81us/sample - loss: 0.0083 - val_loss: 0.0200\n",
      "Epoch 3/50\n",
      "1029/1029 [==============================] - 0s 83us/sample - loss: 0.0088 - val_loss: 0.0212\n",
      "Epoch 4/50\n",
      "1029/1029 [==============================] - 0s 84us/sample - loss: 0.0092 - val_loss: 0.0233\n",
      "Epoch 5/50\n",
      "1029/1029 [==============================] - 0s 80us/sample - loss: 0.0101 - val_loss: 0.0164\n",
      "Epoch 6/50\n",
      "1029/1029 [==============================] - 0s 85us/sample - loss: 0.0090 - val_loss: 0.0186\n",
      "Epoch 7/50\n",
      "1029/1029 [==============================] - 0s 83us/sample - loss: 0.0087 - val_loss: 0.0214\n",
      "Epoch 8/50\n",
      "1029/1029 [==============================] - 0s 77us/sample - loss: 0.0090 - val_loss: 0.0226\n",
      "Epoch 9/50\n",
      "1029/1029 [==============================] - 0s 78us/sample - loss: 0.0095 - val_loss: 0.0188\n",
      "Epoch 10/50\n",
      "1029/1029 [==============================] - 0s 80us/sample - loss: 0.0088 - val_loss: 0.0203\n",
      "Epoch 11/50\n",
      "1029/1029 [==============================] - 0s 81us/sample - loss: 0.0091 - val_loss: 0.0232\n",
      "Epoch 12/50\n",
      "1029/1029 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0148\n",
      "Epoch 13/50\n",
      "1029/1029 [==============================] - 0s 82us/sample - loss: 0.0088 - val_loss: 0.0177\n",
      "Epoch 14/50\n",
      "1029/1029 [==============================] - 0s 81us/sample - loss: 0.0080 - val_loss: 0.0183\n",
      "Epoch 15/50\n",
      "1029/1029 [==============================] - 0s 82us/sample - loss: 0.0080 - val_loss: 0.0178\n",
      "Epoch 16/50\n",
      "1029/1029 [==============================] - 0s 81us/sample - loss: 0.0080 - val_loss: 0.0176\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1029/1029 [==============================] - 0s 79us/sample - loss: 0.0080 - val_loss: 0.0180\n",
      "Epoch 18/50\n",
      "1029/1029 [==============================] - 0s 82us/sample - loss: 0.0081 - val_loss: 0.0190\n",
      "Epoch 19/50\n",
      "1029/1029 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0182\n",
      "Epoch 20/50\n",
      "1029/1029 [==============================] - 0s 81us/sample - loss: 0.0081 - val_loss: 0.0181\n",
      "Epoch 21/50\n",
      "1029/1029 [==============================] - 0s 82us/sample - loss: 0.0081 - val_loss: 0.0193\n",
      "Epoch 22/50\n",
      "1029/1029 [==============================] - 0s 81us/sample - loss: 0.0082 - val_loss: 0.0203\n",
      "Epoch 23/50\n",
      "1029/1029 [==============================] - 0s 80us/sample - loss: 0.0090 - val_loss: 0.0221\n",
      "Epoch 24/50\n",
      "1029/1029 [==============================] - 0s 78us/sample - loss: 0.0089 - val_loss: 0.0215\n",
      "Epoch 25/50\n",
      "1029/1029 [==============================] - 0s 82us/sample - loss: 0.0093 - val_loss: 0.0189\n",
      "Epoch 26/50\n",
      "1029/1029 [==============================] - 0s 80us/sample - loss: 0.0083 - val_loss: 0.0202\n",
      "Epoch 27/50\n",
      "1029/1029 [==============================] - 0s 77us/sample - loss: 0.0085 - val_loss: 0.0233\n",
      "Epoch 28/50\n",
      "1029/1029 [==============================] - 0s 78us/sample - loss: 0.0091 - val_loss: 0.0193\n",
      "Epoch 29/50\n",
      "1029/1029 [==============================] - 0s 81us/sample - loss: 0.0084 - val_loss: 0.0210\n",
      "Epoch 30/50\n",
      "1029/1029 [==============================] - 0s 84us/sample - loss: 0.0090 - val_loss: 0.0218\n",
      "Epoch 31/50\n",
      "1029/1029 [==============================] - 0s 86us/sample - loss: 0.0088 - val_loss: 0.0221\n",
      "Epoch 32/50\n",
      "1029/1029 [==============================] - 0s 83us/sample - loss: 0.0095 - val_loss: 0.0184\n",
      "Epoch 33/50\n",
      "1029/1029 [==============================] - 0s 85us/sample - loss: 0.0083 - val_loss: 0.0208\n",
      "Epoch 34/50\n",
      "1029/1029 [==============================] - 0s 79us/sample - loss: 0.0090 - val_loss: 0.0212\n",
      "Epoch 35/50\n",
      "1029/1029 [==============================] - 0s 75us/sample - loss: 0.0086 - val_loss: 0.0214\n",
      "Epoch 36/50\n",
      "1029/1029 [==============================] - 0s 75us/sample - loss: 0.0089 - val_loss: 0.0214\n",
      "Epoch 37/50\n",
      "1029/1029 [==============================] - 0s 80us/sample - loss: 0.0087 - val_loss: 0.0209\n",
      "Epoch 38/50\n",
      "1029/1029 [==============================] - 0s 77us/sample - loss: 0.0088 - val_loss: 0.0217\n",
      "Epoch 39/50\n",
      "1029/1029 [==============================] - 0s 82us/sample - loss: 0.0087 - val_loss: 0.0208\n",
      "Epoch 40/50\n",
      "1029/1029 [==============================] - 0s 82us/sample - loss: 0.0087 - val_loss: 0.0210\n",
      "Epoch 41/50\n",
      "1029/1029 [==============================] - 0s 81us/sample - loss: 0.0086 - val_loss: 0.0229\n",
      "Epoch 42/50\n",
      "1029/1029 [==============================] - 0s 79us/sample - loss: 0.0095 - val_loss: 0.0177\n",
      "Epoch 43/50\n",
      "1029/1029 [==============================] - 0s 83us/sample - loss: 0.0087 - val_loss: 0.0180\n",
      "Epoch 44/50\n",
      "1029/1029 [==============================] - 0s 81us/sample - loss: 0.0082 - val_loss: 0.0189\n",
      "Epoch 45/50\n",
      "1029/1029 [==============================] - 0s 81us/sample - loss: 0.0082 - val_loss: 0.0205\n",
      "Epoch 46/50\n",
      "1029/1029 [==============================] - 0s 87us/sample - loss: 0.0084 - val_loss: 0.0183\n",
      "Epoch 47/50\n",
      "1029/1029 [==============================] - 0s 79us/sample - loss: 0.0080 - val_loss: 0.0194\n",
      "Epoch 48/50\n",
      "1029/1029 [==============================] - 0s 78us/sample - loss: 0.0082 - val_loss: 0.0200\n",
      "Epoch 49/50\n",
      "1029/1029 [==============================] - 0s 79us/sample - loss: 0.0082 - val_loss: 0.0210\n",
      "Epoch 50/50\n",
      "1029/1029 [==============================] - 0s 79us/sample - loss: 0.0085 - val_loss: 0.0206\n",
      "第262个数，还剩3861个没有训练\n",
      "inv_hat [1.04302262 1.04352044 1.0443176  1.04610086 1.04619995 1.04918184\n",
      " 1.04898274 1.05037821 1.0530777  1.05539024 1.0562966  1.056498\n",
      " 1.05680002 1.05881115 1.05951409 1.06061746 1.06071772 1.04699392\n",
      " 1.04858448 1.05037821 1.0507774  1.05147663 1.05237676 1.05438246\n",
      " 1.05579313 1.05700122 1.05871067 1.05861018 1.05881115 1.06031674]\n",
      "Test RMSE: 0.003\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0107 - val_loss: 0.0091\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0106 - val_loss: 0.0090\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0107 - val_loss: 0.0095\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0107 - val_loss: 0.0095\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0106 - val_loss: 0.0091\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0095\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0106 - val_loss: 0.0092\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0106 - val_loss: 0.0093\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0106 - val_loss: 0.0093\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0106 - val_loss: 0.0093\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0106 - val_loss: 0.0092\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0106 - val_loss: 0.0092\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0106 - val_loss: 0.0093\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0106 - val_loss: 0.0093\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0106 - val_loss: 0.0093\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0106 - val_loss: 0.0097\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0106 - val_loss: 0.0096\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0106 - val_loss: 0.0097\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0105 - val_loss: 0.0094\n",
      "第263个数，还剩3860个没有训练\n",
      "inv_hat [1.16330006 1.12494887 1.12200836 1.12200836 1.08179022 1.07982644\n",
      " 1.07491623 1.05919435 1.03164283 1.03164283 1.0562448  1.07000473\n",
      " 1.04345711 1.03262773 1.03459732 1.02376091 1.02868772 1.03065792\n",
      " 1.03755124 1.01488808 1.01981824 1.00600864 0.99613491 0.99909787\n",
      " 0.9892181  0.98526358 0.96943233 0.97240165 0.94961786 0.95160107]\n",
      "Test RMSE: 0.017\n",
      "Train on 1129 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1129/1129 [==============================] - 0s 78us/sample - loss: 0.0135 - val_loss: 0.0184\n",
      "Epoch 2/50\n",
      "1129/1129 [==============================] - 0s 77us/sample - loss: 0.0170 - val_loss: 0.0186\n",
      "Epoch 3/50\n",
      "1129/1129 [==============================] - 0s 79us/sample - loss: 0.0135 - val_loss: 0.0224\n",
      "Epoch 4/50\n",
      "1129/1129 [==============================] - 0s 78us/sample - loss: 0.0144 - val_loss: 0.0228\n",
      "Epoch 5/50\n",
      "1129/1129 [==============================] - 0s 80us/sample - loss: 0.0203 - val_loss: 0.0161\n",
      "Epoch 6/50\n",
      "1129/1129 [==============================] - 0s 79us/sample - loss: 0.0167 - val_loss: 0.0171\n",
      "Epoch 7/50\n",
      "1129/1129 [==============================] - 0s 79us/sample - loss: 0.0172 - val_loss: 0.0168\n",
      "Epoch 8/50\n",
      "1129/1129 [==============================] - 0s 79us/sample - loss: 0.0191 - val_loss: 0.0237\n",
      "Epoch 9/50\n",
      "1129/1129 [==============================] - 0s 77us/sample - loss: 0.0142 - val_loss: 0.0204\n",
      "Epoch 10/50\n",
      "1129/1129 [==============================] - 0s 74us/sample - loss: 0.0220 - val_loss: 0.0167\n",
      "Epoch 11/50\n",
      "1129/1129 [==============================] - 0s 77us/sample - loss: 0.0153 - val_loss: 0.0159\n",
      "Epoch 12/50\n",
      "1129/1129 [==============================] - 0s 77us/sample - loss: 0.0169 - val_loss: 0.0200\n",
      "Epoch 13/50\n",
      "1129/1129 [==============================] - 0s 80us/sample - loss: 0.0160 - val_loss: 0.0241\n",
      "Epoch 14/50\n",
      "1129/1129 [==============================] - 0s 80us/sample - loss: 0.0173 - val_loss: 0.0164\n",
      "Epoch 15/50\n",
      "1129/1129 [==============================] - 0s 79us/sample - loss: 0.0185 - val_loss: 0.0161\n",
      "Epoch 16/50\n",
      "1129/1129 [==============================] - 0s 76us/sample - loss: 0.0143 - val_loss: 0.0169\n",
      "Epoch 17/50\n",
      "1129/1129 [==============================] - 0s 78us/sample - loss: 0.0171 - val_loss: 0.0231\n",
      "Epoch 18/50\n",
      "1129/1129 [==============================] - 0s 82us/sample - loss: 0.0148 - val_loss: 0.0179\n",
      "Epoch 19/50\n",
      "1129/1129 [==============================] - 0s 82us/sample - loss: 0.0199 - val_loss: 0.0164\n",
      "Epoch 20/50\n",
      "1129/1129 [==============================] - 0s 82us/sample - loss: 0.0145 - val_loss: 0.0164\n",
      "Epoch 21/50\n",
      "1129/1129 [==============================] - 0s 79us/sample - loss: 0.0148 - val_loss: 0.0208\n",
      "Epoch 22/50\n",
      "1129/1129 [==============================] - 0s 77us/sample - loss: 0.0135 - val_loss: 0.0193\n",
      "Epoch 23/50\n",
      "1129/1129 [==============================] - 0s 79us/sample - loss: 0.0170 - val_loss: 0.0162\n",
      "Epoch 24/50\n",
      "1129/1129 [==============================] - 0s 79us/sample - loss: 0.0134 - val_loss: 0.0161\n",
      "Epoch 25/50\n",
      "1129/1129 [==============================] - 0s 76us/sample - loss: 0.0135 - val_loss: 0.0195\n",
      "Epoch 26/50\n",
      "1129/1129 [==============================] - 0s 76us/sample - loss: 0.0137 - val_loss: 0.0206\n",
      "Epoch 27/50\n",
      "1129/1129 [==============================] - 0s 83us/sample - loss: 0.0158 - val_loss: 0.0163\n",
      "Epoch 28/50\n",
      "1129/1129 [==============================] - 0s 79us/sample - loss: 0.0143 - val_loss: 0.0160\n",
      "Epoch 29/50\n",
      "1129/1129 [==============================] - 0s 76us/sample - loss: 0.0131 - val_loss: 0.0188\n",
      "Epoch 30/50\n",
      "1129/1129 [==============================] - 0s 75us/sample - loss: 0.0141 - val_loss: 0.0209\n",
      "Epoch 31/50\n",
      "1129/1129 [==============================] - 0s 75us/sample - loss: 0.0150 - val_loss: 0.0164\n",
      "Epoch 32/50\n",
      "1129/1129 [==============================] - 0s 79us/sample - loss: 0.0150 - val_loss: 0.0160\n",
      "Epoch 33/50\n",
      "1129/1129 [==============================] - 0s 79us/sample - loss: 0.0130 - val_loss: 0.0184\n",
      "Epoch 34/50\n",
      "1129/1129 [==============================] - 0s 77us/sample - loss: 0.0142 - val_loss: 0.0211\n",
      "Epoch 35/50\n",
      "1129/1129 [==============================] - 0s 74us/sample - loss: 0.0144 - val_loss: 0.0165\n",
      "Epoch 36/50\n",
      "1129/1129 [==============================] - 0s 77us/sample - loss: 0.0155 - val_loss: 0.0159\n",
      "Epoch 37/50\n",
      "1129/1129 [==============================] - 0s 74us/sample - loss: 0.0131 - val_loss: 0.0180\n",
      "Epoch 38/50\n",
      "1129/1129 [==============================] - 0s 83us/sample - loss: 0.0146 - val_loss: 0.0214\n",
      "Epoch 39/50\n",
      "1129/1129 [==============================] - 0s 76us/sample - loss: 0.0144 - val_loss: 0.0165\n",
      "Epoch 40/50\n",
      "1129/1129 [==============================] - 0s 74us/sample - loss: 0.0159 - val_loss: 0.0160\n",
      "Epoch 41/50\n",
      "1129/1129 [==============================] - 0s 81us/sample - loss: 0.0130 - val_loss: 0.0181\n",
      "Epoch 42/50\n",
      "1129/1129 [==============================] - 0s 78us/sample - loss: 0.0142 - val_loss: 0.0208\n",
      "Epoch 43/50\n",
      "1129/1129 [==============================] - 0s 79us/sample - loss: 0.0139 - val_loss: 0.0165\n",
      "Epoch 44/50\n",
      "1129/1129 [==============================] - 0s 77us/sample - loss: 0.0149 - val_loss: 0.0160\n",
      "Epoch 45/50\n",
      "1129/1129 [==============================] - 0s 78us/sample - loss: 0.0128 - val_loss: 0.0182\n",
      "Epoch 46/50\n",
      "1129/1129 [==============================] - 0s 75us/sample - loss: 0.0137 - val_loss: 0.0204\n",
      "Epoch 47/50\n",
      "1129/1129 [==============================] - 0s 76us/sample - loss: 0.0138 - val_loss: 0.0165\n",
      "Epoch 48/50\n",
      "1129/1129 [==============================] - 0s 76us/sample - loss: 0.0144 - val_loss: 0.0160\n",
      "Epoch 49/50\n",
      "1129/1129 [==============================] - 0s 75us/sample - loss: 0.0127 - val_loss: 0.0182\n",
      "Epoch 50/50\n",
      "1129/1129 [==============================] - 0s 77us/sample - loss: 0.0138 - val_loss: 0.0206\n",
      "第264个数，还剩3859个没有训练\n",
      "inv_hat [0.87302996 0.87104576 0.88197246 0.88396257 0.87700172 0.85916656\n",
      " 0.87104576 0.84720914 0.85518588 0.84920364 0.86312109 0.86213198\n",
      " 0.86213198 0.87998341 0.85717936 0.84022616 0.83124399 0.82625225\n",
      " 0.83124399 0.8382305  0.83723261 0.82525372 0.8172645  0.81227031\n",
      " 0.80427867 0.79728565 0.79129203 0.77830922 0.80228065 0.79728565]\n",
      "Test RMSE: 0.014\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0036 - val_loss: 0.0179\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0053 - val_loss: 0.0193\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0062 - val_loss: 0.0193\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0049 - val_loss: 0.0199\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0068 - val_loss: 0.0187\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0061 - val_loss: 0.0216\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0100 - val_loss: 0.0274\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0088 - val_loss: 0.0220\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0052 - val_loss: 0.0182\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0048 - val_loss: 0.0221\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0077 - val_loss: 0.0226\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0061 - val_loss: 0.0202\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0051 - val_loss: 0.0205\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0070 - val_loss: 0.0252\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0087 - val_loss: 0.0260\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0079 - val_loss: 0.0219\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0072 - val_loss: 0.0190\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0064 - val_loss: 0.0187\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0058 - val_loss: 0.0202\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0055 - val_loss: 0.0206\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0049 - val_loss: 0.0197\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0045 - val_loss: 0.0202\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0057 - val_loss: 0.0214\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0067 - val_loss: 0.0249\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0068 - val_loss: 0.0234\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0067 - val_loss: 0.0219\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0068 - val_loss: 0.0191\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0061 - val_loss: 0.0186\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0057 - val_loss: 0.0198\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0052 - val_loss: 0.0200\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0049 - val_loss: 0.0202\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0042 - val_loss: 0.0185\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0036 - val_loss: 0.0198\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0047 - val_loss: 0.0185\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0037 - val_loss: 0.0204\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0053 - val_loss: 0.0204\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0042 - val_loss: 0.0197\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0042 - val_loss: 0.0205\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0054 - val_loss: 0.0226\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0059 - val_loss: 0.0232\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0061 - val_loss: 0.0222\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0066 - val_loss: 0.0195\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0063 - val_loss: 0.0178\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0066 - val_loss: 0.0175\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0063 - val_loss: 0.0174\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0057 - val_loss: 0.0173\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0046 - val_loss: 0.0175\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0037 - val_loss: 0.0173\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0037 - val_loss: 0.0181\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0036 - val_loss: 0.0177\n",
      "第265个数，还剩3858个没有训练\n",
      "inv_hat [1.39210065 1.3928793  1.39280489 1.39179875 1.39169809 1.39159743\n",
      " 1.39200003 1.32375242 1.32516493 1.32536677 1.32607366 1.32829781\n",
      " 1.32910745 1.32991724 1.330221   1.33204369 1.3319424  1.33244892\n",
      " 1.32941114 1.32900623 1.32839902 1.32850024 1.32930989 1.33042341\n",
      " 1.330221   1.26572202 1.26631026 1.2665064  1.26719282 1.26886049]\n",
      "Test RMSE: 0.017\n",
      "Train on 647 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "647/647 [==============================] - 0s 81us/sample - loss: 0.0228 - val_loss: 0.0200\n",
      "Epoch 2/50\n",
      "647/647 [==============================] - 0s 81us/sample - loss: 0.0206 - val_loss: 0.0202\n",
      "Epoch 3/50\n",
      "647/647 [==============================] - 0s 77us/sample - loss: 0.0201 - val_loss: 0.0230\n",
      "Epoch 4/50\n",
      "647/647 [==============================] - 0s 78us/sample - loss: 0.0199 - val_loss: 0.0190\n",
      "Epoch 5/50\n",
      "647/647 [==============================] - 0s 84us/sample - loss: 0.0200 - val_loss: 0.0211\n",
      "Epoch 6/50\n",
      "647/647 [==============================] - 0s 81us/sample - loss: 0.0198 - val_loss: 0.0183\n",
      "Epoch 7/50\n",
      "647/647 [==============================] - 0s 79us/sample - loss: 0.0199 - val_loss: 0.0199\n",
      "Epoch 8/50\n",
      "647/647 [==============================] - 0s 78us/sample - loss: 0.0197 - val_loss: 0.0177\n",
      "Epoch 9/50\n",
      "647/647 [==============================] - 0s 82us/sample - loss: 0.0200 - val_loss: 0.0203\n",
      "Epoch 10/50\n",
      "647/647 [==============================] - 0s 82us/sample - loss: 0.0198 - val_loss: 0.0173\n",
      "Epoch 11/50\n",
      "647/647 [==============================] - 0s 78us/sample - loss: 0.0200 - val_loss: 0.0196\n",
      "Epoch 12/50\n",
      "647/647 [==============================] - 0s 82us/sample - loss: 0.0198 - val_loss: 0.0172\n",
      "Epoch 13/50\n",
      "647/647 [==============================] - 0s 77us/sample - loss: 0.0199 - val_loss: 0.0186\n",
      "Epoch 14/50\n",
      "647/647 [==============================] - 0s 77us/sample - loss: 0.0197 - val_loss: 0.0175\n",
      "Epoch 15/50\n",
      "647/647 [==============================] - 0s 77us/sample - loss: 0.0198 - val_loss: 0.0189\n",
      "Epoch 16/50\n",
      "647/647 [==============================] - 0s 76us/sample - loss: 0.0197 - val_loss: 0.0167\n",
      "Epoch 17/50\n",
      "647/647 [==============================] - 0s 76us/sample - loss: 0.0200 - val_loss: 0.0192\n",
      "Epoch 18/50\n",
      "647/647 [==============================] - 0s 79us/sample - loss: 0.0198 - val_loss: 0.0165\n",
      "Epoch 19/50\n",
      "647/647 [==============================] - 0s 76us/sample - loss: 0.0200 - val_loss: 0.0189\n",
      "Epoch 20/50\n",
      "647/647 [==============================] - 0s 77us/sample - loss: 0.0198 - val_loss: 0.0165\n",
      "Epoch 21/50\n",
      "647/647 [==============================] - 0s 81us/sample - loss: 0.0199 - val_loss: 0.0182\n",
      "Epoch 22/50\n",
      "647/647 [==============================] - 0s 80us/sample - loss: 0.0197 - val_loss: 0.0167\n",
      "Epoch 23/50\n",
      "647/647 [==============================] - 0s 77us/sample - loss: 0.0198 - val_loss: 0.0184\n",
      "Epoch 24/50\n",
      "647/647 [==============================] - 0s 81us/sample - loss: 0.0197 - val_loss: 0.0167\n",
      "Epoch 25/50\n",
      "647/647 [==============================] - 0s 77us/sample - loss: 0.0198 - val_loss: 0.0183\n",
      "Epoch 26/50\n",
      "647/647 [==============================] - 0s 81us/sample - loss: 0.0197 - val_loss: 0.0166\n",
      "Epoch 27/50\n",
      "647/647 [==============================] - 0s 78us/sample - loss: 0.0198 - val_loss: 0.0182\n",
      "Epoch 28/50\n",
      "647/647 [==============================] - 0s 78us/sample - loss: 0.0197 - val_loss: 0.0166\n",
      "Epoch 29/50\n",
      "647/647 [==============================] - 0s 77us/sample - loss: 0.0198 - val_loss: 0.0183\n",
      "Epoch 30/50\n",
      "647/647 [==============================] - 0s 76us/sample - loss: 0.0197 - val_loss: 0.0167\n",
      "Epoch 31/50\n",
      "647/647 [==============================] - 0s 76us/sample - loss: 0.0198 - val_loss: 0.0183\n",
      "Epoch 32/50\n",
      "647/647 [==============================] - 0s 74us/sample - loss: 0.0197 - val_loss: 0.0166\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647/647 [==============================] - 0s 75us/sample - loss: 0.0198 - val_loss: 0.0182\n",
      "Epoch 34/50\n",
      "647/647 [==============================] - 0s 77us/sample - loss: 0.0197 - val_loss: 0.0166\n",
      "Epoch 35/50\n",
      "647/647 [==============================] - 0s 76us/sample - loss: 0.0198 - val_loss: 0.0182\n",
      "Epoch 36/50\n",
      "647/647 [==============================] - 0s 80us/sample - loss: 0.0197 - val_loss: 0.0165\n",
      "Epoch 37/50\n",
      "647/647 [==============================] - 0s 76us/sample - loss: 0.0198 - val_loss: 0.0182\n",
      "Epoch 38/50\n",
      "647/647 [==============================] - 0s 76us/sample - loss: 0.0197 - val_loss: 0.0165\n",
      "Epoch 39/50\n",
      "647/647 [==============================] - 0s 79us/sample - loss: 0.0198 - val_loss: 0.0181\n",
      "Epoch 40/50\n",
      "647/647 [==============================] - 0s 79us/sample - loss: 0.0197 - val_loss: 0.0165\n",
      "Epoch 41/50\n",
      "647/647 [==============================] - 0s 80us/sample - loss: 0.0198 - val_loss: 0.0181\n",
      "Epoch 42/50\n",
      "647/647 [==============================] - 0s 75us/sample - loss: 0.0197 - val_loss: 0.0164\n",
      "Epoch 43/50\n",
      "647/647 [==============================] - 0s 78us/sample - loss: 0.0198 - val_loss: 0.0179\n",
      "Epoch 44/50\n",
      "647/647 [==============================] - 0s 75us/sample - loss: 0.0197 - val_loss: 0.0163\n",
      "Epoch 45/50\n",
      "647/647 [==============================] - 0s 76us/sample - loss: 0.0198 - val_loss: 0.0180\n",
      "Epoch 46/50\n",
      "647/647 [==============================] - 0s 73us/sample - loss: 0.0197 - val_loss: 0.0163\n",
      "Epoch 47/50\n",
      "647/647 [==============================] - 0s 75us/sample - loss: 0.0198 - val_loss: 0.0180\n",
      "Epoch 48/50\n",
      "647/647 [==============================] - 0s 76us/sample - loss: 0.0198 - val_loss: 0.0161\n",
      "Epoch 49/50\n",
      "647/647 [==============================] - 0s 72us/sample - loss: 0.0198 - val_loss: 0.0177\n",
      "Epoch 50/50\n",
      "647/647 [==============================] - 0s 76us/sample - loss: 0.0197 - val_loss: 0.0161\n",
      "第266个数，还剩3857个没有训练\n",
      "inv_hat [0.90710545 0.90309446 0.90309446 0.902092   0.89407716 0.89307608\n",
      " 0.89207521 0.88407612 0.87310754 0.86912985 0.87410294 0.87609485\n",
      " 0.87310754 0.86020614 0.86020614 0.85921711 0.86218577 0.86515901\n",
      " 0.8850751  0.86813649 0.87012364 0.85526636 0.84641209 0.84249399\n",
      " 0.83469312 0.8317809  0.82309085 0.81543011 0.81257395 0.81543011]\n",
      "Test RMSE: 0.007\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0103 - val_loss: 0.0062\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0106 - val_loss: 0.0062\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0105 - val_loss: 0.0056\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0103 - val_loss: 0.0056\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0102 - val_loss: 0.0056\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0102 - val_loss: 0.0056\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0102 - val_loss: 0.0056\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0102 - val_loss: 0.0057\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0102 - val_loss: 0.0057\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0102 - val_loss: 0.0057\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0101 - val_loss: 0.0057\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0101 - val_loss: 0.0057\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0101 - val_loss: 0.0058\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0101 - val_loss: 0.0058\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0101 - val_loss: 0.0058\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0101 - val_loss: 0.0058\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0101 - val_loss: 0.0058\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0101 - val_loss: 0.0058\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0101 - val_loss: 0.0058\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0101 - val_loss: 0.0058\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0101 - val_loss: 0.0060\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0101 - val_loss: 0.0058\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0101 - val_loss: 0.0058\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0101 - val_loss: 0.0058\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0101 - val_loss: 0.0058\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0101 - val_loss: 0.0058\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0101 - val_loss: 0.0058\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0101 - val_loss: 0.0060\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0101 - val_loss: 0.0058\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0101 - val_loss: 0.0060\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0101 - val_loss: 0.0058\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0101 - val_loss: 0.0060\n",
      "第267个数，还剩3856个没有训练\n",
      "inv_hat [0.69914466 0.68943613 0.69632631 0.69351035 0.68372144 0.68294737\n",
      " 0.67936962 0.69030877 0.68410859 0.69215168 0.70985566 0.7116114\n",
      " 0.71385605 0.69632631 0.69535503 0.68895149 0.69176364 0.69457816\n",
      " 0.70751595 0.6959378  0.69079362 0.68227017 0.67434843 0.67174447\n",
      " 0.66192806 0.66269673 0.66029517 0.65875925 0.66029517 0.66750588]\n",
      "Test RMSE: 0.008\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0082 - val_loss: 0.0027\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0101 - val_loss: 0.0058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0092 - val_loss: 0.0027\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0091 - val_loss: 0.0029\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0081 - val_loss: 0.0026\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0080 - val_loss: 0.0026\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0085 - val_loss: 0.0027\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0081 - val_loss: 0.0026\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0079 - val_loss: 0.0028\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0081 - val_loss: 0.0028\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0082 - val_loss: 0.0027\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0085 - val_loss: 0.0026\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0081 - val_loss: 0.0026\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0082 - val_loss: 0.0026\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0100 - val_loss: 0.0069\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0088 - val_loss: 0.0026\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0097 - val_loss: 0.0035\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0082 - val_loss: 0.0027\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0045\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0080 - val_loss: 0.0026\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0088 - val_loss: 0.0026\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0082 - val_loss: 0.0026\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0080 - val_loss: 0.0027\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0084 - val_loss: 0.0028\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0082 - val_loss: 0.0027\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0079 - val_loss: 0.0027\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0079 - val_loss: 0.0029\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0080 - val_loss: 0.0029\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0082 - val_loss: 0.0027\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0085 - val_loss: 0.0026\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0081 - val_loss: 0.0026\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0081 - val_loss: 0.0026\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0095 - val_loss: 0.0056\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0086 - val_loss: 0.0027\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0091 - val_loss: 0.0027\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0081 - val_loss: 0.0026\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0083 - val_loss: 0.0027\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0084 - val_loss: 0.0029\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0082 - val_loss: 0.0027\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0079 - val_loss: 0.0030\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0081 - val_loss: 0.0028\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0089 - val_loss: 0.0032\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0084 - val_loss: 0.0027\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0086 - val_loss: 0.0032\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0082 - val_loss: 0.0026\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0027\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0085 - val_loss: 0.0031\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0079 - val_loss: 0.0028\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0080 - val_loss: 0.0029\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0082 - val_loss: 0.0026\n",
      "第268个数，还剩3855个没有训练\n",
      "inv_hat [1.05051444 1.05091492 1.05121515 1.05071468 1.05061456 1.05061456\n",
      " 1.05061456 1.0504143  1.05051444 1.05071468 1.05081479 1.05191585\n",
      " 1.0525164  1.05331713 1.05351734 1.05511866 1.05491847 1.05551892\n",
      " 1.0524163  1.05191585 1.05031419 1.05101492 1.0525164  1.05391763\n",
      " 1.05331713 1.05311705 1.05401773 1.05421791 1.05531874 1.05732026]\n",
      "Test RMSE: 0.001\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0070 - val_loss: 0.0025\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0064 - val_loss: 0.0024\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0065 - val_loss: 0.0029\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0061 - val_loss: 0.0026\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0065 - val_loss: 0.0039\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0059 - val_loss: 0.0024\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0065 - val_loss: 0.0037\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0059 - val_loss: 0.0026\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0065 - val_loss: 0.0038\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0059 - val_loss: 0.0025\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0064 - val_loss: 0.0038\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0059 - val_loss: 0.0026\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0063 - val_loss: 0.0034\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0062 - val_loss: 0.0035\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0059 - val_loss: 0.0026\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0063 - val_loss: 0.0036\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0063 - val_loss: 0.0034\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0059 - val_loss: 0.0025\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 72us/sample - loss: 0.0064 - val_loss: 0.0037\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0065 - val_loss: 0.0039\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0061 - val_loss: 0.0028\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0063 - val_loss: 0.0037\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0063 - val_loss: 0.0036\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0060 - val_loss: 0.0028\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0062 - val_loss: 0.0035\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0060 - val_loss: 0.0028\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0062 - val_loss: 0.0032\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0060 - val_loss: 0.0028\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0061 - val_loss: 0.0034\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0060 - val_loss: 0.0028\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0062 - val_loss: 0.0035\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0061 - val_loss: 0.0032\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0060 - val_loss: 0.0030\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0060 - val_loss: 0.0028\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0062 - val_loss: 0.0034\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0061 - val_loss: 0.0028\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0061 - val_loss: 0.0027\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0062 - val_loss: 0.0030\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0061 - val_loss: 0.0030\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0061 - val_loss: 0.0029\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0061 - val_loss: 0.0028\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0061 - val_loss: 0.0027\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0061 - val_loss: 0.0031\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0061 - val_loss: 0.0030\n",
      "第269个数，还剩3854个没有训练\n",
      "inv_hat [1.18521431 1.18531559 1.18551815 1.18561935 1.18561935 1.18572063\n",
      " 1.18582196 1.18632871 1.18693699 1.18713998 1.18774938 1.1883586\n",
      " 1.1891708  1.1891708  1.18947525 1.19008422 1.19028723 1.19049023\n",
      " 1.18998271 1.18957677 1.1891708  1.1886631  1.18896773 1.18957677\n",
      " 1.18977981 1.19018573 1.19028723 1.19018573 1.19069322 1.19221486]\n",
      "Test RMSE: 0.001\n",
      "Train on 579 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "579/579 [==============================] - 0s 83us/sample - loss: 0.0077 - val_loss: 0.0038\n",
      "Epoch 2/50\n",
      "579/579 [==============================] - 0s 86us/sample - loss: 0.0076 - val_loss: 0.0037\n",
      "Epoch 3/50\n",
      "579/579 [==============================] - 0s 89us/sample - loss: 0.0143 - val_loss: 0.0046\n",
      "Epoch 4/50\n",
      "579/579 [==============================] - 0s 86us/sample - loss: 0.0129 - val_loss: 0.0042\n",
      "Epoch 5/50\n",
      "579/579 [==============================] - 0s 86us/sample - loss: 0.0074 - val_loss: 0.0036\n",
      "Epoch 6/50\n",
      "579/579 [==============================] - 0s 84us/sample - loss: 0.0143 - val_loss: 0.0052\n",
      "Epoch 7/50\n",
      "579/579 [==============================] - 0s 86us/sample - loss: 0.0185 - val_loss: 0.0080\n",
      "Epoch 8/50\n",
      "579/579 [==============================] - 0s 91us/sample - loss: 0.0141 - val_loss: 0.0015\n",
      "Epoch 9/50\n",
      "579/579 [==============================] - 0s 90us/sample - loss: 0.0146 - val_loss: 0.0101\n",
      "Epoch 10/50\n",
      "579/579 [==============================] - 0s 88us/sample - loss: 0.0112 - val_loss: 0.0038\n",
      "Epoch 11/50\n",
      "579/579 [==============================] - 0s 86us/sample - loss: 0.0124 - val_loss: 0.0026\n",
      "Epoch 12/50\n",
      "579/579 [==============================] - 0s 85us/sample - loss: 0.0151 - val_loss: 0.0046\n",
      "Epoch 13/50\n",
      "579/579 [==============================] - 0s 85us/sample - loss: 0.0160 - val_loss: 0.0131\n",
      "Epoch 14/50\n",
      "579/579 [==============================] - 0s 87us/sample - loss: 0.0116 - val_loss: 0.0013\n",
      "Epoch 15/50\n",
      "579/579 [==============================] - 0s 86us/sample - loss: 0.0136 - val_loss: 0.0117\n",
      "Epoch 16/50\n",
      "579/579 [==============================] - 0s 85us/sample - loss: 0.0110 - val_loss: 0.0014\n",
      "Epoch 17/50\n",
      "579/579 [==============================] - 0s 87us/sample - loss: 0.0119 - val_loss: 0.0050\n",
      "Epoch 18/50\n",
      "579/579 [==============================] - 0s 88us/sample - loss: 0.0126 - val_loss: 0.0024\n",
      "Epoch 19/50\n",
      "579/579 [==============================] - 0s 85us/sample - loss: 0.0119 - val_loss: 0.0052\n",
      "Epoch 20/50\n",
      "579/579 [==============================] - 0s 88us/sample - loss: 0.0114 - val_loss: 0.0015\n",
      "Epoch 21/50\n",
      "579/579 [==============================] - 0s 92us/sample - loss: 0.0103 - val_loss: 0.0014\n",
      "Epoch 22/50\n",
      "579/579 [==============================] - 0s 91us/sample - loss: 0.0147 - val_loss: 0.0029\n",
      "Epoch 23/50\n",
      "579/579 [==============================] - 0s 91us/sample - loss: 0.0125 - val_loss: 0.0097\n",
      "Epoch 24/50\n",
      "579/579 [==============================] - 0s 85us/sample - loss: 0.0109 - val_loss: 0.0016\n",
      "Epoch 25/50\n",
      "579/579 [==============================] - 0s 87us/sample - loss: 0.0109 - val_loss: 0.0049\n",
      "Epoch 26/50\n",
      "579/579 [==============================] - 0s 88us/sample - loss: 0.0115 - val_loss: 0.0015\n",
      "Epoch 27/50\n",
      "579/579 [==============================] - 0s 89us/sample - loss: 0.0094 - val_loss: 0.0014\n",
      "Epoch 28/50\n",
      "579/579 [==============================] - 0s 88us/sample - loss: 0.0141 - val_loss: 0.0029\n",
      "Epoch 29/50\n",
      "579/579 [==============================] - 0s 87us/sample - loss: 0.0117 - val_loss: 0.0089\n",
      "Epoch 30/50\n",
      "579/579 [==============================] - 0s 86us/sample - loss: 0.0108 - val_loss: 0.0017\n",
      "Epoch 31/50\n",
      "579/579 [==============================] - 0s 84us/sample - loss: 0.0105 - val_loss: 0.0043\n",
      "Epoch 32/50\n",
      "579/579 [==============================] - 0s 85us/sample - loss: 0.0113 - val_loss: 0.0018\n",
      "Epoch 33/50\n",
      "579/579 [==============================] - 0s 85us/sample - loss: 0.0090 - val_loss: 0.0015\n",
      "Epoch 34/50\n",
      "579/579 [==============================] - 0s 85us/sample - loss: 0.0139 - val_loss: 0.0031\n",
      "Epoch 35/50\n",
      "579/579 [==============================] - 0s 81us/sample - loss: 0.0110 - val_loss: 0.0080\n",
      "Epoch 36/50\n",
      "579/579 [==============================] - 0s 89us/sample - loss: 0.0107 - val_loss: 0.0016\n",
      "Epoch 37/50\n",
      "579/579 [==============================] - 0s 81us/sample - loss: 0.0100 - val_loss: 0.0039\n",
      "Epoch 38/50\n",
      "579/579 [==============================] - 0s 88us/sample - loss: 0.0116 - val_loss: 0.0016\n",
      "Epoch 39/50\n",
      "579/579 [==============================] - 0s 85us/sample - loss: 0.0106 - val_loss: 0.0049\n",
      "Epoch 40/50\n",
      "579/579 [==============================] - 0s 85us/sample - loss: 0.0107 - val_loss: 0.0015\n",
      "Epoch 41/50\n",
      "579/579 [==============================] - 0s 86us/sample - loss: 0.0089 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "579/579 [==============================] - 0s 85us/sample - loss: 0.0130 - val_loss: 0.0023\n",
      "Epoch 43/50\n",
      "579/579 [==============================] - 0s 88us/sample - loss: 0.0104 - val_loss: 0.0072\n",
      "Epoch 44/50\n",
      "579/579 [==============================] - 0s 86us/sample - loss: 0.0093 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "579/579 [==============================] - 0s 89us/sample - loss: 0.0079 - val_loss: 0.0019\n",
      "Epoch 46/50\n",
      "579/579 [==============================] - 0s 88us/sample - loss: 0.0103 - val_loss: 0.0021\n",
      "Epoch 47/50\n",
      "579/579 [==============================] - 0s 95us/sample - loss: 0.0088 - val_loss: 0.0032\n",
      "Epoch 48/50\n",
      "579/579 [==============================] - 0s 92us/sample - loss: 0.0139 - val_loss: 0.0056\n",
      "Epoch 49/50\n",
      "579/579 [==============================] - 0s 91us/sample - loss: 0.0096 - val_loss: 0.0040\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579/579 [==============================] - 0s 89us/sample - loss: 0.0093 - val_loss: 0.0017\n",
      "第270个数，还剩3853个没有训练\n",
      "inv_hat [1.04881572 1.04910529 1.04949076 1.04949076 1.04958706 1.04968333\n",
      " 1.04968333 1.04968333 1.04977955 1.04987572 1.04997175 1.04997175\n",
      " 1.05006787 1.05006787 1.05006787 1.05006787 1.05016394 1.05006787\n",
      " 1.05006787 1.05006787 1.05006787 1.04997175 1.04997175 1.04997175\n",
      " 1.04997175 1.04997175 1.05006787 1.05006787 1.05016394 1.05064358]\n",
      "Test RMSE: 0.000\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0137 - val_loss: 0.0120\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0132 - val_loss: 0.0110\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0131 - val_loss: 0.0110\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0131 - val_loss: 0.0114\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0131 - val_loss: 0.0112\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0130 - val_loss: 0.0110\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0131 - val_loss: 0.0112\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0130 - val_loss: 0.0114\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0130 - val_loss: 0.0111\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0130 - val_loss: 0.0111\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0130 - val_loss: 0.0111\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0130 - val_loss: 0.0111\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0130 - val_loss: 0.0111\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0130 - val_loss: 0.0114\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0130 - val_loss: 0.0111\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0130 - val_loss: 0.0111\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0130 - val_loss: 0.0111\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0130 - val_loss: 0.0111\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0130 - val_loss: 0.0111\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0130 - val_loss: 0.0113\n",
      "第271个数，还剩3852个没有训练\n",
      "inv_hat [0.96638662 0.94815588 0.95598173 0.95677427 0.94112404 0.93904444\n",
      " 0.93637085 0.9461749  0.94102501 0.94894826 0.97560652 0.97481327\n",
      " 0.9767965  0.9572697  0.95855775 0.94944352 0.95588266 0.95974686\n",
      " 0.97481327 0.96093592 0.95647707 0.94875013 0.93587571 0.93300427\n",
      " 0.9216187  0.92617268 0.92617268 0.92142077 0.91835186 0.92448973]\n",
      "Test RMSE: 0.010\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0062 - val_loss: 0.0040\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0068 - val_loss: 0.0031\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0054 - val_loss: 0.0010\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0064 - val_loss: 0.0043\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0092 - val_loss: 0.0027\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0092 - val_loss: 9.2510e-04\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0087 - val_loss: 0.0016\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0088 - val_loss: 0.0011\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0075 - val_loss: 0.0018\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0092 - val_loss: 0.0033\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0107 - val_loss: 0.0077\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0087 - val_loss: 0.0036\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0196 - val_loss: 0.0098\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0189 - val_loss: 0.0177\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0197 - val_loss: 0.0087\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0177 - val_loss: 0.0153\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0190 - val_loss: 0.0101\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0166 - val_loss: 0.0128\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0185 - val_loss: 0.0115\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0158 - val_loss: 0.0107\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0181 - val_loss: 0.0126\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0151 - val_loss: 0.0091\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0181 - val_loss: 0.0133\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0140 - val_loss: 0.0074\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0174 - val_loss: 0.0139\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0137 - val_loss: 0.0064\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0172 - val_loss: 0.0143\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0132 - val_loss: 0.0056\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0170 - val_loss: 0.0144\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0127 - val_loss: 0.0050\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0166 - val_loss: 0.0146\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0126 - val_loss: 0.0044\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0164 - val_loss: 0.0145\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0041\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0163 - val_loss: 0.0142\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0039\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0158 - val_loss: 0.0139\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0119 - val_loss: 0.0041\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0158 - val_loss: 0.0135\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0116 - val_loss: 0.0040\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0153 - val_loss: 0.0133\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0118 - val_loss: 0.0042\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0153 - val_loss: 0.0130\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0115 - val_loss: 0.0041\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0151 - val_loss: 0.0128\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0114 - val_loss: 0.0041\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0149 - val_loss: 0.0125\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0113 - val_loss: 0.0042\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0147 - val_loss: 0.0123\n",
      "第272个数，还剩3851个没有训练\n",
      "inv_hat [1.1326704  1.13368098 1.1326704  1.13368098 1.13368098 1.13368098\n",
      " 1.1326704  1.1326704  1.13368098 1.13368098 1.13368098 1.13368098\n",
      " 1.13469197 1.13469197 1.13469197 1.1357031  1.1357031  1.1357031\n",
      " 1.13469197 1.13469197 1.13469197 1.13469197 1.13469197 1.13469197\n",
      " 1.1357031  1.1357031  1.1357031  1.1357031  1.1357031  1.13772642]\n",
      "Test RMSE: 0.007\n",
      "Train on 1124 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1124/1124 [==============================] - 0s 77us/sample - loss: 0.0086 - val_loss: 0.0125\n",
      "Epoch 2/50\n",
      "1124/1124 [==============================] - 0s 79us/sample - loss: 0.0099 - val_loss: 0.0129\n",
      "Epoch 3/50\n",
      "1124/1124 [==============================] - 0s 80us/sample - loss: 0.0087 - val_loss: 0.0093\n",
      "Epoch 4/50\n",
      "1124/1124 [==============================] - 0s 80us/sample - loss: 0.0096 - val_loss: 0.0087\n",
      "Epoch 5/50\n",
      "1124/1124 [==============================] - 0s 76us/sample - loss: 0.0083 - val_loss: 0.0132\n",
      "Epoch 6/50\n",
      "1124/1124 [==============================] - 0s 76us/sample - loss: 0.0079 - val_loss: 0.0086\n",
      "Epoch 7/50\n",
      "1124/1124 [==============================] - 0s 75us/sample - loss: 0.0089 - val_loss: 0.0091\n",
      "Epoch 8/50\n",
      "1124/1124 [==============================] - 0s 76us/sample - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 9/50\n",
      "1124/1124 [==============================] - 0s 75us/sample - loss: 0.0075 - val_loss: 0.0098\n",
      "Epoch 10/50\n",
      "1124/1124 [==============================] - 0s 76us/sample - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 11/50\n",
      "1124/1124 [==============================] - 0s 79us/sample - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 12/50\n",
      "1124/1124 [==============================] - 0s 84us/sample - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 13/50\n",
      "1124/1124 [==============================] - 0s 81us/sample - loss: 0.0070 - val_loss: 0.0071\n",
      "Epoch 14/50\n",
      "1124/1124 [==============================] - 0s 79us/sample - loss: 0.0070 - val_loss: 0.0069\n",
      "Epoch 15/50\n",
      "1124/1124 [==============================] - 0s 81us/sample - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 16/50\n",
      "1124/1124 [==============================] - 0s 77us/sample - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 17/50\n",
      "1124/1124 [==============================] - 0s 77us/sample - loss: 0.0066 - val_loss: 0.0067\n",
      "Epoch 18/50\n",
      "1124/1124 [==============================] - 0s 77us/sample - loss: 0.0065 - val_loss: 0.0066\n",
      "Epoch 19/50\n",
      "1124/1124 [==============================] - 0s 75us/sample - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 20/50\n",
      "1124/1124 [==============================] - 0s 79us/sample - loss: 0.0065 - val_loss: 0.0066\n",
      "Epoch 21/50\n",
      "1124/1124 [==============================] - 0s 78us/sample - loss: 0.0070 - val_loss: 0.0071\n",
      "Epoch 22/50\n",
      "1124/1124 [==============================] - 0s 77us/sample - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 23/50\n",
      "1124/1124 [==============================] - 0s 77us/sample - loss: 0.0065 - val_loss: 0.0066\n",
      "Epoch 24/50\n",
      "1124/1124 [==============================] - 0s 78us/sample - loss: 0.0069 - val_loss: 0.0069\n",
      "Epoch 25/50\n",
      "1124/1124 [==============================] - 0s 81us/sample - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 26/50\n",
      "1124/1124 [==============================] - 0s 76us/sample - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 27/50\n",
      "1124/1124 [==============================] - 0s 80us/sample - loss: 0.0064 - val_loss: 0.0066\n",
      "Epoch 28/50\n",
      "1124/1124 [==============================] - 0s 80us/sample - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 29/50\n",
      "1124/1124 [==============================] - 0s 80us/sample - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 30/50\n",
      "1124/1124 [==============================] - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 31/50\n",
      "1124/1124 [==============================] - 0s 80us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 32/50\n",
      "1124/1124 [==============================] - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 33/50\n",
      "1124/1124 [==============================] - 0s 76us/sample - loss: 0.0064 - val_loss: 0.0067\n",
      "Epoch 34/50\n",
      "1124/1124 [==============================] - 0s 76us/sample - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 35/50\n",
      "1124/1124 [==============================] - 0s 79us/sample - loss: 0.0079 - val_loss: 0.0081\n",
      "Epoch 36/50\n",
      "1124/1124 [==============================] - 0s 77us/sample - loss: 0.0073 - val_loss: 0.0074\n",
      "Epoch 37/50\n",
      "1124/1124 [==============================] - 0s 78us/sample - loss: 0.0069 - val_loss: 0.0071\n",
      "Epoch 38/50\n",
      "1124/1124 [==============================] - 0s 81us/sample - loss: 0.0066 - val_loss: 0.0069\n",
      "Epoch 39/50\n",
      "1124/1124 [==============================] - 0s 86us/sample - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 40/50\n",
      "1124/1124 [==============================] - 0s 84us/sample - loss: 0.0064 - val_loss: 0.0068\n",
      "Epoch 41/50\n",
      "1124/1124 [==============================] - 0s 81us/sample - loss: 0.0065 - val_loss: 0.0066\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1124/1124 [==============================] - 0s 75us/sample - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 43/50\n",
      "1124/1124 [==============================] - 0s 77us/sample - loss: 0.0071 - val_loss: 0.0072\n",
      "Epoch 44/50\n",
      "1124/1124 [==============================] - 0s 77us/sample - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 45/50\n",
      "1124/1124 [==============================] - 0s 75us/sample - loss: 0.0064 - val_loss: 0.0066\n",
      "Epoch 46/50\n",
      "1124/1124 [==============================] - 0s 76us/sample - loss: 0.0065 - val_loss: 0.0066\n",
      "Epoch 47/50\n",
      "1124/1124 [==============================] - 0s 73us/sample - loss: 0.0064 - val_loss: 0.0067\n",
      "Epoch 48/50\n",
      "1124/1124 [==============================] - 0s 73us/sample - loss: 0.0064 - val_loss: 0.0067\n",
      "Epoch 49/50\n",
      "1124/1124 [==============================] - 0s 81us/sample - loss: 0.0065 - val_loss: 0.0066\n",
      "Epoch 50/50\n",
      "1124/1124 [==============================] - 0s 78us/sample - loss: 0.0066 - val_loss: 0.0066\n",
      "第273个数，还剩3850个没有训练\n",
      "inv_hat [1.35222372 1.34449768 1.34352969 1.34352969 1.33868215 1.33868215\n",
      " 1.33965257 1.33965257 1.34352969 1.34643222 1.35029531 1.34933032\n",
      " 1.35029531 1.35511241 1.34739878 1.34352969 1.34546523 1.34643222\n",
      " 1.35318714 1.35799624 1.35799624 1.35799624 1.36087513 1.35895643\n",
      " 1.35895643 1.35991614 1.35799624 1.3627917  1.36087513 1.35607411]\n",
      "Test RMSE: 0.004\n",
      "Train on 594 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "594/594 [==============================] - 0s 88us/sample - loss: 0.0202 - val_loss: 0.0227\n",
      "Epoch 2/50\n",
      "594/594 [==============================] - 0s 87us/sample - loss: 0.0206 - val_loss: 0.0255\n",
      "Epoch 3/50\n",
      "594/594 [==============================] - 0s 86us/sample - loss: 0.0215 - val_loss: 0.0227\n",
      "Epoch 4/50\n",
      "594/594 [==============================] - 0s 81us/sample - loss: 0.0194 - val_loss: 0.0245\n",
      "Epoch 5/50\n",
      "594/594 [==============================] - 0s 84us/sample - loss: 0.0202 - val_loss: 0.0226\n",
      "Epoch 6/50\n",
      "594/594 [==============================] - 0s 87us/sample - loss: 0.0196 - val_loss: 0.0254\n",
      "Epoch 7/50\n",
      "594/594 [==============================] - 0s 83us/sample - loss: 0.0212 - val_loss: 0.0227\n",
      "Epoch 8/50\n",
      "594/594 [==============================] - 0s 86us/sample - loss: 0.0194 - val_loss: 0.0246\n",
      "Epoch 9/50\n",
      "594/594 [==============================] - 0s 84us/sample - loss: 0.0202 - val_loss: 0.0226\n",
      "Epoch 10/50\n",
      "594/594 [==============================] - 0s 87us/sample - loss: 0.0197 - val_loss: 0.0253\n",
      "Epoch 11/50\n",
      "594/594 [==============================] - 0s 88us/sample - loss: 0.0211 - val_loss: 0.0228\n",
      "Epoch 12/50\n",
      "594/594 [==============================] - 0s 86us/sample - loss: 0.0193 - val_loss: 0.0247\n",
      "Epoch 13/50\n",
      "594/594 [==============================] - 0s 85us/sample - loss: 0.0202 - val_loss: 0.0226\n",
      "Epoch 14/50\n",
      "594/594 [==============================] - 0s 81us/sample - loss: 0.0196 - val_loss: 0.0253\n",
      "Epoch 15/50\n",
      "594/594 [==============================] - 0s 80us/sample - loss: 0.0210 - val_loss: 0.0227\n",
      "Epoch 16/50\n",
      "594/594 [==============================] - 0s 84us/sample - loss: 0.0194 - val_loss: 0.0247\n",
      "Epoch 17/50\n",
      "594/594 [==============================] - 0s 82us/sample - loss: 0.0202 - val_loss: 0.0226\n",
      "Epoch 18/50\n",
      "594/594 [==============================] - 0s 84us/sample - loss: 0.0196 - val_loss: 0.0253\n",
      "Epoch 19/50\n",
      "594/594 [==============================] - 0s 86us/sample - loss: 0.0209 - val_loss: 0.0227\n",
      "Epoch 20/50\n",
      "594/594 [==============================] - 0s 81us/sample - loss: 0.0194 - val_loss: 0.0248\n",
      "Epoch 21/50\n",
      "594/594 [==============================] - 0s 83us/sample - loss: 0.0202 - val_loss: 0.0227\n",
      "Epoch 22/50\n",
      "594/594 [==============================] - 0s 84us/sample - loss: 0.0195 - val_loss: 0.0255\n",
      "Epoch 23/50\n",
      "594/594 [==============================] - 0s 83us/sample - loss: 0.0210 - val_loss: 0.0228\n",
      "Epoch 24/50\n",
      "594/594 [==============================] - 0s 81us/sample - loss: 0.0195 - val_loss: 0.0248\n",
      "Epoch 25/50\n",
      "594/594 [==============================] - 0s 80us/sample - loss: 0.0201 - val_loss: 0.0226\n",
      "Epoch 26/50\n",
      "594/594 [==============================] - 0s 86us/sample - loss: 0.0197 - val_loss: 0.0255\n",
      "Epoch 27/50\n",
      "594/594 [==============================] - 0s 81us/sample - loss: 0.0210 - val_loss: 0.0229\n",
      "Epoch 28/50\n",
      "594/594 [==============================] - 0s 82us/sample - loss: 0.0195 - val_loss: 0.0248\n",
      "Epoch 29/50\n",
      "594/594 [==============================] - 0s 83us/sample - loss: 0.0200 - val_loss: 0.0227\n",
      "Epoch 30/50\n",
      "594/594 [==============================] - 0s 91us/sample - loss: 0.0195 - val_loss: 0.0257\n",
      "Epoch 31/50\n",
      "594/594 [==============================] - 0s 94us/sample - loss: 0.0206 - val_loss: 0.0229\n",
      "Epoch 32/50\n",
      "594/594 [==============================] - 0s 86us/sample - loss: 0.0199 - val_loss: 0.0252\n",
      "Epoch 33/50\n",
      "594/594 [==============================] - 0s 92us/sample - loss: 0.0202 - val_loss: 0.0227\n",
      "Epoch 34/50\n",
      "594/594 [==============================] - 0s 83us/sample - loss: 0.0199 - val_loss: 0.0250\n",
      "Epoch 35/50\n",
      "594/594 [==============================] - 0s 82us/sample - loss: 0.0201 - val_loss: 0.0227\n",
      "Epoch 36/50\n",
      "594/594 [==============================] - 0s 81us/sample - loss: 0.0198 - val_loss: 0.0256\n",
      "Epoch 37/50\n",
      "594/594 [==============================] - ETA: 0s - loss: 0.010 - 0s 84us/sample - loss: 0.0207 - val_loss: 0.0229\n",
      "Epoch 38/50\n",
      "594/594 [==============================] - 0s 83us/sample - loss: 0.0197 - val_loss: 0.0250\n",
      "Epoch 39/50\n",
      "594/594 [==============================] - 0s 81us/sample - loss: 0.0201 - val_loss: 0.0227\n",
      "Epoch 40/50\n",
      "594/594 [==============================] - 0s 81us/sample - loss: 0.0198 - val_loss: 0.0257\n",
      "Epoch 41/50\n",
      "594/594 [==============================] - 0s 82us/sample - loss: 0.0207 - val_loss: 0.0229\n",
      "Epoch 42/50\n",
      "594/594 [==============================] - 0s 86us/sample - loss: 0.0197 - val_loss: 0.0250\n",
      "Epoch 43/50\n",
      "594/594 [==============================] - 0s 84us/sample - loss: 0.0201 - val_loss: 0.0227\n",
      "Epoch 44/50\n",
      "594/594 [==============================] - 0s 87us/sample - loss: 0.0198 - val_loss: 0.0257\n",
      "Epoch 45/50\n",
      "594/594 [==============================] - 0s 90us/sample - loss: 0.0207 - val_loss: 0.0229\n",
      "Epoch 46/50\n",
      "594/594 [==============================] - 0s 91us/sample - loss: 0.0198 - val_loss: 0.0250\n",
      "Epoch 47/50\n",
      "594/594 [==============================] - 0s 86us/sample - loss: 0.0201 - val_loss: 0.0227\n",
      "Epoch 48/50\n",
      "594/594 [==============================] - 0s 82us/sample - loss: 0.0198 - val_loss: 0.0257\n",
      "Epoch 49/50\n",
      "594/594 [==============================] - 0s 85us/sample - loss: 0.0207 - val_loss: 0.0230\n",
      "Epoch 50/50\n",
      "594/594 [==============================] - 0s 85us/sample - loss: 0.0198 - val_loss: 0.0251\n",
      "第274个数，还剩3849个没有训练\n",
      "inv_hat [0.98159475 0.97768136 0.97768136 0.97768136 0.97287307 0.97192458\n",
      " 0.97098093 0.97382622 0.97192458 0.97382622 0.97963157 0.98061168\n",
      " 0.97963157 0.97574572 0.97671161 0.97478381 0.97574572 0.97671161\n",
      " 0.97963157 0.97671161 0.97671161 0.97478381 0.97287307 0.97098093\n",
      " 0.96910885 0.97098093 0.97004225 0.97098093 0.97098093 0.97192458]\n",
      "Test RMSE: 0.003\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0092 - val_loss: 0.0041\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0092 - val_loss: 0.0038\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0091 - val_loss: 0.0038\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0091 - val_loss: 0.0038\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0091 - val_loss: 0.0038\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 87us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0091 - val_loss: 0.0038\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0091 - val_loss: 0.0038\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0092 - val_loss: 0.0039\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0092 - val_loss: 0.0039\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0092 - val_loss: 0.0039\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0092 - val_loss: 0.0039\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 72us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0092 - val_loss: 0.0039\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0092 - val_loss: 0.0039\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0092 - val_loss: 0.0039\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0092 - val_loss: 0.0039\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0092 - val_loss: 0.0039\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0092 - val_loss: 0.0039\n",
      "第275个数，还剩3848个没有训练\n",
      "inv_hat [0.38015745 0.37137615 0.37265749 0.37048935 0.3635998  0.36261673\n",
      " 0.36537004 0.37127758 0.36802717 0.3718689  0.38163949 0.38430856\n",
      " 0.38470416 0.37551749 0.37384066 0.3718689  0.37344622 0.37522153\n",
      " 0.37857723 0.37157326 0.36930729 0.36773181 0.36330484 0.36379646\n",
      " 0.36173224 0.3635998  0.36232187 0.36104446 0.36035684 0.3600622 ]\n",
      "Test RMSE: 0.004\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0064 - val_loss: 0.0028\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0060 - val_loss: 0.0020\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0062 - val_loss: 0.0025\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0061 - val_loss: 0.0025\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0060 - val_loss: 0.0023\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0060 - val_loss: 0.0025\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0059 - val_loss: 0.0023\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0061 - val_loss: 0.0027\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0060 - val_loss: 0.0024\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0060 - val_loss: 0.0024\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0059 - val_loss: 0.0025\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0060 - val_loss: 0.0028\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0060 - val_loss: 0.0024\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0060 - val_loss: 0.0025\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0060 - val_loss: 0.0025\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0060 - val_loss: 0.0025\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0061 - val_loss: 0.0028\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0060 - val_loss: 0.0024\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0061 - val_loss: 0.0027\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0060 - val_loss: 0.0024\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0061 - val_loss: 0.0026\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0060 - val_loss: 0.0025\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0060 - val_loss: 0.0025\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0060 - val_loss: 0.0024\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0059 - val_loss: 0.0023\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0061 - val_loss: 0.0027\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0060 - val_loss: 0.0022\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0061 - val_loss: 0.0026\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0060 - val_loss: 0.0023\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0061 - val_loss: 0.0027\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0060 - val_loss: 0.0023\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0061 - val_loss: 0.0027\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0060 - val_loss: 0.0021\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0061 - val_loss: 0.0025\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0061 - val_loss: 0.0021\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0061 - val_loss: 0.0025\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0060 - val_loss: 0.0023\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0061 - val_loss: 0.0023\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0060 - val_loss: 0.0022\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0060 - val_loss: 0.0021\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0060 - val_loss: 0.0021\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0060 - val_loss: 0.0020\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0061 - val_loss: 0.0022\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0060 - val_loss: 0.0021\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0060 - val_loss: 0.0020\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0060 - val_loss: 0.0019\n",
      "第276个数，还剩3847个没有训练\n",
      "inv_hat [1.20261282 1.20271289 1.20281297 1.20291306 1.20291306 1.20301315\n",
      " 1.20321337 1.20361375 1.20421462 1.204415   1.20501621 1.20561768\n",
      " 1.2064201  1.2064201  1.20672119 1.20732342 1.20752426 1.20772501\n",
      " 1.20712259 1.20672119 1.20621941 1.20581827 1.20611923 1.20662081\n",
      " 1.20682155 1.20722301 1.20732342 1.20722301 1.20772501 1.20923233]\n",
      "Test RMSE: 0.000\n",
      "Train on 655 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "655/655 [==============================] - 0s 90us/sample - loss: 0.0133 - val_loss: 0.0107\n",
      "Epoch 2/50\n",
      "655/655 [==============================] - 0s 89us/sample - loss: 0.0141 - val_loss: 0.0109\n",
      "Epoch 3/50\n",
      "655/655 [==============================] - 0s 87us/sample - loss: 0.0142 - val_loss: 0.0112\n",
      "Epoch 4/50\n",
      "655/655 [==============================] - 0s 88us/sample - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 5/50\n",
      "655/655 [==============================] - 0s 88us/sample - loss: 0.0133 - val_loss: 0.0110\n",
      "Epoch 6/50\n",
      "655/655 [==============================] - 0s 86us/sample - loss: 0.0145 - val_loss: 0.0129\n",
      "Epoch 7/50\n",
      "655/655 [==============================] - 0s 88us/sample - loss: 0.0143 - val_loss: 0.0101\n",
      "Epoch 8/50\n",
      "655/655 [==============================] - 0s 82us/sample - loss: 0.0133 - val_loss: 0.0100\n",
      "Epoch 9/50\n",
      "655/655 [==============================] - 0s 83us/sample - loss: 0.0135 - val_loss: 0.0105\n",
      "Epoch 10/50\n",
      "655/655 [==============================] - 0s 85us/sample - loss: 0.0139 - val_loss: 0.0100\n",
      "Epoch 11/50\n",
      "655/655 [==============================] - 0s 81us/sample - loss: 0.0144 - val_loss: 0.0104\n",
      "Epoch 12/50\n",
      "655/655 [==============================] - 0s 86us/sample - loss: 0.0134 - val_loss: 0.0102\n",
      "Epoch 13/50\n",
      "655/655 [==============================] - 0s 82us/sample - loss: 0.0133 - val_loss: 0.0114\n",
      "Epoch 14/50\n",
      "655/655 [==============================] - 0s 80us/sample - loss: 0.0153 - val_loss: 0.0107\n",
      "Epoch 15/50\n",
      "655/655 [==============================] - 0s 83us/sample - loss: 0.0132 - val_loss: 0.0107\n",
      "Epoch 16/50\n",
      "655/655 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0100\n",
      "Epoch 17/50\n",
      "655/655 [==============================] - 0s 81us/sample - loss: 0.0138 - val_loss: 0.0102\n",
      "Epoch 18/50\n",
      "655/655 [==============================] - 0s 82us/sample - loss: 0.0141 - val_loss: 0.0114\n",
      "Epoch 19/50\n",
      "655/655 [==============================] - 0s 89us/sample - loss: 0.0136 - val_loss: 0.0119\n",
      "Epoch 20/50\n",
      "655/655 [==============================] - 0s 89us/sample - loss: 0.0136 - val_loss: 0.0116\n",
      "Epoch 21/50\n",
      "655/655 [==============================] - 0s 86us/sample - loss: 0.0137 - val_loss: 0.0112\n",
      "Epoch 22/50\n",
      "655/655 [==============================] - 0s 88us/sample - loss: 0.0134 - val_loss: 0.0100\n",
      "Epoch 23/50\n",
      "655/655 [==============================] - 0s 86us/sample - loss: 0.0135 - val_loss: 0.0105\n",
      "Epoch 24/50\n",
      "655/655 [==============================] - 0s 90us/sample - loss: 0.0140 - val_loss: 0.0100\n",
      "Epoch 25/50\n",
      "655/655 [==============================] - 0s 87us/sample - loss: 0.0139 - val_loss: 0.0100\n",
      "Epoch 26/50\n",
      "655/655 [==============================] - 0s 87us/sample - loss: 0.0138 - val_loss: 0.0101\n",
      "Epoch 27/50\n",
      "655/655 [==============================] - 0s 90us/sample - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 28/50\n",
      "655/655 [==============================] - 0s 89us/sample - loss: 0.0133 - val_loss: 0.0100\n",
      "Epoch 29/50\n",
      "655/655 [==============================] - 0s 88us/sample - loss: 0.0133 - val_loss: 0.0104\n",
      "Epoch 30/50\n",
      "655/655 [==============================] - 0s 87us/sample - loss: 0.0135 - val_loss: 0.0105\n",
      "Epoch 31/50\n",
      "655/655 [==============================] - 0s 84us/sample - loss: 0.0139 - val_loss: 0.0107\n",
      "Epoch 32/50\n",
      "655/655 [==============================] - 0s 83us/sample - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 33/50\n",
      "655/655 [==============================] - 0s 92us/sample - loss: 0.0137 - val_loss: 0.0103\n",
      "Epoch 34/50\n",
      "655/655 [==============================] - 0s 83us/sample - loss: 0.0132 - val_loss: 0.0108\n",
      "Epoch 35/50\n",
      "655/655 [==============================] - 0s 86us/sample - loss: 0.0141 - val_loss: 0.0100\n",
      "Epoch 36/50\n",
      "655/655 [==============================] - 0s 89us/sample - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 37/50\n",
      "655/655 [==============================] - 0s 89us/sample - loss: 0.0139 - val_loss: 0.0100\n",
      "Epoch 38/50\n",
      "655/655 [==============================] - 0s 87us/sample - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 39/50\n",
      "655/655 [==============================] - 0s 83us/sample - loss: 0.0143 - val_loss: 0.0101\n",
      "Epoch 40/50\n",
      "655/655 [==============================] - 0s 86us/sample - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 41/50\n",
      "655/655 [==============================] - 0s 89us/sample - loss: 0.0132 - val_loss: 0.0104\n",
      "Epoch 42/50\n",
      "655/655 [==============================] - 0s 87us/sample - loss: 0.0138 - val_loss: 0.0100\n",
      "Epoch 43/50\n",
      "655/655 [==============================] - 0s 88us/sample - loss: 0.0139 - val_loss: 0.0112\n",
      "Epoch 44/50\n",
      "655/655 [==============================] - 0s 86us/sample - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 45/50\n",
      "655/655 [==============================] - 0s 81us/sample - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 46/50\n",
      "655/655 [==============================] - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0102\n",
      "Epoch 47/50\n",
      "655/655 [==============================] - 0s 85us/sample - loss: 0.0131 - val_loss: 0.0105\n",
      "Epoch 48/50\n",
      "655/655 [==============================] - 0s 85us/sample - loss: 0.0139 - val_loss: 0.0101\n",
      "Epoch 49/50\n",
      "655/655 [==============================] - 0s 84us/sample - loss: 0.0134 - val_loss: 0.0104\n",
      "Epoch 50/50\n",
      "655/655 [==============================] - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0102\n",
      "第277个数，还剩3846个没有训练\n",
      "inv_hat [1.05396991 1.05198805 1.05198805 1.05198805 1.05099355 1.05099355\n",
      " 1.05198805 1.05298013 1.05298013 1.05298013 1.05495701 1.05594157\n",
      " 1.05692335 1.05692335 1.05790213 1.05887804 1.05790213 1.05887804\n",
      " 1.05790213 1.05692335 1.05594157 1.05495701 1.05495701 1.05594157\n",
      " 1.05594157 1.05594157 1.05692335 1.05692335 1.05692335 1.05887804]\n",
      "Test RMSE: 0.001\n",
      "Train on 817 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "817/817 [==============================] - 0s 81us/sample - loss: 0.0193 - val_loss: 0.0146\n",
      "Epoch 2/50\n",
      "817/817 [==============================] - 0s 82us/sample - loss: 0.0191 - val_loss: 0.0134\n",
      "Epoch 3/50\n",
      "817/817 [==============================] - 0s 86us/sample - loss: 0.0192 - val_loss: 0.0146\n",
      "Epoch 4/50\n",
      "817/817 [==============================] - 0s 89us/sample - loss: 0.0191 - val_loss: 0.0141\n",
      "Epoch 5/50\n",
      "817/817 [==============================] - 0s 86us/sample - loss: 0.0191 - val_loss: 0.0148\n",
      "Epoch 6/50\n",
      "817/817 [==============================] - 0s 86us/sample - loss: 0.0191 - val_loss: 0.0149\n",
      "Epoch 7/50\n",
      "817/817 [==============================] - 0s 86us/sample - loss: 0.0190 - val_loss: 0.0145\n",
      "Epoch 8/50\n",
      "817/817 [==============================] - 0s 83us/sample - loss: 0.0191 - val_loss: 0.0149\n",
      "Epoch 9/50\n",
      "817/817 [==============================] - 0s 82us/sample - loss: 0.0190 - val_loss: 0.0140\n",
      "Epoch 10/50\n",
      "817/817 [==============================] - 0s 80us/sample - loss: 0.0192 - val_loss: 0.0151\n",
      "Epoch 11/50\n",
      "817/817 [==============================] - 0s 76us/sample - loss: 0.0190 - val_loss: 0.0133\n",
      "Epoch 12/50\n",
      "817/817 [==============================] - 0s 79us/sample - loss: 0.0193 - val_loss: 0.0152\n",
      "Epoch 13/50\n",
      "817/817 [==============================] - 0s 75us/sample - loss: 0.0190 - val_loss: 0.0134\n",
      "Epoch 14/50\n",
      "817/817 [==============================] - 0s 85us/sample - loss: 0.0192 - val_loss: 0.0148\n",
      "Epoch 15/50\n",
      "817/817 [==============================] - 0s 83us/sample - loss: 0.0190 - val_loss: 0.0128\n",
      "Epoch 16/50\n",
      "817/817 [==============================] - 0s 79us/sample - loss: 0.0193 - val_loss: 0.0150\n",
      "Epoch 17/50\n",
      "817/817 [==============================] - 0s 81us/sample - loss: 0.0190 - val_loss: 0.0127\n",
      "Epoch 18/50\n",
      "817/817 [==============================] - 0s 82us/sample - loss: 0.0193 - val_loss: 0.0148\n",
      "Epoch 19/50\n",
      "817/817 [==============================] - 0s 82us/sample - loss: 0.0190 - val_loss: 0.0124\n",
      "Epoch 20/50\n",
      "817/817 [==============================] - 0s 79us/sample - loss: 0.0193 - val_loss: 0.0145\n",
      "Epoch 21/50\n",
      "817/817 [==============================] - 0s 79us/sample - loss: 0.0190 - val_loss: 0.0123\n",
      "Epoch 22/50\n",
      "817/817 [==============================] - 0s 88us/sample - loss: 0.0192 - val_loss: 0.0139\n",
      "Epoch 23/50\n",
      "817/817 [==============================] - 0s 86us/sample - loss: 0.0190 - val_loss: 0.0124\n",
      "Epoch 24/50\n",
      "817/817 [==============================] - 0s 89us/sample - loss: 0.0192 - val_loss: 0.0138\n",
      "Epoch 25/50\n",
      "817/817 [==============================] - 0s 89us/sample - loss: 0.0190 - val_loss: 0.0124\n",
      "Epoch 26/50\n",
      "817/817 [==============================] - 0s 83us/sample - loss: 0.0192 - val_loss: 0.0140\n",
      "Epoch 27/50\n",
      "817/817 [==============================] - 0s 80us/sample - loss: 0.0190 - val_loss: 0.0124\n",
      "Epoch 28/50\n",
      "817/817 [==============================] - 0s 79us/sample - loss: 0.0192 - val_loss: 0.0139\n",
      "Epoch 29/50\n",
      "817/817 [==============================] - 0s 81us/sample - loss: 0.0189 - val_loss: 0.0122\n",
      "Epoch 30/50\n",
      "817/817 [==============================] - 0s 80us/sample - loss: 0.0192 - val_loss: 0.0134\n",
      "Epoch 31/50\n",
      "817/817 [==============================] - 0s 80us/sample - loss: 0.0190 - val_loss: 0.0121\n",
      "Epoch 32/50\n",
      "817/817 [==============================] - 0s 88us/sample - loss: 0.0192 - val_loss: 0.0132\n",
      "Epoch 33/50\n",
      "817/817 [==============================] - 0s 91us/sample - loss: 0.0190 - val_loss: 0.0122\n",
      "Epoch 34/50\n",
      "817/817 [==============================] - 0s 83us/sample - loss: 0.0191 - val_loss: 0.0128\n",
      "Epoch 35/50\n",
      "817/817 [==============================] - 0s 83us/sample - loss: 0.0190 - val_loss: 0.0120\n",
      "Epoch 36/50\n",
      "817/817 [==============================] - 0s 80us/sample - loss: 0.0192 - val_loss: 0.0126\n",
      "Epoch 37/50\n",
      "817/817 [==============================] - 0s 79us/sample - loss: 0.0189 - val_loss: 0.0119\n",
      "Epoch 38/50\n",
      "817/817 [==============================] - 0s 80us/sample - loss: 0.0192 - val_loss: 0.0127\n",
      "Epoch 39/50\n",
      "817/817 [==============================] - 0s 84us/sample - loss: 0.0189 - val_loss: 0.0119\n",
      "Epoch 40/50\n",
      "817/817 [==============================] - 0s 83us/sample - loss: 0.0192 - val_loss: 0.0127\n",
      "Epoch 41/50\n",
      "817/817 [==============================] - 0s 82us/sample - loss: 0.0189 - val_loss: 0.0119\n",
      "Epoch 42/50\n",
      "817/817 [==============================] - 0s 78us/sample - loss: 0.0192 - val_loss: 0.0126\n",
      "Epoch 43/50\n",
      "817/817 [==============================] - 0s 80us/sample - loss: 0.0189 - val_loss: 0.0118\n",
      "Epoch 44/50\n",
      "817/817 [==============================] - 0s 82us/sample - loss: 0.0192 - val_loss: 0.0125\n",
      "Epoch 45/50\n",
      "817/817 [==============================] - 0s 82us/sample - loss: 0.0189 - val_loss: 0.0119\n",
      "Epoch 46/50\n",
      "817/817 [==============================] - 0s 79us/sample - loss: 0.0192 - val_loss: 0.0124\n",
      "Epoch 47/50\n",
      "817/817 [==============================] - 0s 79us/sample - loss: 0.0189 - val_loss: 0.0118\n",
      "Epoch 48/50\n",
      "817/817 [==============================] - 0s 75us/sample - loss: 0.0192 - val_loss: 0.0124\n",
      "Epoch 49/50\n",
      "817/817 [==============================] - 0s 80us/sample - loss: 0.0189 - val_loss: 0.0118\n",
      "Epoch 50/50\n",
      "817/817 [==============================] - 0s 80us/sample - loss: 0.0192 - val_loss: 0.0123\n",
      "第278个数，还剩3845个没有训练\n",
      "inv_hat [0.75398805 0.73410187 0.7321228  0.73014572 0.71048987 0.71048987\n",
      " 0.71146735 0.71734431 0.70463804 0.70951304 0.72521162 0.72521162\n",
      " 0.72521162 0.71244538 0.713424   0.70951304 0.713424   0.713424\n",
      " 0.72127365 0.70561179 0.70269247 0.69300399 0.68530331 0.68722413\n",
      " 0.67860392 0.67955867 0.67574435 0.67384186 0.6700466  0.67289185]\n",
      "Test RMSE: 0.009\n",
      "Train on 598 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "598/598 [==============================] - 0s 79us/sample - loss: 0.0182 - val_loss: 0.0175\n",
      "Epoch 2/50\n",
      "598/598 [==============================] - 0s 82us/sample - loss: 0.0183 - val_loss: 0.0177\n",
      "Epoch 3/50\n",
      "598/598 [==============================] - 0s 80us/sample - loss: 0.0182 - val_loss: 0.0175\n",
      "Epoch 4/50\n",
      "598/598 [==============================] - 0s 83us/sample - loss: 0.0183 - val_loss: 0.0178\n",
      "Epoch 5/50\n",
      "598/598 [==============================] - 0s 90us/sample - loss: 0.0182 - val_loss: 0.0177\n",
      "Epoch 6/50\n",
      "598/598 [==============================] - 0s 84us/sample - loss: 0.0183 - val_loss: 0.0179\n",
      "Epoch 7/50\n",
      "598/598 [==============================] - 0s 85us/sample - loss: 0.0182 - val_loss: 0.0176\n",
      "Epoch 8/50\n",
      "598/598 [==============================] - 0s 87us/sample - loss: 0.0183 - val_loss: 0.0179\n",
      "Epoch 9/50\n",
      "598/598 [==============================] - 0s 86us/sample - loss: 0.0182 - val_loss: 0.0176\n",
      "Epoch 10/50\n",
      "598/598 [==============================] - 0s 85us/sample - loss: 0.0183 - val_loss: 0.0178\n",
      "Epoch 11/50\n",
      "598/598 [==============================] - 0s 82us/sample - loss: 0.0182 - val_loss: 0.0176\n",
      "Epoch 12/50\n",
      "598/598 [==============================] - 0s 81us/sample - loss: 0.0183 - val_loss: 0.0178\n",
      "Epoch 13/50\n",
      "598/598 [==============================] - 0s 83us/sample - loss: 0.0182 - val_loss: 0.0175\n",
      "Epoch 14/50\n",
      "598/598 [==============================] - 0s 83us/sample - loss: 0.0183 - val_loss: 0.0177\n",
      "Epoch 15/50\n",
      "598/598 [==============================] - 0s 83us/sample - loss: 0.0182 - val_loss: 0.0175\n",
      "Epoch 16/50\n",
      "598/598 [==============================] - 0s 89us/sample - loss: 0.0183 - val_loss: 0.0178\n",
      "Epoch 17/50\n",
      "598/598 [==============================] - 0s 86us/sample - loss: 0.0182 - val_loss: 0.0175\n",
      "Epoch 18/50\n",
      "598/598 [==============================] - 0s 89us/sample - loss: 0.0183 - val_loss: 0.0178\n",
      "Epoch 19/50\n",
      "598/598 [==============================] - 0s 89us/sample - loss: 0.0182 - val_loss: 0.0175\n",
      "Epoch 20/50\n",
      "598/598 [==============================] - 0s 84us/sample - loss: 0.0183 - val_loss: 0.0177\n",
      "Epoch 21/50\n",
      "598/598 [==============================] - 0s 86us/sample - loss: 0.0182 - val_loss: 0.0175\n",
      "Epoch 22/50\n",
      "598/598 [==============================] - 0s 81us/sample - loss: 0.0183 - val_loss: 0.0178\n",
      "Epoch 23/50\n",
      "598/598 [==============================] - 0s 79us/sample - loss: 0.0182 - val_loss: 0.0176\n",
      "Epoch 24/50\n",
      "598/598 [==============================] - 0s 78us/sample - loss: 0.0183 - val_loss: 0.0178\n",
      "Epoch 25/50\n",
      "598/598 [==============================] - 0s 82us/sample - loss: 0.0182 - val_loss: 0.0176\n",
      "Epoch 26/50\n",
      "598/598 [==============================] - 0s 80us/sample - loss: 0.0183 - val_loss: 0.0177\n",
      "Epoch 27/50\n",
      "598/598 [==============================] - 0s 81us/sample - loss: 0.0182 - val_loss: 0.0175\n",
      "Epoch 28/50\n",
      "598/598 [==============================] - 0s 84us/sample - loss: 0.0183 - val_loss: 0.0178\n",
      "Epoch 29/50\n",
      "598/598 [==============================] - 0s 91us/sample - loss: 0.0182 - val_loss: 0.0176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "598/598 [==============================] - 0s 85us/sample - loss: 0.0183 - val_loss: 0.0180\n",
      "Epoch 31/50\n",
      "598/598 [==============================] - 0s 84us/sample - loss: 0.0182 - val_loss: 0.0177\n",
      "Epoch 32/50\n",
      "598/598 [==============================] - 0s 84us/sample - loss: 0.0183 - val_loss: 0.0180\n",
      "Epoch 33/50\n",
      "598/598 [==============================] - 0s 85us/sample - loss: 0.0182 - val_loss: 0.0178\n",
      "Epoch 34/50\n",
      "598/598 [==============================] - 0s 86us/sample - loss: 0.0182 - val_loss: 0.0180\n",
      "Epoch 35/50\n",
      "598/598 [==============================] - 0s 85us/sample - loss: 0.0182 - val_loss: 0.0177\n",
      "Epoch 36/50\n",
      "598/598 [==============================] - 0s 87us/sample - loss: 0.0182 - val_loss: 0.0180\n",
      "Epoch 37/50\n",
      "598/598 [==============================] - 0s 88us/sample - loss: 0.0182 - val_loss: 0.0177\n",
      "Epoch 38/50\n",
      "598/598 [==============================] - 0s 82us/sample - loss: 0.0182 - val_loss: 0.0180\n",
      "Epoch 39/50\n",
      "598/598 [==============================] - 0s 85us/sample - loss: 0.0182 - val_loss: 0.0177\n",
      "Epoch 40/50\n",
      "598/598 [==============================] - 0s 96us/sample - loss: 0.0182 - val_loss: 0.0179\n",
      "Epoch 41/50\n",
      "598/598 [==============================] - 0s 91us/sample - loss: 0.0181 - val_loss: 0.0177\n",
      "Epoch 42/50\n",
      "598/598 [==============================] - 0s 90us/sample - loss: 0.0182 - val_loss: 0.0181\n",
      "Epoch 43/50\n",
      "598/598 [==============================] - 0s 84us/sample - loss: 0.0181 - val_loss: 0.0179\n",
      "Epoch 44/50\n",
      "598/598 [==============================] - 0s 84us/sample - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 45/50\n",
      "598/598 [==============================] - 0s 85us/sample - loss: 0.0181 - val_loss: 0.0180\n",
      "Epoch 46/50\n",
      "598/598 [==============================] - 0s 85us/sample - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 47/50\n",
      "598/598 [==============================] - 0s 85us/sample - loss: 0.0181 - val_loss: 0.0180\n",
      "Epoch 48/50\n",
      "598/598 [==============================] - 0s 88us/sample - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 49/50\n",
      "598/598 [==============================] - 0s 82us/sample - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 50/50\n",
      "598/598 [==============================] - 0s 86us/sample - loss: 0.0182 - val_loss: 0.0184\n",
      "第279个数，还剩3844个没有训练\n",
      "inv_hat [0.81975749 0.79913184 0.8017026  0.80110915 0.77387744 0.77265043\n",
      " 0.77578616 0.78445219 0.76991896 0.77454067 0.7969583  0.80031804\n",
      " 0.79517937 0.78053662 0.78053662 0.77274477 0.77810154 0.77790774\n",
      " 0.78562916 0.76869716 0.76682063 0.76317305 0.75380168 0.75574092\n",
      " 0.75131582 0.75833431 0.75067271 0.74810615 0.74073569 0.74164112]\n",
      "Test RMSE: 0.010\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0076 - val_loss: 0.0121\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0092\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0076 - val_loss: 0.0092\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0073 - val_loss: 0.0091\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0070 - val_loss: 0.0095\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0069 - val_loss: 0.0095\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0069 - val_loss: 0.0093\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0070 - val_loss: 0.0102\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0068 - val_loss: 0.0097\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0073 - val_loss: 0.0105\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0078 - val_loss: 0.0096\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0107 - val_loss: 0.0124\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0113 - val_loss: 0.0115\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0077 - val_loss: 0.0097\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0071 - val_loss: 0.0101\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0075 - val_loss: 0.0097\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0090 - val_loss: 0.0128\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0086 - val_loss: 0.0116\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0071 - val_loss: 0.0098\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0078 - val_loss: 0.0091\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0085 - val_loss: 0.0094\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0077 - val_loss: 0.0090\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0083 - val_loss: 0.0102\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0093 - val_loss: 0.0138\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0074 - val_loss: 0.0096\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0069 - val_loss: 0.0091\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0087 - val_loss: 0.0097\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0074 - val_loss: 0.0092\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0080 - val_loss: 0.0090\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0073 - val_loss: 0.0093\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0081 - val_loss: 0.0091\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0070 - val_loss: 0.0094\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0074 - val_loss: 0.0099\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0073 - val_loss: 0.0104\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0091 - val_loss: 0.0130\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0080 - val_loss: 0.0095\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0073 - val_loss: 0.0088\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0085 - val_loss: 0.0094\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0084 - val_loss: 0.0106\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0083 - val_loss: 0.0096\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0084 - val_loss: 0.0106\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0084 - val_loss: 0.0094\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0081 - val_loss: 0.0102\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0082 - val_loss: 0.0095\n",
      "第280个数，还剩3843个没有训练\n",
      "inv_hat [1.04951739 1.0485859  1.04817203 1.04806854 1.04796504 1.04786156\n",
      " 1.04796504 1.04817203 1.04817203 1.0485859  1.04941387 1.04941387\n",
      " 1.04941387 1.04931047 1.04899993 1.0485859  1.04899993 1.04910344\n",
      " 1.04931047 1.0485859  1.04806854 1.04744776 1.04734428 1.04734428\n",
      " 1.04705724 1.04744776 1.02732401 1.02752676 1.02742537 1.0291513 ]\n",
      "Test RMSE: 0.004\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0138 - val_loss: 0.0103\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0137 - val_loss: 0.0126\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0155 - val_loss: 0.0139\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0129 - val_loss: 0.0102\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0142 - val_loss: 0.0095\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0153 - val_loss: 0.0172\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0139 - val_loss: 0.0095\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0134 - val_loss: 0.0123\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0143 - val_loss: 0.0117\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0132 - val_loss: 0.0095\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0147 - val_loss: 0.0154\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0131 - val_loss: 0.0096\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0134 - val_loss: 0.0097\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0140 - val_loss: 0.0142\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0143 - val_loss: 0.0110\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0125 - val_loss: 0.0098\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0131 - val_loss: 0.0097\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0146 - val_loss: 0.0147\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0128 - val_loss: 0.0096\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0136 - val_loss: 0.0097\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0143 - val_loss: 0.0150\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0142 - val_loss: 0.0105\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0126 - val_loss: 0.0098\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0130 - val_loss: 0.0099\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0145 - val_loss: 0.0144\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0128 - val_loss: 0.0096\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0136 - val_loss: 0.0096\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0143 - val_loss: 0.0149\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0139 - val_loss: 0.0101\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0126 - val_loss: 0.0097\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0130 - val_loss: 0.0102\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0145 - val_loss: 0.0137\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0126 - val_loss: 0.0097\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0136 - val_loss: 0.0095\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0144 - val_loss: 0.0152\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0127 - val_loss: 0.0097\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0110\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0143 - val_loss: 0.0126\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0126 - val_loss: 0.0098\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0132 - val_loss: 0.0094\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0146 - val_loss: 0.0151\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0095\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0133 - val_loss: 0.0096\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0137 - val_loss: 0.0135\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0142 - val_loss: 0.0111\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0098\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0131 - val_loss: 0.0097\n",
      "第281个数，还剩3842个没有训练\n",
      "inv_hat [0.71130118 0.69239285 0.69476054 0.6910069  0.67645601 0.67408066\n",
      " 0.6737838  0.68625534 0.6761591  0.6853644  0.70464467 0.70523194\n",
      " 0.7073854  0.69298683 0.69524973 0.6876412  0.69407563 0.69828319\n",
      " 0.70924531 0.69740246 0.69534761 0.68615632 0.67843555 0.6781386\n",
      " 0.66834084 0.67002307 0.66428388 0.65933716 0.65419356 0.65805118]\n",
      "Test RMSE: 0.009\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0119 - val_loss: 0.0125\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0077\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0069\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0068\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0067\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0109 - val_loss: 0.0068\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0109 - val_loss: 0.0066\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0109 - val_loss: 0.0065\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0109 - val_loss: 0.0064\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0109 - val_loss: 0.0064\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0109 - val_loss: 0.0064\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0063\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0109 - val_loss: 0.0062\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0109 - val_loss: 0.0063\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0109 - val_loss: 0.0061\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0109 - val_loss: 0.0062\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0109 - val_loss: 0.0060\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0109 - val_loss: 0.0062\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0109 - val_loss: 0.0059\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0109 - val_loss: 0.0061\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0109 - val_loss: 0.0059\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0109 - val_loss: 0.0061\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0109 - val_loss: 0.0058\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0109 - val_loss: 0.0060\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0109 - val_loss: 0.0058\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 72us/sample - loss: 0.0109 - val_loss: 0.0060\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 72us/sample - loss: 0.0109 - val_loss: 0.0056\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0110 - val_loss: 0.0059\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0058\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0059\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0109 - val_loss: 0.0056\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0109 - val_loss: 0.0058\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0109 - val_loss: 0.0056\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0058\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0055\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0056\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0056\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0058\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0057\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0056\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0109 - val_loss: 0.0058\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0057\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0056\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0056\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0109 - val_loss: 0.0056\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0110 - val_loss: 0.0056\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0109 - val_loss: 0.0056\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0110 - val_loss: 0.0058\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 72us/sample - loss: 0.0109 - val_loss: 0.0057\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 72us/sample - loss: 0.0109 - val_loss: 0.0056\n",
      "第282个数，还剩3841个没有训练\n",
      "inv_hat [0.88989637 0.87330574 0.87387498 0.86970294 0.85920482 0.8596769\n",
      " 0.8568458  0.8661046  0.85552563 0.86269985 0.88337885 0.88604535\n",
      " 0.88242711 0.86932395 0.86941865 0.86600995 0.87140898 0.87046103\n",
      " 0.88375966 0.87017669 0.85929921 0.85401767 0.83580117 0.833837\n",
      " 0.82655481 0.83299564 0.83271526 0.82758049 0.82143307 0.82143307]\n",
      "Test RMSE: 0.010\n",
      "Train on 1132 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1132/1132 [==============================] - 0s 73us/sample - loss: 0.0074 - val_loss: 0.0013\n",
      "Epoch 2/50\n",
      "1132/1132 [==============================] - 0s 74us/sample - loss: 0.0239 - val_loss: 0.0161\n",
      "Epoch 3/50\n",
      "1132/1132 [==============================] - 0s 73us/sample - loss: 0.0234 - val_loss: 0.0138\n",
      "Epoch 4/50\n",
      "1132/1132 [==============================] - 0s 75us/sample - loss: 0.0188 - val_loss: 6.6008e-04\n",
      "Epoch 5/50\n",
      "1132/1132 [==============================] - 0s 75us/sample - loss: 0.0339 - val_loss: 0.0057\n",
      "Epoch 6/50\n",
      "1132/1132 [==============================] - 0s 77us/sample - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 7/50\n",
      "1132/1132 [==============================] - 0s 78us/sample - loss: 0.0098 - val_loss: 7.6157e-04\n",
      "Epoch 8/50\n",
      "1132/1132 [==============================] - 0s 81us/sample - loss: 0.0220 - val_loss: 0.0020\n",
      "Epoch 9/50\n",
      "1132/1132 [==============================] - 0s 75us/sample - loss: 0.0079 - val_loss: 0.0024\n",
      "Epoch 10/50\n",
      "1132/1132 [==============================] - 0s 75us/sample - loss: 0.0184 - val_loss: 0.0010\n",
      "Epoch 11/50\n",
      "1132/1132 [==============================] - 0s 79us/sample - loss: 0.0106 - val_loss: 0.0063\n",
      "Epoch 12/50\n",
      "1132/1132 [==============================] - 0s 80us/sample - loss: 0.0199 - val_loss: 0.0040\n",
      "Epoch 13/50\n",
      "1132/1132 [==============================] - 0s 80us/sample - loss: 0.0242 - val_loss: 0.0277\n",
      "Epoch 14/50\n",
      "1132/1132 [==============================] - 0s 78us/sample - loss: 0.0150 - val_loss: 0.0026\n",
      "Epoch 15/50\n",
      "1132/1132 [==============================] - 0s 78us/sample - loss: 0.0147 - val_loss: 0.0111\n",
      "Epoch 16/50\n",
      "1132/1132 [==============================] - 0s 78us/sample - loss: 0.0198 - val_loss: 0.0138\n",
      "Epoch 17/50\n",
      "1132/1132 [==============================] - 0s 75us/sample - loss: 0.0116 - val_loss: 0.0065\n",
      "Epoch 18/50\n",
      "1132/1132 [==============================] - 0s 76us/sample - loss: 0.0153 - val_loss: 0.0077\n",
      "Epoch 19/50\n",
      "1132/1132 [==============================] - 0s 79us/sample - loss: 0.0081 - val_loss: 0.0013\n",
      "Epoch 20/50\n",
      "1132/1132 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0019\n",
      "Epoch 21/50\n",
      "1132/1132 [==============================] - 0s 76us/sample - loss: 0.0235 - val_loss: 0.0118\n",
      "Epoch 22/50\n",
      "1132/1132 [==============================] - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0046\n",
      "Epoch 23/50\n",
      "1132/1132 [==============================] - 0s 75us/sample - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 24/50\n",
      "1132/1132 [==============================] - 0s 77us/sample - loss: 0.0191 - val_loss: 0.0042\n",
      "Epoch 25/50\n",
      "1132/1132 [==============================] - 0s 82us/sample - loss: 0.0133 - val_loss: 0.0068\n",
      "Epoch 26/50\n",
      "1132/1132 [==============================] - 0s 77us/sample - loss: 0.0184 - val_loss: 0.0141\n",
      "Epoch 27/50\n",
      "1132/1132 [==============================] - 0s 78us/sample - loss: 0.0097 - val_loss: 0.0039\n",
      "Epoch 28/50\n",
      "1132/1132 [==============================] - 0s 78us/sample - loss: 0.0152 - val_loss: 0.0106\n",
      "Epoch 29/50\n",
      "1132/1132 [==============================] - 0s 78us/sample - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 30/50\n",
      "1132/1132 [==============================] - 0s 80us/sample - loss: 0.0056 - val_loss: 0.0034\n",
      "Epoch 31/50\n",
      "1132/1132 [==============================] - 0s 74us/sample - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 32/50\n",
      "1132/1132 [==============================] - 0s 76us/sample - loss: 0.0063 - val_loss: 0.0034\n",
      "Epoch 33/50\n",
      "1132/1132 [==============================] - 0s 83us/sample - loss: 0.0065 - val_loss: 0.0030\n",
      "Epoch 34/50\n",
      "1132/1132 [==============================] - 0s 83us/sample - loss: 0.0113 - val_loss: 0.0023\n",
      "Epoch 35/50\n",
      "1132/1132 [==============================] - 0s 75us/sample - loss: 0.0212 - val_loss: 0.0028\n",
      "Epoch 36/50\n",
      "1132/1132 [==============================] - 0s 74us/sample - loss: 0.0146 - val_loss: 0.0019\n",
      "Epoch 37/50\n",
      "1132/1132 [==============================] - 0s 77us/sample - loss: 0.0179 - val_loss: 0.0024\n",
      "Epoch 38/50\n",
      "1132/1132 [==============================] - 0s 77us/sample - loss: 0.0160 - val_loss: 0.0023\n",
      "Epoch 39/50\n",
      "1132/1132 [==============================] - 0s 77us/sample - loss: 0.0154 - val_loss: 0.0026\n",
      "Epoch 40/50\n",
      "1132/1132 [==============================] - 0s 75us/sample - loss: 0.0177 - val_loss: 0.0020\n",
      "Epoch 41/50\n",
      "1132/1132 [==============================] - 0s 77us/sample - loss: 0.0132 - val_loss: 0.0026\n",
      "Epoch 42/50\n",
      "1132/1132 [==============================] - 0s 78us/sample - loss: 0.0189 - val_loss: 0.0020\n",
      "Epoch 43/50\n",
      "1132/1132 [==============================] - 0s 78us/sample - loss: 0.0115 - val_loss: 0.0023\n",
      "Epoch 44/50\n",
      "1132/1132 [==============================] - 0s 80us/sample - loss: 0.0196 - val_loss: 0.0024\n",
      "Epoch 45/50\n",
      "1132/1132 [==============================] - 0s 76us/sample - loss: 0.0103 - val_loss: 0.0019\n",
      "Epoch 46/50\n",
      "1132/1132 [==============================] - 0s 75us/sample - loss: 0.0199 - val_loss: 0.0023\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132/1132 [==============================] - 0s 74us/sample - loss: 0.0081 - val_loss: 0.0029\n",
      "Epoch 48/50\n",
      "1132/1132 [==============================] - 0s 75us/sample - loss: 0.0162 - val_loss: 0.0031\n",
      "Epoch 49/50\n",
      "1132/1132 [==============================] - 0s 77us/sample - loss: 0.0103 - val_loss: 0.0024\n",
      "Epoch 50/50\n",
      "1132/1132 [==============================] - 0s 76us/sample - loss: 0.0105 - val_loss: 0.0011\n",
      "第283个数，还剩3840个没有训练\n",
      "inv_hat [0.85176198 0.85176198 0.85176198 0.85176198 0.85176198 0.85176198\n",
      " 0.85176198 0.85176198 0.85176198 0.85176198 0.8527375  0.8527375\n",
      " 0.85371366 0.85441599 0.8527375  0.85371366 0.85371366 0.85371366\n",
      " 0.85371366 0.8527375  0.8527375  0.8527375  0.8527375  0.85371366\n",
      " 0.85371366 0.85371366 0.85371366 0.85371366 0.85469045 0.85469045]\n",
      "Test RMSE: 0.001\n",
      "Train on 823 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "823/823 [==============================] - 0s 81us/sample - loss: 0.0115 - val_loss: 0.0151\n",
      "Epoch 2/50\n",
      "823/823 [==============================] - 0s 78us/sample - loss: 0.0080 - val_loss: 0.0137\n",
      "Epoch 3/50\n",
      "823/823 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0136\n",
      "Epoch 4/50\n",
      "823/823 [==============================] - 0s 83us/sample - loss: 0.0070 - val_loss: 0.0140\n",
      "Epoch 5/50\n",
      "823/823 [==============================] - 0s 83us/sample - loss: 0.0062 - val_loss: 0.0136\n",
      "Epoch 6/50\n",
      "823/823 [==============================] - 0s 82us/sample - loss: 0.0061 - val_loss: 0.0132\n",
      "Epoch 7/50\n",
      "823/823 [==============================] - 0s 77us/sample - loss: 0.0062 - val_loss: 0.0131\n",
      "Epoch 8/50\n",
      "823/823 [==============================] - 0s 80us/sample - loss: 0.0059 - val_loss: 0.0130\n",
      "Epoch 9/50\n",
      "823/823 [==============================] - 0s 83us/sample - loss: 0.0058 - val_loss: 0.0132\n",
      "Epoch 10/50\n",
      "823/823 [==============================] - 0s 81us/sample - loss: 0.0058 - val_loss: 0.0131\n",
      "Epoch 11/50\n",
      "823/823 [==============================] - 0s 81us/sample - loss: 0.0059 - val_loss: 0.0132\n",
      "Epoch 12/50\n",
      "823/823 [==============================] - 0s 82us/sample - loss: 0.0058 - val_loss: 0.0131\n",
      "Epoch 13/50\n",
      "823/823 [==============================] - 0s 75us/sample - loss: 0.0058 - val_loss: 0.0132\n",
      "Epoch 14/50\n",
      "823/823 [==============================] - 0s 81us/sample - loss: 0.0058 - val_loss: 0.0131\n",
      "Epoch 15/50\n",
      "823/823 [==============================] - 0s 79us/sample - loss: 0.0059 - val_loss: 0.0132\n",
      "Epoch 16/50\n",
      "823/823 [==============================] - 0s 79us/sample - loss: 0.0058 - val_loss: 0.0131\n",
      "Epoch 17/50\n",
      "823/823 [==============================] - 0s 83us/sample - loss: 0.0059 - val_loss: 0.0132\n",
      "Epoch 18/50\n",
      "823/823 [==============================] - 0s 83us/sample - loss: 0.0058 - val_loss: 0.0131\n",
      "Epoch 19/50\n",
      "823/823 [==============================] - 0s 84us/sample - loss: 0.0059 - val_loss: 0.0132\n",
      "Epoch 20/50\n",
      "823/823 [==============================] - 0s 83us/sample - loss: 0.0058 - val_loss: 0.0131\n",
      "Epoch 21/50\n",
      "823/823 [==============================] - 0s 81us/sample - loss: 0.0059 - val_loss: 0.0131\n",
      "Epoch 22/50\n",
      "823/823 [==============================] - 0s 79us/sample - loss: 0.0058 - val_loss: 0.0131\n",
      "Epoch 23/50\n",
      "823/823 [==============================] - 0s 82us/sample - loss: 0.0059 - val_loss: 0.0131\n",
      "Epoch 24/50\n",
      "823/823 [==============================] - 0s 81us/sample - loss: 0.0059 - val_loss: 0.0131\n",
      "Epoch 25/50\n",
      "823/823 [==============================] - 0s 82us/sample - loss: 0.0059 - val_loss: 0.0130\n",
      "Epoch 26/50\n",
      "823/823 [==============================] - 0s 78us/sample - loss: 0.0058 - val_loss: 0.0131\n",
      "Epoch 27/50\n",
      "823/823 [==============================] - 0s 80us/sample - loss: 0.0059 - val_loss: 0.0131\n",
      "Epoch 28/50\n",
      "823/823 [==============================] - 0s 81us/sample - loss: 0.0060 - val_loss: 0.0131\n",
      "Epoch 29/50\n",
      "823/823 [==============================] - 0s 83us/sample - loss: 0.0058 - val_loss: 0.0131\n",
      "Epoch 30/50\n",
      "823/823 [==============================] - 0s 84us/sample - loss: 0.0059 - val_loss: 0.0131\n",
      "Epoch 31/50\n",
      "823/823 [==============================] - 0s 80us/sample - loss: 0.0059 - val_loss: 0.0131\n",
      "Epoch 32/50\n",
      "823/823 [==============================] - 0s 85us/sample - loss: 0.0060 - val_loss: 0.0131\n",
      "Epoch 33/50\n",
      "823/823 [==============================] - 0s 83us/sample - loss: 0.0062 - val_loss: 0.0131\n",
      "Epoch 34/50\n",
      "823/823 [==============================] - 0s 81us/sample - loss: 0.0059 - val_loss: 0.0133\n",
      "Epoch 35/50\n",
      "823/823 [==============================] - 0s 83us/sample - loss: 0.0058 - val_loss: 0.0130\n",
      "Epoch 36/50\n",
      "823/823 [==============================] - 0s 90us/sample - loss: 0.0059 - val_loss: 0.0132\n",
      "Epoch 37/50\n",
      "823/823 [==============================] - 0s 83us/sample - loss: 0.0058 - val_loss: 0.0131\n",
      "Epoch 38/50\n",
      "823/823 [==============================] - 0s 80us/sample - loss: 0.0059 - val_loss: 0.0131\n",
      "Epoch 39/50\n",
      "823/823 [==============================] - 0s 79us/sample - loss: 0.0059 - val_loss: 0.0132\n",
      "Epoch 40/50\n",
      "823/823 [==============================] - 0s 80us/sample - loss: 0.0060 - val_loss: 0.0130\n",
      "Epoch 41/50\n",
      "823/823 [==============================] - 0s 83us/sample - loss: 0.0061 - val_loss: 0.0131\n",
      "Epoch 42/50\n",
      "823/823 [==============================] - 0s 82us/sample - loss: 0.0059 - val_loss: 0.0130\n",
      "Epoch 43/50\n",
      "823/823 [==============================] - 0s 83us/sample - loss: 0.0059 - val_loss: 0.0131\n",
      "Epoch 44/50\n",
      "823/823 [==============================] - 0s 83us/sample - loss: 0.0060 - val_loss: 0.0131\n",
      "Epoch 45/50\n",
      "823/823 [==============================] - 0s 86us/sample - loss: 0.0061 - val_loss: 0.0131\n",
      "Epoch 46/50\n",
      "823/823 [==============================] - 0s 85us/sample - loss: 0.0059 - val_loss: 0.0133\n",
      "Epoch 47/50\n",
      "823/823 [==============================] - 0s 81us/sample - loss: 0.0058 - val_loss: 0.0131\n",
      "Epoch 48/50\n",
      "823/823 [==============================] - 0s 84us/sample - loss: 0.0059 - val_loss: 0.0132\n",
      "Epoch 49/50\n",
      "823/823 [==============================] - 0s 81us/sample - loss: 0.0058 - val_loss: 0.0131\n",
      "Epoch 50/50\n",
      "823/823 [==============================] - 0s 78us/sample - loss: 0.0059 - val_loss: 0.0133\n",
      "第284个数，还剩3839个没有训练\n",
      "inv_hat [1.01601503 1.01621485 1.01631475 1.01651441 1.01661429 1.01711348\n",
      " 1.01721332 1.01741298 1.0175128  1.01771243 1.01811154 1.01831113\n",
      " 1.0184109  1.01861033 1.01871009 1.01920881 1.01930842 1.01950786\n",
      " 1.01960758 1.01980698 1.00057166 1.00076452 1.00086109 1.0010546\n",
      " 1.00115254 1.00164386 1.00174238 1.00193953 1.00203806 1.00223546]\n",
      "Test RMSE: 0.004\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0133 - val_loss: 0.0123\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0133 - val_loss: 0.0126\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0133 - val_loss: 0.0123\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0133 - val_loss: 0.0125\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0132 - val_loss: 0.0125\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0133 - val_loss: 0.0125\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0132 - val_loss: 0.0125\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0132 - val_loss: 0.0128\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0132 - val_loss: 0.0127\n",
      "第285个数，还剩3838个没有训练\n",
      "inv_hat [1.60491746 1.5845692  1.59493902 1.58755967 1.57151741 1.5320047\n",
      " 1.55229626 1.57350987 1.53558379 1.5419485  1.57699614 1.58257584\n",
      " 1.5664359  1.54055603 1.55150003 1.53528552 1.5449327  1.54811652\n",
      " 1.55737306 1.51938453 1.50796448 1.50091737 1.47696668 1.48334471\n",
      " 1.47557151 1.49645221 1.49010343 1.48384297 1.46799778 1.46620412]\n",
      "Test RMSE: 0.020\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0132 - val_loss: 0.0072\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0133 - val_loss: 0.0070\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0132 - val_loss: 0.0070\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0132 - val_loss: 0.0070\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0131 - val_loss: 0.0070\n",
      "第286个数，还剩3837个没有训练\n",
      "inv_hat [0.93677638 0.91532819 0.91983748 0.92043879 0.89349856 0.88919565\n",
      " 0.89720193 0.90350887 0.88769489 0.89439936 0.91883534 0.92304474\n",
      " 0.91743239 0.89930398 0.90090574 0.90020499 0.90851609 0.90551163\n",
      " 0.91442643 0.89850314 0.89850314 0.89520003 0.88639441 0.88919565\n",
      " 0.88209354 0.89299821 0.88709468 0.8880951  0.8798936  0.88609432]\n",
      "Test RMSE: 0.011\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0085 - val_loss: 0.0039\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0081 - val_loss: 0.0048\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0080 - val_loss: 0.0047\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0080 - val_loss: 0.0047\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0079 - val_loss: 0.0047\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0080 - val_loss: 0.0047\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0079 - val_loss: 0.0048\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0079 - val_loss: 0.0048\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0080 - val_loss: 0.0049\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0079 - val_loss: 0.0049\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0080 - val_loss: 0.0048\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0080 - val_loss: 0.0048\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0080 - val_loss: 0.0048\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0080 - val_loss: 0.0048\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0079 - val_loss: 0.0047\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0079 - val_loss: 0.0046\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0080 - val_loss: 0.0043\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0080 - val_loss: 0.0046\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0080 - val_loss: 0.0043\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0080 - val_loss: 0.0043\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0080 - val_loss: 0.0044\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0080 - val_loss: 0.0043\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0080 - val_loss: 0.0043\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0080 - val_loss: 0.0043\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0080 - val_loss: 0.0041\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0080 - val_loss: 0.0042\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0081 - val_loss: 0.0039\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0043\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0081 - val_loss: 0.0040\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0042\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0082 - val_loss: 0.0039\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0040\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0082 - val_loss: 0.0038\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0083 - val_loss: 0.0038\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0083 - val_loss: 0.0037\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0084 - val_loss: 0.0037\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0084 - val_loss: 0.0036\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0084 - val_loss: 0.0036\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0083 - val_loss: 0.0036\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0083 - val_loss: 0.0036\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0081 - val_loss: 0.0037\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0081 - val_loss: 0.0037\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0080 - val_loss: 0.0039\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0079 - val_loss: 0.0040\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0079 - val_loss: 0.0040\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0079 - val_loss: 0.0040\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0079 - val_loss: 0.0041\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0079 - val_loss: 0.0041\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0078 - val_loss: 0.0040\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0079 - val_loss: 0.0042\n",
      "第287个数，还剩3836个没有训练\n",
      "inv_hat [0.88102436 0.8619789  0.86490543 0.86314938 0.84892367 0.8448373\n",
      " 0.84289238 0.85427894 0.84386477 0.85311014 0.89463341 0.89433938\n",
      " 0.89316347 0.87085993 0.86978578 0.86500293 0.87085993 0.87349728\n",
      " 0.88493783 0.87271574 0.86295426 0.85661719 0.84114245 0.83871283\n",
      " 0.83288558 0.83880994 0.83890715 0.83337099 0.82842187 0.83162378]\n",
      "Test RMSE: 0.012\n",
      "Train on 881 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "881/881 [==============================] - 0s 88us/sample - loss: 0.0084 - val_loss: 0.0089\n",
      "Epoch 2/50\n",
      "881/881 [==============================] - 0s 80us/sample - loss: 0.0079 - val_loss: 0.0094\n",
      "Epoch 3/50\n",
      "881/881 [==============================] - 0s 82us/sample - loss: 0.0080 - val_loss: 0.0090\n",
      "Epoch 4/50\n",
      "881/881 [==============================] - 0s 83us/sample - loss: 0.0083 - val_loss: 0.0095\n",
      "Epoch 5/50\n",
      "881/881 [==============================] - 0s 86us/sample - loss: 0.0109 - val_loss: 0.0207\n",
      "Epoch 6/50\n",
      "881/881 [==============================] - 0s 86us/sample - loss: 0.0152 - val_loss: 0.0118\n",
      "Epoch 7/50\n",
      "881/881 [==============================] - 0s 83us/sample - loss: 0.0116 - val_loss: 0.0130\n",
      "Epoch 8/50\n",
      "881/881 [==============================] - 0s 82us/sample - loss: 0.0203 - val_loss: 0.0200\n",
      "Epoch 9/50\n",
      "881/881 [==============================] - 0s 84us/sample - loss: 0.0119 - val_loss: 0.0142\n",
      "Epoch 10/50\n",
      "881/881 [==============================] - 0s 84us/sample - loss: 0.0098 - val_loss: 0.0087\n",
      "Epoch 11/50\n",
      "881/881 [==============================] - 0s 83us/sample - loss: 0.0184 - val_loss: 0.0130\n",
      "Epoch 12/50\n",
      "881/881 [==============================] - 0s 84us/sample - loss: 0.0085 - val_loss: 0.0143\n",
      "Epoch 13/50\n",
      "881/881 [==============================] - 0s 82us/sample - loss: 0.0189 - val_loss: 0.0085\n",
      "Epoch 14/50\n",
      "881/881 [==============================] - 0s 78us/sample - loss: 0.0078 - val_loss: 0.0091\n",
      "Epoch 15/50\n",
      "881/881 [==============================] - 0s 81us/sample - loss: 0.0128 - val_loss: 0.0107\n",
      "Epoch 16/50\n",
      "881/881 [==============================] - 0s 81us/sample - loss: 0.0093 - val_loss: 0.0145\n",
      "Epoch 17/50\n",
      "881/881 [==============================] - 0s 83us/sample - loss: 0.0147 - val_loss: 0.0085\n",
      "Epoch 18/50\n",
      "881/881 [==============================] - 0s 87us/sample - loss: 0.0097 - val_loss: 0.0086\n",
      "Epoch 19/50\n",
      "881/881 [==============================] - 0s 83us/sample - loss: 0.0087 - val_loss: 0.0119\n",
      "Epoch 20/50\n",
      "881/881 [==============================] - 0s 81us/sample - loss: 0.0154 - val_loss: 0.0088\n",
      "Epoch 21/50\n",
      "881/881 [==============================] - 0s 78us/sample - loss: 0.0085 - val_loss: 0.0088\n",
      "Epoch 22/50\n",
      "881/881 [==============================] - 0s 84us/sample - loss: 0.0164 - val_loss: 0.0154\n",
      "Epoch 23/50\n",
      "881/881 [==============================] - 0s 84us/sample - loss: 0.0077 - val_loss: 0.0127\n",
      "Epoch 24/50\n",
      "881/881 [==============================] - 0s 81us/sample - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 25/50\n",
      "881/881 [==============================] - 0s 80us/sample - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 26/50\n",
      "881/881 [==============================] - 0s 86us/sample - loss: 0.0102 - val_loss: 0.0144\n",
      "Epoch 27/50\n",
      "881/881 [==============================] - 0s 91us/sample - loss: 0.0146 - val_loss: 0.0086\n",
      "Epoch 28/50\n",
      "881/881 [==============================] - 0s 79us/sample - loss: 0.0077 - val_loss: 0.0093\n",
      "Epoch 29/50\n",
      "881/881 [==============================] - 0s 81us/sample - loss: 0.0115 - val_loss: 0.0123\n",
      "Epoch 30/50\n",
      "881/881 [==============================] - 0s 87us/sample - loss: 0.0083 - val_loss: 0.0129\n",
      "Epoch 31/50\n",
      "881/881 [==============================] - 0s 79us/sample - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 32/50\n",
      "881/881 [==============================] - 0s 81us/sample - loss: 0.0105 - val_loss: 0.0091\n",
      "Epoch 33/50\n",
      "881/881 [==============================] - 0s 82us/sample - loss: 0.0084 - val_loss: 0.0134\n",
      "Epoch 34/50\n",
      "881/881 [==============================] - 0s 80us/sample - loss: 0.0144 - val_loss: 0.0084\n",
      "Epoch 35/50\n",
      "881/881 [==============================] - 0s 81us/sample - loss: 0.0081 - val_loss: 0.0091\n",
      "Epoch 36/50\n",
      "881/881 [==============================] - 0s 81us/sample - loss: 0.0093 - val_loss: 0.0118\n",
      "Epoch 37/50\n",
      "881/881 [==============================] - 0s 81us/sample - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 38/50\n",
      "881/881 [==============================] - 0s 83us/sample - loss: 0.0089 - val_loss: 0.0093\n",
      "Epoch 39/50\n",
      "881/881 [==============================] - 0s 86us/sample - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 40/50\n",
      "881/881 [==============================] - 0s 82us/sample - loss: 0.0078 - val_loss: 0.0123\n",
      "Epoch 41/50\n",
      "881/881 [==============================] - 0s 86us/sample - loss: 0.0136 - val_loss: 0.0086\n",
      "Epoch 42/50\n",
      "881/881 [==============================] - 0s 84us/sample - loss: 0.0081 - val_loss: 0.0091\n",
      "Epoch 43/50\n",
      "881/881 [==============================] - 0s 77us/sample - loss: 0.0093 - val_loss: 0.0126\n",
      "Epoch 44/50\n",
      "881/881 [==============================] - 0s 82us/sample - loss: 0.0106 - val_loss: 0.0099\n",
      "Epoch 45/50\n",
      "881/881 [==============================] - 0s 86us/sample - loss: 0.0077 - val_loss: 0.0092\n",
      "Epoch 46/50\n",
      "881/881 [==============================] - 0s 85us/sample - loss: 0.0123 - val_loss: 0.0126\n",
      "Epoch 47/50\n",
      "881/881 [==============================] - 0s 89us/sample - loss: 0.0081 - val_loss: 0.0122\n",
      "Epoch 48/50\n",
      "881/881 [==============================] - 0s 87us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 49/50\n",
      "881/881 [==============================] - 0s 85us/sample - loss: 0.0087 - val_loss: 0.0093\n",
      "Epoch 50/50\n",
      "881/881 [==============================] - 0s 84us/sample - loss: 0.0075 - val_loss: 0.0117\n",
      "第288个数，还剩3835个没有训练\n",
      "inv_hat [1.25115727 1.2444175  1.24538256 1.2444175  1.2386131  1.236673\n",
      " 1.23764345 1.24055067 1.23764345 1.24055067 1.2492353  1.25019672\n",
      " 1.2492353  1.24345189 1.24370236 1.24176545 1.24370236 1.2446699\n",
      " 1.24853274 1.24370236 1.24176545 1.23788361 1.23593892 1.23496572\n",
      " 1.2339918  1.23691163 1.23593892 1.2339918  1.2330173  1.2339918 ]\n",
      "Test RMSE: 0.004\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0112 - val_loss: 0.0073\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0111 - val_loss: 0.0076\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0076\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0075\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0110 - val_loss: 0.0075\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0075\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0075\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0075\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0110 - val_loss: 0.0075\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0073\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0075\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0073\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0110 - val_loss: 0.0075\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0073\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0073\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0110 - val_loss: 0.0075\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0075\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0073\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0073\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0110 - val_loss: 0.0073\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0075\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0110 - val_loss: 0.0073\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0110 - val_loss: 0.0073\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0073\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0073\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0073\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0075\n",
      "第289个数，还剩3834个没有训练\n",
      "inv_hat [0.98674705 0.96896108 0.97275728 0.97025957 0.95857423 0.95807489\n",
      " 0.95457992 0.96636408 0.95747573 0.96736294 0.98874594 0.99374344\n",
      " 0.99284379 0.97515528 0.97885236 0.97275728 0.97535509 0.98155041\n",
      " 0.99544273 0.98135054 0.98025136 0.97385634 0.96077123 0.9556783\n",
      " 0.94469556 0.94719141 0.94569386 0.94140121 0.94100193 0.95148459]\n",
      "Test RMSE: 0.009\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0093\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0094\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0096\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0111 - val_loss: 0.0096\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0115 - val_loss: 0.0098\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0096\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0115 - val_loss: 0.0102\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0096\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0098\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0102\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0102\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0101\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0101\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0106\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0110 - val_loss: 0.0106\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0111 - val_loss: 0.0101\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0103\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0106\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0102\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0103\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0106\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0110 - val_loss: 0.0103\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0103\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0110 - val_loss: 0.0106\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0111 - val_loss: 0.0101\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0110 - val_loss: 0.0106\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0102\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0104\n",
      "第290个数，还剩3833个没有训练\n",
      "inv_hat [1.65869736 1.6193547  1.61994031 1.61164352 1.57755874 1.57032723\n",
      " 1.57267271 1.59738854 1.56671079 1.58205329 1.62277051 1.64062645\n",
      " 1.63496792 1.60041577 1.6046144  1.59738854 1.60568824 1.61154585\n",
      " 1.6267716  1.59104033 1.58810998 1.57374785 1.555272   1.55879212\n",
      " 1.54676327 1.54715452 1.53149938 1.52484296 1.51984949 1.53365256]\n",
      "Test RMSE: 0.021\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0081\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0113 - val_loss: 0.0083\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0112 - val_loss: 0.0084\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0112 - val_loss: 0.0079\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0079\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0112 - val_loss: 0.0086\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0116 - val_loss: 0.0097\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0111 - val_loss: 0.0081\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0081\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0115 - val_loss: 0.0097\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0113 - val_loss: 0.0085\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0078\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0112 - val_loss: 0.0088\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0115 - val_loss: 0.0093\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0080\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0082\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0116 - val_loss: 0.0099\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0080\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0112 - val_loss: 0.0079\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0083\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0079\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0112 - val_loss: 0.0089\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0079\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0084\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0115 - val_loss: 0.0094\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0081\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0081\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0092\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0114 - val_loss: 0.0085\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0110 - val_loss: 0.0079\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0112 - val_loss: 0.0086\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0114 - val_loss: 0.0093\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0080\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0082\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0094\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0082\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0081\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0113 - val_loss: 0.0090\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0081\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0084\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0114 - val_loss: 0.0093\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0082\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0081\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0112 - val_loss: 0.0090\n",
      "第291个数，还剩3832个没有训练\n",
      "inv_hat [1.10145092 1.0816699  1.0856273  1.08364875 1.06682452 1.06187412\n",
      " 1.05791306 1.07375354 1.06286433 1.0688045  1.09551814 1.09848466\n",
      " 1.10046221 1.08068053 1.0727638  1.06187412 1.06979434 1.06781453\n",
      " 1.07672243 1.05791306 1.04800748 1.04305307 1.02917492 1.03611505\n",
      " 1.03115805 1.04701661 1.04602587 1.04007993 1.03809763 1.04007993]\n",
      "Test RMSE: 0.012\n",
      "Train on 671 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "671/671 [==============================] - 0s 87us/sample - loss: 0.0146 - val_loss: 0.0060\n",
      "Epoch 2/50\n",
      "671/671 [==============================] - 0s 89us/sample - loss: 0.0153 - val_loss: 0.0055\n",
      "Epoch 3/50\n",
      "671/671 [==============================] - 0s 83us/sample - loss: 0.0147 - val_loss: 0.0072\n",
      "Epoch 4/50\n",
      "671/671 [==============================] - 0s 86us/sample - loss: 0.0145 - val_loss: 0.0057\n",
      "Epoch 5/50\n",
      "671/671 [==============================] - 0s 84us/sample - loss: 0.0142 - val_loss: 0.0055\n",
      "Epoch 6/50\n",
      "671/671 [==============================] - 0s 87us/sample - loss: 0.0143 - val_loss: 0.0062\n",
      "Epoch 7/50\n",
      "671/671 [==============================] - 0s 81us/sample - loss: 0.0145 - val_loss: 0.0077\n",
      "Epoch 8/50\n",
      "671/671 [==============================] - 0s 79us/sample - loss: 0.0146 - val_loss: 0.0054\n",
      "Epoch 9/50\n",
      "671/671 [==============================] - 0s 82us/sample - loss: 0.0145 - val_loss: 0.0055\n",
      "Epoch 10/50\n",
      "671/671 [==============================] - 0s 82us/sample - loss: 0.0145 - val_loss: 0.0058\n",
      "Epoch 11/50\n",
      "671/671 [==============================] - 0s 80us/sample - loss: 0.0150 - val_loss: 0.0073\n",
      "Epoch 12/50\n",
      "671/671 [==============================] - 0s 83us/sample - loss: 0.0150 - val_loss: 0.0084\n",
      "Epoch 13/50\n",
      "671/671 [==============================] - 0s 80us/sample - loss: 0.0162 - val_loss: 0.0053\n",
      "Epoch 14/50\n",
      "671/671 [==============================] - 0s 79us/sample - loss: 0.0161 - val_loss: 0.0110\n",
      "Epoch 15/50\n",
      "671/671 [==============================] - 0s 79us/sample - loss: 0.0161 - val_loss: 0.0068\n",
      "Epoch 16/50\n",
      "671/671 [==============================] - 0s 78us/sample - loss: 0.0164 - val_loss: 0.0093\n",
      "Epoch 17/50\n",
      "671/671 [==============================] - 0s 82us/sample - loss: 0.0164 - val_loss: 0.0066\n",
      "Epoch 18/50\n",
      "671/671 [==============================] - 0s 79us/sample - loss: 0.0156 - val_loss: 0.0087\n",
      "Epoch 19/50\n",
      "671/671 [==============================] - 0s 79us/sample - loss: 0.0155 - val_loss: 0.0085\n",
      "Epoch 20/50\n",
      "671/671 [==============================] - 0s 80us/sample - loss: 0.0160 - val_loss: 0.0079\n",
      "Epoch 21/50\n",
      "671/671 [==============================] - 0s 82us/sample - loss: 0.0154 - val_loss: 0.0057\n",
      "Epoch 22/50\n",
      "671/671 [==============================] - 0s 82us/sample - loss: 0.0149 - val_loss: 0.0064\n",
      "Epoch 23/50\n",
      "671/671 [==============================] - 0s 80us/sample - loss: 0.0144 - val_loss: 0.0063\n",
      "Epoch 24/50\n",
      "671/671 [==============================] - 0s 81us/sample - loss: 0.0144 - val_loss: 0.0052\n",
      "Epoch 25/50\n",
      "671/671 [==============================] - 0s 81us/sample - loss: 0.0141 - val_loss: 0.0054\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671/671 [==============================] - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0054\n",
      "Epoch 27/50\n",
      "671/671 [==============================] - 0s 80us/sample - loss: 0.0140 - val_loss: 0.0053\n",
      "Epoch 28/50\n",
      "671/671 [==============================] - 0s 87us/sample - loss: 0.0143 - val_loss: 0.0064\n",
      "Epoch 29/50\n",
      "671/671 [==============================] - 0s 80us/sample - loss: 0.0144 - val_loss: 0.0052\n",
      "Epoch 30/50\n",
      "671/671 [==============================] - 0s 80us/sample - loss: 0.0143 - val_loss: 0.0067\n",
      "Epoch 31/50\n",
      "671/671 [==============================] - 0s 80us/sample - loss: 0.0146 - val_loss: 0.0079\n",
      "Epoch 32/50\n",
      "671/671 [==============================] - 0s 79us/sample - loss: 0.0148 - val_loss: 0.0079\n",
      "Epoch 33/50\n",
      "671/671 [==============================] - 0s 76us/sample - loss: 0.0154 - val_loss: 0.0053\n",
      "Epoch 34/50\n",
      "671/671 [==============================] - 0s 77us/sample - loss: 0.0149 - val_loss: 0.0060\n",
      "Epoch 35/50\n",
      "671/671 [==============================] - 0s 80us/sample - loss: 0.0141 - val_loss: 0.0061\n",
      "Epoch 36/50\n",
      "671/671 [==============================] - 0s 77us/sample - loss: 0.0140 - val_loss: 0.0055\n",
      "Epoch 37/50\n",
      "671/671 [==============================] - 0s 81us/sample - loss: 0.0138 - val_loss: 0.0055\n",
      "Epoch 38/50\n",
      "671/671 [==============================] - 0s 82us/sample - loss: 0.0138 - val_loss: 0.0056\n",
      "Epoch 39/50\n",
      "671/671 [==============================] - 0s 77us/sample - loss: 0.0139 - val_loss: 0.0055\n",
      "Epoch 40/50\n",
      "671/671 [==============================] - 0s 79us/sample - loss: 0.0138 - val_loss: 0.0052\n",
      "Epoch 41/50\n",
      "671/671 [==============================] - 0s 79us/sample - loss: 0.0138 - val_loss: 0.0053\n",
      "Epoch 42/50\n",
      "671/671 [==============================] - 0s 81us/sample - loss: 0.0139 - val_loss: 0.0054\n",
      "Epoch 43/50\n",
      "671/671 [==============================] - 0s 80us/sample - loss: 0.0141 - val_loss: 0.0055\n",
      "Epoch 44/50\n",
      "671/671 [==============================] - 0s 81us/sample - loss: 0.0141 - val_loss: 0.0058\n",
      "Epoch 45/50\n",
      "671/671 [==============================] - 0s 85us/sample - loss: 0.0141 - val_loss: 0.0054\n",
      "Epoch 46/50\n",
      "671/671 [==============================] - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0057\n",
      "Epoch 47/50\n",
      "671/671 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0053\n",
      "Epoch 48/50\n",
      "671/671 [==============================] - 0s 80us/sample - loss: 0.0142 - val_loss: 0.0055\n",
      "Epoch 49/50\n",
      "671/671 [==============================] - 0s 89us/sample - loss: 0.0142 - val_loss: 0.0053\n",
      "Epoch 50/50\n",
      "671/671 [==============================] - 0s 85us/sample - loss: 0.0143 - val_loss: 0.0063\n",
      "第292个数，还剩3831个没有训练\n",
      "inv_hat [1.011981   1.011981   1.011981   1.011981   1.011981   1.0129741\n",
      " 1.0129741  1.0129741  1.0129741  1.0129741  1.0129741  1.0129741\n",
      " 1.0129741  1.0139684  1.0139684  1.0139684  1.0139684  1.0139684\n",
      " 1.0139684  1.0139684  1.01496147 1.01496147 1.01496147 1.01496147\n",
      " 1.01496147 1.01496147 1.01496147 1.01496147 1.01496147 1.01496147]\n",
      "Test RMSE: 0.000\n",
      "Train on 507 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "507/507 [==============================] - 0s 87us/sample - loss: 0.0218 - val_loss: 0.0227\n",
      "Epoch 2/50\n",
      "507/507 [==============================] - 0s 91us/sample - loss: 0.0222 - val_loss: 0.0224\n",
      "Epoch 3/50\n",
      "507/507 [==============================] - 0s 98us/sample - loss: 0.0219 - val_loss: 0.0238\n",
      "Epoch 4/50\n",
      "507/507 [==============================] - 0s 91us/sample - loss: 0.0219 - val_loss: 0.0238\n",
      "Epoch 5/50\n",
      "507/507 [==============================] - 0s 94us/sample - loss: 0.0218 - val_loss: 0.0245\n",
      "Epoch 6/50\n",
      "507/507 [==============================] - 0s 88us/sample - loss: 0.0219 - val_loss: 0.0243\n",
      "Epoch 7/50\n",
      "507/507 [==============================] - 0s 89us/sample - loss: 0.0218 - val_loss: 0.0247\n",
      "Epoch 8/50\n",
      "507/507 [==============================] - 0s 87us/sample - loss: 0.0218 - val_loss: 0.0245\n",
      "Epoch 9/50\n",
      "507/507 [==============================] - 0s 86us/sample - loss: 0.0219 - val_loss: 0.0251\n",
      "Epoch 10/50\n",
      "507/507 [==============================] - 0s 92us/sample - loss: 0.0219 - val_loss: 0.0248\n",
      "Epoch 11/50\n",
      "507/507 [==============================] - 0s 85us/sample - loss: 0.0218 - val_loss: 0.0253\n",
      "Epoch 12/50\n",
      "507/507 [==============================] - 0s 86us/sample - loss: 0.0219 - val_loss: 0.0250\n",
      "Epoch 13/50\n",
      "507/507 [==============================] - 0s 89us/sample - loss: 0.0219 - val_loss: 0.0256\n",
      "Epoch 14/50\n",
      "507/507 [==============================] - 0s 93us/sample - loss: 0.0219 - val_loss: 0.0253\n",
      "Epoch 15/50\n",
      "507/507 [==============================] - 0s 93us/sample - loss: 0.0219 - val_loss: 0.0258\n",
      "Epoch 16/50\n",
      "507/507 [==============================] - 0s 85us/sample - loss: 0.0219 - val_loss: 0.0255\n",
      "Epoch 17/50\n",
      "507/507 [==============================] - 0s 87us/sample - loss: 0.0219 - val_loss: 0.0261\n",
      "Epoch 18/50\n",
      "507/507 [==============================] - 0s 84us/sample - loss: 0.0220 - val_loss: 0.0256\n",
      "Epoch 19/50\n",
      "507/507 [==============================] - 0s 84us/sample - loss: 0.0219 - val_loss: 0.0263\n",
      "Epoch 20/50\n",
      "507/507 [==============================] - 0s 83us/sample - loss: 0.0220 - val_loss: 0.0257\n",
      "Epoch 21/50\n",
      "507/507 [==============================] - 0s 88us/sample - loss: 0.0219 - val_loss: 0.0263\n",
      "Epoch 22/50\n",
      "507/507 [==============================] - 0s 87us/sample - loss: 0.0220 - val_loss: 0.0259\n",
      "Epoch 23/50\n",
      "507/507 [==============================] - 0s 83us/sample - loss: 0.0219 - val_loss: 0.0265\n",
      "Epoch 24/50\n",
      "507/507 [==============================] - 0s 84us/sample - loss: 0.0220 - val_loss: 0.0259\n",
      "Epoch 25/50\n",
      "507/507 [==============================] - 0s 87us/sample - loss: 0.0220 - val_loss: 0.0266\n",
      "Epoch 26/50\n",
      "507/507 [==============================] - 0s 85us/sample - loss: 0.0220 - val_loss: 0.0261\n",
      "Epoch 27/50\n",
      "507/507 [==============================] - 0s 87us/sample - loss: 0.0220 - val_loss: 0.0267\n",
      "Epoch 28/50\n",
      "507/507 [==============================] - 0s 87us/sample - loss: 0.0220 - val_loss: 0.0262\n",
      "Epoch 29/50\n",
      "507/507 [==============================] - 0s 95us/sample - loss: 0.0220 - val_loss: 0.0268\n",
      "Epoch 30/50\n",
      "507/507 [==============================] - 0s 96us/sample - loss: 0.0220 - val_loss: 0.0263\n",
      "Epoch 31/50\n",
      "507/507 [==============================] - 0s 93us/sample - loss: 0.0220 - val_loss: 0.0269\n",
      "Epoch 32/50\n",
      "507/507 [==============================] - 0s 90us/sample - loss: 0.0220 - val_loss: 0.0264\n",
      "Epoch 33/50\n",
      "507/507 [==============================] - 0s 95us/sample - loss: 0.0220 - val_loss: 0.0271\n",
      "Epoch 34/50\n",
      "507/507 [==============================] - 0s 87us/sample - loss: 0.0220 - val_loss: 0.0264\n",
      "Epoch 35/50\n",
      "507/507 [==============================] - 0s 86us/sample - loss: 0.0220 - val_loss: 0.0270\n",
      "Epoch 36/50\n",
      "507/507 [==============================] - 0s 88us/sample - loss: 0.0220 - val_loss: 0.0264\n",
      "Epoch 37/50\n",
      "507/507 [==============================] - 0s 94us/sample - loss: 0.0220 - val_loss: 0.0270\n",
      "Epoch 38/50\n",
      "507/507 [==============================] - 0s 86us/sample - loss: 0.0220 - val_loss: 0.0263\n",
      "Epoch 39/50\n",
      "507/507 [==============================] - 0s 90us/sample - loss: 0.0220 - val_loss: 0.0270\n",
      "Epoch 40/50\n",
      "507/507 [==============================] - 0s 87us/sample - loss: 0.0220 - val_loss: 0.0263\n",
      "Epoch 41/50\n",
      "507/507 [==============================] - 0s 85us/sample - loss: 0.0220 - val_loss: 0.0269\n",
      "Epoch 42/50\n",
      "507/507 [==============================] - 0s 90us/sample - loss: 0.0220 - val_loss: 0.0264\n",
      "Epoch 43/50\n",
      "507/507 [==============================] - 0s 88us/sample - loss: 0.0219 - val_loss: 0.0268\n",
      "Epoch 44/50\n",
      "507/507 [==============================] - 0s 87us/sample - loss: 0.0219 - val_loss: 0.0263\n",
      "Epoch 45/50\n",
      "507/507 [==============================] - 0s 85us/sample - loss: 0.0219 - val_loss: 0.0270\n",
      "Epoch 46/50\n",
      "507/507 [==============================] - 0s 86us/sample - loss: 0.0220 - val_loss: 0.0261\n",
      "Epoch 47/50\n",
      "507/507 [==============================] - 0s 86us/sample - loss: 0.0221 - val_loss: 0.0269\n",
      "Epoch 48/50\n",
      "507/507 [==============================] - 0s 87us/sample - loss: 0.0220 - val_loss: 0.0263\n",
      "Epoch 49/50\n",
      "507/507 [==============================] - 0s 86us/sample - loss: 0.0218 - val_loss: 0.0266\n",
      "Epoch 50/50\n",
      "507/507 [==============================] - 0s 91us/sample - loss: 0.0219 - val_loss: 0.0262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第293个数，还剩3830个没有训练\n",
      "inv_hat [0.86005723 0.84837408 0.85129538 0.85226909 0.83172429 0.82975636\n",
      " 0.83369263 0.84057089 0.83172429 0.83860982 0.85519001 0.86005723\n",
      " 0.85811053 0.84837408 0.84740021 0.84057089 0.84447866 0.84253014\n",
      " 0.84837408 0.83664588 0.83369263 0.83074029 0.82385655 0.82385655\n",
      " 0.81894463 0.82483941 0.81992664 0.81796283 0.81125976 0.81403788]\n",
      "Test RMSE: 0.009\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0053\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0086 - val_loss: 0.0032\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0084 - val_loss: 0.0029\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0075 - val_loss: 0.0033\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0073 - val_loss: 0.0043\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0071 - val_loss: 0.0049\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0072 - val_loss: 0.0048\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0069 - val_loss: 0.0034\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0069 - val_loss: 0.0053\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0069 - val_loss: 0.0031\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0074 - val_loss: 0.0047\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0093 - val_loss: 0.0042\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0134 - val_loss: 0.0160\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0111 - val_loss: 0.0094\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0079 - val_loss: 0.0035\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0078 - val_loss: 0.0032\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0070 - val_loss: 0.0038\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0073 - val_loss: 0.0052\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0083 - val_loss: 0.0041\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0120 - val_loss: 0.0137\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0103 - val_loss: 0.0078\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0077 - val_loss: 0.0029\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0088 - val_loss: 0.0032\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0084 - val_loss: 0.0035\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0079 - val_loss: 0.0041\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0072 - val_loss: 0.0036\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0068 - val_loss: 0.0027\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0067 - val_loss: 0.0028\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0071 - val_loss: 0.0064\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0069 - val_loss: 0.0031\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0074 - val_loss: 0.0051\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0073 - val_loss: 0.0029\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0091 - val_loss: 0.0030\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0090 - val_loss: 0.0056\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0068 - val_loss: 0.0039\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0082 - val_loss: 0.0060\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0082 - val_loss: 0.0044\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0070 - val_loss: 0.0035\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0072 - val_loss: 0.0031\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0078 - val_loss: 0.0049\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0075 - val_loss: 0.0035\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0073 - val_loss: 0.0031\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0070 - val_loss: 0.0030\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0070 - val_loss: 0.0032\n",
      "第294个数，还剩3829个没有训练\n",
      "inv_hat [1.1151268  1.1151268  1.1151268  1.11614378 1.1151268  1.11614378\n",
      " 1.11614378 1.11614378 1.11614378 1.11614378 1.11716046 1.11716046\n",
      " 1.11716046 1.11716046 1.11817707 1.11817707 1.11817707 1.11919328\n",
      " 1.11919328 1.11882965 1.11716046 1.11817707 1.11817707 1.11817707\n",
      " 1.11919328 1.1202093  1.1202093  1.1202093  1.1202093  1.12122499]\n",
      "Test RMSE: 0.001\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0116 - val_loss: 0.0169\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0128 - val_loss: 0.0174\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0112 - val_loss: 0.0169\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0110 - val_loss: 0.0166\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0108 - val_loss: 0.0167\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0130 - val_loss: 0.0188\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0166\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0108 - val_loss: 0.0167\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0165\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0116 - val_loss: 0.0170\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0169\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0110 - val_loss: 0.0167\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0125 - val_loss: 0.0173\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0116 - val_loss: 0.0171\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0174\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0115 - val_loss: 0.0165\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0113 - val_loss: 0.0166\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0133 - val_loss: 0.0187\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0108 - val_loss: 0.0166\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0106 - val_loss: 0.0181\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0114 - val_loss: 0.0166\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0120 - val_loss: 0.0166\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0126 - val_loss: 0.0193\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0113 - val_loss: 0.0165\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0107 - val_loss: 0.0166\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0126 - val_loss: 0.0178\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0108 - val_loss: 0.0166\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0107 - val_loss: 0.0166\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0107 - val_loss: 0.0165\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0167\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0121 - val_loss: 0.0165\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0166\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0107 - val_loss: 0.0173\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0106 - val_loss: 0.0166\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0106 - val_loss: 0.0166\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0117 - val_loss: 0.0165\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0121 - val_loss: 0.0185\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0114 - val_loss: 0.0166\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0108 - val_loss: 0.0166\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0169\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0111 - val_loss: 0.0167\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0108 - val_loss: 0.0167\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0109 - val_loss: 0.0168\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0118 - val_loss: 0.0165\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0111 - val_loss: 0.0167\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0107 - val_loss: 0.0165\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0106 - val_loss: 0.0166\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0104 - val_loss: 0.0166\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0105 - val_loss: 0.0172\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0105 - val_loss: 0.0176\n",
      "第295个数，还剩3828个没有训练\n",
      "inv_hat [1.04824281 1.04425042 1.04425042 1.04325338 1.04026513 1.04126078\n",
      " 1.0422569  1.04425042 1.0422569  1.04325338 1.0472441  1.0472441\n",
      " 1.04824281 1.04624572 1.04624572 1.04524779 1.04524779 1.0472441\n",
      " 1.04924209 1.0472441  1.04624572 1.04325338 1.04126078 1.03827549\n",
      " 1.03528551 1.03528551 1.03329422 1.03229612 1.03229612 1.0342896 ]\n",
      "Test RMSE: 0.002\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0118 - val_loss: 0.0078\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0117 - val_loss: 0.0078\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0118 - val_loss: 0.0077\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0079\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0119 - val_loss: 0.0078\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0078\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0120 - val_loss: 0.0078\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0120 - val_loss: 0.0078\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0078\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0078\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0123 - val_loss: 0.0078\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0123 - val_loss: 0.0079\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0126 - val_loss: 0.0082\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0125 - val_loss: 0.0082\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0078\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0121 - val_loss: 0.0079\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0121 - val_loss: 0.0079\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0080\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0080\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0080\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0121 - val_loss: 0.0081\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0121 - val_loss: 0.0081\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0121 - val_loss: 0.0081\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0120 - val_loss: 0.0080\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0119 - val_loss: 0.0079\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0119 - val_loss: 0.0080\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0119 - val_loss: 0.0079\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0119 - val_loss: 0.0079\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0119 - val_loss: 0.0080\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0119 - val_loss: 0.0080\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0118 - val_loss: 0.0079\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0118 - val_loss: 0.0078\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0118 - val_loss: 0.0078\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0079\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0118 - val_loss: 0.0079\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0078\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0118 - val_loss: 0.0078\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0118 - val_loss: 0.0078\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0118 - val_loss: 0.0078\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0118 - val_loss: 0.0079\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0079\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0078\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0118 - val_loss: 0.0078\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0118 - val_loss: 0.0078\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0079\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0119 - val_loss: 0.0079\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0119 - val_loss: 0.0079\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0118 - val_loss: 0.0078\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0078\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0118 - val_loss: 0.0078\n",
      "第296个数，还剩3827个没有训练\n",
      "inv_hat [0.88283792 0.85842194 0.86143909 0.85988149 0.83266089 0.83044457\n",
      " 0.83246806 0.84531845 0.82842262 0.83738859 0.86445931 0.86611679\n",
      " 0.8633873  0.84289843 0.8429952  0.8316007  0.8379681  0.83941726\n",
      " 0.85103792 0.83227532 0.82832634 0.8218859  0.81019975 0.81106003\n",
      " 0.80180436 0.80742987 0.80113778 0.79666703 0.78898197 0.79135119]\n",
      "Test RMSE: 0.012\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0129 - val_loss: 0.0088\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0124 - val_loss: 0.0087\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0124 - val_loss: 0.0089\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0126 - val_loss: 0.0108\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0123 - val_loss: 0.0090\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0090\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0124 - val_loss: 0.0102\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0091\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0121 - val_loss: 0.0090\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0123 - val_loss: 0.0101\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0122 - val_loss: 0.0090\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0092\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0123 - val_loss: 0.0100\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0121 - val_loss: 0.0090\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0095\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0123 - val_loss: 0.0099\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0121 - val_loss: 0.0091\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0096\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0123 - val_loss: 0.0100\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0121 - val_loss: 0.0089\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0123 - val_loss: 0.0100\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0121 - val_loss: 0.0090\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0123 - val_loss: 0.0098\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0121 - val_loss: 0.0090\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0123 - val_loss: 0.0098\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0121 - val_loss: 0.0091\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0123 - val_loss: 0.0099\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0121 - val_loss: 0.0090\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0099\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0121 - val_loss: 0.0090\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0099\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0123 - val_loss: 0.0099\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0121 - val_loss: 0.0091\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0099\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0123 - val_loss: 0.0099\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0121 - val_loss: 0.0092\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0121 - val_loss: 0.0096\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0123 - val_loss: 0.0101\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0121 - val_loss: 0.0093\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0121 - val_loss: 0.0096\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0123 - val_loss: 0.0101\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0121 - val_loss: 0.0098\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0121 - val_loss: 0.0092\n",
      "第297个数，还剩3826个没有训练\n",
      "inv_hat [1.08266134 1.06796336 1.07286292 1.06796336 1.05130115 1.05032072\n",
      " 1.04934037 1.05718278 1.04934037 1.05718278 1.07776218 1.08168161\n",
      " 1.0787421  1.05718278 1.05032072 1.04541825 1.05130115 1.05326177\n",
      " 1.06404349 1.04934037 1.04541825 1.0375723  1.02776065 1.02285284\n",
      " 1.01303079 1.01892541 1.01892541 1.01597837 1.01106542 1.01401343]\n",
      "Test RMSE: 0.009\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0082 - val_loss: 0.0017\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0090 - val_loss: 0.0068\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0099 - val_loss: 0.0091\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0103 - val_loss: 0.0068\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0092 - val_loss: 0.0019\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0083 - val_loss: 0.0017\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0087 - val_loss: 0.0058\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0093 - val_loss: 0.0072\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0093 - val_loss: 0.0039\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0086 - val_loss: 0.0033\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0087 - val_loss: 0.0033\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0085 - val_loss: 0.0044\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0086 - val_loss: 0.0038\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0086 - val_loss: 0.0042\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0085 - val_loss: 0.0028\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0082 - val_loss: 0.0022\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0081 - val_loss: 0.0015\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0081 - val_loss: 0.0017\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0081 - val_loss: 0.0019\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0081 - val_loss: 0.0017\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0081 - val_loss: 0.0018\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0081 - val_loss: 0.0028\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0086 - val_loss: 0.0041\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0086 - val_loss: 0.0047\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0087 - val_loss: 0.0042\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0086 - val_loss: 0.0040\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0086 - val_loss: 0.0039\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0084 - val_loss: 0.0020\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0082 - val_loss: 0.0020\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0081 - val_loss: 0.0020\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0081 - val_loss: 0.0023\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0082 - val_loss: 0.0025\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0022\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0082 - val_loss: 0.0027\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0083 - val_loss: 0.0026\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0081 - val_loss: 0.0020\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0080 - val_loss: 8.7234e-04\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0019\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0080 - val_loss: 0.0017\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0028\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0084 - val_loss: 0.0037\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0083 - val_loss: 0.0025\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0082 - val_loss: 0.0025\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0084 - val_loss: 0.0039\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0085 - val_loss: 0.0036\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0085 - val_loss: 0.0031\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0084 - val_loss: 0.0038\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0083 - val_loss: 0.0023\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0080 - val_loss: 0.0012\n",
      "第298个数，还剩3825个没有训练\n",
      "inv_hat [1.11183754 1.11183754 1.11183754 1.11183754 1.11183754 1.11183754\n",
      " 1.11183754 1.11183754 1.11183754 1.11283487 1.11283487 1.11283487\n",
      " 1.11283487 1.11283487 1.11283487 1.11283487 1.11283487 1.11283487\n",
      " 1.11383221 1.11283487 1.11283487 1.11183754 1.11183754 1.11084036\n",
      " 1.11084036 1.11084036 1.11183754 1.11183754 1.11084036 1.11183754]\n",
      "Test RMSE: 0.001\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0085\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0124 - val_loss: 0.0108\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0120 - val_loss: 0.0083\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0121 - val_loss: 0.0091\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0120 - val_loss: 0.0092\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0120 - val_loss: 0.0088\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0120 - val_loss: 0.0090\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0120 - val_loss: 0.0090\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0120 - val_loss: 0.0089\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0120 - val_loss: 0.0090\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0120 - val_loss: 0.0090\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0120 - val_loss: 0.0090\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0120 - val_loss: 0.0090\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0120 - val_loss: 0.0090\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0120 - val_loss: 0.0090\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0120 - val_loss: 0.0090\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0120 - val_loss: 0.0092\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0120 - val_loss: 0.0090\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0120 - val_loss: 0.0090\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0120 - val_loss: 0.0092\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0120 - val_loss: 0.0092\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0120 - val_loss: 0.0092\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0120 - val_loss: 0.0092\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0120 - val_loss: 0.0092\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0120 - val_loss: 0.0090\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0121 - val_loss: 0.0093\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0120 - val_loss: 0.0092\n",
      "第299个数，还剩3824个没有训练\n",
      "inv_hat [0.84154683 0.81524619 0.81662989 0.81307184 0.78629844 0.78353321\n",
      " 0.78363198 0.79410136 0.77938572 0.78886634 0.81544383 0.81485083\n",
      " 0.81435664 0.79449649 0.79489162 0.78945894 0.79834915 0.78886634\n",
      " 0.80101664 0.78086694 0.76931484 0.76595844 0.75219786 0.75180136\n",
      " 0.74307827 0.75418067 0.75299098 0.74476327 0.73534806 0.73544711]\n",
      "Test RMSE: 0.013\n",
      "Train on 826 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "826/826 [==============================] - 0s 82us/sample - loss: 0.0225 - val_loss: 0.0157\n",
      "Epoch 2/50\n",
      "826/826 [==============================] - 0s 81us/sample - loss: 0.0219 - val_loss: 0.0149\n",
      "Epoch 3/50\n",
      "826/826 [==============================] - 0s 81us/sample - loss: 0.0226 - val_loss: 0.0157\n",
      "Epoch 4/50\n",
      "826/826 [==============================] - 0s 80us/sample - loss: 0.0237 - val_loss: 0.0165\n",
      "Epoch 5/50\n",
      "826/826 [==============================] - 0s 81us/sample - loss: 0.0223 - val_loss: 0.0204\n",
      "Epoch 6/50\n",
      "826/826 [==============================] - 0s 78us/sample - loss: 0.0232 - val_loss: 0.0151\n",
      "Epoch 7/50\n",
      "826/826 [==============================] - 0s 79us/sample - loss: 0.0221 - val_loss: 0.0157\n",
      "Epoch 8/50\n",
      "826/826 [==============================] - 0s 79us/sample - loss: 0.0246 - val_loss: 0.0154\n",
      "Epoch 9/50\n",
      "826/826 [==============================] - 0s 82us/sample - loss: 0.0226 - val_loss: 0.0209\n",
      "Epoch 10/50\n",
      "826/826 [==============================] - 0s 78us/sample - loss: 0.0237 - val_loss: 0.0154\n",
      "Epoch 11/50\n",
      "826/826 [==============================] - 0s 78us/sample - loss: 0.0225 - val_loss: 0.0162\n",
      "Epoch 12/50\n",
      "826/826 [==============================] - 0s 80us/sample - loss: 0.0249 - val_loss: 0.0158\n",
      "Epoch 13/50\n",
      "826/826 [==============================] - 0s 78us/sample - loss: 0.0226 - val_loss: 0.0189\n",
      "Epoch 14/50\n",
      "826/826 [==============================] - 0s 82us/sample - loss: 0.0225 - val_loss: 0.0155\n",
      "Epoch 15/50\n",
      "826/826 [==============================] - 0s 85us/sample - loss: 0.0222 - val_loss: 0.0149\n",
      "Epoch 16/50\n",
      "826/826 [==============================] - 0s 82us/sample - loss: 0.0233 - val_loss: 0.0155\n",
      "Epoch 17/50\n",
      "826/826 [==============================] - 0s 83us/sample - loss: 0.0223 - val_loss: 0.0176\n",
      "Epoch 18/50\n",
      "826/826 [==============================] - 0s 84us/sample - loss: 0.0221 - val_loss: 0.0151\n",
      "Epoch 19/50\n",
      "826/826 [==============================] - 0s 83us/sample - loss: 0.0220 - val_loss: 0.0149\n",
      "Epoch 20/50\n",
      "826/826 [==============================] - 0s 80us/sample - loss: 0.0224 - val_loss: 0.0155\n",
      "Epoch 21/50\n",
      "826/826 [==============================] - 0s 78us/sample - loss: 0.0221 - val_loss: 0.0166\n",
      "Epoch 22/50\n",
      "826/826 [==============================] - 0s 78us/sample - loss: 0.0219 - val_loss: 0.0156\n",
      "Epoch 23/50\n",
      "826/826 [==============================] - 0s 81us/sample - loss: 0.0219 - val_loss: 0.0149\n",
      "Epoch 24/50\n",
      "826/826 [==============================] - 0s 81us/sample - loss: 0.0222 - val_loss: 0.0155\n",
      "Epoch 25/50\n",
      "826/826 [==============================] - 0s 86us/sample - loss: 0.0220 - val_loss: 0.0160\n",
      "Epoch 26/50\n",
      "826/826 [==============================] - 0s 84us/sample - loss: 0.0219 - val_loss: 0.0158\n",
      "Epoch 27/50\n",
      "826/826 [==============================] - 0s 84us/sample - loss: 0.0219 - val_loss: 0.0151\n",
      "Epoch 28/50\n",
      "826/826 [==============================] - 0s 80us/sample - loss: 0.0220 - val_loss: 0.0149\n",
      "Epoch 29/50\n",
      "826/826 [==============================] - 0s 82us/sample - loss: 0.0222 - val_loss: 0.0157\n",
      "Epoch 30/50\n",
      "826/826 [==============================] - 0s 81us/sample - loss: 0.0220 - val_loss: 0.0162\n",
      "Epoch 31/50\n",
      "826/826 [==============================] - 0s 80us/sample - loss: 0.0219 - val_loss: 0.0152\n",
      "Epoch 32/50\n",
      "826/826 [==============================] - 0s 80us/sample - loss: 0.0220 - val_loss: 0.0149\n",
      "Epoch 33/50\n",
      "826/826 [==============================] - 0s 79us/sample - loss: 0.0223 - val_loss: 0.0155\n",
      "Epoch 34/50\n",
      "826/826 [==============================] - 0s 83us/sample - loss: 0.0221 - val_loss: 0.0168\n",
      "Epoch 35/50\n",
      "826/826 [==============================] - 0s 82us/sample - loss: 0.0219 - val_loss: 0.0155\n",
      "Epoch 36/50\n",
      "826/826 [==============================] - 0s 81us/sample - loss: 0.0219 - val_loss: 0.0149\n",
      "Epoch 37/50\n",
      "826/826 [==============================] - 0s 77us/sample - loss: 0.0223 - val_loss: 0.0155\n",
      "Epoch 38/50\n",
      "826/826 [==============================] - 0s 80us/sample - loss: 0.0221 - val_loss: 0.0167\n",
      "Epoch 39/50\n",
      "826/826 [==============================] - 0s 80us/sample - loss: 0.0219 - val_loss: 0.0156\n",
      "Epoch 40/50\n",
      "826/826 [==============================] - 0s 80us/sample - loss: 0.0219 - val_loss: 0.0149\n",
      "Epoch 41/50\n",
      "826/826 [==============================] - 0s 83us/sample - loss: 0.0222 - val_loss: 0.0152\n",
      "Epoch 42/50\n",
      "826/826 [==============================] - 0s 85us/sample - loss: 0.0220 - val_loss: 0.0161\n",
      "Epoch 43/50\n",
      "826/826 [==============================] - 0s 89us/sample - loss: 0.0219 - val_loss: 0.0160\n",
      "Epoch 44/50\n",
      "826/826 [==============================] - 0s 84us/sample - loss: 0.0219 - val_loss: 0.0150\n",
      "Epoch 45/50\n",
      "826/826 [==============================] - 0s 87us/sample - loss: 0.0221 - val_loss: 0.0151\n",
      "Epoch 46/50\n",
      "826/826 [==============================] - 0s 79us/sample - loss: 0.0221 - val_loss: 0.0163\n",
      "Epoch 47/50\n",
      "826/826 [==============================] - 0s 78us/sample - loss: 0.0219 - val_loss: 0.0159\n",
      "Epoch 48/50\n",
      "826/826 [==============================] - 0s 80us/sample - loss: 0.0219 - val_loss: 0.0149\n",
      "Epoch 49/50\n",
      "826/826 [==============================] - 0s 77us/sample - loss: 0.0222 - val_loss: 0.0151\n",
      "Epoch 50/50\n",
      "826/826 [==============================] - 0s 79us/sample - loss: 0.0220 - val_loss: 0.0160\n",
      "第300个数，还剩3823个没有训练\n",
      "inv_hat [1.08641031 1.08061365 1.07881325 1.07781263 1.03835713 1.03926306\n",
      " 1.05072995 1.06027287 1.04439488 1.051333   1.076812   1.07160494\n",
      " 1.06248082 1.05374487 1.0540463  1.03795456 1.0427851  1.04157774\n",
      " 1.05384542 1.0331216  1.03614242 1.02748092 1.0140771  1.00681864\n",
      " 0.9934116  1.00530644 0.99976182 0.9907914  0.98444389 0.9906906 ]\n",
      "Test RMSE: 0.013\n",
      "Train on 963 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "963/963 [==============================] - 0s 80us/sample - loss: 0.0103 - val_loss: 0.0168\n",
      "Epoch 2/50\n",
      "963/963 [==============================] - 0s 79us/sample - loss: 0.0094 - val_loss: 0.0169\n",
      "Epoch 3/50\n",
      "963/963 [==============================] - 0s 77us/sample - loss: 0.0094 - val_loss: 0.0169\n",
      "Epoch 4/50\n",
      "963/963 [==============================] - 0s 77us/sample - loss: 0.0093 - val_loss: 0.0170\n",
      "Epoch 5/50\n",
      "963/963 [==============================] - 0s 78us/sample - loss: 0.0093 - val_loss: 0.0172\n",
      "Epoch 6/50\n",
      "963/963 [==============================] - 0s 78us/sample - loss: 0.0092 - val_loss: 0.0173\n",
      "Epoch 7/50\n",
      "963/963 [==============================] - 0s 78us/sample - loss: 0.0093 - val_loss: 0.0172\n",
      "Epoch 8/50\n",
      "963/963 [==============================] - 0s 77us/sample - loss: 0.0090 - val_loss: 0.0170\n",
      "Epoch 9/50\n",
      "963/963 [==============================] - 0s 83us/sample - loss: 0.0092 - val_loss: 0.0172\n",
      "Epoch 10/50\n",
      "963/963 [==============================] - 0s 84us/sample - loss: 0.0091 - val_loss: 0.0166\n",
      "Epoch 11/50\n",
      "963/963 [==============================] - 0s 82us/sample - loss: 0.0087 - val_loss: 0.0170\n",
      "Epoch 12/50\n",
      "963/963 [==============================] - 0s 78us/sample - loss: 0.0092 - val_loss: 0.0177\n",
      "Epoch 13/50\n",
      "963/963 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0176\n",
      "Epoch 14/50\n",
      "963/963 [==============================] - 0s 83us/sample - loss: 0.0094 - val_loss: 0.0171\n",
      "Epoch 15/50\n",
      "963/963 [==============================] - 0s 80us/sample - loss: 0.0094 - val_loss: 0.0178\n",
      "Epoch 16/50\n",
      "963/963 [==============================] - 0s 85us/sample - loss: 0.0097 - val_loss: 0.0169\n",
      "Epoch 17/50\n",
      "963/963 [==============================] - 0s 80us/sample - loss: 0.0101 - val_loss: 0.0173\n",
      "Epoch 18/50\n",
      "963/963 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0170\n",
      "Epoch 19/50\n",
      "963/963 [==============================] - 0s 85us/sample - loss: 0.0096 - val_loss: 0.0175\n",
      "Epoch 20/50\n",
      "963/963 [==============================] - 0s 84us/sample - loss: 0.0093 - val_loss: 0.0176\n",
      "Epoch 21/50\n",
      "963/963 [==============================] - 0s 84us/sample - loss: 0.0101 - val_loss: 0.0174\n",
      "Epoch 22/50\n",
      "963/963 [==============================] - 0s 86us/sample - loss: 0.0093 - val_loss: 0.0170\n",
      "Epoch 23/50\n",
      "963/963 [==============================] - 0s 85us/sample - loss: 0.0089 - val_loss: 0.0172\n",
      "Epoch 24/50\n",
      "963/963 [==============================] - 0s 81us/sample - loss: 0.0089 - val_loss: 0.0165\n",
      "Epoch 25/50\n",
      "963/963 [==============================] - 0s 83us/sample - loss: 0.0088 - val_loss: 0.0167\n",
      "Epoch 26/50\n",
      "963/963 [==============================] - 0s 82us/sample - loss: 0.0087 - val_loss: 0.0165\n",
      "Epoch 27/50\n",
      "963/963 [==============================] - 0s 80us/sample - loss: 0.0086 - val_loss: 0.0165\n",
      "Epoch 28/50\n",
      "963/963 [==============================] - 0s 77us/sample - loss: 0.0088 - val_loss: 0.0165\n",
      "Epoch 29/50\n",
      "963/963 [==============================] - 0s 80us/sample - loss: 0.0088 - val_loss: 0.0168\n",
      "Epoch 30/50\n",
      "963/963 [==============================] - 0s 76us/sample - loss: 0.0089 - val_loss: 0.0167\n",
      "Epoch 31/50\n",
      "963/963 [==============================] - 0s 76us/sample - loss: 0.0086 - val_loss: 0.0165\n",
      "Epoch 32/50\n",
      "963/963 [==============================] - 0s 76us/sample - loss: 0.0086 - val_loss: 0.0165\n",
      "Epoch 33/50\n",
      "963/963 [==============================] - 0s 77us/sample - loss: 0.0089 - val_loss: 0.0173\n",
      "Epoch 34/50\n",
      "963/963 [==============================] - 0s 84us/sample - loss: 0.0092 - val_loss: 0.0169\n",
      "Epoch 35/50\n",
      "963/963 [==============================] - 0s 83us/sample - loss: 0.0088 - val_loss: 0.0167\n",
      "Epoch 36/50\n",
      "963/963 [==============================] - 0s 78us/sample - loss: 0.0089 - val_loss: 0.0168\n",
      "Epoch 37/50\n",
      "963/963 [==============================] - 0s 80us/sample - loss: 0.0090 - val_loss: 0.0168\n",
      "Epoch 38/50\n",
      "963/963 [==============================] - 0s 78us/sample - loss: 0.0087 - val_loss: 0.0165\n",
      "Epoch 39/50\n",
      "963/963 [==============================] - 0s 77us/sample - loss: 0.0087 - val_loss: 0.0172\n",
      "Epoch 40/50\n",
      "963/963 [==============================] - 0s 79us/sample - loss: 0.0088 - val_loss: 0.0166\n",
      "Epoch 41/50\n",
      "963/963 [==============================] - 0s 81us/sample - loss: 0.0086 - val_loss: 0.0164\n",
      "Epoch 42/50\n",
      "963/963 [==============================] - 0s 80us/sample - loss: 0.0087 - val_loss: 0.0167\n",
      "Epoch 43/50\n",
      "963/963 [==============================] - 0s 81us/sample - loss: 0.0088 - val_loss: 0.0169\n",
      "Epoch 44/50\n",
      "963/963 [==============================] - 0s 84us/sample - loss: 0.0090 - val_loss: 0.0169\n",
      "Epoch 45/50\n",
      "963/963 [==============================] - 0s 82us/sample - loss: 0.0094 - val_loss: 0.0176\n",
      "Epoch 46/50\n",
      "963/963 [==============================] - 0s 81us/sample - loss: 0.0094 - val_loss: 0.0168\n",
      "Epoch 47/50\n",
      "963/963 [==============================] - 0s 78us/sample - loss: 0.0089 - val_loss: 0.0170\n",
      "Epoch 48/50\n",
      "963/963 [==============================] - 0s 80us/sample - loss: 0.0090 - val_loss: 0.0169\n",
      "Epoch 49/50\n",
      "963/963 [==============================] - 0s 83us/sample - loss: 0.0089 - val_loss: 0.0171\n",
      "Epoch 50/50\n",
      "963/963 [==============================] - 0s 79us/sample - loss: 0.0090 - val_loss: 0.0167\n",
      "第301个数，还剩3822个没有训练\n",
      "inv_hat [1.01606952 1.01606952 1.01606952 1.01606952 1.01707329 1.01707329\n",
      " 1.01707329 1.01707329 1.01707329 1.01707329 1.00000682 1.00000682\n",
      " 1.00100255 1.00100255 1.00100255 1.00100255 1.00100255 1.00100255\n",
      " 1.00200165 1.00200165 1.00200165 1.00200165 1.00200165 1.00200165\n",
      " 1.00300379 1.00300379 1.00300379 1.00300379 1.00300379 1.00300379]\n",
      "Test RMSE: 0.003\n",
      "Train on 1147 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1147/1147 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0045\n",
      "Epoch 2/50\n",
      "1147/1147 [==============================] - 0s 76us/sample - loss: 0.0074 - val_loss: 0.0040\n",
      "Epoch 3/50\n",
      "1147/1147 [==============================] - 0s 79us/sample - loss: 0.0167 - val_loss: 0.0289\n",
      "Epoch 4/50\n",
      "1147/1147 [==============================] - 0s 75us/sample - loss: 0.0152 - val_loss: 0.0042\n",
      "Epoch 5/50\n",
      "1147/1147 [==============================] - 0s 76us/sample - loss: 0.0230 - val_loss: 0.0111\n",
      "Epoch 6/50\n",
      "1147/1147 [==============================] - 0s 74us/sample - loss: 0.0177 - val_loss: 0.0041\n",
      "Epoch 7/50\n",
      "1147/1147 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0247\n",
      "Epoch 8/50\n",
      "1147/1147 [==============================] - 0s 79us/sample - loss: 0.0164 - val_loss: 0.0050\n",
      "Epoch 9/50\n",
      "1147/1147 [==============================] - 0s 80us/sample - loss: 0.0164 - val_loss: 0.0183\n",
      "Epoch 10/50\n",
      "1147/1147 [==============================] - 0s 76us/sample - loss: 0.0191 - val_loss: 0.0040\n",
      "Epoch 11/50\n",
      "1147/1147 [==============================] - 0s 80us/sample - loss: 0.0097 - val_loss: 0.0208\n",
      "Epoch 12/50\n",
      "1147/1147 [==============================] - 0s 78us/sample - loss: 0.0144 - val_loss: 0.0079\n",
      "Epoch 13/50\n",
      "1147/1147 [==============================] - 0s 76us/sample - loss: 0.0124 - val_loss: 0.0245\n",
      "Epoch 14/50\n",
      "1147/1147 [==============================] - 0s 74us/sample - loss: 0.0186 - val_loss: 0.0040\n",
      "Epoch 15/50\n",
      "1147/1147 [==============================] - 0s 79us/sample - loss: 0.0088 - val_loss: 0.0174\n",
      "Epoch 16/50\n",
      "1147/1147 [==============================] - 0s 79us/sample - loss: 0.0124 - val_loss: 0.0072\n",
      "Epoch 17/50\n",
      "1147/1147 [==============================] - 0s 76us/sample - loss: 0.0123 - val_loss: 0.0226\n",
      "Epoch 18/50\n",
      "1147/1147 [==============================] - 0s 74us/sample - loss: 0.0178 - val_loss: 0.0055\n",
      "Epoch 19/50\n",
      "1147/1147 [==============================] - 0s 75us/sample - loss: 0.0094 - val_loss: 0.0153\n",
      "Epoch 20/50\n",
      "1147/1147 [==============================] - 0s 76us/sample - loss: 0.0110 - val_loss: 0.0042\n",
      "Epoch 21/50\n",
      "1147/1147 [==============================] - 0s 78us/sample - loss: 0.0130 - val_loss: 0.0148\n",
      "Epoch 22/50\n",
      "1147/1147 [==============================] - 0s 78us/sample - loss: 0.0134 - val_loss: 0.0040\n",
      "Epoch 23/50\n",
      "1147/1147 [==============================] - 0s 74us/sample - loss: 0.0099 - val_loss: 0.0173\n",
      "Epoch 24/50\n",
      "1147/1147 [==============================] - 0s 73us/sample - loss: 0.0121 - val_loss: 0.0041\n",
      "Epoch 25/50\n",
      "1147/1147 [==============================] - 0s 78us/sample - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 26/50\n",
      "1147/1147 [==============================] - 0s 79us/sample - loss: 0.0116 - val_loss: 0.0045\n",
      "Epoch 27/50\n",
      "1147/1147 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0155\n",
      "Epoch 28/50\n",
      "1147/1147 [==============================] - 0s 79us/sample - loss: 0.0121 - val_loss: 0.0056\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1147/1147 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0089\n",
      "Epoch 30/50\n",
      "1147/1147 [==============================] - 0s 82us/sample - loss: 0.0104 - val_loss: 0.0048\n",
      "Epoch 31/50\n",
      "1147/1147 [==============================] - 0s 74us/sample - loss: 0.0115 - val_loss: 0.0152\n",
      "Epoch 32/50\n",
      "1147/1147 [==============================] - 0s 74us/sample - loss: 0.0113 - val_loss: 0.0047\n",
      "Epoch 33/50\n",
      "1147/1147 [==============================] - 0s 71us/sample - loss: 0.0111 - val_loss: 0.0088\n",
      "Epoch 34/50\n",
      "1147/1147 [==============================] - 0s 72us/sample - loss: 0.0100 - val_loss: 0.0052\n",
      "Epoch 35/50\n",
      "1147/1147 [==============================] - 0s 72us/sample - loss: 0.0117 - val_loss: 0.0149\n",
      "Epoch 36/50\n",
      "1147/1147 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0047\n",
      "Epoch 37/50\n",
      "1147/1147 [==============================] - 0s 77us/sample - loss: 0.0103 - val_loss: 0.0081\n",
      "Epoch 38/50\n",
      "1147/1147 [==============================] - 0s 79us/sample - loss: 0.0097 - val_loss: 0.0072\n",
      "Epoch 39/50\n",
      "1147/1147 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0135\n",
      "Epoch 40/50\n",
      "1147/1147 [==============================] - 0s 78us/sample - loss: 0.0103 - val_loss: 0.0049\n",
      "Epoch 41/50\n",
      "1147/1147 [==============================] - 0s 77us/sample - loss: 0.0099 - val_loss: 0.0073\n",
      "Epoch 42/50\n",
      "1147/1147 [==============================] - 0s 72us/sample - loss: 0.0093 - val_loss: 0.0090\n",
      "Epoch 43/50\n",
      "1147/1147 [==============================] - 0s 77us/sample - loss: 0.0127 - val_loss: 0.0122\n",
      "Epoch 44/50\n",
      "1147/1147 [==============================] - 0s 72us/sample - loss: 0.0102 - val_loss: 0.0067\n",
      "Epoch 45/50\n",
      "1147/1147 [==============================] - 0s 75us/sample - loss: 0.0102 - val_loss: 0.0054\n",
      "Epoch 46/50\n",
      "1147/1147 [==============================] - 0s 77us/sample - loss: 0.0085 - val_loss: 0.0096\n",
      "Epoch 47/50\n",
      "1147/1147 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0122\n",
      "Epoch 48/50\n",
      "1147/1147 [==============================] - 0s 74us/sample - loss: 0.0094 - val_loss: 0.0056\n",
      "Epoch 49/50\n",
      "1147/1147 [==============================] - 0s 79us/sample - loss: 0.0097 - val_loss: 0.0059\n",
      "Epoch 50/50\n",
      "1147/1147 [==============================] - 0s 76us/sample - loss: 0.0083 - val_loss: 0.0088\n",
      "第302个数，还剩3821个没有训练\n",
      "inv_hat [0.18769003 0.18769003 0.18758929 0.18738774 0.18728692 0.18728692\n",
      " 0.18738774 0.18738774 0.18758929 0.18779074 0.18799209 0.18799209\n",
      " 0.18859545 0.18869589 0.18869589 0.18889668 0.18909734 0.18909734\n",
      " 0.18919761 0.18959829 0.19029789 0.19029789 0.19029789 0.19019808\n",
      " 0.19019808 0.19009822 0.18999832 0.19009822 0.19019808 0.19029789]\n",
      "Test RMSE: 0.000\n",
      "Train on 515 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "515/515 [==============================] - 0s 86us/sample - loss: 0.0198 - val_loss: 0.0213\n",
      "Epoch 2/50\n",
      "515/515 [==============================] - 0s 90us/sample - loss: 0.0198 - val_loss: 0.0209\n",
      "Epoch 3/50\n",
      "515/515 [==============================] - 0s 93us/sample - loss: 0.0193 - val_loss: 0.0205\n",
      "Epoch 4/50\n",
      "515/515 [==============================] - 0s 86us/sample - loss: 0.0192 - val_loss: 0.0204\n",
      "Epoch 5/50\n",
      "515/515 [==============================] - 0s 93us/sample - loss: 0.0191 - val_loss: 0.0204\n",
      "Epoch 6/50\n",
      "515/515 [==============================] - 0s 95us/sample - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 7/50\n",
      "515/515 [==============================] - 0s 94us/sample - loss: 0.0190 - val_loss: 0.0203\n",
      "Epoch 8/50\n",
      "515/515 [==============================] - 0s 89us/sample - loss: 0.0190 - val_loss: 0.0203\n",
      "Epoch 9/50\n",
      "515/515 [==============================] - 0s 89us/sample - loss: 0.0190 - val_loss: 0.0203\n",
      "Epoch 10/50\n",
      "515/515 [==============================] - 0s 87us/sample - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 11/50\n",
      "515/515 [==============================] - 0s 89us/sample - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 12/50\n",
      "515/515 [==============================] - 0s 90us/sample - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 13/50\n",
      "515/515 [==============================] - 0s 90us/sample - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 14/50\n",
      "515/515 [==============================] - 0s 86us/sample - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 15/50\n",
      "515/515 [==============================] - 0s 91us/sample - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 16/50\n",
      "515/515 [==============================] - 0s 86us/sample - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 17/50\n",
      "515/515 [==============================] - 0s 88us/sample - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 18/50\n",
      "515/515 [==============================] - 0s 87us/sample - loss: 0.0188 - val_loss: 0.0204\n",
      "Epoch 19/50\n",
      "515/515 [==============================] - 0s 84us/sample - loss: 0.0188 - val_loss: 0.0204\n",
      "Epoch 20/50\n",
      "515/515 [==============================] - 0s 82us/sample - loss: 0.0188 - val_loss: 0.0204\n",
      "Epoch 21/50\n",
      "515/515 [==============================] - 0s 86us/sample - loss: 0.0188 - val_loss: 0.0204\n",
      "Epoch 22/50\n",
      "515/515 [==============================] - 0s 85us/sample - loss: 0.0188 - val_loss: 0.0204\n",
      "Epoch 23/50\n",
      "515/515 [==============================] - 0s 85us/sample - loss: 0.0188 - val_loss: 0.0204\n",
      "Epoch 24/50\n",
      "515/515 [==============================] - 0s 91us/sample - loss: 0.0188 - val_loss: 0.0204\n",
      "Epoch 25/50\n",
      "515/515 [==============================] - 0s 90us/sample - loss: 0.0188 - val_loss: 0.0204\n",
      "Epoch 26/50\n",
      "515/515 [==============================] - 0s 90us/sample - loss: 0.0188 - val_loss: 0.0204\n",
      "Epoch 27/50\n",
      "515/515 [==============================] - 0s 86us/sample - loss: 0.0188 - val_loss: 0.0204\n",
      "Epoch 28/50\n",
      "515/515 [==============================] - 0s 97us/sample - loss: 0.0187 - val_loss: 0.0204\n",
      "Epoch 29/50\n",
      "515/515 [==============================] - 0s 96us/sample - loss: 0.0187 - val_loss: 0.0204\n",
      "Epoch 30/50\n",
      "515/515 [==============================] - 0s 89us/sample - loss: 0.0187 - val_loss: 0.0205\n",
      "Epoch 31/50\n",
      "515/515 [==============================] - 0s 95us/sample - loss: 0.0187 - val_loss: 0.0205\n",
      "Epoch 32/50\n",
      "515/515 [==============================] - 0s 88us/sample - loss: 0.0187 - val_loss: 0.0205\n",
      "Epoch 33/50\n",
      "515/515 [==============================] - 0s 82us/sample - loss: 0.0187 - val_loss: 0.0206\n",
      "Epoch 34/50\n",
      "515/515 [==============================] - 0s 83us/sample - loss: 0.0187 - val_loss: 0.0206\n",
      "Epoch 35/50\n",
      "515/515 [==============================] - 0s 81us/sample - loss: 0.0187 - val_loss: 0.0206\n",
      "Epoch 36/50\n",
      "515/515 [==============================] - 0s 82us/sample - loss: 0.0187 - val_loss: 0.0206\n",
      "Epoch 37/50\n",
      "515/515 [==============================] - 0s 88us/sample - loss: 0.0187 - val_loss: 0.0206\n",
      "Epoch 38/50\n",
      "515/515 [==============================] - 0s 84us/sample - loss: 0.0186 - val_loss: 0.0206\n",
      "Epoch 39/50\n",
      "515/515 [==============================] - 0s 84us/sample - loss: 0.0186 - val_loss: 0.0207\n",
      "Epoch 40/50\n",
      "515/515 [==============================] - 0s 82us/sample - loss: 0.0186 - val_loss: 0.0207\n",
      "Epoch 41/50\n",
      "515/515 [==============================] - 0s 87us/sample - loss: 0.0186 - val_loss: 0.0207\n",
      "Epoch 42/50\n",
      "515/515 [==============================] - 0s 88us/sample - loss: 0.0186 - val_loss: 0.0207\n",
      "Epoch 43/50\n",
      "515/515 [==============================] - 0s 80us/sample - loss: 0.0186 - val_loss: 0.0207\n",
      "Epoch 44/50\n",
      "515/515 [==============================] - 0s 83us/sample - loss: 0.0186 - val_loss: 0.0207\n",
      "Epoch 45/50\n",
      "515/515 [==============================] - 0s 84us/sample - loss: 0.0186 - val_loss: 0.0207\n",
      "Epoch 46/50\n",
      "515/515 [==============================] - 0s 85us/sample - loss: 0.0186 - val_loss: 0.0207\n",
      "Epoch 47/50\n",
      "515/515 [==============================] - 0s 85us/sample - loss: 0.0186 - val_loss: 0.0207\n",
      "Epoch 48/50\n",
      "515/515 [==============================] - 0s 85us/sample - loss: 0.0186 - val_loss: 0.0207\n",
      "Epoch 49/50\n",
      "515/515 [==============================] - 0s 86us/sample - loss: 0.0186 - val_loss: 0.0207\n",
      "Epoch 50/50\n",
      "515/515 [==============================] - 0s 83us/sample - loss: 0.0186 - val_loss: 0.0207\n",
      "第303个数，还剩3820个没有训练\n",
      "inv_hat [1.23233654 1.23433038 1.24529301 1.22236463 1.22735105 1.22036985\n",
      " 1.19443435 1.19343694 1.1904452  1.20540685 1.19842401 1.21737749\n",
      " 1.25823894 1.25823894 1.25525244 1.22635379 1.22535663 1.21039474\n",
      " 1.21637995 1.22635379 1.2462893  1.23133945 1.22834828 1.21837502\n",
      " 1.20440924 1.19443435 1.17848231 1.1855871  1.15848409 1.16651622]\n",
      "Test RMSE: 0.016\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 72us/sample - loss: 0.0055 - val_loss: 0.0064\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0053 - val_loss: 0.0057\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0061 - val_loss: 0.0053\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0057 - val_loss: 0.0055\n",
      "第304个数，还剩3819个没有训练\n",
      "inv_hat [1.31323553 1.30872044 1.30831889 1.30811794 1.30329457 1.30429974\n",
      " 1.30480239 1.30651091 1.30661126 1.3075154  1.31143038 1.31333579\n",
      " 1.31423796 1.31102897 1.31042695 1.30992521 1.31253361 1.31283449\n",
      " 1.31584115 1.30942324 1.30741495 1.30379712 1.30168603 1.30088146\n",
      " 1.29856764 1.29957379 1.29947318 1.30078089 1.29997626 1.30329457]\n",
      "Test RMSE: 0.002\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0067 - val_loss: 0.0029\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0066 - val_loss: 0.0029\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0068 - val_loss: 0.0033\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0069 - val_loss: 0.0040\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0066 - val_loss: 0.0036\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0065 - val_loss: 0.0032\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0029\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0065 - val_loss: 0.0031\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0066 - val_loss: 0.0036\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0066 - val_loss: 0.0037\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0030\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0030\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0064 - val_loss: 0.0031\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0065 - val_loss: 0.0034\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0064 - val_loss: 0.0034\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0030\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0030\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0031\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0031\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0031\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0064 - val_loss: 0.0031\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0064 - val_loss: 0.0032\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0064 - val_loss: 0.0032\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0064 - val_loss: 0.0032\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0032\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0064 - val_loss: 0.0032\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0064 - val_loss: 0.0031\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0064 - val_loss: 0.0030\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0031\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0031\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0064 - val_loss: 0.0031\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0032\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0064 - val_loss: 0.0032\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0064 - val_loss: 0.0032\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0032\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0034\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0032\n",
      "第305个数，还剩3818个没有训练\n",
      "inv_hat [1.14624324 1.11778123 1.12634271 1.12407883 1.09792552 1.09920252\n",
      " 1.10784941 1.1165024  1.094194   1.10382    1.14023052 1.14624324\n",
      " 1.1411174  1.11945372 1.11748618 1.11424021 1.12604744 1.12289773\n",
      " 1.13451603 1.1122735  1.09173958 1.08369276 1.06692981 1.06879127\n",
      " 1.06604831 1.07780833 1.07329886 1.06771348 1.05478959 1.05498527]\n",
      "Test RMSE: 0.015\n",
      "Train on 537 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "537/537 [==============================] - 0s 81us/sample - loss: 0.0154 - val_loss: 0.0175\n",
      "Epoch 2/50\n",
      "537/537 [==============================] - 0s 80us/sample - loss: 0.0151 - val_loss: 0.0166\n",
      "Epoch 3/50\n",
      "537/537 [==============================] - 0s 85us/sample - loss: 0.0148 - val_loss: 0.0170\n",
      "Epoch 4/50\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.0145 - val_loss: 0.0167\n",
      "Epoch 5/50\n",
      "537/537 [==============================] - 0s 88us/sample - loss: 0.0144 - val_loss: 0.0168\n",
      "Epoch 6/50\n",
      "537/537 [==============================] - 0s 89us/sample - loss: 0.0143 - val_loss: 0.0166\n",
      "Epoch 7/50\n",
      "537/537 [==============================] - 0s 86us/sample - loss: 0.0143 - val_loss: 0.0166\n",
      "Epoch 8/50\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.0143 - val_loss: 0.0166\n",
      "Epoch 9/50\n",
      "537/537 [==============================] - 0s 79us/sample - loss: 0.0143 - val_loss: 0.0165\n",
      "Epoch 10/50\n",
      "537/537 [==============================] - 0s 85us/sample - loss: 0.0143 - val_loss: 0.0166\n",
      "Epoch 11/50\n",
      "537/537 [==============================] - 0s 85us/sample - loss: 0.0143 - val_loss: 0.0165\n",
      "Epoch 12/50\n",
      "537/537 [==============================] - 0s 90us/sample - loss: 0.0143 - val_loss: 0.0164\n",
      "Epoch 13/50\n",
      "537/537 [==============================] - 0s 83us/sample - loss: 0.0143 - val_loss: 0.0164\n",
      "Epoch 14/50\n",
      "537/537 [==============================] - 0s 83us/sample - loss: 0.0143 - val_loss: 0.0166\n",
      "Epoch 15/50\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.0143 - val_loss: 0.0163\n",
      "Epoch 16/50\n",
      "537/537 [==============================] - 0s 81us/sample - loss: 0.0143 - val_loss: 0.0166\n",
      "Epoch 17/50\n",
      "537/537 [==============================] - 0s 86us/sample - loss: 0.0143 - val_loss: 0.0161\n",
      "Epoch 18/50\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.0143 - val_loss: 0.0167\n",
      "Epoch 19/50\n",
      "537/537 [==============================] - 0s 86us/sample - loss: 0.0143 - val_loss: 0.0161\n",
      "Epoch 20/50\n",
      "537/537 [==============================] - 0s 89us/sample - loss: 0.0143 - val_loss: 0.0165\n",
      "Epoch 21/50\n",
      "537/537 [==============================] - 0s 87us/sample - loss: 0.0143 - val_loss: 0.0162\n",
      "Epoch 22/50\n",
      "537/537 [==============================] - 0s 86us/sample - loss: 0.0143 - val_loss: 0.0164\n",
      "Epoch 23/50\n",
      "537/537 [==============================] - 0s 86us/sample - loss: 0.0142 - val_loss: 0.0162\n",
      "Epoch 24/50\n",
      "537/537 [==============================] - 0s 88us/sample - loss: 0.0142 - val_loss: 0.0162\n",
      "Epoch 25/50\n",
      "537/537 [==============================] - 0s 88us/sample - loss: 0.0142 - val_loss: 0.0163\n",
      "Epoch 26/50\n",
      "537/537 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0162\n",
      "Epoch 27/50\n",
      "537/537 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0163\n",
      "Epoch 28/50\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.0142 - val_loss: 0.0162\n",
      "Epoch 29/50\n",
      "537/537 [==============================] - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0163\n",
      "Epoch 30/50\n",
      "537/537 [==============================] - 0s 79us/sample - loss: 0.0142 - val_loss: 0.0162\n",
      "Epoch 31/50\n",
      "537/537 [==============================] - 0s 79us/sample - loss: 0.0142 - val_loss: 0.0163\n",
      "Epoch 32/50\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.0142 - val_loss: 0.0161\n",
      "Epoch 33/50\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.0143 - val_loss: 0.0163\n",
      "Epoch 34/50\n",
      "537/537 [==============================] - 0s 88us/sample - loss: 0.0142 - val_loss: 0.0162\n",
      "Epoch 35/50\n",
      "537/537 [==============================] - 0s 87us/sample - loss: 0.0142 - val_loss: 0.0163\n",
      "Epoch 36/50\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.0142 - val_loss: 0.0161\n",
      "Epoch 37/50\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.0142 - val_loss: 0.0163\n",
      "Epoch 38/50\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.0142 - val_loss: 0.0161\n",
      "Epoch 39/50\n",
      "537/537 [==============================] - 0s 87us/sample - loss: 0.0142 - val_loss: 0.0162\n",
      "Epoch 40/50\n",
      "537/537 [==============================] - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0161\n",
      "Epoch 41/50\n",
      "537/537 [==============================] - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0162\n",
      "Epoch 42/50\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0161\n",
      "Epoch 43/50\n",
      "537/537 [==============================] - 0s 89us/sample - loss: 0.0142 - val_loss: 0.0162\n",
      "Epoch 44/50\n",
      "537/537 [==============================] - 0s 88us/sample - loss: 0.0142 - val_loss: 0.0162\n",
      "Epoch 45/50\n",
      "537/537 [==============================] - 0s 85us/sample - loss: 0.0142 - val_loss: 0.0162\n",
      "Epoch 46/50\n",
      "537/537 [==============================] - 0s 85us/sample - loss: 0.0142 - val_loss: 0.0161\n",
      "Epoch 47/50\n",
      "537/537 [==============================] - 0s 79us/sample - loss: 0.0142 - val_loss: 0.0162\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 78us/sample - loss: 0.0142 - val_loss: 0.0161\n",
      "Epoch 49/50\n",
      "537/537 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0162\n",
      "Epoch 50/50\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0161\n",
      "第306个数，还剩3817个没有训练\n",
      "inv_hat [1.45563608 1.41145911 1.41244379 1.41441307 1.38978581 1.38288593\n",
      " 1.37894258 1.39175686 1.3730265  1.38682898 1.43606428 1.43803158\n",
      " 1.43114529 1.39077123 1.38880018 1.36908192 1.38091433 1.39077123\n",
      " 1.41342843 1.39175686 1.38288593 1.36908192 1.35428627 1.35132662\n",
      " 1.34343361 1.35527273 1.35551396 1.35250495 1.33850024 1.34738011]\n",
      "Test RMSE: 0.018\n",
      "Train on 749 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "749/749 [==============================] - 0s 81us/sample - loss: 0.0071 - val_loss: 0.0094\n",
      "Epoch 2/50\n",
      "749/749 [==============================] - 0s 83us/sample - loss: 0.0067 - val_loss: 0.0089\n",
      "Epoch 3/50\n",
      "749/749 [==============================] - 0s 84us/sample - loss: 0.0082 - val_loss: 0.0089\n",
      "Epoch 4/50\n",
      "749/749 [==============================] - 0s 87us/sample - loss: 0.0140 - val_loss: 0.0108\n",
      "Epoch 5/50\n",
      "749/749 [==============================] - 0s 90us/sample - loss: 0.0132 - val_loss: 0.0090\n",
      "Epoch 6/50\n",
      "749/749 [==============================] - 0s 89us/sample - loss: 0.0188 - val_loss: 0.0128\n",
      "Epoch 7/50\n",
      "749/749 [==============================] - 0s 84us/sample - loss: 0.0114 - val_loss: 0.0094\n",
      "Epoch 8/50\n",
      "749/749 [==============================] - 0s 84us/sample - loss: 0.0121 - val_loss: 0.0120\n",
      "Epoch 9/50\n",
      "749/749 [==============================] - 0s 83us/sample - loss: 0.0123 - val_loss: 0.0099\n",
      "Epoch 10/50\n",
      "749/749 [==============================] - 0s 82us/sample - loss: 0.0090 - val_loss: 0.0106\n",
      "Epoch 11/50\n",
      "749/749 [==============================] - 0s 82us/sample - loss: 0.0087 - val_loss: 0.0090\n",
      "Epoch 12/50\n",
      "749/749 [==============================] - 0s 85us/sample - loss: 0.0081 - val_loss: 0.0088\n",
      "Epoch 13/50\n",
      "749/749 [==============================] - 0s 80us/sample - loss: 0.0087 - val_loss: 0.0101\n",
      "Epoch 14/50\n",
      "749/749 [==============================] - 0s 88us/sample - loss: 0.0087 - val_loss: 0.0092\n",
      "Epoch 15/50\n",
      "749/749 [==============================] - 0s 89us/sample - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 16/50\n",
      "749/749 [==============================] - 0s 85us/sample - loss: 0.0088 - val_loss: 0.0089\n",
      "Epoch 17/50\n",
      "749/749 [==============================] - 0s 89us/sample - loss: 0.0078 - val_loss: 0.0089\n",
      "Epoch 18/50\n",
      "749/749 [==============================] - 0s 87us/sample - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 19/50\n",
      "749/749 [==============================] - 0s 79us/sample - loss: 0.0082 - val_loss: 0.0090\n",
      "Epoch 20/50\n",
      "749/749 [==============================] - 0s 83us/sample - loss: 0.0093 - val_loss: 0.0088\n",
      "Epoch 21/50\n",
      "749/749 [==============================] - 0s 83us/sample - loss: 0.0069 - val_loss: 0.0095\n",
      "Epoch 22/50\n",
      "749/749 [==============================] - 0s 82us/sample - loss: 0.0074 - val_loss: 0.0093\n",
      "Epoch 23/50\n",
      "749/749 [==============================] - 0s 81us/sample - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 24/50\n",
      "749/749 [==============================] - 0s 81us/sample - loss: 0.0077 - val_loss: 0.0088\n",
      "Epoch 25/50\n",
      "749/749 [==============================] - 0s 83us/sample - loss: 0.0062 - val_loss: 0.0089\n",
      "Epoch 26/50\n",
      "749/749 [==============================] - 0s 79us/sample - loss: 0.0072 - val_loss: 0.0089\n",
      "Epoch 27/50\n",
      "749/749 [==============================] - 0s 81us/sample - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 28/50\n",
      "749/749 [==============================] - 0s 80us/sample - loss: 0.0088 - val_loss: 0.0089\n",
      "Epoch 29/50\n",
      "749/749 [==============================] - 0s 78us/sample - loss: 0.0078 - val_loss: 0.0087\n",
      "Epoch 30/50\n",
      "749/749 [==============================] - 0s 79us/sample - loss: 0.0081 - val_loss: 0.0096\n",
      "Epoch 31/50\n",
      "749/749 [==============================] - 0s 81us/sample - loss: 0.0081 - val_loss: 0.0090\n",
      "Epoch 32/50\n",
      "749/749 [==============================] - 0s 82us/sample - loss: 0.0086 - val_loss: 0.0109\n",
      "Epoch 33/50\n",
      "749/749 [==============================] - 0s 82us/sample - loss: 0.0088 - val_loss: 0.0090\n",
      "Epoch 34/50\n",
      "749/749 [==============================] - 0s 82us/sample - loss: 0.0079 - val_loss: 0.0087\n",
      "Epoch 35/50\n",
      "749/749 [==============================] - 0s 78us/sample - loss: 0.0074 - val_loss: 0.0087\n",
      "Epoch 36/50\n",
      "749/749 [==============================] - 0s 77us/sample - loss: 0.0068 - val_loss: 0.0089\n",
      "Epoch 37/50\n",
      "749/749 [==============================] - 0s 80us/sample - loss: 0.0088 - val_loss: 0.0088\n",
      "Epoch 38/50\n",
      "749/749 [==============================] - 0s 80us/sample - loss: 0.0064 - val_loss: 0.0101\n",
      "Epoch 39/50\n",
      "749/749 [==============================] - 0s 78us/sample - loss: 0.0066 - val_loss: 0.0089\n",
      "Epoch 40/50\n",
      "749/749 [==============================] - 0s 80us/sample - loss: 0.0090 - val_loss: 0.0087\n",
      "Epoch 41/50\n",
      "749/749 [==============================] - 0s 81us/sample - loss: 0.0073 - val_loss: 0.0090\n",
      "Epoch 42/50\n",
      "749/749 [==============================] - 0s 79us/sample - loss: 0.0077 - val_loss: 0.0090\n",
      "Epoch 43/50\n",
      "749/749 [==============================] - 0s 79us/sample - loss: 0.0081 - val_loss: 0.0087\n",
      "Epoch 44/50\n",
      "749/749 [==============================] - 0s 78us/sample - loss: 0.0071 - val_loss: 0.0090\n",
      "Epoch 45/50\n",
      "749/749 [==============================] - 0s 81us/sample - loss: 0.0071 - val_loss: 0.0089\n",
      "Epoch 46/50\n",
      "749/749 [==============================] - 0s 78us/sample - loss: 0.0083 - val_loss: 0.0087\n",
      "Epoch 47/50\n",
      "749/749 [==============================] - 0s 80us/sample - loss: 0.0068 - val_loss: 0.0097\n",
      "Epoch 48/50\n",
      "749/749 [==============================] - 0s 83us/sample - loss: 0.0070 - val_loss: 0.0089\n",
      "Epoch 49/50\n",
      "749/749 [==============================] - 0s 80us/sample - loss: 0.0083 - val_loss: 0.0087\n",
      "Epoch 50/50\n",
      "749/749 [==============================] - 0s 79us/sample - loss: 0.0068 - val_loss: 0.0096\n",
      "第307个数，还剩3816个没有训练\n",
      "inv_hat [1.14220479 1.13930359 1.14027259 1.14027259 1.13833261 1.13833261\n",
      " 1.13833261 1.13930359 1.13735972 1.13930359 1.14220479 1.14316797\n",
      " 1.14220479 1.14027259 1.13930359 1.13735972 1.13735972 1.13833261\n",
      " 1.13930359 1.13833261 1.13735972 1.1363851  1.13540857 1.13540857\n",
      " 1.13443025 1.13540857 1.13443025 1.1334503  1.13443025 1.13540857]\n",
      "Test RMSE: 0.001\n",
      "Train on 1086 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1086/1086 [==============================] - 0s 82us/sample - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 2/50\n",
      "1086/1086 [==============================] - 0s 81us/sample - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 3/50\n",
      "1086/1086 [==============================] - 0s 76us/sample - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 4/50\n",
      "1086/1086 [==============================] - 0s 80us/sample - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 5/50\n",
      "1086/1086 [==============================] - 0s 80us/sample - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 6/50\n",
      "1086/1086 [==============================] - 0s 81us/sample - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 7/50\n",
      "1086/1086 [==============================] - 0s 83us/sample - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 8/50\n",
      "1086/1086 [==============================] - 0s 81us/sample - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 9/50\n",
      "1086/1086 [==============================] - 0s 84us/sample - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 10/50\n",
      "1086/1086 [==============================] - 0s 79us/sample - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 11/50\n",
      "1086/1086 [==============================] - 0s 84us/sample - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 12/50\n",
      "1086/1086 [==============================] - 0s 82us/sample - loss: 0.0049 - val_loss: 0.0028\n",
      "Epoch 13/50\n",
      "1086/1086 [==============================] - 0s 84us/sample - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 14/50\n",
      "1086/1086 [==============================] - 0s 83us/sample - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 15/50\n",
      "1086/1086 [==============================] - 0s 83us/sample - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 16/50\n",
      "1086/1086 [==============================] - 0s 83us/sample - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 17/50\n",
      "1086/1086 [==============================] - 0s 82us/sample - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 18/50\n",
      "1086/1086 [==============================] - 0s 83us/sample - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 19/50\n",
      "1086/1086 [==============================] - 0s 84us/sample - loss: 0.0081 - val_loss: 0.0034\n",
      "Epoch 20/50\n",
      "1086/1086 [==============================] - 0s 83us/sample - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 21/50\n",
      "1086/1086 [==============================] - 0s 85us/sample - loss: 0.0059 - val_loss: 0.0040\n",
      "Epoch 22/50\n",
      "1086/1086 [==============================] - 0s 82us/sample - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 23/50\n",
      "1086/1086 [==============================] - 0s 85us/sample - loss: 0.0059 - val_loss: 0.0034\n",
      "Epoch 24/50\n",
      "1086/1086 [==============================] - 0s 84us/sample - loss: 0.0061 - val_loss: 0.0029\n",
      "Epoch 25/50\n",
      "1086/1086 [==============================] - 0s 82us/sample - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 26/50\n",
      "1086/1086 [==============================] - 0s 83us/sample - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 27/50\n",
      "1086/1086 [==============================] - 0s 77us/sample - loss: 0.0055 - val_loss: 0.0034\n",
      "Epoch 28/50\n",
      "1086/1086 [==============================] - 0s 84us/sample - loss: 0.0056 - val_loss: 0.0032\n",
      "Epoch 29/50\n",
      "1086/1086 [==============================] - 0s 83us/sample - loss: 0.0054 - val_loss: 0.0030\n",
      "Epoch 30/50\n",
      "1086/1086 [==============================] - 0s 82us/sample - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 31/50\n",
      "1086/1086 [==============================] - 0s 80us/sample - loss: 0.0051 - val_loss: 0.0033\n",
      "Epoch 32/50\n",
      "1086/1086 [==============================] - 0s 80us/sample - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 33/50\n",
      "1086/1086 [==============================] - 0s 83us/sample - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 34/50\n",
      "1086/1086 [==============================] - 0s 83us/sample - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 35/50\n",
      "1086/1086 [==============================] - 0s 81us/sample - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 36/50\n",
      "1086/1086 [==============================] - 0s 84us/sample - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 37/50\n",
      "1086/1086 [==============================] - 0s 81us/sample - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 38/50\n",
      "1086/1086 [==============================] - 0s 78us/sample - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 39/50\n",
      "1086/1086 [==============================] - 0s 79us/sample - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 40/50\n",
      "1086/1086 [==============================] - 0s 80us/sample - loss: 0.0065 - val_loss: 0.0028\n",
      "Epoch 41/50\n",
      "1086/1086 [==============================] - 0s 80us/sample - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 42/50\n",
      "1086/1086 [==============================] - 0s 79us/sample - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 43/50\n",
      "1086/1086 [==============================] - 0s 79us/sample - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 44/50\n",
      "1086/1086 [==============================] - 0s 80us/sample - loss: 0.0049 - val_loss: 0.0029\n",
      "Epoch 45/50\n",
      "1086/1086 [==============================] - 0s 80us/sample - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 46/50\n",
      "1086/1086 [==============================] - 0s 81us/sample - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 47/50\n",
      "1086/1086 [==============================] - 0s 83us/sample - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 48/50\n",
      "1086/1086 [==============================] - 0s 79us/sample - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 49/50\n",
      "1086/1086 [==============================] - 0s 80us/sample - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 50/50\n",
      "1086/1086 [==============================] - 0s 82us/sample - loss: 0.0054 - val_loss: 0.0040\n",
      "第308个数，还剩3815个没有训练\n",
      "inv_hat [1.0884632  1.08826254 1.08836288 1.0884632  1.08856341 1.08896483\n",
      " 1.08896483 1.08876411 1.08886445 1.08936619 1.08966737 1.08996847\n",
      " 1.08996847 1.09097278 1.09107325 1.09187712 1.09237967 1.09258078\n",
      " 1.09298295 1.09348597 1.09348597 1.09328475 1.09358645 1.09368709\n",
      " 1.09338534 1.09348597 1.09348597 1.09358645 1.09408963 1.09388835]\n",
      "Test RMSE: 0.001\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0136 - val_loss: 0.0086\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0125 - val_loss: 0.0082\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0124 - val_loss: 0.0080\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0124 - val_loss: 0.0082\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0082\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0125 - val_loss: 0.0082\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0124 - val_loss: 0.0082\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0125 - val_loss: 0.0084\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0124 - val_loss: 0.0078\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0125 - val_loss: 0.0084\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0125 - val_loss: 0.0083\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0124 - val_loss: 0.0078\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0125 - val_loss: 0.0086\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0124 - val_loss: 0.0078\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0124 - val_loss: 0.0083\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0124 - val_loss: 0.0080\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0124 - val_loss: 0.0078\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0124 - val_loss: 0.0083\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0125 - val_loss: 0.0081\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0124 - val_loss: 0.0077\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0124 - val_loss: 0.0082\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0082\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0124 - val_loss: 0.0076\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0124 - val_loss: 0.0080\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0085\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0124 - val_loss: 0.0077\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0125 - val_loss: 0.0085\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0124 - val_loss: 0.0078\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0124 - val_loss: 0.0078\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0125 - val_loss: 0.0085\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0124 - val_loss: 0.0078\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0124 - val_loss: 0.0078\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0125 - val_loss: 0.0086\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0125 - val_loss: 0.0079\n",
      "第309个数，还剩3814个没有训练\n",
      "inv_hat [0.51416194 0.49910001 0.49939674 0.49554086 0.47858329 0.47710834\n",
      " 0.48281503 0.49563966 0.48734777 0.49484918 0.51128418 0.51426115\n",
      " 0.51416194 0.50187045 0.49702342 0.49208373 0.49732002 0.49662804\n",
      " 0.50117767 0.48596763 0.48163354 0.47789486 0.46935138 0.46748861\n",
      " 0.46180942 0.46797872 0.46758664 0.46083134 0.45907162 0.45848529]\n",
      "Test RMSE: 0.008\n",
      "Train on 546 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "546/546 [==============================] - 0s 82us/sample - loss: 0.0104 - val_loss: 0.0078\n",
      "Epoch 2/50\n",
      "546/546 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0119\n",
      "Epoch 3/50\n",
      "546/546 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0066\n",
      "Epoch 4/50\n",
      "546/546 [==============================] - 0s 82us/sample - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 5/50\n",
      "546/546 [==============================] - 0s 79us/sample - loss: 0.0116 - val_loss: 0.0100\n",
      "Epoch 6/50\n",
      "546/546 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0066\n",
      "Epoch 7/50\n",
      "546/546 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0068\n",
      "Epoch 8/50\n",
      "546/546 [==============================] - 0s 81us/sample - loss: 0.0101 - val_loss: 0.0073\n",
      "Epoch 9/50\n",
      "546/546 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0066\n",
      "Epoch 10/50\n",
      "546/546 [==============================] - 0s 81us/sample - loss: 0.0102 - val_loss: 0.0067\n",
      "Epoch 11/50\n",
      "546/546 [==============================] - 0s 78us/sample - loss: 0.0101 - val_loss: 0.0071\n",
      "Epoch 12/50\n",
      "546/546 [==============================] - 0s 79us/sample - loss: 0.0099 - val_loss: 0.0066\n",
      "Epoch 13/50\n",
      "546/546 [==============================] - 0s 77us/sample - loss: 0.0101 - val_loss: 0.0068\n",
      "Epoch 14/50\n",
      "546/546 [==============================] - 0s 82us/sample - loss: 0.0100 - val_loss: 0.0067\n",
      "Epoch 15/50\n",
      "546/546 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0068\n",
      "Epoch 16/50\n",
      "546/546 [==============================] - 0s 78us/sample - loss: 0.0099 - val_loss: 0.0069\n",
      "Epoch 17/50\n",
      "546/546 [==============================] - 0s 89us/sample - loss: 0.0099 - val_loss: 0.0066\n",
      "Epoch 18/50\n",
      "546/546 [==============================] - 0s 84us/sample - loss: 0.0100 - val_loss: 0.0069\n",
      "Epoch 19/50\n",
      "546/546 [==============================] - 0s 84us/sample - loss: 0.0098 - val_loss: 0.0068\n",
      "Epoch 20/50\n",
      "546/546 [==============================] - 0s 88us/sample - loss: 0.0100 - val_loss: 0.0066\n",
      "Epoch 21/50\n",
      "546/546 [==============================] - 0s 86us/sample - loss: 0.0101 - val_loss: 0.0069\n",
      "Epoch 22/50\n",
      "546/546 [==============================] - 0s 85us/sample - loss: 0.0098 - val_loss: 0.0069\n",
      "Epoch 23/50\n",
      "546/546 [==============================] - 0s 86us/sample - loss: 0.0098 - val_loss: 0.0067\n",
      "Epoch 24/50\n",
      "546/546 [==============================] - 0s 86us/sample - loss: 0.0099 - val_loss: 0.0069\n",
      "Epoch 25/50\n",
      "546/546 [==============================] - 0s 89us/sample - loss: 0.0097 - val_loss: 0.0066\n",
      "Epoch 26/50\n",
      "546/546 [==============================] - 0s 86us/sample - loss: 0.0098 - val_loss: 0.0066\n",
      "Epoch 27/50\n",
      "546/546 [==============================] - 0s 89us/sample - loss: 0.0098 - val_loss: 0.0066\n",
      "Epoch 28/50\n",
      "546/546 [==============================] - 0s 84us/sample - loss: 0.0098 - val_loss: 0.0066\n",
      "Epoch 29/50\n",
      "546/546 [==============================] - 0s 91us/sample - loss: 0.0097 - val_loss: 0.0066\n",
      "Epoch 30/50\n",
      "546/546 [==============================] - 0s 88us/sample - loss: 0.0098 - val_loss: 0.0066\n",
      "Epoch 31/50\n",
      "546/546 [==============================] - 0s 86us/sample - loss: 0.0098 - val_loss: 0.0066\n",
      "Epoch 32/50\n",
      "546/546 [==============================] - 0s 84us/sample - loss: 0.0098 - val_loss: 0.0066\n",
      "Epoch 33/50\n",
      "546/546 [==============================] - 0s 85us/sample - loss: 0.0098 - val_loss: 0.0067\n",
      "Epoch 34/50\n",
      "546/546 [==============================] - 0s 85us/sample - loss: 0.0102 - val_loss: 0.0069\n",
      "Epoch 35/50\n",
      "546/546 [==============================] - 0s 83us/sample - loss: 0.0098 - val_loss: 0.0066\n",
      "Epoch 36/50\n",
      "546/546 [==============================] - 0s 81us/sample - loss: 0.0102 - val_loss: 0.0069\n",
      "Epoch 37/50\n",
      "546/546 [==============================] - 0s 85us/sample - loss: 0.0105 - val_loss: 0.0071\n",
      "Epoch 38/50\n",
      "546/546 [==============================] - 0s 80us/sample - loss: 0.0097 - val_loss: 0.0066\n",
      "Epoch 39/50\n",
      "546/546 [==============================] - 0s 77us/sample - loss: 0.0099 - val_loss: 0.0067\n",
      "Epoch 40/50\n",
      "546/546 [==============================] - 0s 80us/sample - loss: 0.0099 - val_loss: 0.0066\n",
      "Epoch 41/50\n",
      "546/546 [==============================] - 0s 85us/sample - loss: 0.0101 - val_loss: 0.0068\n",
      "Epoch 42/50\n",
      "546/546 [==============================] - 0s 83us/sample - loss: 0.0098 - val_loss: 0.0070\n",
      "Epoch 43/50\n",
      "546/546 [==============================] - 0s 80us/sample - loss: 0.0099 - val_loss: 0.0067\n",
      "Epoch 44/50\n",
      "546/546 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0067\n",
      "Epoch 45/50\n",
      "546/546 [==============================] - 0s 78us/sample - loss: 0.0098 - val_loss: 0.0067\n",
      "Epoch 46/50\n",
      "546/546 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0066\n",
      "Epoch 47/50\n",
      "546/546 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0069\n",
      "Epoch 48/50\n",
      "546/546 [==============================] - 0s 79us/sample - loss: 0.0098 - val_loss: 0.0069\n",
      "Epoch 49/50\n",
      "546/546 [==============================] - 0s 82us/sample - loss: 0.0099 - val_loss: 0.0066\n",
      "Epoch 50/50\n",
      "546/546 [==============================] - 0s 79us/sample - loss: 0.0100 - val_loss: 0.0068\n",
      "第310个数，还剩3813个没有训练\n",
      "inv_hat [1.01704796 1.01773355 1.01763571 1.01792898 1.01812434 1.01851458\n",
      " 1.01831955 1.01792898 1.01792898 1.01822198 1.01822198 1.01870931\n",
      " 1.01977771 1.02006806 1.02055124 1.02170583 1.02208913 1.02237617\n",
      " 1.02199347 1.02141777 1.02084047 1.01987458 1.01977771 1.02006806\n",
      " 1.02074407 1.02103313 1.0211294  1.02151385 1.02160986 1.0227581 ]\n",
      "Test RMSE: 0.000\n",
      "Train on 831 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "831/831 [==============================] - 0s 77us/sample - loss: 0.0200 - val_loss: 0.0210\n",
      "Epoch 2/50\n",
      "831/831 [==============================] - 0s 75us/sample - loss: 0.0196 - val_loss: 0.0210\n",
      "Epoch 3/50\n",
      "831/831 [==============================] - 0s 84us/sample - loss: 0.0197 - val_loss: 0.0210\n",
      "Epoch 4/50\n",
      "831/831 [==============================] - 0s 83us/sample - loss: 0.0197 - val_loss: 0.0220\n",
      "Epoch 5/50\n",
      "831/831 [==============================] - 0s 81us/sample - loss: 0.0205 - val_loss: 0.0215\n",
      "Epoch 6/50\n",
      "831/831 [==============================] - 0s 79us/sample - loss: 0.0199 - val_loss: 0.0209\n",
      "Epoch 7/50\n",
      "831/831 [==============================] - 0s 86us/sample - loss: 0.0196 - val_loss: 0.0208\n",
      "Epoch 8/50\n",
      "831/831 [==============================] - 0s 78us/sample - loss: 0.0196 - val_loss: 0.0210\n",
      "Epoch 9/50\n",
      "831/831 [==============================] - 0s 80us/sample - loss: 0.0196 - val_loss: 0.0220\n",
      "Epoch 10/50\n",
      "831/831 [==============================] - 0s 79us/sample - loss: 0.0205 - val_loss: 0.0215\n",
      "Epoch 11/50\n",
      "831/831 [==============================] - 0s 80us/sample - loss: 0.0199 - val_loss: 0.0209\n",
      "Epoch 12/50\n",
      "831/831 [==============================] - 0s 78us/sample - loss: 0.0196 - val_loss: 0.0208\n",
      "Epoch 13/50\n",
      "831/831 [==============================] - 0s 79us/sample - loss: 0.0197 - val_loss: 0.0209\n",
      "Epoch 14/50\n",
      "831/831 [==============================] - 0s 77us/sample - loss: 0.0196 - val_loss: 0.0219\n",
      "Epoch 15/50\n",
      "831/831 [==============================] - 0s 78us/sample - loss: 0.0204 - val_loss: 0.0216\n",
      "Epoch 16/50\n",
      "831/831 [==============================] - 0s 78us/sample - loss: 0.0200 - val_loss: 0.0209\n",
      "Epoch 17/50\n",
      "831/831 [==============================] - 0s 78us/sample - loss: 0.0195 - val_loss: 0.0208\n",
      "Epoch 18/50\n",
      "831/831 [==============================] - 0s 79us/sample - loss: 0.0196 - val_loss: 0.0209\n",
      "Epoch 19/50\n",
      "831/831 [==============================] - 0s 80us/sample - loss: 0.0196 - val_loss: 0.0215\n",
      "Epoch 20/50\n",
      "831/831 [==============================] - 0s 78us/sample - loss: 0.0202 - val_loss: 0.0217\n",
      "Epoch 21/50\n",
      "831/831 [==============================] - 0s 74us/sample - loss: 0.0201 - val_loss: 0.0209\n",
      "Epoch 22/50\n",
      "831/831 [==============================] - 0s 81us/sample - loss: 0.0196 - val_loss: 0.0208\n",
      "Epoch 23/50\n",
      "831/831 [==============================] - 0s 78us/sample - loss: 0.0200 - val_loss: 0.0209\n",
      "Epoch 24/50\n",
      "831/831 [==============================] - 0s 80us/sample - loss: 0.0198 - val_loss: 0.0220\n",
      "Epoch 25/50\n",
      "831/831 [==============================] - 0s 84us/sample - loss: 0.0205 - val_loss: 0.0213\n",
      "Epoch 26/50\n",
      "831/831 [==============================] - 0s 80us/sample - loss: 0.0198 - val_loss: 0.0209\n",
      "Epoch 27/50\n",
      "831/831 [==============================] - 0s 83us/sample - loss: 0.0194 - val_loss: 0.0208\n",
      "Epoch 28/50\n",
      "831/831 [==============================] - 0s 79us/sample - loss: 0.0197 - val_loss: 0.0209\n",
      "Epoch 29/50\n",
      "831/831 [==============================] - 0s 81us/sample - loss: 0.0196 - val_loss: 0.0209\n",
      "Epoch 30/50\n",
      "831/831 [==============================] - 0s 79us/sample - loss: 0.0198 - val_loss: 0.0220\n",
      "Epoch 31/50\n",
      "831/831 [==============================] - 0s 79us/sample - loss: 0.0203 - val_loss: 0.0211\n",
      "Epoch 32/50\n",
      "831/831 [==============================] - 0s 82us/sample - loss: 0.0195 - val_loss: 0.0207\n",
      "Epoch 33/50\n",
      "831/831 [==============================] - 0s 83us/sample - loss: 0.0198 - val_loss: 0.0208\n",
      "Epoch 34/50\n",
      "831/831 [==============================] - 0s 80us/sample - loss: 0.0196 - val_loss: 0.0210\n",
      "Epoch 35/50\n",
      "831/831 [==============================] - 0s 78us/sample - loss: 0.0198 - val_loss: 0.0219\n",
      "Epoch 36/50\n",
      "831/831 [==============================] - 0s 74us/sample - loss: 0.0202 - val_loss: 0.0211\n",
      "Epoch 37/50\n",
      "831/831 [==============================] - 0s 82us/sample - loss: 0.0195 - val_loss: 0.0208\n",
      "Epoch 38/50\n",
      "831/831 [==============================] - 0s 78us/sample - loss: 0.0195 - val_loss: 0.0208\n",
      "Epoch 39/50\n",
      "831/831 [==============================] - 0s 80us/sample - loss: 0.0196 - val_loss: 0.0209\n",
      "Epoch 40/50\n",
      "831/831 [==============================] - 0s 80us/sample - loss: 0.0195 - val_loss: 0.0214\n",
      "Epoch 41/50\n",
      "831/831 [==============================] - 0s 83us/sample - loss: 0.0199 - val_loss: 0.0214\n",
      "Epoch 42/50\n",
      "831/831 [==============================] - 0s 81us/sample - loss: 0.0198 - val_loss: 0.0209\n",
      "Epoch 43/50\n",
      "831/831 [==============================] - 0s 83us/sample - loss: 0.0195 - val_loss: 0.0209\n",
      "Epoch 44/50\n",
      "831/831 [==============================] - 0s 80us/sample - loss: 0.0196 - val_loss: 0.0210\n",
      "Epoch 45/50\n",
      "831/831 [==============================] - 0s 80us/sample - loss: 0.0195 - val_loss: 0.0215\n",
      "Epoch 46/50\n",
      "831/831 [==============================] - 0s 83us/sample - loss: 0.0199 - val_loss: 0.0213\n",
      "Epoch 47/50\n",
      "831/831 [==============================] - 0s 84us/sample - loss: 0.0197 - val_loss: 0.0209\n",
      "Epoch 48/50\n",
      "831/831 [==============================] - 0s 81us/sample - loss: 0.0194 - val_loss: 0.0208\n",
      "Epoch 49/50\n",
      "831/831 [==============================] - 0s 80us/sample - loss: 0.0197 - val_loss: 0.0209\n",
      "Epoch 50/50\n",
      "831/831 [==============================] - 0s 78us/sample - loss: 0.0195 - val_loss: 0.0215\n",
      "第311个数，还剩3812个没有训练\n",
      "inv_hat [0.97976543 0.95787731 0.96185513 0.95986601 0.94298731 0.94397818\n",
      " 0.95092225 0.96185513 0.94992951 0.95688324 0.98175485 0.98274938\n",
      " 0.98175485 0.95986601 0.95887163 0.95787731 0.9628499  0.96583454\n",
      " 0.97180525 0.95588931 0.95092225 0.94199676 0.93112523 0.93309815\n",
      " 0.92915414 0.93803797 0.93531258 0.93531258 0.93136554 0.93531258]\n",
      "Test RMSE: 0.010\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0121 - val_loss: 0.0055\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0098 - val_loss: 0.0036\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0107 - val_loss: 0.0045\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0117 - val_loss: 0.0047\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0115 - val_loss: 0.0043\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0107 - val_loss: 0.0040\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0104 - val_loss: 0.0037\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0104 - val_loss: 0.0038\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0105 - val_loss: 0.0039\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0104 - val_loss: 0.0039\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0102 - val_loss: 0.0036\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0101 - val_loss: 0.0036\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0102 - val_loss: 0.0037\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0103 - val_loss: 0.0038\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0103 - val_loss: 0.0037\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0102 - val_loss: 0.0036\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0101 - val_loss: 0.0036\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0102 - val_loss: 0.0037\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0102 - val_loss: 0.0036\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0101 - val_loss: 0.0036\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0101 - val_loss: 0.0036\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0102 - val_loss: 0.0037\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0101 - val_loss: 0.0036\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0100 - val_loss: 0.0036\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0036\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0102 - val_loss: 0.0037\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0102 - val_loss: 0.0036\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0100 - val_loss: 0.0036\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0100 - val_loss: 0.0036\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0101 - val_loss: 0.0036\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0101 - val_loss: 0.0036\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0101 - val_loss: 0.0036\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0036\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0100 - val_loss: 0.0036\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0101 - val_loss: 0.0036\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0036\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0100 - val_loss: 0.0036\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0100 - val_loss: 0.0036\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0036\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0100 - val_loss: 0.0036\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0100 - val_loss: 0.0036\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0100 - val_loss: 0.0036\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0100 - val_loss: 0.0036\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0036\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0100 - val_loss: 0.0036\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0101 - val_loss: 0.0036\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0101 - val_loss: 0.0036\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0100 - val_loss: 0.0036\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0036\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0100 - val_loss: 0.0036\n",
      "第312个数，还剩3811个没有训练\n",
      "inv_hat [0.62304925 0.61180114 0.61247895 0.61063946 0.59865626 0.59740226\n",
      " 0.59836683 0.60570614 0.59942816 0.60483622 0.61839089 0.61819695\n",
      " 0.61732414 0.60754323 0.60686629 0.60329028 0.60570614 0.60812359\n",
      " 0.61393189 0.60464296 0.60193808 0.59759512 0.5920054  0.59036874\n",
      " 0.58632857 0.58882902 0.58661697 0.58555951 0.58190904 0.58402197]\n",
      "Test RMSE: 0.006\n",
      "Train on 1188 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 0.0100 - val_loss: 0.0236\n",
      "Epoch 2/50\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 0.0109 - val_loss: 0.0158\n",
      "Epoch 3/50\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0279\n",
      "Epoch 4/50\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 0.0135 - val_loss: 0.0339\n",
      "Epoch 5/50\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 0.0209 - val_loss: 0.0167\n",
      "Epoch 6/50\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 0.0104 - val_loss: 0.0219\n",
      "Epoch 7/50\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 0.0177 - val_loss: 0.0170\n",
      "Epoch 8/50\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 0.0127 - val_loss: 0.0358\n",
      "Epoch 9/50\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 0.0190 - val_loss: 0.0229\n",
      "Epoch 10/50\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 0.0123 - val_loss: 0.0174\n",
      "Epoch 11/50\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 0.0123 - val_loss: 0.0172\n",
      "Epoch 12/50\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 0.0185 - val_loss: 0.0300\n",
      "Epoch 13/50\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0261\n",
      "Epoch 14/50\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 0.0149 - val_loss: 0.0168\n",
      "Epoch 15/50\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 0.0116 - val_loss: 0.0179\n",
      "Epoch 16/50\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 0.0182 - val_loss: 0.0261\n",
      "Epoch 17/50\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 0.0131 - val_loss: 0.0240\n",
      "Epoch 18/50\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 0.0139 - val_loss: 0.0170\n",
      "Epoch 19/50\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 0.0120 - val_loss: 0.0176\n",
      "Epoch 20/50\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 0.0176 - val_loss: 0.0270\n",
      "Epoch 21/50\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 0.0140 - val_loss: 0.0214\n",
      "Epoch 22/50\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 0.0117 - val_loss: 0.0177\n",
      "Epoch 23/50\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0163\n",
      "Epoch 24/50\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 0.0143 - val_loss: 0.0273\n",
      "Epoch 25/50\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 0.0141 - val_loss: 0.0218\n",
      "Epoch 26/50\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 0.0120 - val_loss: 0.0175\n",
      "Epoch 27/50\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 0.0123 - val_loss: 0.0163\n",
      "Epoch 28/50\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 0.0140 - val_loss: 0.0266\n",
      "Epoch 29/50\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 0.0129 - val_loss: 0.0220\n",
      "Epoch 30/50\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 0.0123 - val_loss: 0.0172\n",
      "Epoch 31/50\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0166\n",
      "Epoch 32/50\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 0.0148 - val_loss: 0.0255\n",
      "Epoch 33/50\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 0.0130 - val_loss: 0.0209\n",
      "Epoch 34/50\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0176\n",
      "Epoch 35/50\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 0.0119 - val_loss: 0.0166\n",
      "Epoch 36/50\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0252\n",
      "Epoch 37/50\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 0.0135 - val_loss: 0.0197\n",
      "Epoch 38/50\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0178\n",
      "Epoch 39/50\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 0.0121 - val_loss: 0.0164\n",
      "Epoch 40/50\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 0.0130 - val_loss: 0.0249\n",
      "Epoch 41/50\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 0.0136 - val_loss: 0.0195\n",
      "Epoch 42/50\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0179\n",
      "Epoch 43/50\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 0.0119 - val_loss: 0.0165\n",
      "Epoch 44/50\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 0.0130 - val_loss: 0.0244\n",
      "Epoch 45/50\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 0.0134 - val_loss: 0.0193\n",
      "Epoch 46/50\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 0.0108 - val_loss: 0.0179\n",
      "Epoch 47/50\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 0.0120 - val_loss: 0.0164\n",
      "Epoch 48/50\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 0.0121 - val_loss: 0.0245\n",
      "Epoch 49/50\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 0.0138 - val_loss: 0.0185\n",
      "Epoch 50/50\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 0.0102 - val_loss: 0.0180\n",
      "第313个数，还剩3810个没有训练\n",
      "inv_hat [0.93166999 0.90204143 0.89606293 0.89191508 0.86276046 0.86056349\n",
      " 0.87076815 0.87598813 0.85478263 0.8570731  0.88575488 0.8851497\n",
      " 0.88111862 0.85179909 0.86136215 0.85120288 0.85597733 0.85100423\n",
      " 0.86435964 0.84624333 0.83824322 0.83342128 0.81894324 0.82040448\n",
      " 0.82391726 0.84189313 0.84515481 0.83814465 0.82763381 0.82704637]\n",
      "Test RMSE: 0.014\n",
      "Train on 958 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "958/958 [==============================] - 0s 77us/sample - loss: 0.0147 - val_loss: 0.0082\n",
      "Epoch 2/50\n",
      "958/958 [==============================] - 0s 82us/sample - loss: 0.0143 - val_loss: 0.0078\n",
      "Epoch 3/50\n",
      "958/958 [==============================] - 0s 80us/sample - loss: 0.0144 - val_loss: 0.0085\n",
      "Epoch 4/50\n",
      "958/958 [==============================] - 0s 80us/sample - loss: 0.0143 - val_loss: 0.0082\n",
      "Epoch 5/50\n",
      "958/958 [==============================] - 0s 86us/sample - loss: 0.0143 - val_loss: 0.0086\n",
      "Epoch 6/50\n",
      "958/958 [==============================] - 0s 83us/sample - loss: 0.0143 - val_loss: 0.0086\n",
      "Epoch 7/50\n",
      "958/958 [==============================] - 0s 84us/sample - loss: 0.0143 - val_loss: 0.0087\n",
      "Epoch 8/50\n",
      "958/958 [==============================] - 0s 84us/sample - loss: 0.0143 - val_loss: 0.0088\n",
      "Epoch 9/50\n",
      "958/958 [==============================] - 0s 82us/sample - loss: 0.0143 - val_loss: 0.0088\n",
      "Epoch 10/50\n",
      "958/958 [==============================] - 0s 78us/sample - loss: 0.0143 - val_loss: 0.0089\n",
      "Epoch 11/50\n",
      "958/958 [==============================] - 0s 83us/sample - loss: 0.0143 - val_loss: 0.0090\n",
      "Epoch 12/50\n",
      "958/958 [==============================] - 0s 84us/sample - loss: 0.0142 - val_loss: 0.0089\n",
      "Epoch 13/50\n",
      "958/958 [==============================] - 0s 77us/sample - loss: 0.0143 - val_loss: 0.0090\n",
      "Epoch 14/50\n",
      "958/958 [==============================] - 0s 78us/sample - loss: 0.0142 - val_loss: 0.0091\n",
      "Epoch 15/50\n",
      "958/958 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0092\n",
      "Epoch 16/50\n",
      "958/958 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0091\n",
      "Epoch 17/50\n",
      "958/958 [==============================] - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0092\n",
      "Epoch 18/50\n",
      "958/958 [==============================] - 0s 78us/sample - loss: 0.0142 - val_loss: 0.0092\n",
      "Epoch 19/50\n",
      "958/958 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0092\n",
      "Epoch 20/50\n",
      "958/958 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0092\n",
      "Epoch 21/50\n",
      "958/958 [==============================] - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0092\n",
      "Epoch 22/50\n",
      "958/958 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0092\n",
      "Epoch 23/50\n",
      "958/958 [==============================] - 0s 86us/sample - loss: 0.0142 - val_loss: 0.0093\n",
      "Epoch 24/50\n",
      "958/958 [==============================] - 0s 84us/sample - loss: 0.0142 - val_loss: 0.0092\n",
      "Epoch 25/50\n",
      "958/958 [==============================] - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0093\n",
      "Epoch 26/50\n",
      "958/958 [==============================] - 0s 80us/sample - loss: 0.0142 - val_loss: 0.0092\n",
      "Epoch 27/50\n",
      "958/958 [==============================] - 0s 79us/sample - loss: 0.0142 - val_loss: 0.0093\n",
      "Epoch 28/50\n",
      "958/958 [==============================] - 0s 78us/sample - loss: 0.0142 - val_loss: 0.0094\n",
      "Epoch 29/50\n",
      "958/958 [==============================] - 0s 79us/sample - loss: 0.0142 - val_loss: 0.0092\n",
      "Epoch 30/50\n",
      "958/958 [==============================] - 0s 84us/sample - loss: 0.0142 - val_loss: 0.0094\n",
      "Epoch 31/50\n",
      "958/958 [==============================] - 0s 88us/sample - loss: 0.0142 - val_loss: 0.0095\n",
      "Epoch 32/50\n",
      "958/958 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0093\n",
      "Epoch 33/50\n",
      "958/958 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0095\n",
      "Epoch 34/50\n",
      "958/958 [==============================] - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0096\n",
      "Epoch 35/50\n",
      "958/958 [==============================] - 0s 80us/sample - loss: 0.0142 - val_loss: 0.0094\n",
      "Epoch 36/50\n",
      "958/958 [==============================] - 0s 79us/sample - loss: 0.0142 - val_loss: 0.0096\n",
      "Epoch 37/50\n",
      "958/958 [==============================] - 0s 80us/sample - loss: 0.0142 - val_loss: 0.0095\n",
      "Epoch 38/50\n",
      "958/958 [==============================] - 0s 80us/sample - loss: 0.0142 - val_loss: 0.0095\n",
      "Epoch 39/50\n",
      "958/958 [==============================] - 0s 77us/sample - loss: 0.0142 - val_loss: 0.0095\n",
      "Epoch 40/50\n",
      "958/958 [==============================] - 0s 75us/sample - loss: 0.0142 - val_loss: 0.0095\n",
      "Epoch 41/50\n",
      "958/958 [==============================] - 0s 79us/sample - loss: 0.0142 - val_loss: 0.0095\n",
      "Epoch 42/50\n",
      "958/958 [==============================] - 0s 78us/sample - loss: 0.0142 - val_loss: 0.0095\n",
      "Epoch 43/50\n",
      "958/958 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0095\n",
      "Epoch 44/50\n",
      "958/958 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0095\n",
      "Epoch 45/50\n",
      "958/958 [==============================] - 0s 80us/sample - loss: 0.0142 - val_loss: 0.0096\n",
      "Epoch 46/50\n",
      "958/958 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0096\n",
      "Epoch 47/50\n",
      "958/958 [==============================] - 0s 86us/sample - loss: 0.0142 - val_loss: 0.0096\n",
      "Epoch 48/50\n",
      "958/958 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0096\n",
      "Epoch 49/50\n",
      "958/958 [==============================] - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0096\n",
      "Epoch 50/50\n",
      "958/958 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0096\n",
      "第314个数，还剩3809个没有训练\n",
      "inv_hat [1.18057783 1.15555508 1.15172442 1.14885481 1.12316455 1.12127164\n",
      " 1.13170025 1.14121705 1.12221799 1.13170025 1.15939091 1.15459688\n",
      " 1.14503321 1.12032577 1.12885186 1.12221799 1.12790307 1.12600663\n",
      " 1.13931097 1.12221799 1.11938015 1.10573103 1.09491906 1.09295752\n",
      " 1.08610244 1.09491906 1.08903831 1.08512458 1.07438973 1.07731331]\n",
      "Test RMSE: 0.014\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0110 - val_loss: 0.0057\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0105 - val_loss: 0.0045\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0106 - val_loss: 0.0045\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0112 - val_loss: 0.0067\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0106 - val_loss: 0.0045\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0108 - val_loss: 0.0044\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0115 - val_loss: 0.0078\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0108 - val_loss: 0.0045\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0045\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0113 - val_loss: 0.0080\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0113 - val_loss: 0.0047\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0112 - val_loss: 0.0054\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0112 - val_loss: 0.0070\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0110 - val_loss: 0.0059\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0112 - val_loss: 0.0055\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0123 - val_loss: 0.0074\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0108 - val_loss: 0.0055\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0049\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0121 - val_loss: 0.0079\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0107 - val_loss: 0.0048\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0108 - val_loss: 0.0046\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0116 - val_loss: 0.0072\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0106 - val_loss: 0.0045\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0107 - val_loss: 0.0044\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0071\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0106 - val_loss: 0.0045\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0044\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0066\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0106 - val_loss: 0.0045\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0106 - val_loss: 0.0045\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0109 - val_loss: 0.0064\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0050\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0106 - val_loss: 0.0047\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0108 - val_loss: 0.0056\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0115 - val_loss: 0.0063\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0050\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0051\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0107 - val_loss: 0.0051\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0047\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0119 - val_loss: 0.0076\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0106 - val_loss: 0.0046\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0108 - val_loss: 0.0044\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0117 - val_loss: 0.0074\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0106 - val_loss: 0.0045\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0108 - val_loss: 0.0044\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0071\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0106 - val_loss: 0.0045\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0107 - val_loss: 0.0044\n",
      "第315个数，还剩3808个没有训练\n",
      "inv_hat [1.23786139 1.21022842 1.2151643  1.21812653 1.18852848 1.1875428\n",
      " 1.19148583 1.20134759 1.18360092 1.18655728 1.21318978 1.21417709\n",
      " 1.20924148 1.19148583 1.18655728 1.17670394 1.18655728 1.18360092\n",
      " 1.19345766 1.17473393 1.17079476 1.16587233 1.15209887 1.15111568\n",
      " 1.14718333 1.15898375 1.15406558 1.15406558 1.14620051 1.14816632]\n",
      "Test RMSE: 0.012\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0066 - val_loss: 0.0015\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0072 - val_loss: 0.0029\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0070 - val_loss: 0.0027\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0013\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0097 - val_loss: 0.0045\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0073 - val_loss: 0.0015\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0066 - val_loss: 0.0019\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0071 - val_loss: 0.0015\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0070 - val_loss: 0.0017\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0079 - val_loss: 0.0020\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0088 - val_loss: 0.0040\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0075 - val_loss: 0.0013\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0067 - val_loss: 0.0017\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0069 - val_loss: 0.0014\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0072 - val_loss: 0.0013\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0077 - val_loss: 0.0020\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0077 - val_loss: 0.0020\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0073 - val_loss: 0.0014\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0070 - val_loss: 0.0013\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0071 - val_loss: 0.0013\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0073 - val_loss: 0.0014\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0073 - val_loss: 0.0015\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0073 - val_loss: 0.0015\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0072 - val_loss: 0.0013\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0071 - val_loss: 0.0013\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0071 - val_loss: 0.0014\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0070 - val_loss: 0.0013\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0069 - val_loss: 0.0013\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0069 - val_loss: 0.0013\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0069 - val_loss: 0.0013\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0069 - val_loss: 0.0013\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0069 - val_loss: 0.0013\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0069 - val_loss: 0.0013\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0069 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0069 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0069 - val_loss: 0.0013\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0068 - val_loss: 0.0013\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0068 - val_loss: 0.0013\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0068 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0068 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0068 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0068 - val_loss: 0.0014\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0068 - val_loss: 0.0014\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0068 - val_loss: 0.0014\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0067 - val_loss: 0.0014\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0066 - val_loss: 0.0014\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0066 - val_loss: 0.0013\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0066 - val_loss: 0.0013\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0071 - val_loss: 0.0021\n",
      "第316个数，还剩3807个没有训练\n",
      "inv_hat [0.35543894 0.35109857 0.35186979 0.35090575 0.34628223 0.34637853\n",
      " 0.34551225 0.34782271 0.34541605 0.34695611 0.35196624 0.35206258\n",
      " 0.35071301 0.34743757 0.34743757 0.34580096 0.34666733 0.34724497\n",
      " 0.35071301 0.34714869 0.34772643 0.34580096 0.34204958 0.33955093\n",
      " 0.3378222  0.33878252 0.33724623 0.33619042 0.33513494 0.33705421]\n",
      "Test RMSE: 0.003\n",
      "Train on 872 samples, validate on 30 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "872/872 [==============================] - 0s 82us/sample - loss: 0.0151 - val_loss: 0.0221\n",
      "Epoch 2/50\n",
      "872/872 [==============================] - 0s 81us/sample - loss: 0.0154 - val_loss: 0.0234\n",
      "Epoch 3/50\n",
      "872/872 [==============================] - 0s 86us/sample - loss: 0.0158 - val_loss: 0.0234\n",
      "Epoch 4/50\n",
      "872/872 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0229\n",
      "Epoch 5/50\n",
      "872/872 [==============================] - 0s 83us/sample - loss: 0.0164 - val_loss: 0.0223\n",
      "Epoch 6/50\n",
      "872/872 [==============================] - 0s 89us/sample - loss: 0.0155 - val_loss: 0.0249\n",
      "Epoch 7/50\n",
      "872/872 [==============================] - 0s 84us/sample - loss: 0.0161 - val_loss: 0.0220\n",
      "Epoch 8/50\n",
      "872/872 [==============================] - 0s 85us/sample - loss: 0.0156 - val_loss: 0.0225\n",
      "Epoch 9/50\n",
      "872/872 [==============================] - 0s 82us/sample - loss: 0.0162 - val_loss: 0.0252\n",
      "Epoch 10/50\n",
      "872/872 [==============================] - 0s 82us/sample - loss: 0.0170 - val_loss: 0.0228\n",
      "Epoch 11/50\n",
      "872/872 [==============================] - 0s 81us/sample - loss: 0.0155 - val_loss: 0.0231\n",
      "Epoch 12/50\n",
      "872/872 [==============================] - 0s 85us/sample - loss: 0.0168 - val_loss: 0.0234\n",
      "Epoch 13/50\n",
      "872/872 [==============================] - 0s 84us/sample - loss: 0.0158 - val_loss: 0.0235\n",
      "Epoch 14/50\n",
      "872/872 [==============================] - 0s 83us/sample - loss: 0.0155 - val_loss: 0.0223\n",
      "Epoch 15/50\n",
      "872/872 [==============================] - 0s 81us/sample - loss: 0.0157 - val_loss: 0.0222\n",
      "Epoch 16/50\n",
      "872/872 [==============================] - 0s 84us/sample - loss: 0.0150 - val_loss: 0.0235\n",
      "Epoch 17/50\n",
      "872/872 [==============================] - 0s 81us/sample - loss: 0.0154 - val_loss: 0.0223\n",
      "Epoch 18/50\n",
      "872/872 [==============================] - 0s 84us/sample - loss: 0.0149 - val_loss: 0.0222\n",
      "Epoch 19/50\n",
      "872/872 [==============================] - 0s 84us/sample - loss: 0.0155 - val_loss: 0.0234\n",
      "Epoch 20/50\n",
      "872/872 [==============================] - 0s 85us/sample - loss: 0.0155 - val_loss: 0.0229\n",
      "Epoch 21/50\n",
      "872/872 [==============================] - 0s 82us/sample - loss: 0.0151 - val_loss: 0.0223\n",
      "Epoch 22/50\n",
      "872/872 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0225\n",
      "Epoch 23/50\n",
      "872/872 [==============================] - 0s 85us/sample - loss: 0.0149 - val_loss: 0.0232\n",
      "Epoch 24/50\n",
      "872/872 [==============================] - 0s 80us/sample - loss: 0.0152 - val_loss: 0.0222\n",
      "Epoch 25/50\n",
      "872/872 [==============================] - 0s 83us/sample - loss: 0.0149 - val_loss: 0.0221\n",
      "Epoch 26/50\n",
      "872/872 [==============================] - 0s 84us/sample - loss: 0.0154 - val_loss: 0.0232\n",
      "Epoch 27/50\n",
      "872/872 [==============================] - 0s 85us/sample - loss: 0.0155 - val_loss: 0.0229\n",
      "Epoch 28/50\n",
      "872/872 [==============================] - 0s 86us/sample - loss: 0.0151 - val_loss: 0.0224\n",
      "Epoch 29/50\n",
      "872/872 [==============================] - 0s 80us/sample - loss: 0.0156 - val_loss: 0.0224\n",
      "Epoch 30/50\n",
      "872/872 [==============================] - 0s 84us/sample - loss: 0.0149 - val_loss: 0.0232\n",
      "Epoch 31/50\n",
      "872/872 [==============================] - 0s 84us/sample - loss: 0.0152 - val_loss: 0.0222\n",
      "Epoch 32/50\n",
      "872/872 [==============================] - 0s 84us/sample - loss: 0.0150 - val_loss: 0.0220\n",
      "Epoch 33/50\n",
      "872/872 [==============================] - 0s 85us/sample - loss: 0.0153 - val_loss: 0.0232\n",
      "Epoch 34/50\n",
      "872/872 [==============================] - 0s 82us/sample - loss: 0.0155 - val_loss: 0.0228\n",
      "Epoch 35/50\n",
      "872/872 [==============================] - 0s 84us/sample - loss: 0.0151 - val_loss: 0.0224\n",
      "Epoch 36/50\n",
      "872/872 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0225\n",
      "Epoch 37/50\n",
      "872/872 [==============================] - 0s 82us/sample - loss: 0.0149 - val_loss: 0.0231\n",
      "Epoch 38/50\n",
      "872/872 [==============================] - 0s 83us/sample - loss: 0.0151 - val_loss: 0.0221\n",
      "Epoch 39/50\n",
      "872/872 [==============================] - 0s 85us/sample - loss: 0.0149 - val_loss: 0.0219\n",
      "Epoch 40/50\n",
      "872/872 [==============================] - 0s 88us/sample - loss: 0.0151 - val_loss: 0.0233\n",
      "Epoch 41/50\n",
      "872/872 [==============================] - 0s 86us/sample - loss: 0.0155 - val_loss: 0.0227\n",
      "Epoch 42/50\n",
      "872/872 [==============================] - 0s 90us/sample - loss: 0.0150 - val_loss: 0.0224\n",
      "Epoch 43/50\n",
      "872/872 [==============================] - 0s 85us/sample - loss: 0.0157 - val_loss: 0.0226\n",
      "Epoch 44/50\n",
      "872/872 [==============================] - 0s 84us/sample - loss: 0.0150 - val_loss: 0.0230\n",
      "Epoch 45/50\n",
      "872/872 [==============================] - 0s 86us/sample - loss: 0.0150 - val_loss: 0.0221\n",
      "Epoch 46/50\n",
      "872/872 [==============================] - 0s 82us/sample - loss: 0.0149 - val_loss: 0.0219\n",
      "Epoch 47/50\n",
      "872/872 [==============================] - 0s 86us/sample - loss: 0.0150 - val_loss: 0.0229\n",
      "Epoch 48/50\n",
      "872/872 [==============================] - 0s 82us/sample - loss: 0.0151 - val_loss: 0.0227\n",
      "Epoch 49/50\n",
      "872/872 [==============================] - 0s 85us/sample - loss: 0.0148 - val_loss: 0.0220\n",
      "Epoch 50/50\n",
      "872/872 [==============================] - 0s 78us/sample - loss: 0.0151 - val_loss: 0.0223\n",
      "第317个数，还剩3806个没有训练\n",
      "inv_hat [1.08973869 1.05469301 1.06773989 1.06071596 1.03661434 1.03159142\n",
      " 1.03761885 1.06874291 1.04465058 1.05569692 1.08077357 1.07977147\n",
      " 1.08377903 1.06171964 1.06573348 1.06673666 1.07876927 1.07676476\n",
      " 1.08775302 1.06874291 1.06272324 1.05168071 1.02757318 1.0346052\n",
      " 1.02656875 1.03058682 1.02154672 1.01953822 1.018534   1.0205424 ]\n",
      "Test RMSE: 0.015\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0119 - val_loss: 0.0068\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0121 - val_loss: 0.0076\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0120 - val_loss: 0.0071\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0119 - val_loss: 0.0070\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0120 - val_loss: 0.0071\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0120 - val_loss: 0.0073\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0120 - val_loss: 0.0073\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 72us/sample - loss: 0.0120 - val_loss: 0.0073\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 72us/sample - loss: 0.0120 - val_loss: 0.0074\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0120 - val_loss: 0.0074\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0120 - val_loss: 0.0074\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0119 - val_loss: 0.0074\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0119 - val_loss: 0.0074\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0120 - val_loss: 0.0075\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0119 - val_loss: 0.0074\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0119 - val_loss: 0.0074\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0119 - val_loss: 0.0074\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0119 - val_loss: 0.0074\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0120 - val_loss: 0.0074\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0120 - val_loss: 0.0074\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0120 - val_loss: 0.0076\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0120 - val_loss: 0.0075\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0120 - val_loss: 0.0077\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0120 - val_loss: 0.0074\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0120 - val_loss: 0.0077\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0120 - val_loss: 0.0075\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0120 - val_loss: 0.0073\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0120 - val_loss: 0.0074\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0120 - val_loss: 0.0076\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0120 - val_loss: 0.0075\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0120 - val_loss: 0.0075\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0120 - val_loss: 0.0074\n",
      "第318个数，还剩3805个没有训练\n",
      "inv_hat [1.27389382 1.25552049 1.25958846 1.25363613 1.23264533 1.23037203\n",
      " 1.2335351  1.24640082 1.2310638  1.23857945 1.2644532  1.26117663\n",
      " 1.25978699 1.23947004 1.23857945 1.2316569  1.24144951 1.24135052\n",
      " 1.2546278  1.23136037 1.22148461 1.21073748 1.19516894 1.19388995\n",
      " 1.18602572 1.19634981 1.19457862 1.18887517 1.18092029 1.18661513]\n",
      "Test RMSE: 0.012\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0113 - val_loss: 0.0037\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0102 - val_loss: 0.0066\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0104 - val_loss: 0.0043\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0131 - val_loss: 0.0111\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0104 - val_loss: 0.0063\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0115 - val_loss: 0.0047\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0113 - val_loss: 0.0040\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0104 - val_loss: 0.0074\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0105 - val_loss: 0.0044\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0119 - val_loss: 0.0091\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0100 - val_loss: 0.0058\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0107 - val_loss: 0.0041\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0112 - val_loss: 0.0092\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0101 - val_loss: 0.0037\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0101 - val_loss: 0.0052\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0055\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0099 - val_loss: 0.0065\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0103 - val_loss: 0.0037\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0113 - val_loss: 0.0085\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0098 - val_loss: 0.0049\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0103 - val_loss: 0.0041\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0108 - val_loss: 0.0080\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0099 - val_loss: 0.0037\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0100 - val_loss: 0.0048\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0100 - val_loss: 0.0059\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0106 - val_loss: 0.0048\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0099 - val_loss: 0.0062\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0101 - val_loss: 0.0041\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0098 - val_loss: 0.0054\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0102 - val_loss: 0.0035\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0107 - val_loss: 0.0077\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0097 - val_loss: 0.0040\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0098 - val_loss: 0.0041\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0099 - val_loss: 0.0051\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0098 - val_loss: 0.0038\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0095 - val_loss: 0.0045\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0097 - val_loss: 0.0039\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0102 - val_loss: 0.0051\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0044\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0097 - val_loss: 0.0036\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0102 - val_loss: 0.0058\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0095 - val_loss: 0.0038\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0097 - val_loss: 0.0041\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0099 - val_loss: 0.0051\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0099 - val_loss: 0.0039\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0095 - val_loss: 0.0045\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0097 - val_loss: 0.0039\n",
      "第319个数，还剩3804个没有训练\n",
      "inv_hat [1.16144669 1.14305566 1.14941158 1.14696662 1.13367387 1.13250164\n",
      " 1.13132938 1.13934121 1.1327946  1.14149157 1.16457931 1.16722302\n",
      " 1.1709446  1.15351997 1.15440054 1.15175903 1.15694454 1.15978267\n",
      " 1.17633021 1.16360025 1.16242551 1.15361784 1.1429579  1.14002539\n",
      " 1.13054814 1.13621405 1.13132938 1.12957141 1.12976679 1.13728899]\n",
      "Test RMSE: 0.010\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0074 - val_loss: 0.0046\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0132 - val_loss: 0.0086\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0130 - val_loss: 0.0204\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0132 - val_loss: 0.0018\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0170 - val_loss: 0.0118\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0148 - val_loss: 0.0154\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0165 - val_loss: 0.0085\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0088 - val_loss: 0.0030\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0106 - val_loss: 0.0127\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0165 - val_loss: 0.0217\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0128 - val_loss: 0.0032\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0092 - val_loss: 0.0099\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0083 - val_loss: 0.0101\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0174 - val_loss: 0.0189\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0080 - val_loss: 0.0093\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0128 - val_loss: 0.0157\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0099 - val_loss: 0.0045\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0150 - val_loss: 0.0160\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0069 - val_loss: 0.0082\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0120 - val_loss: 0.0125\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0097 - val_loss: 0.0022\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0143 - val_loss: 0.0115\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0089\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0107 - val_loss: 0.0068\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0121 - val_loss: 0.0091\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0072 - val_loss: 0.0014\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0093 - val_loss: 0.0075\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0077 - val_loss: 0.0043\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0078 - val_loss: 0.0079\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0135 - val_loss: 0.0195\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0080 - val_loss: 0.0061\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0082 - val_loss: 0.0058\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0131 - val_loss: 0.0134\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0097 - val_loss: 0.0089\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0082 - val_loss: 0.0033\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0127 - val_loss: 0.0124\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0084 - val_loss: 0.0020\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0125 - val_loss: 0.0098\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0062 - val_loss: 0.0036\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0091 - val_loss: 0.0070\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0095 - val_loss: 0.0054\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0107 - val_loss: 0.0079\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0068 - val_loss: 0.0013\n",
      "第320个数，还剩3803个没有训练\n",
      "inv_hat [1.12143273 1.12153466 1.12173854 1.12204423 1.12235004 1.1228596\n",
      " 1.12255392 1.12235004 1.12275766 1.12306348 1.12377694 1.12377694\n",
      " 1.12449038 1.12489812 1.12540768 1.12591721 1.12591721 1.12612107\n",
      " 1.12642676 1.12622301 1.12591721 1.12550961 1.12571337 1.1258153\n",
      " 1.12601917 1.12642676 1.12612107 1.12601917 1.12632496 1.12764968]\n",
      "Test RMSE: 0.000\n",
      "Train on 855 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "855/855 [==============================] - 0s 84us/sample - loss: 0.0107 - val_loss: 0.0028\n",
      "Epoch 2/50\n",
      "855/855 [==============================] - 0s 81us/sample - loss: 0.0173 - val_loss: 0.0203\n",
      "Epoch 3/50\n",
      "855/855 [==============================] - 0s 75us/sample - loss: 0.0132 - val_loss: 0.0094\n",
      "Epoch 4/50\n",
      "855/855 [==============================] - 0s 81us/sample - loss: 0.0100 - val_loss: 0.0074\n",
      "Epoch 5/50\n",
      "855/855 [==============================] - 0s 80us/sample - loss: 0.0130 - val_loss: 0.0028\n",
      "Epoch 6/50\n",
      "855/855 [==============================] - 0s 80us/sample - loss: 0.0131 - val_loss: 0.0179\n",
      "Epoch 7/50\n",
      "855/855 [==============================] - 0s 84us/sample - loss: 0.0123 - val_loss: 0.0073\n",
      "Epoch 8/50\n",
      "855/855 [==============================] - 0s 79us/sample - loss: 0.0097 - val_loss: 0.0068\n",
      "Epoch 9/50\n",
      "855/855 [==============================] - 0s 77us/sample - loss: 0.0123 - val_loss: 0.0024\n",
      "Epoch 10/50\n",
      "855/855 [==============================] - 0s 79us/sample - loss: 0.0125 - val_loss: 0.0169\n",
      "Epoch 11/50\n",
      "855/855 [==============================] - 0s 80us/sample - loss: 0.0129 - val_loss: 6.8333e-04\n",
      "Epoch 12/50\n",
      "855/855 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0017\n",
      "Epoch 13/50\n",
      "855/855 [==============================] - 0s 78us/sample - loss: 0.0144 - val_loss: 0.0149\n",
      "Epoch 14/50\n",
      "855/855 [==============================] - 0s 78us/sample - loss: 0.0130 - val_loss: 0.0038\n",
      "Epoch 15/50\n",
      "855/855 [==============================] - 0s 74us/sample - loss: 0.0111 - val_loss: 0.0020\n",
      "Epoch 16/50\n",
      "855/855 [==============================] - 0s 75us/sample - loss: 0.0136 - val_loss: 0.0155\n",
      "Epoch 17/50\n",
      "855/855 [==============================] - 0s 75us/sample - loss: 0.0134 - val_loss: 0.0041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "855/855 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0015\n",
      "Epoch 19/50\n",
      "855/855 [==============================] - 0s 78us/sample - loss: 0.0118 - val_loss: 0.0124\n",
      "Epoch 20/50\n",
      "855/855 [==============================] - 0s 82us/sample - loss: 0.0117 - val_loss: 0.0022\n",
      "Epoch 21/50\n",
      "855/855 [==============================] - 0s 78us/sample - loss: 0.0108 - val_loss: 0.0028\n",
      "Epoch 22/50\n",
      "855/855 [==============================] - 0s 73us/sample - loss: 0.0126 - val_loss: 0.0152\n",
      "Epoch 23/50\n",
      "855/855 [==============================] - 0s 78us/sample - loss: 0.0127 - val_loss: 0.0021\n",
      "Epoch 24/50\n",
      "855/855 [==============================] - 0s 77us/sample - loss: 0.0101 - val_loss: 2.9732e-04\n",
      "Epoch 25/50\n",
      "855/855 [==============================] - 0s 82us/sample - loss: 0.0115 - val_loss: 0.0083\n",
      "Epoch 26/50\n",
      "855/855 [==============================] - 0s 74us/sample - loss: 0.0102 - val_loss: 0.0018\n",
      "Epoch 27/50\n",
      "855/855 [==============================] - 0s 75us/sample - loss: 0.0101 - val_loss: 0.0107\n",
      "Epoch 28/50\n",
      "855/855 [==============================] - 0s 75us/sample - loss: 0.0127 - val_loss: 0.0021\n",
      "Epoch 29/50\n",
      "855/855 [==============================] - 0s 82us/sample - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 30/50\n",
      "855/855 [==============================] - 0s 82us/sample - loss: 0.0102 - val_loss: 0.0042\n",
      "Epoch 31/50\n",
      "855/855 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0085\n",
      "Epoch 32/50\n",
      "855/855 [==============================] - 0s 75us/sample - loss: 0.0143 - val_loss: 0.0145\n",
      "Epoch 33/50\n",
      "855/855 [==============================] - 0s 76us/sample - loss: 0.0137 - val_loss: 0.0027\n",
      "Epoch 34/50\n",
      "855/855 [==============================] - 0s 79us/sample - loss: 0.0108 - val_loss: 0.0020\n",
      "Epoch 35/50\n",
      "855/855 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 36/50\n",
      "855/855 [==============================] - 0s 78us/sample - loss: 0.0119 - val_loss: 0.0043\n",
      "Epoch 37/50\n",
      "855/855 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0025\n",
      "Epoch 38/50\n",
      "855/855 [==============================] - 0s 84us/sample - loss: 0.0118 - val_loss: 0.0130\n",
      "Epoch 39/50\n",
      "855/855 [==============================] - 0s 81us/sample - loss: 0.0123 - val_loss: 0.0020\n",
      "Epoch 40/50\n",
      "855/855 [==============================] - 0s 82us/sample - loss: 0.0096 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "855/855 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 42/50\n",
      "855/855 [==============================] - 0s 79us/sample - loss: 0.0100 - val_loss: 0.0055\n",
      "Epoch 43/50\n",
      "855/855 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 44/50\n",
      "855/855 [==============================] - 0s 75us/sample - loss: 0.0125 - val_loss: 0.0058\n",
      "Epoch 45/50\n",
      "855/855 [==============================] - 0s 81us/sample - loss: 0.0108 - val_loss: 0.0051\n",
      "Epoch 46/50\n",
      "855/855 [==============================] - 0s 83us/sample - loss: 0.0106 - val_loss: 0.0124\n",
      "Epoch 47/50\n",
      "855/855 [==============================] - 0s 81us/sample - loss: 0.0127 - val_loss: 0.0040\n",
      "Epoch 48/50\n",
      "855/855 [==============================] - 0s 79us/sample - loss: 0.0105 - val_loss: 8.9858e-04\n",
      "Epoch 49/50\n",
      "855/855 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0128\n",
      "Epoch 50/50\n",
      "855/855 [==============================] - 0s 77us/sample - loss: 0.0127 - val_loss: 0.0023\n",
      "第321个数，还剩3802个没有训练\n",
      "inv_hat [0.93035213 0.93035213 0.93035213 0.93035213 0.93035213 0.93035213\n",
      " 0.93035213 0.93035213 0.93035213 0.93035213 0.93035213 0.93035213\n",
      " 0.93035213 0.93035213 0.93035213 0.93035213 0.93035213 0.93035213\n",
      " 0.93035213 0.93035213 0.93035213 0.93035213 0.93035213 0.93035213\n",
      " 0.93035213 0.93035213 0.93035213 0.93035213 0.93035213 0.93035213]\n",
      "Test RMSE: 0.001\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0118 - val_loss: 0.0081\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0118 - val_loss: 0.0083\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0078\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0110 - val_loss: 0.0082\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0079\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0081\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0079\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0081\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0109 - val_loss: 0.0081\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0109 - val_loss: 0.0080\n",
      "第322个数，还剩3801个没有训练\n",
      "inv_hat [1.22750583 1.20099997 1.20626253 1.20675892 1.17209938 1.17031206\n",
      " 1.17348939 1.18650023 1.16812753 1.17686493 1.20705687 1.21261657\n",
      " 1.20795045 1.18938068 1.18799016 1.17597142 1.18113613 1.18312288\n",
      " 1.19285688 1.17150367 1.17150367 1.16653883 1.1546203  1.15511709\n",
      " 1.14627523 1.15263359 1.14130704 1.13713321 1.12699484 1.13156742]\n",
      "Test RMSE: 0.014\n",
      "Train on 835 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "835/835 [==============================] - 0s 81us/sample - loss: 0.0287 - val_loss: 0.0512\n",
      "Epoch 2/50\n",
      "835/835 [==============================] - 0s 82us/sample - loss: 0.0281 - val_loss: 0.0471\n",
      "Epoch 3/50\n",
      "835/835 [==============================] - 0s 80us/sample - loss: 0.0277 - val_loss: 0.0476\n",
      "Epoch 4/50\n",
      "835/835 [==============================] - 0s 78us/sample - loss: 0.0275 - val_loss: 0.0469\n",
      "Epoch 5/50\n",
      "835/835 [==============================] - 0s 77us/sample - loss: 0.0274 - val_loss: 0.0467\n",
      "Epoch 6/50\n",
      "835/835 [==============================] - 0s 79us/sample - loss: 0.0274 - val_loss: 0.0467\n",
      "Epoch 7/50\n",
      "835/835 [==============================] - 0s 87us/sample - loss: 0.0274 - val_loss: 0.0467\n",
      "Epoch 8/50\n",
      "835/835 [==============================] - 0s 82us/sample - loss: 0.0274 - val_loss: 0.0466\n",
      "Epoch 9/50\n",
      "835/835 [==============================] - 0s 80us/sample - loss: 0.0274 - val_loss: 0.0466\n",
      "Epoch 10/50\n",
      "835/835 [==============================] - 0s 82us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 11/50\n",
      "835/835 [==============================] - 0s 80us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 12/50\n",
      "835/835 [==============================] - 0s 81us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 13/50\n",
      "835/835 [==============================] - 0s 82us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 14/50\n",
      "835/835 [==============================] - 0s 77us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 15/50\n",
      "835/835 [==============================] - 0s 78us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 16/50\n",
      "835/835 [==============================] - 0s 73us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 17/50\n",
      "835/835 [==============================] - 0s 77us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 18/50\n",
      "835/835 [==============================] - 0s 79us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 19/50\n",
      "835/835 [==============================] - 0s 77us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 20/50\n",
      "835/835 [==============================] - 0s 79us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 21/50\n",
      "835/835 [==============================] - 0s 82us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 22/50\n",
      "835/835 [==============================] - 0s 78us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 23/50\n",
      "835/835 [==============================] - 0s 82us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 24/50\n",
      "835/835 [==============================] - 0s 80us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 25/50\n",
      "835/835 [==============================] - 0s 84us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 26/50\n",
      "835/835 [==============================] - 0s 83us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 27/50\n",
      "835/835 [==============================] - 0s 82us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 28/50\n",
      "835/835 [==============================] - 0s 80us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 29/50\n",
      "835/835 [==============================] - 0s 80us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 30/50\n",
      "835/835 [==============================] - 0s 81us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 31/50\n",
      "835/835 [==============================] - 0s 82us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 32/50\n",
      "835/835 [==============================] - 0s 79us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 33/50\n",
      "835/835 [==============================] - 0s 79us/sample - loss: 0.0274 - val_loss: 0.0466\n",
      "Epoch 34/50\n",
      "835/835 [==============================] - 0s 82us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 35/50\n",
      "835/835 [==============================] - 0s 81us/sample - loss: 0.0274 - val_loss: 0.0466\n",
      "Epoch 36/50\n",
      "835/835 [==============================] - 0s 79us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 37/50\n",
      "835/835 [==============================] - 0s 78us/sample - loss: 0.0274 - val_loss: 0.0466\n",
      "Epoch 38/50\n",
      "835/835 [==============================] - 0s 82us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 39/50\n",
      "835/835 [==============================] - 0s 79us/sample - loss: 0.0274 - val_loss: 0.0466\n",
      "Epoch 40/50\n",
      "835/835 [==============================] - 0s 83us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 41/50\n",
      "835/835 [==============================] - 0s 75us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 42/50\n",
      "835/835 [==============================] - 0s 81us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 43/50\n",
      "835/835 [==============================] - 0s 79us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 44/50\n",
      "835/835 [==============================] - 0s 78us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 45/50\n",
      "835/835 [==============================] - 0s 82us/sample - loss: 0.0274 - val_loss: 0.0466\n",
      "Epoch 46/50\n",
      "835/835 [==============================] - 0s 81us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 47/50\n",
      "835/835 [==============================] - 0s 85us/sample - loss: 0.0274 - val_loss: 0.0466\n",
      "Epoch 48/50\n",
      "835/835 [==============================] - 0s 82us/sample - loss: 0.0274 - val_loss: 0.0465\n",
      "Epoch 49/50\n",
      "835/835 [==============================] - 0s 81us/sample - loss: 0.0274 - val_loss: 0.0466\n",
      "Epoch 50/50\n",
      "835/835 [==============================] - 0s 83us/sample - loss: 0.0274 - val_loss: 0.0466\n",
      "第323个数，还剩3800个没有训练\n",
      "inv_hat [0.64288095 1.00359218 1.00654666 0.98352012 0.95087881 0.93241655\n",
      " 0.92851349 0.92753699 0.90893118 0.91187459 0.92851349 0.94506354\n",
      " 0.94020656 0.92753699 0.93241655 0.92558294 0.92656009 0.92851349\n",
      " 0.93923409 0.92021434 0.92530333 0.91187459 0.90500381 0.90402151\n",
      " 0.90107378 0.90205647 0.88041275 0.87745961 0.87352236 0.87549087]\n",
      "Test RMSE: 0.066\n",
      "Train on 482 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "482/482 [==============================] - 0s 85us/sample - loss: 0.0104 - val_loss: 0.0207\n",
      "Epoch 2/50\n",
      "482/482 [==============================] - 0s 84us/sample - loss: 0.0098 - val_loss: 0.0167\n",
      "Epoch 3/50\n",
      "482/482 [==============================] - 0s 80us/sample - loss: 0.0091 - val_loss: 0.0159\n",
      "Epoch 4/50\n",
      "482/482 [==============================] - 0s 79us/sample - loss: 0.0095 - val_loss: 0.0159\n",
      "Epoch 5/50\n",
      "482/482 [==============================] - 0s 84us/sample - loss: 0.0091 - val_loss: 0.0157\n",
      "Epoch 6/50\n",
      "482/482 [==============================] - 0s 85us/sample - loss: 0.0092 - val_loss: 0.0158\n",
      "Epoch 7/50\n",
      "482/482 [==============================] - 0s 83us/sample - loss: 0.0090 - val_loss: 0.0160\n",
      "Epoch 8/50\n",
      "482/482 [==============================] - 0s 83us/sample - loss: 0.0090 - val_loss: 0.0160\n",
      "Epoch 9/50\n",
      "482/482 [==============================] - 0s 82us/sample - loss: 0.0089 - val_loss: 0.0158\n",
      "Epoch 10/50\n",
      "482/482 [==============================] - 0s 85us/sample - loss: 0.0090 - val_loss: 0.0160\n",
      "Epoch 11/50\n",
      "482/482 [==============================] - 0s 80us/sample - loss: 0.0090 - val_loss: 0.0158\n",
      "Epoch 12/50\n",
      "482/482 [==============================] - 0s 88us/sample - loss: 0.0089 - val_loss: 0.0158\n",
      "Epoch 13/50\n",
      "482/482 [==============================] - 0s 90us/sample - loss: 0.0089 - val_loss: 0.0158\n",
      "Epoch 14/50\n",
      "482/482 [==============================] - 0s 85us/sample - loss: 0.0090 - val_loss: 0.0158\n",
      "Epoch 15/50\n",
      "482/482 [==============================] - 0s 83us/sample - loss: 0.0089 - val_loss: 0.0158\n",
      "Epoch 16/50\n",
      "482/482 [==============================] - 0s 82us/sample - loss: 0.0089 - val_loss: 0.0158\n",
      "Epoch 17/50\n",
      "482/482 [==============================] - 0s 84us/sample - loss: 0.0089 - val_loss: 0.0157\n",
      "Epoch 18/50\n",
      "482/482 [==============================] - 0s 82us/sample - loss: 0.0089 - val_loss: 0.0157\n",
      "Epoch 19/50\n",
      "482/482 [==============================] - 0s 82us/sample - loss: 0.0090 - val_loss: 0.0157\n",
      "Epoch 20/50\n",
      "482/482 [==============================] - 0s 87us/sample - loss: 0.0089 - val_loss: 0.0157\n",
      "Epoch 21/50\n",
      "482/482 [==============================] - 0s 80us/sample - loss: 0.0089 - val_loss: 0.0158\n",
      "Epoch 22/50\n",
      "482/482 [==============================] - 0s 81us/sample - loss: 0.0089 - val_loss: 0.0157\n",
      "Epoch 23/50\n",
      "482/482 [==============================] - 0s 84us/sample - loss: 0.0089 - val_loss: 0.0157\n",
      "Epoch 24/50\n",
      "482/482 [==============================] - 0s 82us/sample - loss: 0.0089 - val_loss: 0.0158\n",
      "Epoch 25/50\n",
      "482/482 [==============================] - 0s 82us/sample - loss: 0.0089 - val_loss: 0.0158\n",
      "Epoch 26/50\n",
      "482/482 [==============================] - 0s 79us/sample - loss: 0.0089 - val_loss: 0.0158\n",
      "Epoch 27/50\n",
      "482/482 [==============================] - 0s 83us/sample - loss: 0.0089 - val_loss: 0.0157\n",
      "Epoch 28/50\n",
      "482/482 [==============================] - 0s 86us/sample - loss: 0.0088 - val_loss: 0.0157\n",
      "Epoch 29/50\n",
      "482/482 [==============================] - 0s 85us/sample - loss: 0.0088 - val_loss: 0.0157\n",
      "Epoch 30/50\n",
      "482/482 [==============================] - 0s 84us/sample - loss: 0.0089 - val_loss: 0.0158\n",
      "Epoch 31/50\n",
      "482/482 [==============================] - 0s 90us/sample - loss: 0.0089 - val_loss: 0.0158\n",
      "Epoch 32/50\n",
      "482/482 [==============================] - 0s 85us/sample - loss: 0.0089 - val_loss: 0.0157\n",
      "Epoch 33/50\n",
      "482/482 [==============================] - 0s 90us/sample - loss: 0.0089 - val_loss: 0.0158\n",
      "Epoch 34/50\n",
      "482/482 [==============================] - 0s 87us/sample - loss: 0.0088 - val_loss: 0.0157\n",
      "Epoch 35/50\n",
      "482/482 [==============================] - 0s 84us/sample - loss: 0.0089 - val_loss: 0.0157\n",
      "Epoch 36/50\n",
      "482/482 [==============================] - 0s 84us/sample - loss: 0.0090 - val_loss: 0.0157\n",
      "Epoch 37/50\n",
      "482/482 [==============================] - 0s 85us/sample - loss: 0.0089 - val_loss: 0.0158\n",
      "Epoch 38/50\n",
      "482/482 [==============================] - 0s 87us/sample - loss: 0.0089 - val_loss: 0.0158\n",
      "Epoch 39/50\n",
      "482/482 [==============================] - 0s 88us/sample - loss: 0.0089 - val_loss: 0.0157\n",
      "Epoch 40/50\n",
      "482/482 [==============================] - 0s 88us/sample - loss: 0.0089 - val_loss: 0.0157\n",
      "Epoch 41/50\n",
      "482/482 [==============================] - 0s 86us/sample - loss: 0.0089 - val_loss: 0.0158\n",
      "Epoch 42/50\n",
      "482/482 [==============================] - 0s 80us/sample - loss: 0.0088 - val_loss: 0.0157\n",
      "Epoch 43/50\n",
      "482/482 [==============================] - 0s 87us/sample - loss: 0.0089 - val_loss: 0.0158\n",
      "Epoch 44/50\n",
      "482/482 [==============================] - 0s 82us/sample - loss: 0.0088 - val_loss: 0.0157\n",
      "Epoch 45/50\n",
      "482/482 [==============================] - 0s 84us/sample - loss: 0.0088 - val_loss: 0.0157\n",
      "Epoch 46/50\n",
      "482/482 [==============================] - 0s 86us/sample - loss: 0.0089 - val_loss: 0.0157\n",
      "Epoch 47/50\n",
      "482/482 [==============================] - 0s 89us/sample - loss: 0.0089 - val_loss: 0.0157\n",
      "Epoch 48/50\n",
      "482/482 [==============================] - 0s 84us/sample - loss: 0.0089 - val_loss: 0.0158\n",
      "Epoch 49/50\n",
      "482/482 [==============================] - 0s 80us/sample - loss: 0.0089 - val_loss: 0.0157\n",
      "Epoch 50/50\n",
      "482/482 [==============================] - 0s 85us/sample - loss: 0.0089 - val_loss: 0.0158\n",
      "第324个数，还剩3799个没有训练\n",
      "inv_hat [1.05141658 1.05103742 1.05122714 1.05094248 1.05075249 1.05056243\n",
      " 1.05075249 1.05113229 1.05198418 1.05226727 1.04183784 1.04350936\n",
      " 1.04429244 1.04487817 1.04497569 1.04614263 1.04643355 1.04643355\n",
      " 1.04419466 1.04350936 1.04223208 1.04203503 1.04350936 1.04507316\n",
      " 1.04478062 1.04439017 1.04526788 1.04604558 1.04768986 1.05008625]\n",
      "Test RMSE: 0.002\n",
      "Train on 685 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "685/685 [==============================] - 0s 78us/sample - loss: 0.0052 - val_loss: 0.0086\n",
      "Epoch 2/50\n",
      "685/685 [==============================] - 0s 78us/sample - loss: 0.0062 - val_loss: 0.0073\n",
      "Epoch 3/50\n",
      "685/685 [==============================] - 0s 77us/sample - loss: 0.0092 - val_loss: 0.0089\n",
      "Epoch 4/50\n",
      "685/685 [==============================] - 0s 81us/sample - loss: 0.0054 - val_loss: 0.0096\n",
      "Epoch 5/50\n",
      "685/685 [==============================] - 0s 80us/sample - loss: 0.0050 - val_loss: 0.0071\n",
      "Epoch 6/50\n",
      "685/685 [==============================] - 0s 84us/sample - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 7/50\n",
      "685/685 [==============================] - 0s 79us/sample - loss: 0.0060 - val_loss: 0.0055\n",
      "Epoch 8/50\n",
      "685/685 [==============================] - 0s 76us/sample - loss: 0.0049 - val_loss: 0.0080\n",
      "Epoch 9/50\n",
      "685/685 [==============================] - 0s 82us/sample - loss: 0.0050 - val_loss: 0.0072\n",
      "Epoch 10/50\n",
      "685/685 [==============================] - 0s 78us/sample - loss: 0.0046 - val_loss: 0.0058\n",
      "Epoch 11/50\n",
      "685/685 [==============================] - 0s 80us/sample - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 12/50\n",
      "685/685 [==============================] - 0s 77us/sample - loss: 0.0058 - val_loss: 0.0065\n",
      "Epoch 13/50\n",
      "685/685 [==============================] - 0s 80us/sample - loss: 0.0080 - val_loss: 0.0095\n",
      "Epoch 14/50\n",
      "685/685 [==============================] - 0s 82us/sample - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 15/50\n",
      "685/685 [==============================] - 0s 87us/sample - loss: 0.0055 - val_loss: 0.0069\n",
      "Epoch 16/50\n",
      "685/685 [==============================] - 0s 83us/sample - loss: 0.0072 - val_loss: 0.0089\n",
      "Epoch 17/50\n",
      "685/685 [==============================] - 0s 85us/sample - loss: 0.0060 - val_loss: 0.0055\n",
      "Epoch 18/50\n",
      "685/685 [==============================] - 0s 82us/sample - loss: 0.0051 - val_loss: 0.0073\n",
      "Epoch 19/50\n",
      "685/685 [==============================] - 0s 82us/sample - loss: 0.0067 - val_loss: 0.0095\n",
      "Epoch 20/50\n",
      "685/685 [==============================] - 0s 79us/sample - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 21/50\n",
      "685/685 [==============================] - 0s 77us/sample - loss: 0.0050 - val_loss: 0.0076\n",
      "Epoch 22/50\n",
      "685/685 [==============================] - 0s 78us/sample - loss: 0.0065 - val_loss: 0.0091\n",
      "Epoch 23/50\n",
      "685/685 [==============================] - 0s 76us/sample - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 24/50\n",
      "685/685 [==============================] - 0s 77us/sample - loss: 0.0058 - val_loss: 0.0063\n",
      "Epoch 25/50\n",
      "685/685 [==============================] - 0s 79us/sample - loss: 0.0066 - val_loss: 0.0093\n",
      "Epoch 26/50\n",
      "685/685 [==============================] - 0s 83us/sample - loss: 0.0062 - val_loss: 0.0067\n",
      "Epoch 27/50\n",
      "685/685 [==============================] - 0s 80us/sample - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 28/50\n",
      "685/685 [==============================] - 0s 86us/sample - loss: 0.0067 - val_loss: 0.0079\n",
      "Epoch 29/50\n",
      "685/685 [==============================] - 0s 85us/sample - loss: 0.0055 - val_loss: 0.0066\n",
      "Epoch 30/50\n",
      "685/685 [==============================] - 0s 87us/sample - loss: 0.0066 - val_loss: 0.0095\n",
      "Epoch 31/50\n",
      "685/685 [==============================] - 0s 85us/sample - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 32/50\n",
      "685/685 [==============================] - 0s 77us/sample - loss: 0.0056 - val_loss: 0.0066\n",
      "Epoch 33/50\n",
      "685/685 [==============================] - 0s 78us/sample - loss: 0.0077 - val_loss: 0.0097\n",
      "Epoch 34/50\n",
      "685/685 [==============================] - 0s 79us/sample - loss: 0.0058 - val_loss: 0.0063\n",
      "Epoch 35/50\n",
      "685/685 [==============================] - 0s 78us/sample - loss: 0.0071 - val_loss: 0.0058\n",
      "Epoch 36/50\n",
      "685/685 [==============================] - 0s 82us/sample - loss: 0.0066 - val_loss: 0.0071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "685/685 [==============================] - 0s 80us/sample - loss: 0.0049 - val_loss: 0.0073\n",
      "Epoch 38/50\n",
      "685/685 [==============================] - 0s 82us/sample - loss: 0.0048 - val_loss: 0.0066\n",
      "Epoch 39/50\n",
      "685/685 [==============================] - 0s 81us/sample - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 40/50\n",
      "685/685 [==============================] - 0s 80us/sample - loss: 0.0072 - val_loss: 0.0091\n",
      "Epoch 41/50\n",
      "685/685 [==============================] - 0s 82us/sample - loss: 0.0049 - val_loss: 0.0082\n",
      "Epoch 42/50\n",
      "685/685 [==============================] - 0s 82us/sample - loss: 0.0047 - val_loss: 0.0065\n",
      "Epoch 43/50\n",
      "685/685 [==============================] - 0s 78us/sample - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 44/50\n",
      "685/685 [==============================] - 0s 79us/sample - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 45/50\n",
      "685/685 [==============================] - 0s 82us/sample - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 46/50\n",
      "685/685 [==============================] - 0s 78us/sample - loss: 0.0047 - val_loss: 0.0058\n",
      "Epoch 47/50\n",
      "685/685 [==============================] - 0s 76us/sample - loss: 0.0052 - val_loss: 0.0060\n",
      "Epoch 48/50\n",
      "685/685 [==============================] - 0s 86us/sample - loss: 0.0064 - val_loss: 0.0085\n",
      "Epoch 49/50\n",
      "685/685 [==============================] - 0s 77us/sample - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 50/50\n",
      "685/685 [==============================] - 0s 78us/sample - loss: 0.0071 - val_loss: 0.0085\n",
      "第325个数，还剩3798个没有训练\n",
      "inv_hat [1.09372621 1.09274956 1.09274956 1.09274956 1.09274956 1.09274956\n",
      " 1.09274956 1.09274956 1.09372621 1.09372621 1.09372621 1.09567075\n",
      " 1.09663857 1.09663857 1.09663857 1.09663857 1.09760354 1.09760354\n",
      " 1.09567075 1.09469987 1.09372621 1.09372621 1.09372621 1.09469987\n",
      " 1.09469987 1.09469987 1.09469987 1.09567075 1.09663857 1.09856546]\n",
      "Test RMSE: 0.001\n",
      "Train on 643 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "643/643 [==============================] - 0s 82us/sample - loss: 0.0233 - val_loss: 0.0209\n",
      "Epoch 2/50\n",
      "643/643 [==============================] - 0s 83us/sample - loss: 0.0229 - val_loss: 0.0213\n",
      "Epoch 3/50\n",
      "643/643 [==============================] - 0s 78us/sample - loss: 0.0229 - val_loss: 0.0221\n",
      "Epoch 4/50\n",
      "643/643 [==============================] - 0s 76us/sample - loss: 0.0228 - val_loss: 0.0214\n",
      "Epoch 5/50\n",
      "643/643 [==============================] - 0s 76us/sample - loss: 0.0228 - val_loss: 0.0207\n",
      "Epoch 6/50\n",
      "643/643 [==============================] - ETA: 0s - loss: 0.024 - 0s 79us/sample - loss: 0.0228 - val_loss: 0.0204\n",
      "Epoch 7/50\n",
      "643/643 [==============================] - 0s 74us/sample - loss: 0.0227 - val_loss: 0.0201\n",
      "Epoch 8/50\n",
      "643/643 [==============================] - ETA: 0s - loss: 0.024 - 0s 75us/sample - loss: 0.0227 - val_loss: 0.0198\n",
      "Epoch 9/50\n",
      "643/643 [==============================] - 0s 76us/sample - loss: 0.0228 - val_loss: 0.0197\n",
      "Epoch 10/50\n",
      "643/643 [==============================] - 0s 78us/sample - loss: 0.0227 - val_loss: 0.0196\n",
      "Epoch 11/50\n",
      "643/643 [==============================] - 0s 75us/sample - loss: 0.0227 - val_loss: 0.0194\n",
      "Epoch 12/50\n",
      "643/643 [==============================] - 0s 76us/sample - loss: 0.0227 - val_loss: 0.0192\n",
      "Epoch 13/50\n",
      "643/643 [==============================] - 0s 78us/sample - loss: 0.0228 - val_loss: 0.0193\n",
      "Epoch 14/50\n",
      "643/643 [==============================] - 0s 82us/sample - loss: 0.0227 - val_loss: 0.0193\n",
      "Epoch 15/50\n",
      "643/643 [==============================] - 0s 82us/sample - loss: 0.0227 - val_loss: 0.0192\n",
      "Epoch 16/50\n",
      "643/643 [==============================] - 0s 80us/sample - loss: 0.0227 - val_loss: 0.0191\n",
      "Epoch 17/50\n",
      "643/643 [==============================] - 0s 80us/sample - loss: 0.0227 - val_loss: 0.0191\n",
      "Epoch 18/50\n",
      "643/643 [==============================] - 0s 87us/sample - loss: 0.0227 - val_loss: 0.0191\n",
      "Epoch 19/50\n",
      "643/643 [==============================] - 0s 82us/sample - loss: 0.0227 - val_loss: 0.0191\n",
      "Epoch 20/50\n",
      "643/643 [==============================] - 0s 84us/sample - loss: 0.0227 - val_loss: 0.0191\n",
      "Epoch 21/50\n",
      "643/643 [==============================] - 0s 74us/sample - loss: 0.0227 - val_loss: 0.0192\n",
      "Epoch 22/50\n",
      "643/643 [==============================] - 0s 75us/sample - loss: 0.0227 - val_loss: 0.0192\n",
      "Epoch 23/50\n",
      "643/643 [==============================] - 0s 74us/sample - loss: 0.0227 - val_loss: 0.0193\n",
      "Epoch 24/50\n",
      "643/643 [==============================] - 0s 73us/sample - loss: 0.0227 - val_loss: 0.0193\n",
      "Epoch 25/50\n",
      "643/643 [==============================] - 0s 73us/sample - loss: 0.0227 - val_loss: 0.0194\n",
      "Epoch 26/50\n",
      "643/643 [==============================] - 0s 78us/sample - loss: 0.0227 - val_loss: 0.0194\n",
      "Epoch 27/50\n",
      "643/643 [==============================] - ETA: 0s - loss: 0.024 - 0s 81us/sample - loss: 0.0227 - val_loss: 0.0195\n",
      "Epoch 28/50\n",
      "643/643 [==============================] - 0s 81us/sample - loss: 0.0227 - val_loss: 0.0196\n",
      "Epoch 29/50\n",
      "643/643 [==============================] - 0s 81us/sample - loss: 0.0227 - val_loss: 0.0197\n",
      "Epoch 30/50\n",
      "643/643 [==============================] - 0s 80us/sample - loss: 0.0227 - val_loss: 0.0198\n",
      "Epoch 31/50\n",
      "643/643 [==============================] - 0s 78us/sample - loss: 0.0227 - val_loss: 0.0198\n",
      "Epoch 32/50\n",
      "643/643 [==============================] - 0s 80us/sample - loss: 0.0227 - val_loss: 0.0199\n",
      "Epoch 33/50\n",
      "643/643 [==============================] - 0s 77us/sample - loss: 0.0227 - val_loss: 0.0199\n",
      "Epoch 34/50\n",
      "643/643 [==============================] - 0s 77us/sample - loss: 0.0227 - val_loss: 0.0199\n",
      "Epoch 35/50\n",
      "643/643 [==============================] - 0s 76us/sample - loss: 0.0227 - val_loss: 0.0198\n",
      "Epoch 36/50\n",
      "643/643 [==============================] - 0s 76us/sample - loss: 0.0227 - val_loss: 0.0199\n",
      "Epoch 37/50\n",
      "643/643 [==============================] - 0s 75us/sample - loss: 0.0227 - val_loss: 0.0199\n",
      "Epoch 38/50\n",
      "643/643 [==============================] - 0s 75us/sample - loss: 0.0227 - val_loss: 0.0199\n",
      "Epoch 39/50\n",
      "643/643 [==============================] - 0s 79us/sample - loss: 0.0227 - val_loss: 0.0199\n",
      "Epoch 40/50\n",
      "643/643 [==============================] - 0s 79us/sample - loss: 0.0227 - val_loss: 0.0200\n",
      "Epoch 41/50\n",
      "643/643 [==============================] - 0s 82us/sample - loss: 0.0227 - val_loss: 0.0200\n",
      "Epoch 42/50\n",
      "643/643 [==============================] - 0s 82us/sample - loss: 0.0227 - val_loss: 0.0201\n",
      "Epoch 43/50\n",
      "643/643 [==============================] - 0s 76us/sample - loss: 0.0227 - val_loss: 0.0201\n",
      "Epoch 44/50\n",
      "643/643 [==============================] - 0s 80us/sample - loss: 0.0227 - val_loss: 0.0202\n",
      "Epoch 45/50\n",
      "643/643 [==============================] - 0s 75us/sample - loss: 0.0227 - val_loss: 0.0201\n",
      "Epoch 46/50\n",
      "643/643 [==============================] - 0s 74us/sample - loss: 0.0227 - val_loss: 0.0202\n",
      "Epoch 47/50\n",
      "643/643 [==============================] - 0s 76us/sample - loss: 0.0227 - val_loss: 0.0202\n",
      "Epoch 48/50\n",
      "643/643 [==============================] - 0s 75us/sample - loss: 0.0227 - val_loss: 0.0202\n",
      "Epoch 49/50\n",
      "643/643 [==============================] - 0s 75us/sample - loss: 0.0227 - val_loss: 0.0203\n",
      "Epoch 50/50\n",
      "643/643 [==============================] - 0s 75us/sample - loss: 0.0227 - val_loss: 0.0204\n",
      "第326个数，还剩3797个没有训练\n",
      "inv_hat [1.47578113 1.44391298 1.44199533 1.43624814 1.40587577 1.40587577\n",
      " 1.4049344  1.42670627 1.40587577 1.41910761 1.44391298 1.44199533\n",
      " 1.43624814 1.42100424 1.41816    1.40776056 1.41816    1.42195338\n",
      " 1.43911973 1.41910761 1.41437294 1.4049344  1.38623592 1.38716463\n",
      " 1.37606488 1.38067759 1.37330584 1.36689398 1.36051944 1.36051944]\n",
      "Test RMSE: 0.016\n",
      "Train on 724 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "724/724 [==============================] - 0s 82us/sample - loss: 0.0077 - val_loss: 0.0055\n",
      "Epoch 2/50\n",
      "724/724 [==============================] - 0s 81us/sample - loss: 0.0075 - val_loss: 0.0043\n",
      "Epoch 3/50\n",
      "724/724 [==============================] - 0s 80us/sample - loss: 0.0074 - val_loss: 0.0059\n",
      "Epoch 4/50\n",
      "724/724 [==============================] - 0s 80us/sample - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 5/50\n",
      "724/724 [==============================] - 0s 79us/sample - loss: 0.0087 - val_loss: 0.0066\n",
      "Epoch 6/50\n",
      "724/724 [==============================] - 0s 84us/sample - loss: 0.0086 - val_loss: 0.0056\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "724/724 [==============================] - 0s 83us/sample - loss: 0.0081 - val_loss: 0.0049\n",
      "Epoch 8/50\n",
      "724/724 [==============================] - 0s 84us/sample - loss: 0.0082 - val_loss: 0.0054\n",
      "Epoch 9/50\n",
      "724/724 [==============================] - 0s 80us/sample - loss: 0.0094 - val_loss: 0.0035\n",
      "Epoch 10/50\n",
      "724/724 [==============================] - 0s 79us/sample - loss: 0.0089 - val_loss: 0.0058\n",
      "Epoch 11/50\n",
      "724/724 [==============================] - 0s 89us/sample - loss: 0.0079 - val_loss: 0.0064\n",
      "Epoch 12/50\n",
      "724/724 [==============================] - 0s 83us/sample - loss: 0.0089 - val_loss: 0.0060\n",
      "Epoch 13/50\n",
      "724/724 [==============================] - 0s 82us/sample - loss: 0.0093 - val_loss: 0.0051\n",
      "Epoch 14/50\n",
      "724/724 [==============================] - 0s 83us/sample - loss: 0.0075 - val_loss: 0.0052\n",
      "Epoch 15/50\n",
      "724/724 [==============================] - 0s 83us/sample - loss: 0.0076 - val_loss: 0.0043\n",
      "Epoch 16/50\n",
      "724/724 [==============================] - 0s 84us/sample - loss: 0.0076 - val_loss: 0.0041\n",
      "Epoch 17/50\n",
      "724/724 [==============================] - 0s 85us/sample - loss: 0.0075 - val_loss: 0.0054\n",
      "Epoch 18/50\n",
      "724/724 [==============================] - 0s 83us/sample - loss: 0.0074 - val_loss: 0.0051\n",
      "Epoch 19/50\n",
      "724/724 [==============================] - 0s 86us/sample - loss: 0.0072 - val_loss: 0.0050\n",
      "Epoch 20/50\n",
      "724/724 [==============================] - 0s 84us/sample - loss: 0.0074 - val_loss: 0.0041\n",
      "Epoch 21/50\n",
      "724/724 [==============================] - 0s 83us/sample - loss: 0.0073 - val_loss: 0.0047\n",
      "Epoch 22/50\n",
      "724/724 [==============================] - 0s 82us/sample - loss: 0.0077 - val_loss: 0.0040\n",
      "Epoch 23/50\n",
      "724/724 [==============================] - 0s 91us/sample - loss: 0.0073 - val_loss: 0.0043\n",
      "Epoch 24/50\n",
      "724/724 [==============================] - 0s 84us/sample - loss: 0.0073 - val_loss: 0.0040\n",
      "Epoch 25/50\n",
      "724/724 [==============================] - 0s 84us/sample - loss: 0.0076 - val_loss: 0.0035\n",
      "Epoch 26/50\n",
      "724/724 [==============================] - 0s 90us/sample - loss: 0.0074 - val_loss: 0.0054\n",
      "Epoch 27/50\n",
      "724/724 [==============================] - 0s 85us/sample - loss: 0.0075 - val_loss: 0.0063\n",
      "Epoch 28/50\n",
      "724/724 [==============================] - 0s 84us/sample - loss: 0.0079 - val_loss: 0.0066\n",
      "Epoch 29/50\n",
      "724/724 [==============================] - 0s 81us/sample - loss: 0.0082 - val_loss: 0.0054\n",
      "Epoch 30/50\n",
      "724/724 [==============================] - 0s 83us/sample - loss: 0.0080 - val_loss: 0.0053\n",
      "Epoch 31/50\n",
      "724/724 [==============================] - 0s 82us/sample - loss: 0.0088 - val_loss: 0.0036\n",
      "Epoch 32/50\n",
      "724/724 [==============================] - 0s 83us/sample - loss: 0.0085 - val_loss: 0.0051\n",
      "Epoch 33/50\n",
      "724/724 [==============================] - 0s 84us/sample - loss: 0.0075 - val_loss: 0.0077\n",
      "Epoch 34/50\n",
      "724/724 [==============================] - 0s 90us/sample - loss: 0.0081 - val_loss: 0.0063\n",
      "Epoch 35/50\n",
      "724/724 [==============================] - 0s 90us/sample - loss: 0.0079 - val_loss: 0.0042\n",
      "Epoch 36/50\n",
      "724/724 [==============================] - 0s 83us/sample - loss: 0.0076 - val_loss: 0.0042\n",
      "Epoch 37/50\n",
      "724/724 [==============================] - 0s 84us/sample - loss: 0.0075 - val_loss: 0.0053\n",
      "Epoch 38/50\n",
      "724/724 [==============================] - 0s 87us/sample - loss: 0.0073 - val_loss: 0.0039\n",
      "Epoch 39/50\n",
      "724/724 [==============================] - 0s 84us/sample - loss: 0.0077 - val_loss: 0.0039\n",
      "Epoch 40/50\n",
      "724/724 [==============================] - 0s 81us/sample - loss: 0.0076 - val_loss: 0.0039\n",
      "Epoch 41/50\n",
      "724/724 [==============================] - 0s 85us/sample - loss: 0.0084 - val_loss: 0.0041\n",
      "Epoch 42/50\n",
      "724/724 [==============================] - 0s 87us/sample - loss: 0.0078 - val_loss: 0.0057\n",
      "Epoch 43/50\n",
      "724/724 [==============================] - 0s 88us/sample - loss: 0.0077 - val_loss: 0.0064\n",
      "Epoch 44/50\n",
      "724/724 [==============================] - 0s 90us/sample - loss: 0.0079 - val_loss: 0.0043\n",
      "Epoch 45/50\n",
      "724/724 [==============================] - 0s 84us/sample - loss: 0.0074 - val_loss: 0.0053\n",
      "Epoch 46/50\n",
      "724/724 [==============================] - 0s 82us/sample - loss: 0.0073 - val_loss: 0.0035\n",
      "Epoch 47/50\n",
      "724/724 [==============================] - 0s 83us/sample - loss: 0.0075 - val_loss: 0.0041\n",
      "Epoch 48/50\n",
      "724/724 [==============================] - 0s 87us/sample - loss: 0.0073 - val_loss: 0.0039\n",
      "Epoch 49/50\n",
      "724/724 [==============================] - 0s 83us/sample - loss: 0.0078 - val_loss: 0.0045\n",
      "Epoch 50/50\n",
      "724/724 [==============================] - 0s 80us/sample - loss: 0.0075 - val_loss: 0.0046\n",
      "第327个数，还剩3796个没有训练\n",
      "inv_hat [1.1210773  1.12128127 1.12128127 1.11037138 1.11037138 1.11037138\n",
      " 1.11037138 1.11037138 1.11037138 1.11037138 1.11037138 1.11037138\n",
      " 1.11136371 1.11136371 1.11136371 1.11235614 1.11235614 1.11235614\n",
      " 1.11235614 1.11136371 1.11136371 1.11037138 1.11037138 1.11037138\n",
      " 1.11136371 1.11136371 1.11136371 1.11235614 1.11235614 1.11434072]\n",
      "Test RMSE: 0.002\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0091 - val_loss: 0.0047\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0091 - val_loss: 0.0057\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0090 - val_loss: 0.0053\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0090 - val_loss: 0.0048\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0090 - val_loss: 0.0049\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0090 - val_loss: 0.0048\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0090 - val_loss: 0.0049\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0090 - val_loss: 0.0046\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0090 - val_loss: 0.0046\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0090 - val_loss: 0.0046\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0090 - val_loss: 0.0042\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0089 - val_loss: 0.0042\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0090 - val_loss: 0.0044\n",
      "第328个数，还剩3795个没有训练\n",
      "inv_hat [0.57478778 0.55896499 0.55995208 0.55600518 0.54222316 0.53927651\n",
      " 0.5402585  0.54910787 0.53927651 0.5451722  0.55896499 0.56587982\n",
      " 0.56192699 0.54910787 0.54812352 0.5432059  0.54615571 0.5451722\n",
      " 0.55403327 0.5432059  0.54418893 0.53535148 0.53241052 0.53143076\n",
      " 0.52458009 0.52067158 0.51384285 0.50897394 0.50702842 0.51189438]\n",
      "Test RMSE: 0.007\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0114 - val_loss: 0.0089\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0101 - val_loss: 0.0087\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0110 - val_loss: 0.0071\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0085 - val_loss: 0.0032\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0094 - val_loss: 0.0055\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0089 - val_loss: 0.0039\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0021\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0080 - val_loss: 0.0022\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0080 - val_loss: 0.0022\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0080 - val_loss: 0.0021\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0081 - val_loss: 0.0023\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0080 - val_loss: 0.0021\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0080 - val_loss: 0.0022\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0081 - val_loss: 0.0020\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0082 - val_loss: 0.0022\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0088 - val_loss: 0.0036\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0100 - val_loss: 0.0040\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0087 - val_loss: 0.0022\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0089 - val_loss: 0.0063\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0098 - val_loss: 0.0070\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0100 - val_loss: 0.0062\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0083 - val_loss: 0.0024\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0091 - val_loss: 0.0046\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0035\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0082 - val_loss: 0.0021\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0087 - val_loss: 0.0052\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0099 - val_loss: 0.0064\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0091 - val_loss: 0.0054\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0084 - val_loss: 0.0021\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0090 - val_loss: 0.0040\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0090 - val_loss: 0.0034\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0082 - val_loss: 0.0025\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0092 - val_loss: 0.0060\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0099 - val_loss: 0.0052\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0083 - val_loss: 0.0026\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0087 - val_loss: 0.0034\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0089 - val_loss: 0.0035\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0082 - val_loss: 0.0022\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0082 - val_loss: 0.0032\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0088 - val_loss: 0.0054\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0095 - val_loss: 0.0055\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0084 - val_loss: 0.0033\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0085 - val_loss: 0.0030\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0087 - val_loss: 0.0036\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0084 - val_loss: 0.0026\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0081 - val_loss: 0.0026\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0085 - val_loss: 0.0049\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0094 - val_loss: 0.0056\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0086 - val_loss: 0.0041\n",
      "第329个数，还剩3794个没有训练\n",
      "inv_hat [0.66080445 0.6521022  0.65113704 0.65017216 0.6443889  0.6443889\n",
      " 0.6453521  0.65017216 0.64631552 0.64727924 0.65403342 0.65403342\n",
      " 0.65499943 0.65306764 0.65403342 0.6521022  0.65113704 0.65017216\n",
      " 0.65499943 0.65113704 0.64920759 0.64727924 0.64342607 0.64053936\n",
      " 0.63957767 0.64246354 0.64246354 0.6415013  0.63765529 0.63669457]\n",
      "Test RMSE: 0.005\n",
      "Train on 573 samples, validate on 30 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573/573 [==============================] - 0s 78us/sample - loss: 0.0141 - val_loss: 0.0312\n",
      "Epoch 2/50\n",
      "573/573 [==============================] - 0s 78us/sample - loss: 0.0137 - val_loss: 0.0254\n",
      "Epoch 3/50\n",
      "573/573 [==============================] - 0s 85us/sample - loss: 0.0130 - val_loss: 0.0268\n",
      "Epoch 4/50\n",
      "573/573 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0245\n",
      "Epoch 5/50\n",
      "573/573 [==============================] - 0s 75us/sample - loss: 0.0121 - val_loss: 0.0254\n",
      "Epoch 6/50\n",
      "573/573 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0238\n",
      "Epoch 7/50\n",
      "573/573 [==============================] - 0s 78us/sample - loss: 0.0108 - val_loss: 0.0229\n",
      "Epoch 8/50\n",
      "573/573 [==============================] - 0s 79us/sample - loss: 0.0100 - val_loss: 0.0226\n",
      "Epoch 9/50\n",
      "573/573 [==============================] - 0s 80us/sample - loss: 0.0099 - val_loss: 0.0228\n",
      "Epoch 10/50\n",
      "573/573 [==============================] - 0s 83us/sample - loss: 0.0098 - val_loss: 0.0230\n",
      "Epoch 11/50\n",
      "573/573 [==============================] - 0s 79us/sample - loss: 0.0098 - val_loss: 0.0232\n",
      "Epoch 12/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0100 - val_loss: 0.0232\n",
      "Epoch 13/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0103 - val_loss: 0.0226\n",
      "Epoch 14/50\n",
      "573/573 [==============================] - 0s 79us/sample - loss: 0.0100 - val_loss: 0.0226\n",
      "Epoch 15/50\n",
      "573/573 [==============================] - 0s 79us/sample - loss: 0.0097 - val_loss: 0.0230\n",
      "Epoch 16/50\n",
      "573/573 [==============================] - 0s 86us/sample - loss: 0.0098 - val_loss: 0.0231\n",
      "Epoch 17/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0098 - val_loss: 0.0232\n",
      "Epoch 18/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0100 - val_loss: 0.0230\n",
      "Epoch 19/50\n",
      "573/573 [==============================] - 0s 79us/sample - loss: 0.0099 - val_loss: 0.0233\n",
      "Epoch 20/50\n",
      "573/573 [==============================] - 0s 79us/sample - loss: 0.0107 - val_loss: 0.0235\n",
      "Epoch 21/50\n",
      "573/573 [==============================] - 0s 76us/sample - loss: 0.0099 - val_loss: 0.0227\n",
      "Epoch 22/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0098 - val_loss: 0.0228\n",
      "Epoch 23/50\n",
      "573/573 [==============================] - 0s 78us/sample - loss: 0.0098 - val_loss: 0.0230\n",
      "Epoch 24/50\n",
      "573/573 [==============================] - 0s 76us/sample - loss: 0.0100 - val_loss: 0.0231\n",
      "Epoch 25/50\n",
      "573/573 [==============================] - 0s 83us/sample - loss: 0.0102 - val_loss: 0.0225\n",
      "Epoch 26/50\n",
      "573/573 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0230\n",
      "Epoch 27/50\n",
      "573/573 [==============================] - 0s 77us/sample - loss: 0.0100 - val_loss: 0.0227\n",
      "Epoch 28/50\n",
      "573/573 [==============================] - 0s 80us/sample - loss: 0.0099 - val_loss: 0.0231\n",
      "Epoch 29/50\n",
      "573/573 [==============================] - 0s 80us/sample - loss: 0.0102 - val_loss: 0.0226\n",
      "Epoch 30/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0098 - val_loss: 0.0229\n",
      "Epoch 31/50\n",
      "573/573 [==============================] - 0s 82us/sample - loss: 0.0099 - val_loss: 0.0232\n",
      "Epoch 32/50\n",
      "573/573 [==============================] - 0s 82us/sample - loss: 0.0103 - val_loss: 0.0226\n",
      "Epoch 33/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0100 - val_loss: 0.0227\n",
      "Epoch 34/50\n",
      "573/573 [==============================] - 0s 85us/sample - loss: 0.0098 - val_loss: 0.0227\n",
      "Epoch 35/50\n",
      "573/573 [==============================] - 0s 76us/sample - loss: 0.0097 - val_loss: 0.0228\n",
      "Epoch 36/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0098 - val_loss: 0.0231\n",
      "Epoch 37/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0099 - val_loss: 0.0230\n",
      "Epoch 38/50\n",
      "573/573 [==============================] - 0s 79us/sample - loss: 0.0099 - val_loss: 0.0231\n",
      "Epoch 39/50\n",
      "573/573 [==============================] - 0s 77us/sample - loss: 0.0105 - val_loss: 0.0235\n",
      "Epoch 40/50\n",
      "573/573 [==============================] - 0s 80us/sample - loss: 0.0099 - val_loss: 0.0225\n",
      "Epoch 41/50\n",
      "573/573 [==============================] - 0s 82us/sample - loss: 0.0097 - val_loss: 0.0228\n",
      "Epoch 42/50\n",
      "573/573 [==============================] - 0s 81us/sample - loss: 0.0099 - val_loss: 0.0230\n",
      "Epoch 43/50\n",
      "573/573 [==============================] - 0s 78us/sample - loss: 0.0101 - val_loss: 0.0227\n",
      "Epoch 44/50\n",
      "573/573 [==============================] - 0s 75us/sample - loss: 0.0099 - val_loss: 0.0227\n",
      "Epoch 45/50\n",
      "573/573 [==============================] - 0s 77us/sample - loss: 0.0098 - val_loss: 0.0232\n",
      "Epoch 46/50\n",
      "573/573 [==============================] - 0s 77us/sample - loss: 0.0103 - val_loss: 0.0228\n",
      "Epoch 47/50\n",
      "573/573 [==============================] - 0s 77us/sample - loss: 0.0099 - val_loss: 0.0227\n",
      "Epoch 48/50\n",
      "573/573 [==============================] - 0s 76us/sample - loss: 0.0097 - val_loss: 0.0229\n",
      "Epoch 49/50\n",
      "573/573 [==============================] - 0s 75us/sample - loss: 0.0098 - val_loss: 0.0229\n",
      "Epoch 50/50\n",
      "573/573 [==============================] - 0s 76us/sample - loss: 0.0098 - val_loss: 0.0231\n",
      "第330个数，还剩3793个没有训练\n",
      "inv_hat [1.0093746  1.00947403 1.00957345 1.00957345 1.00977224 1.00987175\n",
      " 1.00997128 1.00997128 1.01007084 1.01027004 1.01036968 1.01036968\n",
      " 1.01046936 1.01056894 1.01076843 1.01076843 1.01086822 1.01096804\n",
      " 1.01096804 1.01116752 1.01126715 1.01136694 1.01166655 1.01176651\n",
      " 1.01176651 1.01186651 1.01196644 1.01216667 1.01216667 1.01226687]\n",
      "Test RMSE: 0.002\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0086\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0088\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0088\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0088\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0088\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "第331个数，还剩3792个没有训练\n",
      "inv_hat [1.41136429 1.38612487 1.3865223  1.38334329 1.35077107 1.33538629\n",
      " 1.34134129 1.35355056 1.33141649 1.33717279 1.36169138 1.36983454\n",
      " 1.36566331 1.34769388 1.3520615  1.34769388 1.34858728 1.34858728\n",
      " 1.36040062 1.33598171 1.33171416 1.32317977 1.30859406 1.31087604\n",
      " 1.30512167 1.32218752 1.32317977 1.32238592 1.31544007 1.31355491]\n",
      "Test RMSE: 0.013\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0081 - val_loss: 0.0048\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0082 - val_loss: 0.0047\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0081 - val_loss: 0.0048\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0081 - val_loss: 0.0048\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0081 - val_loss: 0.0048\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0081 - val_loss: 0.0047\n",
      "第332个数，还剩3791个没有训练\n",
      "inv_hat [0.89999876 0.88834072 0.89162709 0.88883857 0.86906687 0.865697\n",
      " 0.86728261 0.877896   0.86658887 0.87362878 0.89840349 0.89840349\n",
      " 0.89730689 0.88127492 0.88356307 0.87402564 0.88107595 0.87988249\n",
      " 0.88923681 0.87749895 0.8725376  0.86609337 0.85342194 0.85263079\n",
      " 0.84640428 0.85312525 0.85609266 0.85757693 0.85411423 0.85846769]\n",
      "Test RMSE: 0.009\n",
      "Train on 564 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "564/564 [==============================] - 0s 75us/sample - loss: 0.0189 - val_loss: 0.0280\n",
      "Epoch 2/50\n",
      "564/564 [==============================] - 0s 77us/sample - loss: 0.0195 - val_loss: 0.0266\n",
      "Epoch 3/50\n",
      "564/564 [==============================] - 0s 77us/sample - loss: 0.0187 - val_loss: 0.0266\n",
      "Epoch 4/50\n",
      "564/564 [==============================] - 0s 76us/sample - loss: 0.0187 - val_loss: 0.0272\n",
      "Epoch 5/50\n",
      "564/564 [==============================] - 0s 76us/sample - loss: 0.0187 - val_loss: 0.0284\n",
      "Epoch 6/50\n",
      "564/564 [==============================] - 0s 78us/sample - loss: 0.0193 - val_loss: 0.0272\n",
      "Epoch 7/50\n",
      "564/564 [==============================] - 0s 75us/sample - loss: 0.0186 - val_loss: 0.0265\n",
      "Epoch 8/50\n",
      "564/564 [==============================] - 0s 75us/sample - loss: 0.0189 - val_loss: 0.0274\n",
      "Epoch 9/50\n",
      "564/564 [==============================] - 0s 81us/sample - loss: 0.0187 - val_loss: 0.0277\n",
      "Epoch 10/50\n",
      "564/564 [==============================] - 0s 82us/sample - loss: 0.0187 - val_loss: 0.0267\n",
      "Epoch 11/50\n",
      "564/564 [==============================] - 0s 87us/sample - loss: 0.0191 - val_loss: 0.0287\n",
      "Epoch 12/50\n",
      "564/564 [==============================] - 0s 83us/sample - loss: 0.0196 - val_loss: 0.0275\n",
      "Epoch 13/50\n",
      "564/564 [==============================] - 0s 81us/sample - loss: 0.0187 - val_loss: 0.0280\n",
      "Epoch 14/50\n",
      "564/564 [==============================] - 0s 80us/sample - loss: 0.0187 - val_loss: 0.0283\n",
      "Epoch 15/50\n",
      "564/564 [==============================] - 0s 82us/sample - loss: 0.0187 - val_loss: 0.0279\n",
      "Epoch 16/50\n",
      "564/564 [==============================] - 0s 83us/sample - loss: 0.0186 - val_loss: 0.0277\n",
      "Epoch 17/50\n",
      "564/564 [==============================] - 0s 81us/sample - loss: 0.0186 - val_loss: 0.0271\n",
      "Epoch 18/50\n",
      "564/564 [==============================] - 0s 81us/sample - loss: 0.0188 - val_loss: 0.0281\n",
      "Epoch 19/50\n",
      "564/564 [==============================] - 0s 82us/sample - loss: 0.0188 - val_loss: 0.0281\n",
      "Epoch 20/50\n",
      "564/564 [==============================] - 0s 80us/sample - loss: 0.0186 - val_loss: 0.0276\n",
      "Epoch 21/50\n",
      "564/564 [==============================] - 0s 81us/sample - loss: 0.0187 - val_loss: 0.0286\n",
      "Epoch 22/50\n",
      "564/564 [==============================] - 0s 76us/sample - loss: 0.0189 - val_loss: 0.0279\n",
      "Epoch 23/50\n",
      "564/564 [==============================] - 0s 76us/sample - loss: 0.0185 - val_loss: 0.0278\n",
      "Epoch 24/50\n",
      "564/564 [==============================] - 0s 75us/sample - loss: 0.0186 - val_loss: 0.0283\n",
      "Epoch 25/50\n",
      "564/564 [==============================] - 0s 79us/sample - loss: 0.0186 - val_loss: 0.0287\n",
      "Epoch 26/50\n",
      "564/564 [==============================] - 0s 84us/sample - loss: 0.0187 - val_loss: 0.0283\n",
      "Epoch 27/50\n",
      "564/564 [==============================] - 0s 80us/sample - loss: 0.0185 - val_loss: 0.0278\n",
      "Epoch 28/50\n",
      "564/564 [==============================] - 0s 77us/sample - loss: 0.0187 - val_loss: 0.0288\n",
      "Epoch 29/50\n",
      "564/564 [==============================] - 0s 77us/sample - loss: 0.0189 - val_loss: 0.0280\n",
      "Epoch 30/50\n",
      "564/564 [==============================] - 0s 79us/sample - loss: 0.0185 - val_loss: 0.0279\n",
      "Epoch 31/50\n",
      "564/564 [==============================] - 0s 87us/sample - loss: 0.0186 - val_loss: 0.0288\n",
      "Epoch 32/50\n",
      "564/564 [==============================] - 0s 83us/sample - loss: 0.0188 - val_loss: 0.0282\n",
      "Epoch 33/50\n",
      "564/564 [==============================] - 0s 80us/sample - loss: 0.0185 - val_loss: 0.0281\n",
      "Epoch 34/50\n",
      "564/564 [==============================] - 0s 83us/sample - loss: 0.0186 - val_loss: 0.0290\n",
      "Epoch 35/50\n",
      "564/564 [==============================] - 0s 81us/sample - loss: 0.0188 - val_loss: 0.0282\n",
      "Epoch 36/50\n",
      "564/564 [==============================] - 0s 85us/sample - loss: 0.0185 - val_loss: 0.0278\n",
      "Epoch 37/50\n",
      "564/564 [==============================] - 0s 80us/sample - loss: 0.0186 - val_loss: 0.0284\n",
      "Epoch 38/50\n",
      "564/564 [==============================] - 0s 83us/sample - loss: 0.0186 - val_loss: 0.0285\n",
      "Epoch 39/50\n",
      "564/564 [==============================] - 0s 79us/sample - loss: 0.0185 - val_loss: 0.0279\n",
      "Epoch 40/50\n",
      "564/564 [==============================] - 0s 80us/sample - loss: 0.0188 - val_loss: 0.0294\n",
      "Epoch 41/50\n",
      "564/564 [==============================] - 0s 79us/sample - loss: 0.0190 - val_loss: 0.0280\n",
      "Epoch 42/50\n",
      "564/564 [==============================] - 0s 79us/sample - loss: 0.0189 - val_loss: 0.0293\n",
      "Epoch 43/50\n",
      "564/564 [==============================] - 0s 82us/sample - loss: 0.0189 - val_loss: 0.0281\n",
      "Epoch 44/50\n",
      "564/564 [==============================] - 0s 84us/sample - loss: 0.0188 - val_loss: 0.0291\n",
      "Epoch 45/50\n",
      "564/564 [==============================] - 0s 81us/sample - loss: 0.0188 - val_loss: 0.0279\n",
      "Epoch 46/50\n",
      "564/564 [==============================] - 0s 79us/sample - loss: 0.0188 - val_loss: 0.0290\n",
      "Epoch 47/50\n",
      "564/564 [==============================] - 0s 74us/sample - loss: 0.0189 - val_loss: 0.0280\n",
      "Epoch 48/50\n",
      "564/564 [==============================] - 0s 78us/sample - loss: 0.0187 - val_loss: 0.0288\n",
      "Epoch 49/50\n",
      "564/564 [==============================] - 0s 81us/sample - loss: 0.0187 - val_loss: 0.0286\n",
      "Epoch 50/50\n",
      "564/564 [==============================] - 0s 77us/sample - loss: 0.0186 - val_loss: 0.0283\n",
      "第333个数，还剩3790个没有训练\n",
      "inv_hat [0.96837867 0.94769386 0.9496483  0.94476934 0.92457973 0.91985713\n",
      " 0.92363229 0.93508927 0.9217418  0.92743019 0.94769386 0.95062691\n",
      " 0.94671806 0.92838306 0.92743019 0.92268633 0.92838306 0.9302928\n",
      " 0.94088417 0.92552851 0.91797838 0.911452   0.90227071 0.90045588\n",
      " 0.8986485  0.90500667 0.90227071 0.8986485  0.89505656 0.8977476 ]\n",
      "Test RMSE: 0.010\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0125 - val_loss: 0.0083\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0125 - val_loss: 0.0088\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0079\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0124 - val_loss: 0.0083\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0126 - val_loss: 0.0089\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0125 - val_loss: 0.0079\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0124 - val_loss: 0.0081\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0125 - val_loss: 0.0089\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0081\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0125 - val_loss: 0.0092\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0126 - val_loss: 0.0081\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0124 - val_loss: 0.0078\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0125 - val_loss: 0.0091\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0127 - val_loss: 0.0084\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0124 - val_loss: 0.0078\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0124 - val_loss: 0.0091\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0127 - val_loss: 0.0086\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0124 - val_loss: 0.0078\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0125 - val_loss: 0.0093\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0087\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0124 - val_loss: 0.0078\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0125 - val_loss: 0.0091\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0130 - val_loss: 0.0090\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0124 - val_loss: 0.0078\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0125 - val_loss: 0.0090\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0130 - val_loss: 0.0093\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0124 - val_loss: 0.0078\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0125 - val_loss: 0.0088\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0129 - val_loss: 0.0094\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0124 - val_loss: 0.0078\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0125 - val_loss: 0.0087\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0078\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0125 - val_loss: 0.0085\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0129 - val_loss: 0.0095\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0125 - val_loss: 0.0078\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0125 - val_loss: 0.0084\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0079\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0124 - val_loss: 0.0082\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0126 - val_loss: 0.0096\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0126 - val_loss: 0.0079\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0124 - val_loss: 0.0081\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0126 - val_loss: 0.0095\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0126 - val_loss: 0.0080\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0125 - val_loss: 0.0093\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0127 - val_loss: 0.0082\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0124 - val_loss: 0.0079\n",
      "第334个数，还剩3789个没有训练\n",
      "inv_hat [0.95343373 0.92737942 0.92938937 0.92737942 0.9043409  0.90234442\n",
      " 0.9013466  0.91734528 0.9013466  0.91233814 0.94247792 0.94146961\n",
      " 0.93743899 0.91333902 0.91233814 0.89835483 0.9043409  0.90733779\n",
      " 0.92336271 0.90533963 0.9013466  0.89138433 0.88046037 0.87946916\n",
      " 0.86463934 0.86957447 0.86463934 0.85872825 0.85184757 0.85577729]\n",
      "Test RMSE: 0.012\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0086 - val_loss: 0.0049\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0100 - val_loss: 0.0026\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0115 - val_loss: 0.0013\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0168 - val_loss: 0.0132\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0180 - val_loss: 0.0210\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0169 - val_loss: 0.0111\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0106 - val_loss: 0.0055\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0138 - val_loss: 0.0074\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0177 - val_loss: 0.0135\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0140 - val_loss: 0.0102\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0122 - val_loss: 0.0014\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0147 - val_loss: 0.0056\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0033\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0127 - val_loss: 0.0093\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0108 - val_loss: 0.0013\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0131 - val_loss: 0.0057\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0148 - val_loss: 0.0044\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0096 - val_loss: 0.0012\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0092 - val_loss: 0.0043\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0129 - val_loss: 0.0046\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0097 - val_loss: 0.0018\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0098 - val_loss: 0.0013\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0105 - val_loss: 0.0057\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0021\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0106 - val_loss: 0.0050\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0016\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0102 - val_loss: 0.0044\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0126 - val_loss: 0.0034\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0087 - val_loss: 0.0013\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0085 - val_loss: 0.0023\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0097 - val_loss: 0.0033\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0098 - val_loss: 0.0019\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0102 - val_loss: 0.0038\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0088 - val_loss: 0.0038\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0107 - val_loss: 0.0037\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0114 - val_loss: 0.0068\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0103 - val_loss: 0.0030\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0102 - val_loss: 0.0024\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0120 - val_loss: 0.0025\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0085 - val_loss: 0.0011\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0085 - val_loss: 0.0017\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 86us/sample - loss: 0.0093 - val_loss: 0.0045\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0098 - val_loss: 0.0023\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0100 - val_loss: 0.0038\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0088 - val_loss: 0.0033\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0105 - val_loss: 0.0031\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0104 - val_loss: 0.0045\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0091 - val_loss: 0.0015\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0090 - val_loss: 0.0032\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0112 - val_loss: 0.0027\n",
      "第335个数，还剩3788个没有训练\n",
      "inv_hat [1.10825162 1.10825162 1.10926349 1.10926349 1.10926349 1.10825162\n",
      " 1.10825162 1.10723972 1.10825162 1.10825162 1.10825162 1.10926349\n",
      " 1.11027521 1.11027521 1.11027521 1.11027521 1.11128701 1.11128701\n",
      " 1.11128701 1.11027521 1.10926349 1.10825162 1.10825162 1.10926349\n",
      " 1.10926349 1.10926349 1.11027521 1.11027521 1.11027521 1.11128701]\n",
      "Test RMSE: 0.001\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0115 - val_loss: 0.0047\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0112 - val_loss: 0.0047\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0048\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0047\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0049\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0047\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0049\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0049\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0049\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0110 - val_loss: 0.0049\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0049\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0049\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0110 - val_loss: 0.0049\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0049\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0049\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0049\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0110 - val_loss: 0.0049\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0049\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0049\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0110 - val_loss: 0.0049\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0110 - val_loss: 0.0049\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0049\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0049\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0048\n",
      "第336个数，还剩3787个没有训练\n",
      "inv_hat [1.02851173 1.00884472 1.01179108 1.00688128 0.98630193 0.9872803\n",
      " 0.98923754 1.0029561  0.99217467 0.99805312 1.01670461 1.01965446\n",
      " 1.01965446 1.00001387 0.99903345 0.9911955  0.99707299 1.00001387\n",
      " 1.01277343 0.99609301 0.98923754 0.98043493 0.96464404 0.96464404\n",
      " 0.95673786 0.96464404 0.96068914 0.95673786 0.95180392 0.95575062]\n",
      "Test RMSE: 0.011\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0058\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0057\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0112 - val_loss: 0.0062\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0058\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0108 - val_loss: 0.0058\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0108 - val_loss: 0.0057\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0111 - val_loss: 0.0062\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0058\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0108 - val_loss: 0.0058\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0108 - val_loss: 0.0057\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0062\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0058\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0108 - val_loss: 0.0057\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0108 - val_loss: 0.0058\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0061\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0108 - val_loss: 0.0057\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0108 - val_loss: 0.0057\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0058\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0059\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0108 - val_loss: 0.0058\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0108 - val_loss: 0.0058\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0108 - val_loss: 0.0059\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0108 - val_loss: 0.0058\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0108 - val_loss: 0.0058\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0108 - val_loss: 0.0059\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0108 - val_loss: 0.0058\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0108 - val_loss: 0.0059\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0108 - val_loss: 0.0059\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0108 - val_loss: 0.0059\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0108 - val_loss: 0.0059\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0108 - val_loss: 0.0059\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0108 - val_loss: 0.0059\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0108 - val_loss: 0.0059\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0108 - val_loss: 0.0059\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0108 - val_loss: 0.0059\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0108 - val_loss: 0.0059\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0108 - val_loss: 0.0059\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0108 - val_loss: 0.0059\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0108 - val_loss: 0.0059\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0108 - val_loss: 0.0059\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0108 - val_loss: 0.0060\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0108 - val_loss: 0.0059\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0108 - val_loss: 0.0059\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0108 - val_loss: 0.0061\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0108 - val_loss: 0.0060\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0108 - val_loss: 0.0059\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0108 - val_loss: 0.0060\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0108 - val_loss: 0.0060\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0108 - val_loss: 0.0059\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0108 - val_loss: 0.0059\n",
      "第337个数，还剩3786个没有训练\n",
      "inv_hat [1.77345607 1.71765898 1.71666322 1.70479857 1.64654323 1.64160764\n",
      " 1.65147911 1.67616159 1.64555618 1.66628805 1.72861484 1.72662282\n",
      " 1.72761883 1.66826263 1.66431327 1.65740247 1.66332608 1.64851762\n",
      " 1.66530066 1.61495978 1.59522599 1.5843746  1.55873291 1.56464934\n",
      " 1.5636632  1.5843746  1.5824018  1.56464934 1.55183126 1.54098739]\n",
      "Test RMSE: 0.027\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0176 - val_loss: 0.0124\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0177 - val_loss: 0.0125\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0177 - val_loss: 0.0129\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0177 - val_loss: 0.0129\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0176 - val_loss: 0.0128\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0176 - val_loss: 0.0128\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0176 - val_loss: 0.0128\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0176 - val_loss: 0.0129\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0177 - val_loss: 0.0130\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0176 - val_loss: 0.0128\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0176 - val_loss: 0.0128\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0177 - val_loss: 0.0130\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0176 - val_loss: 0.0130\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0176 - val_loss: 0.0128\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0176 - val_loss: 0.0129\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0177 - val_loss: 0.0130\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0177 - val_loss: 0.0130\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0177 - val_loss: 0.0131\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0177 - val_loss: 0.0131\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0177 - val_loss: 0.0131\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0177 - val_loss: 0.0130\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0177 - val_loss: 0.0131\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0177 - val_loss: 0.0131\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0177 - val_loss: 0.0131\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0177 - val_loss: 0.0131\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0178 - val_loss: 0.0132\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0178 - val_loss: 0.0132\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0178 - val_loss: 0.0132\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0178 - val_loss: 0.0132\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0177 - val_loss: 0.0131\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0177 - val_loss: 0.0131\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0177 - val_loss: 0.0132\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0177 - val_loss: 0.0131\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0177 - val_loss: 0.0131\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0177 - val_loss: 0.0131\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0177 - val_loss: 0.0131\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0177 - val_loss: 0.0131\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0177 - val_loss: 0.0131\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0177 - val_loss: 0.0131\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0177 - val_loss: 0.0132\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0177 - val_loss: 0.0131\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0177 - val_loss: 0.0132\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0177 - val_loss: 0.0132\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0177 - val_loss: 0.0131\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0176 - val_loss: 0.0129\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0176 - val_loss: 0.0131\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0176 - val_loss: 0.0129\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0176 - val_loss: 0.0129\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0176 - val_loss: 0.0130\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0177 - val_loss: 0.0131\n",
      "第338个数，还剩3785个没有训练\n",
      "inv_hat [4.28442279 4.18925641 4.2147013  4.20686706 4.15508285 4.14143984\n",
      " 4.11225731 4.17362282 4.1765525  4.23136443 4.36632509 4.38314813\n",
      " 4.42278959 4.31693828 4.28048584 4.24117524 4.25393974 4.28639136\n",
      " 4.35445984 4.28540702 4.26474933 4.25393974 4.16971719 4.17069344\n",
      " 4.13073101 4.18339145 4.178506   4.15703293 4.14631022 4.20784601]\n",
      "Test RMSE: 0.054\n",
      "Train on 603 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "603/603 [==============================] - 0s 90us/sample - loss: 0.0100 - val_loss: 0.0067\n",
      "Epoch 2/50\n",
      "603/603 [==============================] - 0s 90us/sample - loss: 0.0104 - val_loss: 0.0067\n",
      "Epoch 3/50\n",
      "603/603 [==============================] - 0s 86us/sample - loss: 0.0124 - val_loss: 0.0075\n",
      "Epoch 4/50\n",
      "603/603 [==============================] - 0s 85us/sample - loss: 0.0203 - val_loss: 0.0137\n",
      "Epoch 5/50\n",
      "603/603 [==============================] - 0s 81us/sample - loss: 0.0138 - val_loss: 0.0102\n",
      "Epoch 6/50\n",
      "603/603 [==============================] - 0s 82us/sample - loss: 0.0163 - val_loss: 0.0062\n",
      "Epoch 7/50\n",
      "603/603 [==============================] - 0s 81us/sample - loss: 0.0207 - val_loss: 0.0177\n",
      "Epoch 8/50\n",
      "603/603 [==============================] - 0s 83us/sample - loss: 0.0184 - val_loss: 0.0160\n",
      "Epoch 9/50\n",
      "603/603 [==============================] - 0s 84us/sample - loss: 0.0189 - val_loss: 0.0287\n",
      "Epoch 10/50\n",
      "603/603 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0093\n",
      "Epoch 11/50\n",
      "603/603 [==============================] - 0s 82us/sample - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 12/50\n",
      "603/603 [==============================] - 0s 85us/sample - loss: 0.0142 - val_loss: 0.0101\n",
      "Epoch 13/50\n",
      "603/603 [==============================] - 0s 82us/sample - loss: 0.0138 - val_loss: 0.0147\n",
      "Epoch 14/50\n",
      "603/603 [==============================] - 0s 78us/sample - loss: 0.0146 - val_loss: 0.0112\n",
      "Epoch 15/50\n",
      "603/603 [==============================] - 0s 79us/sample - loss: 0.0137 - val_loss: 0.0165\n",
      "Epoch 16/50\n",
      "603/603 [==============================] - 0s 82us/sample - loss: 0.0131 - val_loss: 0.0091\n",
      "Epoch 17/50\n",
      "603/603 [==============================] - 0s 82us/sample - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 18/50\n",
      "603/603 [==============================] - 0s 83us/sample - loss: 0.0128 - val_loss: 0.0072\n",
      "Epoch 19/50\n",
      "603/603 [==============================] - 0s 82us/sample - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 20/50\n",
      "603/603 [==============================] - 0s 81us/sample - loss: 0.0126 - val_loss: 0.0075\n",
      "Epoch 21/50\n",
      "603/603 [==============================] - 0s 83us/sample - loss: 0.0119 - val_loss: 0.0121\n",
      "Epoch 22/50\n",
      "603/603 [==============================] - 0s 84us/sample - loss: 0.0131 - val_loss: 0.0072\n",
      "Epoch 23/50\n",
      "603/603 [==============================] - 0s 80us/sample - loss: 0.0128 - val_loss: 0.0167\n",
      "Epoch 24/50\n",
      "603/603 [==============================] - 0s 82us/sample - loss: 0.0125 - val_loss: 0.0092\n",
      "Epoch 25/50\n",
      "603/603 [==============================] - 0s 83us/sample - loss: 0.0108 - val_loss: 0.0077\n",
      "Epoch 26/50\n",
      "603/603 [==============================] - 0s 84us/sample - loss: 0.0121 - val_loss: 0.0064\n",
      "Epoch 27/50\n",
      "603/603 [==============================] - 0s 84us/sample - loss: 0.0110 - val_loss: 0.0103\n",
      "Epoch 28/50\n",
      "603/603 [==============================] - 0s 83us/sample - loss: 0.0116 - val_loss: 0.0069\n",
      "Epoch 29/50\n",
      "603/603 [==============================] - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0086\n",
      "Epoch 30/50\n",
      "603/603 [==============================] - 0s 85us/sample - loss: 0.0123 - val_loss: 0.0067\n",
      "Epoch 31/50\n",
      "603/603 [==============================] - 0s 85us/sample - loss: 0.0113 - val_loss: 0.0126\n",
      "Epoch 32/50\n",
      "603/603 [==============================] - 0s 84us/sample - loss: 0.0123 - val_loss: 0.0086\n",
      "Epoch 33/50\n",
      "603/603 [==============================] - 0s 83us/sample - loss: 0.0108 - val_loss: 0.0091\n",
      "Epoch 34/50\n",
      "603/603 [==============================] - 0s 82us/sample - loss: 0.0120 - val_loss: 0.0065\n",
      "Epoch 35/50\n",
      "603/603 [==============================] - 0s 82us/sample - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 36/50\n",
      "603/603 [==============================] - 0s 82us/sample - loss: 0.0124 - val_loss: 0.0078\n",
      "Epoch 37/50\n",
      "603/603 [==============================] - 0s 83us/sample - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 38/50\n",
      "603/603 [==============================] - 0s 89us/sample - loss: 0.0114 - val_loss: 0.0069\n",
      "Epoch 39/50\n",
      "603/603 [==============================] - 0s 86us/sample - loss: 0.0102 - val_loss: 0.0075\n",
      "Epoch 40/50\n",
      "603/603 [==============================] - 0s 85us/sample - loss: 0.0125 - val_loss: 0.0070\n",
      "Epoch 41/50\n",
      "603/603 [==============================] - 0s 82us/sample - loss: 0.0107 - val_loss: 0.0115\n",
      "Epoch 42/50\n",
      "603/603 [==============================] - 0s 88us/sample - loss: 0.0121 - val_loss: 0.0075\n",
      "Epoch 43/50\n",
      "603/603 [==============================] - 0s 82us/sample - loss: 0.0101 - val_loss: 0.0096\n",
      "Epoch 44/50\n",
      "603/603 [==============================] - 0s 80us/sample - loss: 0.0121 - val_loss: 0.0075\n",
      "Epoch 45/50\n",
      "603/603 [==============================] - 0s 79us/sample - loss: 0.0101 - val_loss: 0.0094\n",
      "Epoch 46/50\n",
      "603/603 [==============================] - 0s 85us/sample - loss: 0.0121 - val_loss: 0.0077\n",
      "Epoch 47/50\n",
      "603/603 [==============================] - 0s 85us/sample - loss: 0.0101 - val_loss: 0.0093\n",
      "Epoch 48/50\n",
      "603/603 [==============================] - 0s 84us/sample - loss: 0.0118 - val_loss: 0.0070\n",
      "Epoch 49/50\n",
      "603/603 [==============================] - 0s 80us/sample - loss: 0.0102 - val_loss: 0.0094\n",
      "Epoch 50/50\n",
      "603/603 [==============================] - 0s 80us/sample - loss: 0.0121 - val_loss: 0.0081\n",
      "第339个数，还剩3784个没有训练\n",
      "inv_hat [1.02524745 1.02524745 1.02524745 1.02524745 1.02524745 1.02524745\n",
      " 1.02524745 1.02524745 1.02524745 1.02524745 1.02524745 1.0261841\n",
      " 1.0261841  1.0261841  1.0261841  1.0261841  1.0261841  1.0261841\n",
      " 1.02430623 1.02430623 1.02336029 1.02336029 1.02336029 1.02524745\n",
      " 1.02430623 1.02430623 1.0261841  1.0261841  1.02804298 1.02896523]\n",
      "Test RMSE: 0.001\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0144 - val_loss: 0.0023\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0143 - val_loss: 0.0023\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0141 - val_loss: 0.0024\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0144 - val_loss: 0.0024\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0141 - val_loss: 0.0021\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0147 - val_loss: 0.0065\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0147 - val_loss: 0.0025\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0155 - val_loss: 0.0070\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0147 - val_loss: 0.0031\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0141 - val_loss: 0.0021\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0147 - val_loss: 0.0064\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0141 - val_loss: 0.0034\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0148 - val_loss: 0.0031\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0147 - val_loss: 0.0035\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0142 - val_loss: 0.0022\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0142 - val_loss: 0.0041\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0151 - val_loss: 0.0042\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0148 - val_loss: 0.0059\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0143 - val_loss: 0.0024\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0139 - val_loss: 0.0023\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0138 - val_loss: 0.0022\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0140 - val_loss: 0.0021\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0147 - val_loss: 0.0064\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0038\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0149 - val_loss: 0.0045\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0148 - val_loss: 0.0040\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0141 - val_loss: 0.0022\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0143 - val_loss: 0.0029\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0139 - val_loss: 0.0022\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0137 - val_loss: 0.0024\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0141 - val_loss: 0.0022\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0151 - val_loss: 0.0066\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0146 - val_loss: 0.0025\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0154 - val_loss: 0.0065\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0147 - val_loss: 0.0029\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0140 - val_loss: 0.0021\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0146 - val_loss: 0.0064\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0141 - val_loss: 0.0038\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0149 - val_loss: 0.0043\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0147 - val_loss: 0.0041\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0141 - val_loss: 0.0021\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0143 - val_loss: 0.0029\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0139 - val_loss: 0.0025\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0147 - val_loss: 0.0057\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0140 - val_loss: 0.0033\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0147 - val_loss: 0.0028\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0145 - val_loss: 0.0038\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0139 - val_loss: 0.0040\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0145 - val_loss: 0.0025\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0150 - val_loss: 0.0058\n",
      "第340个数，还剩3783个没有训练\n",
      "inv_hat [1.05608253 1.05529691 1.05441357 1.05431555 1.05431555 1.05441357\n",
      " 1.05441357 1.05421744 1.05441357 1.05451171 1.05460986 1.054708\n",
      " 1.05451171 1.05500249 1.05529691 1.05578783 1.05568972 1.05627903\n",
      " 1.05647544 1.05608253 1.05637728 1.05627903 1.05647544 1.05657371\n",
      " 1.05696687 1.05716338 1.05726171 1.05736004 1.05755672 1.05863877]\n",
      "Test RMSE: 0.001\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0135 - val_loss: 0.0072\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0130 - val_loss: 0.0078\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0128 - val_loss: 0.0077\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0128 - val_loss: 0.0077\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0127 - val_loss: 0.0075\n",
      "第341个数，还剩3782个没有训练\n",
      "inv_hat [1.11671529 1.10166169 1.10670169 1.10468576 1.08955828 1.08552138\n",
      " 1.08552138 1.10065361 1.08552138 1.09460397 1.12369191 1.12867385\n",
      " 1.12967016 1.10871751 1.10871751 1.10367776 1.1117306  1.10670169\n",
      " 1.11671529 1.09460397 1.08854905 1.07946575 1.06735356 1.06735356\n",
      " 1.06230654 1.08047511 1.08249364 1.07542853 1.06836301 1.07139116]\n",
      "Test RMSE: 0.012\n",
      "Train on 1029 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1029/1029 [==============================] - 0s 82us/sample - loss: 0.0087 - val_loss: 0.0195\n",
      "Epoch 2/50\n",
      "1029/1029 [==============================] - 0s 83us/sample - loss: 0.0087 - val_loss: 0.0190\n",
      "Epoch 3/50\n",
      "1029/1029 [==============================] - 0s 84us/sample - loss: 0.0084 - val_loss: 0.0175\n",
      "Epoch 4/50\n",
      "1029/1029 [==============================] - 0s 80us/sample - loss: 0.0087 - val_loss: 0.0178\n",
      "Epoch 5/50\n",
      "1029/1029 [==============================] - 0s 79us/sample - loss: 0.0085 - val_loss: 0.0186\n",
      "Epoch 6/50\n",
      "1029/1029 [==============================] - 0s 77us/sample - loss: 0.0083 - val_loss: 0.0191\n",
      "Epoch 7/50\n",
      "1029/1029 [==============================] - 0s 77us/sample - loss: 0.0084 - val_loss: 0.0187\n",
      "Epoch 8/50\n",
      "1029/1029 [==============================] - 0s 78us/sample - loss: 0.0084 - val_loss: 0.0179\n",
      "Epoch 9/50\n",
      "1029/1029 [==============================] - 0s 81us/sample - loss: 0.0084 - val_loss: 0.0190\n",
      "Epoch 10/50\n",
      "1029/1029 [==============================] - 0s 80us/sample - loss: 0.0084 - val_loss: 0.0194\n",
      "Epoch 11/50\n",
      "1029/1029 [==============================] - 0s 79us/sample - loss: 0.0086 - val_loss: 0.0183\n",
      "Epoch 12/50\n",
      "1029/1029 [==============================] - 0s 80us/sample - loss: 0.0085 - val_loss: 0.0175\n",
      "Epoch 13/50\n",
      "1029/1029 [==============================] - 0s 81us/sample - loss: 0.0084 - val_loss: 0.0199\n",
      "Epoch 14/50\n",
      "1029/1029 [==============================] - 0s 79us/sample - loss: 0.0092 - val_loss: 0.0225\n",
      "Epoch 15/50\n",
      "1029/1029 [==============================] - 0s 85us/sample - loss: 0.0098 - val_loss: 0.0197\n",
      "Epoch 16/50\n",
      "1029/1029 [==============================] - 0s 81us/sample - loss: 0.0088 - val_loss: 0.0200\n",
      "Epoch 17/50\n",
      "1029/1029 [==============================] - 0s 86us/sample - loss: 0.0090 - val_loss: 0.0235\n",
      "Epoch 18/50\n",
      "1029/1029 [==============================] - 0s 80us/sample - loss: 0.0115 - val_loss: 0.0156\n",
      "Epoch 19/50\n",
      "1029/1029 [==============================] - 0s 81us/sample - loss: 0.0095 - val_loss: 0.0165\n",
      "Epoch 20/50\n",
      "1029/1029 [==============================] - 0s 79us/sample - loss: 0.0097 - val_loss: 0.0223\n",
      "Epoch 21/50\n",
      "1029/1029 [==============================] - 0s 78us/sample - loss: 0.0096 - val_loss: 0.0218\n",
      "Epoch 22/50\n",
      "1029/1029 [==============================] - 0s 80us/sample - loss: 0.0103 - val_loss: 0.0167\n",
      "Epoch 23/50\n",
      "1029/1029 [==============================] - 0s 78us/sample - loss: 0.0091 - val_loss: 0.0173\n",
      "Epoch 24/50\n",
      "1029/1029 [==============================] - 0s 80us/sample - loss: 0.0087 - val_loss: 0.0184\n",
      "Epoch 25/50\n",
      "1029/1029 [==============================] - 0s 81us/sample - loss: 0.0083 - val_loss: 0.0189\n",
      "Epoch 26/50\n",
      "1029/1029 [==============================] - 0s 81us/sample - loss: 0.0084 - val_loss: 0.0185\n",
      "Epoch 27/50\n",
      "1029/1029 [==============================] - 0s 81us/sample - loss: 0.0083 - val_loss: 0.0191\n",
      "Epoch 28/50\n",
      "1029/1029 [==============================] - 0s 82us/sample - loss: 0.0084 - val_loss: 0.0195\n",
      "Epoch 29/50\n",
      "1029/1029 [==============================] - 0s 81us/sample - loss: 0.0084 - val_loss: 0.0183\n",
      "Epoch 30/50\n",
      "1029/1029 [==============================] - 0s 81us/sample - loss: 0.0083 - val_loss: 0.0194\n",
      "Epoch 31/50\n",
      "1029/1029 [==============================] - 0s 79us/sample - loss: 0.0085 - val_loss: 0.0180\n",
      "Epoch 32/50\n",
      "1029/1029 [==============================] - 0s 77us/sample - loss: 0.0084 - val_loss: 0.0181\n",
      "Epoch 33/50\n",
      "1029/1029 [==============================] - 0s 77us/sample - loss: 0.0084 - val_loss: 0.0189\n",
      "Epoch 34/50\n",
      "1029/1029 [==============================] - 0s 78us/sample - loss: 0.0083 - val_loss: 0.0184\n",
      "Epoch 35/50\n",
      "1029/1029 [==============================] - 0s 79us/sample - loss: 0.0084 - val_loss: 0.0190\n",
      "Epoch 36/50\n",
      "1029/1029 [==============================] - 0s 77us/sample - loss: 0.0085 - val_loss: 0.0199\n",
      "Epoch 37/50\n",
      "1029/1029 [==============================] - 0s 80us/sample - loss: 0.0085 - val_loss: 0.0184\n",
      "Epoch 38/50\n",
      "1029/1029 [==============================] - 0s 80us/sample - loss: 0.0083 - val_loss: 0.0188\n",
      "Epoch 39/50\n",
      "1029/1029 [==============================] - 0s 79us/sample - loss: 0.0083 - val_loss: 0.0196\n",
      "Epoch 40/50\n",
      "1029/1029 [==============================] - 0s 83us/sample - loss: 0.0085 - val_loss: 0.0201\n",
      "Epoch 41/50\n",
      "1029/1029 [==============================] - 0s 80us/sample - loss: 0.0088 - val_loss: 0.0221\n",
      "Epoch 42/50\n",
      "1029/1029 [==============================] - 0s 80us/sample - loss: 0.0094 - val_loss: 0.0211\n",
      "Epoch 43/50\n",
      "1029/1029 [==============================] - 0s 79us/sample - loss: 0.0094 - val_loss: 0.0194\n",
      "Epoch 44/50\n",
      "1029/1029 [==============================] - 0s 82us/sample - loss: 0.0084 - val_loss: 0.0206\n",
      "Epoch 45/50\n",
      "1029/1029 [==============================] - 0s 85us/sample - loss: 0.0092 - val_loss: 0.0217\n",
      "Epoch 46/50\n",
      "1029/1029 [==============================] - 0s 82us/sample - loss: 0.0096 - val_loss: 0.0187\n",
      "Epoch 47/50\n",
      "1029/1029 [==============================] - 0s 83us/sample - loss: 0.0085 - val_loss: 0.0200\n",
      "Epoch 48/50\n",
      "1029/1029 [==============================] - 0s 79us/sample - loss: 0.0089 - val_loss: 0.0233\n",
      "Epoch 49/50\n",
      "1029/1029 [==============================] - 0s 82us/sample - loss: 0.0109 - val_loss: 0.0160\n",
      "Epoch 50/50\n",
      "1029/1029 [==============================] - 0s 84us/sample - loss: 0.0095 - val_loss: 0.0167\n",
      "第342个数，还剩3781个没有训练\n",
      "inv_hat [1.02347584 1.02397767 1.02468015 1.02628546 1.02638579 1.0292946\n",
      " 1.02899365 1.03039794 1.03290909 1.03512366 1.03592998 1.03603084\n",
      " 1.03623248 1.038148   1.0387536  1.03976382 1.03976382 1.02618512\n",
      " 1.02768976 1.0292946  1.02959544 1.03019728 1.03099986 1.03290909\n",
      " 1.03421713 1.03532512 1.03693804 1.03673636 1.03683719 1.0382489 ]\n",
      "Test RMSE: 0.003\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0088 - val_loss: 0.0036\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0084 - val_loss: 0.0033\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0083 - val_loss: 0.0034\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0082 - val_loss: 0.0032\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0083 - val_loss: 0.0032\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0083 - val_loss: 0.0032\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0083 - val_loss: 0.0032\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0083 - val_loss: 0.0032\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0083 - val_loss: 0.0032\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0083 - val_loss: 0.0032\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0083 - val_loss: 0.0032\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0083 - val_loss: 0.0032\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0083 - val_loss: 0.0032\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0083 - val_loss: 0.0032\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0083 - val_loss: 0.0033\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0083 - val_loss: 0.0032\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0083 - val_loss: 0.0032\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0083 - val_loss: 0.0032\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0083 - val_loss: 0.0032\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0083 - val_loss: 0.0032\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0083 - val_loss: 0.0032\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0083 - val_loss: 0.0032\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0083 - val_loss: 0.0032\n",
      "第343个数，还剩3780个没有训练\n",
      "inv_hat [0.98493851 0.96692419 0.9735755  0.96799967 0.9525709  0.95023084\n",
      " 0.94935352 0.96516477 0.95539974 0.96516477 0.98238977 0.97719763\n",
      " 0.97729552 0.95725386 0.95169326 0.9380582  0.94662504 0.94974342\n",
      " 0.96682644 0.94925608 0.94487168 0.9329047  0.92106017 0.91756991\n",
      " 0.90305128 0.90469471 0.90179484 0.89706181 0.89281526 0.90044214]\n",
      "Test RMSE: 0.011\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0077 - val_loss: 0.0046\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0079 - val_loss: 0.0044\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0093 - val_loss: 0.0046\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0080 - val_loss: 0.0048\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0073 - val_loss: 0.0038\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0067 - val_loss: 0.0027\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0072 - val_loss: 0.0035\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0069 - val_loss: 0.0034\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0085 - val_loss: 0.0032\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0149 - val_loss: 0.0084\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0093 - val_loss: 0.0032\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0080 - val_loss: 0.0024\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0070 - val_loss: 0.0035\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0075 - val_loss: 0.0031\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0132 - val_loss: 0.0066\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0101 - val_loss: 0.0030\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0076 - val_loss: 0.0033\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0070 - val_loss: 0.0034\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0074 - val_loss: 0.0023\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0108 - val_loss: 0.0034\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0091 - val_loss: 0.0023\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0082 - val_loss: 0.0039\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0077 - val_loss: 0.0023\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0082 - val_loss: 0.0025\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0105 - val_loss: 0.0035\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0084 - val_loss: 0.0023\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0077 - val_loss: 0.0033\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0073 - val_loss: 0.0023\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0080 - val_loss: 0.0023\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0102 - val_loss: 0.0035\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0085 - val_loss: 0.0028\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0070 - val_loss: 0.0028\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0068 - val_loss: 0.0035\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0072 - val_loss: 0.0023\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0100 - val_loss: 0.0036\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0085 - val_loss: 0.0029\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0068 - val_loss: 0.0030\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0068 - val_loss: 0.0035\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0069 - val_loss: 0.0029\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0088 - val_loss: 0.0031\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0119 - val_loss: 0.0063\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0071 - val_loss: 0.0024\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0069 - val_loss: 0.0031\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0070 - val_loss: 0.0024\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0096 - val_loss: 0.0037\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0098 - val_loss: 0.0038\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0067 - val_loss: 0.0028\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0070 - val_loss: 0.0023\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0075 - val_loss: 0.0023\n",
      "第344个数，还剩3779个没有训练\n",
      "inv_hat [1.03110916 1.03110916 1.03110916 1.0320875  1.0320875  1.03306572\n",
      " 1.03306572 1.03306572 1.03306572 1.03404373 1.03404373 1.03404373\n",
      " 1.03502141 1.03502141 1.03599904 1.03599904 1.03697636 1.03697636\n",
      " 1.03697636 1.03697636 1.03697636 1.03599904 1.03599904 1.03697636\n",
      " 1.03697636 1.03795365 1.03795365 1.03795365 1.03795365 1.0399077 ]\n",
      "Test RMSE: 0.001\n",
      "Train on 627 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "627/627 [==============================] - 0s 77us/sample - loss: 0.0215 - val_loss: 0.0088\n",
      "Epoch 2/50\n",
      "627/627 [==============================] - 0s 75us/sample - loss: 0.0211 - val_loss: 0.0055\n",
      "Epoch 3/50\n",
      "627/627 [==============================] - 0s 80us/sample - loss: 0.0214 - val_loss: 0.0068\n",
      "Epoch 4/50\n",
      "627/627 [==============================] - 0s 84us/sample - loss: 0.0211 - val_loss: 0.0055\n",
      "Epoch 5/50\n",
      "627/627 [==============================] - 0s 85us/sample - loss: 0.0212 - val_loss: 0.0063\n",
      "Epoch 6/50\n",
      "627/627 [==============================] - 0s 80us/sample - loss: 0.0211 - val_loss: 0.0055\n",
      "Epoch 7/50\n",
      "627/627 [==============================] - 0s 82us/sample - loss: 0.0211 - val_loss: 0.0061\n",
      "Epoch 8/50\n",
      "627/627 [==============================] - 0s 83us/sample - loss: 0.0211 - val_loss: 0.0055\n",
      "Epoch 9/50\n",
      "627/627 [==============================] - 0s 88us/sample - loss: 0.0211 - val_loss: 0.0061\n",
      "Epoch 10/50\n",
      "627/627 [==============================] - 0s 76us/sample - loss: 0.0211 - val_loss: 0.0055\n",
      "Epoch 11/50\n",
      "627/627 [==============================] - 0s 81us/sample - loss: 0.0211 - val_loss: 0.0059\n",
      "Epoch 12/50\n",
      "627/627 [==============================] - 0s 77us/sample - loss: 0.0211 - val_loss: 0.0056\n",
      "Epoch 13/50\n",
      "627/627 [==============================] - 0s 78us/sample - loss: 0.0211 - val_loss: 0.0063\n",
      "Epoch 14/50\n",
      "627/627 [==============================] - 0s 80us/sample - loss: 0.0210 - val_loss: 0.0055\n",
      "Epoch 15/50\n",
      "627/627 [==============================] - 0s 83us/sample - loss: 0.0211 - val_loss: 0.0062\n",
      "Epoch 16/50\n",
      "627/627 [==============================] - 0s 84us/sample - loss: 0.0210 - val_loss: 0.0056\n",
      "Epoch 17/50\n",
      "627/627 [==============================] - 0s 81us/sample - loss: 0.0211 - val_loss: 0.0062\n",
      "Epoch 18/50\n",
      "627/627 [==============================] - 0s 80us/sample - loss: 0.0210 - val_loss: 0.0057\n",
      "Epoch 19/50\n",
      "627/627 [==============================] - 0s 82us/sample - loss: 0.0211 - val_loss: 0.0066\n",
      "Epoch 20/50\n",
      "627/627 [==============================] - 0s 77us/sample - loss: 0.0210 - val_loss: 0.0055\n",
      "Epoch 21/50\n",
      "627/627 [==============================] - 0s 77us/sample - loss: 0.0212 - val_loss: 0.0073\n",
      "Epoch 22/50\n",
      "627/627 [==============================] - 0s 77us/sample - loss: 0.0210 - val_loss: 0.0056\n",
      "Epoch 23/50\n",
      "627/627 [==============================] - 0s 81us/sample - loss: 0.0213 - val_loss: 0.0076\n",
      "Epoch 24/50\n",
      "627/627 [==============================] - 0s 83us/sample - loss: 0.0210 - val_loss: 0.0061\n",
      "Epoch 25/50\n",
      "627/627 [==============================] - 0s 79us/sample - loss: 0.0214 - val_loss: 0.0080\n",
      "Epoch 26/50\n",
      "627/627 [==============================] - 0s 78us/sample - loss: 0.0210 - val_loss: 0.0062\n",
      "Epoch 27/50\n",
      "627/627 [==============================] - 0s 79us/sample - loss: 0.0213 - val_loss: 0.0079\n",
      "Epoch 28/50\n",
      "627/627 [==============================] - 0s 79us/sample - loss: 0.0210 - val_loss: 0.0065\n",
      "Epoch 29/50\n",
      "627/627 [==============================] - 0s 84us/sample - loss: 0.0213 - val_loss: 0.0076\n",
      "Epoch 30/50\n",
      "627/627 [==============================] - 0s 83us/sample - loss: 0.0210 - val_loss: 0.0066\n",
      "Epoch 31/50\n",
      "627/627 [==============================] - 0s 83us/sample - loss: 0.0213 - val_loss: 0.0076\n",
      "Epoch 32/50\n",
      "627/627 [==============================] - 0s 87us/sample - loss: 0.0210 - val_loss: 0.0069\n",
      "Epoch 33/50\n",
      "627/627 [==============================] - 0s 87us/sample - loss: 0.0213 - val_loss: 0.0077\n",
      "Epoch 34/50\n",
      "627/627 [==============================] - 0s 84us/sample - loss: 0.0210 - val_loss: 0.0070\n",
      "Epoch 35/50\n",
      "627/627 [==============================] - 0s 84us/sample - loss: 0.0213 - val_loss: 0.0076\n",
      "Epoch 36/50\n",
      "627/627 [==============================] - 0s 84us/sample - loss: 0.0210 - val_loss: 0.0069\n",
      "Epoch 37/50\n",
      "627/627 [==============================] - 0s 85us/sample - loss: 0.0213 - val_loss: 0.0070\n",
      "Epoch 38/50\n",
      "627/627 [==============================] - 0s 78us/sample - loss: 0.0210 - val_loss: 0.0067\n",
      "Epoch 39/50\n",
      "627/627 [==============================] - 0s 76us/sample - loss: 0.0212 - val_loss: 0.0069\n",
      "Epoch 40/50\n",
      "627/627 [==============================] - 0s 78us/sample - loss: 0.0210 - val_loss: 0.0066\n",
      "Epoch 41/50\n",
      "627/627 [==============================] - 0s 78us/sample - loss: 0.0212 - val_loss: 0.0064\n",
      "Epoch 42/50\n",
      "627/627 [==============================] - 0s 80us/sample - loss: 0.0210 - val_loss: 0.0060\n",
      "Epoch 43/50\n",
      "627/627 [==============================] - 0s 80us/sample - loss: 0.0211 - val_loss: 0.0056\n",
      "Epoch 44/50\n",
      "627/627 [==============================] - 0s 81us/sample - loss: 0.0210 - val_loss: 0.0055\n",
      "Epoch 45/50\n",
      "627/627 [==============================] - 0s 78us/sample - loss: 0.0210 - val_loss: 0.0055\n",
      "Epoch 46/50\n",
      "627/627 [==============================] - 0s 82us/sample - loss: 0.0210 - val_loss: 0.0055\n",
      "Epoch 47/50\n",
      "627/627 [==============================] - 0s 81us/sample - loss: 0.0210 - val_loss: 0.0056\n",
      "Epoch 48/50\n",
      "627/627 [==============================] - 0s 79us/sample - loss: 0.0210 - val_loss: 0.0056\n",
      "Epoch 49/50\n",
      "627/627 [==============================] - 0s 83us/sample - loss: 0.0210 - val_loss: 0.0056\n",
      "Epoch 50/50\n",
      "627/627 [==============================] - 0s 80us/sample - loss: 0.0210 - val_loss: 0.0056\n",
      "第345个数，还剩3778个没有训练\n",
      "inv_hat [1.01975898 1.01905883 1.01875877 1.01785892 1.01256711 1.01087262\n",
      " 1.00957808 1.00957808 1.00957808 1.00957808 1.00967764 1.00967764\n",
      " 1.00967764 1.01087262 1.01386388 1.01436284 1.01436284 1.0141632\n",
      " 1.01396368 1.01386388 1.01336493 1.0131655  1.01306574 1.01326527\n",
      " 1.01336493 1.01386388 1.01396368 1.0141632  1.01426301 1.0145625 ]\n",
      "Test RMSE: 0.001\n",
      "Train on 1178 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1178/1178 [==============================] - 0s 79us/sample - loss: 0.0132 - val_loss: 0.0079\n",
      "Epoch 2/50\n",
      "1178/1178 [==============================] - 0s 81us/sample - loss: 0.0133 - val_loss: 0.0079\n",
      "Epoch 3/50\n",
      "1178/1178 [==============================] - 0s 80us/sample - loss: 0.0132 - val_loss: 0.0086\n",
      "Epoch 4/50\n",
      "1178/1178 [==============================] - 0s 80us/sample - loss: 0.0136 - val_loss: 0.0087\n",
      "Epoch 5/50\n",
      "1178/1178 [==============================] - 0s 79us/sample - loss: 0.0127 - val_loss: 0.0070\n",
      "Epoch 6/50\n",
      "1178/1178 [==============================] - 0s 81us/sample - loss: 0.0127 - val_loss: 0.0078\n",
      "Epoch 7/50\n",
      "1178/1178 [==============================] - 0s 78us/sample - loss: 0.0141 - val_loss: 0.0101\n",
      "Epoch 8/50\n",
      "1178/1178 [==============================] - 0s 77us/sample - loss: 0.0127 - val_loss: 0.0068\n",
      "Epoch 9/50\n",
      "1178/1178 [==============================] - 0s 76us/sample - loss: 0.0132 - val_loss: 0.0080\n",
      "Epoch 10/50\n",
      "1178/1178 [==============================] - 0s 82us/sample - loss: 0.0162 - val_loss: 0.0132\n",
      "Epoch 11/50\n",
      "1178/1178 [==============================] - 0s 83us/sample - loss: 0.0132 - val_loss: 0.0091\n",
      "Epoch 12/50\n",
      "1178/1178 [==============================] - 0s 79us/sample - loss: 0.0157 - val_loss: 0.0083\n",
      "Epoch 13/50\n",
      "1178/1178 [==============================] - 0s 78us/sample - loss: 0.0190 - val_loss: 0.0176\n",
      "Epoch 14/50\n",
      "1178/1178 [==============================] - 0s 76us/sample - loss: 0.0144 - val_loss: 0.0121\n",
      "Epoch 15/50\n",
      "1178/1178 [==============================] - 0s 80us/sample - loss: 0.0170 - val_loss: 0.0078\n",
      "Epoch 16/50\n",
      "1178/1178 [==============================] - 0s 80us/sample - loss: 0.0176 - val_loss: 0.0186\n",
      "Epoch 17/50\n",
      "1178/1178 [==============================] - 0s 84us/sample - loss: 0.0140 - val_loss: 0.0096\n",
      "Epoch 18/50\n",
      "1178/1178 [==============================] - 0s 82us/sample - loss: 0.0159 - val_loss: 0.0076\n",
      "Epoch 19/50\n",
      "1178/1178 [==============================] - 0s 83us/sample - loss: 0.0167 - val_loss: 0.0179\n",
      "Epoch 20/50\n",
      "1178/1178 [==============================] - 0s 80us/sample - loss: 0.0137 - val_loss: 0.0088\n",
      "Epoch 21/50\n",
      "1178/1178 [==============================] - 0s 82us/sample - loss: 0.0155 - val_loss: 0.0078\n",
      "Epoch 22/50\n",
      "1178/1178 [==============================] - 0s 83us/sample - loss: 0.0163 - val_loss: 0.0175\n",
      "Epoch 23/50\n",
      "1178/1178 [==============================] - 0s 81us/sample - loss: 0.0136 - val_loss: 0.0086\n",
      "Epoch 24/50\n",
      "1178/1178 [==============================] - 0s 76us/sample - loss: 0.0152 - val_loss: 0.0078\n",
      "Epoch 25/50\n",
      "1178/1178 [==============================] - 0s 76us/sample - loss: 0.0160 - val_loss: 0.0170\n",
      "Epoch 26/50\n",
      "1178/1178 [==============================] - 0s 75us/sample - loss: 0.0135 - val_loss: 0.0083\n",
      "Epoch 27/50\n",
      "1178/1178 [==============================] - 0s 76us/sample - loss: 0.0150 - val_loss: 0.0079\n",
      "Epoch 28/50\n",
      "1178/1178 [==============================] - 0s 74us/sample - loss: 0.0158 - val_loss: 0.0163\n",
      "Epoch 29/50\n",
      "1178/1178 [==============================] - 0s 79us/sample - loss: 0.0134 - val_loss: 0.0080\n",
      "Epoch 30/50\n",
      "1178/1178 [==============================] - 0s 80us/sample - loss: 0.0148 - val_loss: 0.0084\n",
      "Epoch 31/50\n",
      "1178/1178 [==============================] - 0s 82us/sample - loss: 0.0155 - val_loss: 0.0154\n",
      "Epoch 32/50\n",
      "1178/1178 [==============================] - 0s 78us/sample - loss: 0.0132 - val_loss: 0.0079\n",
      "Epoch 33/50\n",
      "1178/1178 [==============================] - 0s 75us/sample - loss: 0.0144 - val_loss: 0.0089\n",
      "Epoch 34/50\n",
      "1178/1178 [==============================] - 0s 75us/sample - loss: 0.0154 - val_loss: 0.0146\n",
      "Epoch 35/50\n",
      "1178/1178 [==============================] - 0s 76us/sample - loss: 0.0132 - val_loss: 0.0081\n",
      "Epoch 36/50\n",
      "1178/1178 [==============================] - 0s 76us/sample - loss: 0.0144 - val_loss: 0.0096\n",
      "Epoch 37/50\n",
      "1178/1178 [==============================] - 0s 77us/sample - loss: 0.0155 - val_loss: 0.0135\n",
      "Epoch 38/50\n",
      "1178/1178 [==============================] - 0s 75us/sample - loss: 0.0131 - val_loss: 0.0082\n",
      "Epoch 39/50\n",
      "1178/1178 [==============================] - 0s 77us/sample - loss: 0.0145 - val_loss: 0.0109\n",
      "Epoch 40/50\n",
      "1178/1178 [==============================] - 0s 77us/sample - loss: 0.0153 - val_loss: 0.0123\n",
      "Epoch 41/50\n",
      "1178/1178 [==============================] - 0s 82us/sample - loss: 0.0131 - val_loss: 0.0082\n",
      "Epoch 42/50\n",
      "1178/1178 [==============================] - 0s 78us/sample - loss: 0.0146 - val_loss: 0.0123\n",
      "Epoch 43/50\n",
      "1178/1178 [==============================] - 0s 82us/sample - loss: 0.0151 - val_loss: 0.0109\n",
      "Epoch 44/50\n",
      "1178/1178 [==============================] - 0s 80us/sample - loss: 0.0131 - val_loss: 0.0078\n",
      "Epoch 45/50\n",
      "1178/1178 [==============================] - 0s 82us/sample - loss: 0.0144 - val_loss: 0.0133\n",
      "Epoch 46/50\n",
      "1178/1178 [==============================] - 0s 76us/sample - loss: 0.0149 - val_loss: 0.0100\n",
      "Epoch 47/50\n",
      "1178/1178 [==============================] - 0s 78us/sample - loss: 0.0132 - val_loss: 0.0076\n",
      "Epoch 48/50\n",
      "1178/1178 [==============================] - 0s 75us/sample - loss: 0.0143 - val_loss: 0.0141\n",
      "Epoch 49/50\n",
      "1178/1178 [==============================] - 0s 78us/sample - loss: 0.0145 - val_loss: 0.0092\n",
      "Epoch 50/50\n",
      "1178/1178 [==============================] - 0s 78us/sample - loss: 0.0134 - val_loss: 0.0073\n",
      "第346个数，还剩3777个没有训练\n",
      "inv_hat [1.67956249 1.65342428 1.64437551 1.64336997 1.61018793 1.61018793\n",
      " 1.60717126 1.62325991 1.60616572 1.61722668 1.65744593 1.65342428\n",
      " 1.64839721 1.62627657 1.63403301 1.6081768  1.6202433  1.62527098\n",
      " 1.57700599 1.54885665 1.5468463  1.5307653  1.51569313 1.5177025\n",
      " 1.50162991 1.51267923 1.50062551 1.4885752  1.4855632  1.4855632 ]\n",
      "Test RMSE: 0.017\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - ETA: 0s - loss: 0.007 - 0s 79us/sample - loss: 0.0059 - val_loss: 0.0066\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0057 - val_loss: 0.0066\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0055 - val_loss: 0.0066\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0057 - val_loss: 0.0066\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0051 - val_loss: 0.0066\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0047 - val_loss: 0.0062\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0056 - val_loss: 0.0062\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0051 - val_loss: 0.0067\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0057 - val_loss: 0.0064\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0056 - val_loss: 0.0063\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0057 - val_loss: 0.0063\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0054 - val_loss: 0.0063\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0050 - val_loss: 0.0063\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0048 - val_loss: 0.0064\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0047 - val_loss: 0.0062\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0052 - val_loss: 0.0062\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0049 - val_loss: 0.0065\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0052 - val_loss: 0.0063\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0050 - val_loss: 0.0066\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0053 - val_loss: 0.0062\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0051 - val_loss: 0.0066\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0052 - val_loss: 0.0062\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0050 - val_loss: 0.0066\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0052 - val_loss: 0.0062\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0049 - val_loss: 0.0063\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0051 - val_loss: 0.0062\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0047 - val_loss: 0.0062\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0051 - val_loss: 0.0062\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0046 - val_loss: 0.0063\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0052 - val_loss: 0.0063\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0047 - val_loss: 0.0063\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0049 - val_loss: 0.0064\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0045 - val_loss: 0.0063\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0043 - val_loss: 0.0063\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0047 - val_loss: 0.0068\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0046 - val_loss: 0.0065\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0055 - val_loss: 0.0069\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0044 - val_loss: 0.0062\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0045 - val_loss: 0.0062\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0048 - val_loss: 0.0062\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0043 - val_loss: 0.0063\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0046 - val_loss: 0.0064\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0045 - val_loss: 0.0062\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0047 - val_loss: 0.0065\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0044 - val_loss: 0.0063\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0044 - val_loss: 0.0063\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0048 - val_loss: 0.0064\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0048 - val_loss: 0.0064\n",
      "第347个数，还剩3776个没有训练\n",
      "inv_hat [1.01579463 1.01559853 1.01569664 1.01559853 1.01550042 1.01540232\n",
      " 1.01530422 1.0173649  1.01540232 1.0194277  1.02720594 1.02878513\n",
      " 1.03007011 1.02227974 1.02218132 1.01834697 1.02365797 1.02198459\n",
      " 1.0263185  1.01481393 1.00931604 1.00872303 0.99837768 1.00103226\n",
      " 0.99788651 1.00595852 1.00556397 1.00655066 1.00250872 1.00704415]\n",
      "Test RMSE: 0.005\n",
      "Train on 696 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "696/696 [==============================] - 0s 80us/sample - loss: 0.0180 - val_loss: 0.0104\n",
      "Epoch 2/50\n",
      "696/696 [==============================] - 0s 83us/sample - loss: 0.0181 - val_loss: 0.0146\n",
      "Epoch 3/50\n",
      "696/696 [==============================] - 0s 84us/sample - loss: 0.0182 - val_loss: 0.0106\n",
      "Epoch 4/50\n",
      "696/696 [==============================] - 0s 84us/sample - loss: 0.0173 - val_loss: 0.0100\n",
      "Epoch 5/50\n",
      "696/696 [==============================] - 0s 80us/sample - loss: 0.0186 - val_loss: 0.0153\n",
      "Epoch 6/50\n",
      "696/696 [==============================] - 0s 77us/sample - loss: 0.0193 - val_loss: 0.0134\n",
      "Epoch 7/50\n",
      "696/696 [==============================] - 0s 76us/sample - loss: 0.0181 - val_loss: 0.0165\n",
      "Epoch 8/50\n",
      "696/696 [==============================] - 0s 81us/sample - loss: 0.0183 - val_loss: 0.0143\n",
      "Epoch 9/50\n",
      "696/696 [==============================] - 0s 78us/sample - loss: 0.0184 - val_loss: 0.0109\n",
      "Epoch 10/50\n",
      "696/696 [==============================] - 0s 80us/sample - loss: 0.0176 - val_loss: 0.0127\n",
      "Epoch 11/50\n",
      "696/696 [==============================] - 0s 79us/sample - loss: 0.0182 - val_loss: 0.0128\n",
      "Epoch 12/50\n",
      "696/696 [==============================] - 0s 83us/sample - loss: 0.0179 - val_loss: 0.0125\n",
      "Epoch 13/50\n",
      "696/696 [==============================] - 0s 84us/sample - loss: 0.0184 - val_loss: 0.0091\n",
      "Epoch 14/50\n",
      "696/696 [==============================] - 0s 81us/sample - loss: 0.0170 - val_loss: 0.0098\n",
      "Epoch 15/50\n",
      "696/696 [==============================] - 0s 82us/sample - loss: 0.0185 - val_loss: 0.0122\n",
      "Epoch 16/50\n",
      "696/696 [==============================] - 0s 81us/sample - loss: 0.0169 - val_loss: 0.0133\n",
      "Epoch 17/50\n",
      "696/696 [==============================] - 0s 82us/sample - loss: 0.0178 - val_loss: 0.0088\n",
      "Epoch 18/50\n",
      "696/696 [==============================] - 0s 78us/sample - loss: 0.0170 - val_loss: 0.0096\n",
      "Epoch 19/50\n",
      "696/696 [==============================] - 0s 78us/sample - loss: 0.0176 - val_loss: 0.0149\n",
      "Epoch 20/50\n",
      "696/696 [==============================] - 0s 76us/sample - loss: 0.0197 - val_loss: 0.0128\n",
      "Epoch 21/50\n",
      "696/696 [==============================] - 0s 78us/sample - loss: 0.0175 - val_loss: 0.0166\n",
      "Epoch 22/50\n",
      "696/696 [==============================] - 0s 76us/sample - loss: 0.0186 - val_loss: 0.0119\n",
      "Epoch 23/50\n",
      "696/696 [==============================] - 0s 82us/sample - loss: 0.0178 - val_loss: 0.0114\n",
      "Epoch 24/50\n",
      "696/696 [==============================] - 0s 84us/sample - loss: 0.0174 - val_loss: 0.0114\n",
      "Epoch 25/50\n",
      "696/696 [==============================] - 0s 85us/sample - loss: 0.0176 - val_loss: 0.0114\n",
      "Epoch 26/50\n",
      "696/696 [==============================] - 0s 83us/sample - loss: 0.0174 - val_loss: 0.0096\n",
      "Epoch 27/50\n",
      "696/696 [==============================] - 0s 79us/sample - loss: 0.0168 - val_loss: 0.0142\n",
      "Epoch 28/50\n",
      "696/696 [==============================] - 0s 79us/sample - loss: 0.0186 - val_loss: 0.0124\n",
      "Epoch 29/50\n",
      "696/696 [==============================] - 0s 79us/sample - loss: 0.0166 - val_loss: 0.0099\n",
      "Epoch 30/50\n",
      "696/696 [==============================] - 0s 81us/sample - loss: 0.0172 - val_loss: 0.0123\n",
      "Epoch 31/50\n",
      "696/696 [==============================] - 0s 85us/sample - loss: 0.0175 - val_loss: 0.0111\n",
      "Epoch 32/50\n",
      "696/696 [==============================] - 0s 79us/sample - loss: 0.0180 - val_loss: 0.0110\n",
      "Epoch 33/50\n",
      "696/696 [==============================] - 0s 77us/sample - loss: 0.0167 - val_loss: 0.0131\n",
      "Epoch 34/50\n",
      "696/696 [==============================] - 0s 78us/sample - loss: 0.0181 - val_loss: 0.0128\n",
      "Epoch 35/50\n",
      "696/696 [==============================] - 0s 80us/sample - loss: 0.0168 - val_loss: 0.0097\n",
      "Epoch 36/50\n",
      "696/696 [==============================] - 0s 80us/sample - loss: 0.0172 - val_loss: 0.0123\n",
      "Epoch 37/50\n",
      "696/696 [==============================] - 0s 82us/sample - loss: 0.0174 - val_loss: 0.0111\n",
      "Epoch 38/50\n",
      "696/696 [==============================] - 0s 77us/sample - loss: 0.0183 - val_loss: 0.0123\n",
      "Epoch 39/50\n",
      "696/696 [==============================] - 0s 75us/sample - loss: 0.0169 - val_loss: 0.0118\n",
      "Epoch 40/50\n",
      "696/696 [==============================] - 0s 80us/sample - loss: 0.0170 - val_loss: 0.0118\n",
      "Epoch 41/50\n",
      "696/696 [==============================] - 0s 82us/sample - loss: 0.0184 - val_loss: 0.0125\n",
      "Epoch 42/50\n",
      "696/696 [==============================] - 0s 78us/sample - loss: 0.0167 - val_loss: 0.0118\n",
      "Epoch 43/50\n",
      "696/696 [==============================] - 0s 80us/sample - loss: 0.0167 - val_loss: 0.0098\n",
      "Epoch 44/50\n",
      "696/696 [==============================] - 0s 76us/sample - loss: 0.0174 - val_loss: 0.0087\n",
      "Epoch 45/50\n",
      "696/696 [==============================] - 0s 74us/sample - loss: 0.0163 - val_loss: 0.0118\n",
      "Epoch 46/50\n",
      "696/696 [==============================] - 0s 76us/sample - loss: 0.0187 - val_loss: 0.0107\n",
      "Epoch 47/50\n",
      "696/696 [==============================] - 0s 76us/sample - loss: 0.0162 - val_loss: 0.0095\n",
      "Epoch 48/50\n",
      "696/696 [==============================] - 0s 78us/sample - loss: 0.0162 - val_loss: 0.0090\n",
      "Epoch 49/50\n",
      "696/696 [==============================] - 0s 81us/sample - loss: 0.0160 - val_loss: 0.0090\n",
      "Epoch 50/50\n",
      "696/696 [==============================] - 0s 81us/sample - loss: 0.0163 - val_loss: 0.0090\n",
      "第348个数，还剩3775个没有训练\n",
      "inv_hat [1.03092933 1.02897091 1.02897091 1.02897091 1.02798259 1.02698909\n",
      " 1.02698909 1.02798259 1.02698909 1.02798259 1.02798259 1.02798259\n",
      " 1.02798259 1.02798259 1.02798259 1.02798259 1.02798259 1.02798259\n",
      " 1.02897091 1.02798259 1.02798259 1.02798259 1.02798259 1.02798259\n",
      " 1.02798259 1.02798259 1.02798259 1.02798259 1.02798259 1.02798259]\n",
      "Test RMSE: 0.001\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0090\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0109 - val_loss: 0.0088\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0108 - val_loss: 0.0085\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0108 - val_loss: 0.0086\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0084\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0108 - val_loss: 0.0084\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0107 - val_loss: 0.0082\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0107 - val_loss: 0.0082\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0107 - val_loss: 0.0081\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0081\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0107 - val_loss: 0.0081\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0107 - val_loss: 0.0081\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0081\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0107 - val_loss: 0.0081\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0107 - val_loss: 0.0081\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0107 - val_loss: 0.0079\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0107 - val_loss: 0.0079\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0107 - val_loss: 0.0079\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0107 - val_loss: 0.0079\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0107 - val_loss: 0.0079\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0107 - val_loss: 0.0079\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0107 - val_loss: 0.0079\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0106 - val_loss: 0.0078\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0107 - val_loss: 0.0079\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0107 - val_loss: 0.0081\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0106 - val_loss: 0.0078\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0107 - val_loss: 0.0079\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0081\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0107 - val_loss: 0.0079\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0106 - val_loss: 0.0078\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0107 - val_loss: 0.0082\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0106 - val_loss: 0.0077\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0081\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0106 - val_loss: 0.0078\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0107 - val_loss: 0.0081\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0081\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0106 - val_loss: 0.0077\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0081\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0107 - val_loss: 0.0081\n",
      "第349个数，还剩3774个没有训练\n",
      "inv_hat [1.2199679  1.19143011 1.19842942 1.19862384 1.17207291 1.17139168\n",
      " 1.17129435 1.18627627 1.16701194 1.17946764 1.2064956  1.21261619\n",
      " 1.20727293 1.17693808 1.17333791 1.16000248 1.17022388 1.17100247\n",
      " 1.18802669 1.16243662 1.15932091 1.14510011 1.13145489 1.12687214\n",
      " 1.11175209 1.11477691 1.1062869  1.09925837 1.09066505 1.10052756]\n",
      "Test RMSE: 0.015\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0112 - val_loss: 0.0085\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0116 - val_loss: 0.0097\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0117 - val_loss: 0.0090\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0112 - val_loss: 0.0084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0112 - val_loss: 0.0092\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0112 - val_loss: 0.0091\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0085\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0091\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0088\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0085\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0089\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0089\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0086\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0091\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0111 - val_loss: 0.0088\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0085\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0089\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0089\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0111 - val_loss: 0.0085\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0111 - val_loss: 0.0090\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0111 - val_loss: 0.0089\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0085\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0089\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0111 - val_loss: 0.0089\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0111 - val_loss: 0.0086\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0089\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0089\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0111 - val_loss: 0.0086\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0111 - val_loss: 0.0089\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0111 - val_loss: 0.0089\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0111 - val_loss: 0.0086\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0111 - val_loss: 0.0090\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0111 - val_loss: 0.0088\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0111 - val_loss: 0.0086\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0089\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0111 - val_loss: 0.0089\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0087\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0111 - val_loss: 0.0090\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0087\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0087\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0089\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0111 - val_loss: 0.0088\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0086\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0111 - val_loss: 0.0090\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0111 - val_loss: 0.0089\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0087\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0088\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0088\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0088\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0088\n",
      "第350个数，还剩3773个没有训练\n",
      "inv_hat [1.47215184 1.45031177 1.44832797 1.44832797 1.41755111 1.4115964\n",
      " 1.40961207 1.42152201 1.40861987 1.41953639 1.45527245 1.46222023\n",
      " 1.46321296 1.41854375 1.3818462  1.35708497 1.36401505 1.36896662\n",
      " 1.38878504 1.369957   1.36896662 1.36302484 1.34224207 1.34323124\n",
      " 1.33136322 1.34323124 1.33729649 1.34026373 1.33235204 1.33432968]\n",
      "Test RMSE: 0.018\n",
      "Train on 1015 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1015/1015 [==============================] - 0s 88us/sample - loss: 0.0168 - val_loss: 0.0122\n",
      "Epoch 2/50\n",
      "1015/1015 [==============================] - 0s 85us/sample - loss: 0.0187 - val_loss: 0.0143\n",
      "Epoch 3/50\n",
      "1015/1015 [==============================] - 0s 83us/sample - loss: 0.0179 - val_loss: 0.0149\n",
      "Epoch 4/50\n",
      "1015/1015 [==============================] - 0s 77us/sample - loss: 0.0185 - val_loss: 0.0131\n",
      "Epoch 5/50\n",
      "1015/1015 [==============================] - 0s 77us/sample - loss: 0.0176 - val_loss: 0.0126\n",
      "Epoch 6/50\n",
      "1015/1015 [==============================] - 0s 80us/sample - loss: 0.0169 - val_loss: 0.0124\n",
      "Epoch 7/50\n",
      "1015/1015 [==============================] - 0s 83us/sample - loss: 0.0170 - val_loss: 0.0126\n",
      "Epoch 8/50\n",
      "1015/1015 [==============================] - 0s 83us/sample - loss: 0.0173 - val_loss: 0.0137\n",
      "Epoch 9/50\n",
      "1015/1015 [==============================] - 0s 84us/sample - loss: 0.0174 - val_loss: 0.0131\n",
      "Epoch 10/50\n",
      "1015/1015 [==============================] - 0s 88us/sample - loss: 0.0173 - val_loss: 0.0128\n",
      "Epoch 11/50\n",
      "1015/1015 [==============================] - 0s 90us/sample - loss: 0.0170 - val_loss: 0.0124\n",
      "Epoch 12/50\n",
      "1015/1015 [==============================] - 0s 83us/sample - loss: 0.0168 - val_loss: 0.0124\n",
      "Epoch 13/50\n",
      "1015/1015 [==============================] - 0s 81us/sample - loss: 0.0170 - val_loss: 0.0127\n",
      "Epoch 14/50\n",
      "1015/1015 [==============================] - 0s 81us/sample - loss: 0.0171 - val_loss: 0.0132\n",
      "Epoch 15/50\n",
      "1015/1015 [==============================] - 0s 83us/sample - loss: 0.0172 - val_loss: 0.0128\n",
      "Epoch 16/50\n",
      "1015/1015 [==============================] - 0s 84us/sample - loss: 0.0171 - val_loss: 0.0124\n",
      "Epoch 17/50\n",
      "1015/1015 [==============================] - 0s 83us/sample - loss: 0.0168 - val_loss: 0.0125\n",
      "Epoch 18/50\n",
      "1015/1015 [==============================] - 0s 86us/sample - loss: 0.0169 - val_loss: 0.0126\n",
      "Epoch 19/50\n",
      "1015/1015 [==============================] - 0s 83us/sample - loss: 0.0170 - val_loss: 0.0129\n",
      "Epoch 20/50\n",
      "1015/1015 [==============================] - 0s 82us/sample - loss: 0.0170 - val_loss: 0.0126\n",
      "Epoch 21/50\n",
      "1015/1015 [==============================] - 0s 80us/sample - loss: 0.0169 - val_loss: 0.0123\n",
      "Epoch 22/50\n",
      "1015/1015 [==============================] - 0s 82us/sample - loss: 0.0168 - val_loss: 0.0125\n",
      "Epoch 23/50\n",
      "1015/1015 [==============================] - 0s 81us/sample - loss: 0.0169 - val_loss: 0.0126\n",
      "Epoch 24/50\n",
      "1015/1015 [==============================] - 0s 80us/sample - loss: 0.0169 - val_loss: 0.0124\n",
      "Epoch 25/50\n",
      "1015/1015 [==============================] - 0s 80us/sample - loss: 0.0168 - val_loss: 0.0124\n",
      "Epoch 26/50\n",
      "1015/1015 [==============================] - 0s 78us/sample - loss: 0.0168 - val_loss: 0.0125\n",
      "Epoch 27/50\n",
      "1015/1015 [==============================] - 0s 79us/sample - loss: 0.0169 - val_loss: 0.0124\n",
      "Epoch 28/50\n",
      "1015/1015 [==============================] - 0s 79us/sample - loss: 0.0168 - val_loss: 0.0124\n",
      "Epoch 29/50\n",
      "1015/1015 [==============================] - 0s 82us/sample - loss: 0.0168 - val_loss: 0.0125\n",
      "Epoch 30/50\n",
      "1015/1015 [==============================] - 0s 83us/sample - loss: 0.0168 - val_loss: 0.0124\n",
      "Epoch 31/50\n",
      "1015/1015 [==============================] - 0s 81us/sample - loss: 0.0168 - val_loss: 0.0124\n",
      "Epoch 32/50\n",
      "1015/1015 [==============================] - 0s 81us/sample - loss: 0.0168 - val_loss: 0.0124\n",
      "Epoch 33/50\n",
      "1015/1015 [==============================] - 0s 85us/sample - loss: 0.0168 - val_loss: 0.0125\n",
      "Epoch 34/50\n",
      "1015/1015 [==============================] - 0s 82us/sample - loss: 0.0168 - val_loss: 0.0125\n",
      "Epoch 35/50\n",
      "1015/1015 [==============================] - 0s 82us/sample - loss: 0.0168 - val_loss: 0.0124\n",
      "Epoch 36/50\n",
      "1015/1015 [==============================] - 0s 83us/sample - loss: 0.0168 - val_loss: 0.0123\n",
      "Epoch 37/50\n",
      "1015/1015 [==============================] - 0s 79us/sample - loss: 0.0168 - val_loss: 0.0123\n",
      "Epoch 38/50\n",
      "1015/1015 [==============================] - 0s 80us/sample - loss: 0.0168 - val_loss: 0.0125\n",
      "Epoch 39/50\n",
      "1015/1015 [==============================] - 0s 85us/sample - loss: 0.0168 - val_loss: 0.0123\n",
      "Epoch 40/50\n",
      "1015/1015 [==============================] - 0s 81us/sample - loss: 0.0168 - val_loss: 0.0123\n",
      "Epoch 41/50\n",
      "1015/1015 [==============================] - 0s 79us/sample - loss: 0.0168 - val_loss: 0.0124\n",
      "Epoch 42/50\n",
      "1015/1015 [==============================] - 0s 83us/sample - loss: 0.0168 - val_loss: 0.0123\n",
      "Epoch 43/50\n",
      "1015/1015 [==============================] - 0s 81us/sample - loss: 0.0167 - val_loss: 0.0124\n",
      "Epoch 44/50\n",
      "1015/1015 [==============================] - 0s 82us/sample - loss: 0.0168 - val_loss: 0.0124\n",
      "Epoch 45/50\n",
      "1015/1015 [==============================] - 0s 80us/sample - loss: 0.0168 - val_loss: 0.0124\n",
      "Epoch 46/50\n",
      "1015/1015 [==============================] - 0s 81us/sample - loss: 0.0168 - val_loss: 0.0123\n",
      "Epoch 47/50\n",
      "1015/1015 [==============================] - 0s 78us/sample - loss: 0.0167 - val_loss: 0.0123\n",
      "Epoch 48/50\n",
      "1015/1015 [==============================] - 0s 83us/sample - loss: 0.0168 - val_loss: 0.0124\n",
      "Epoch 49/50\n",
      "1015/1015 [==============================] - 0s 83us/sample - loss: 0.0168 - val_loss: 0.0124\n",
      "Epoch 50/50\n",
      "1015/1015 [==============================] - 0s 83us/sample - loss: 0.0168 - val_loss: 0.0124\n",
      "第351个数，还剩3772个没有训练\n",
      "inv_hat [1.12157791 1.08789027 1.09481753 1.09481753 1.05226375 1.05524563\n",
      " 1.06021391 1.07504177 1.05226375 1.06021391 1.08986895 1.09283759\n",
      " 1.08887956 1.07405444 1.07998075 1.06714722 1.07602931 1.07899273\n",
      " 1.08789027 1.0691199  1.06813342 1.06220083 1.04629805 1.05027552\n",
      " 1.04430884 1.04928127 1.03236677 1.03137115 1.01941656 1.01941656]\n",
      "Test RMSE: 0.014\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0056\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0112 - val_loss: 0.0051\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0112 - val_loss: 0.0050\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0111 - val_loss: 0.0053\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0052\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0051\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0052\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0053\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0053\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0053\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0110 - val_loss: 0.0053\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0054\n",
      "第352个数，还剩3771个没有训练\n",
      "inv_hat [2.67398304 2.6341099  2.64302426 2.63383694 2.59371034 2.58910887\n",
      " 2.59127372 2.62040043 2.5972315  2.61786175 2.67270368 2.68432077\n",
      " 2.68796583 2.63829238 2.6484887  2.64083967 2.65614698 2.6628102\n",
      " 2.69102051 2.63701904 2.62475478 2.61152004 2.5746974  2.57505728\n",
      " 2.55888858 2.57577687 2.57505728 2.56597877 2.55395768 2.56867381]\n",
      "Test RMSE: 0.027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 881 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "881/881 [==============================] - 0s 81us/sample - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 2/50\n",
      "881/881 [==============================] - 0s 79us/sample - loss: 0.0076 - val_loss: 0.0099\n",
      "Epoch 3/50\n",
      "881/881 [==============================] - 0s 82us/sample - loss: 0.0085 - val_loss: 0.0083\n",
      "Epoch 4/50\n",
      "881/881 [==============================] - 0s 82us/sample - loss: 0.0077 - val_loss: 0.0092\n",
      "Epoch 5/50\n",
      "881/881 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0105\n",
      "Epoch 6/50\n",
      "881/881 [==============================] - 0s 79us/sample - loss: 0.0085 - val_loss: 0.0135\n",
      "Epoch 7/50\n",
      "881/881 [==============================] - 0s 78us/sample - loss: 0.0093 - val_loss: 0.0128\n",
      "Epoch 8/50\n",
      "881/881 [==============================] - 0s 84us/sample - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 9/50\n",
      "881/881 [==============================] - 0s 80us/sample - loss: 0.0095 - val_loss: 0.0086\n",
      "Epoch 10/50\n",
      "881/881 [==============================] - 0s 83us/sample - loss: 0.0086 - val_loss: 0.0093\n",
      "Epoch 11/50\n",
      "881/881 [==============================] - 0s 84us/sample - loss: 0.0083 - val_loss: 0.0129\n",
      "Epoch 12/50\n",
      "881/881 [==============================] - 0s 82us/sample - loss: 0.0075 - val_loss: 0.0106\n",
      "Epoch 13/50\n",
      "881/881 [==============================] - 0s 79us/sample - loss: 0.0081 - val_loss: 0.0088\n",
      "Epoch 14/50\n",
      "881/881 [==============================] - 0s 82us/sample - loss: 0.0073 - val_loss: 0.0098\n",
      "Epoch 15/50\n",
      "881/881 [==============================] - 0s 76us/sample - loss: 0.0069 - val_loss: 0.0090\n",
      "Epoch 16/50\n",
      "881/881 [==============================] - 0s 79us/sample - loss: 0.0078 - val_loss: 0.0086\n",
      "Epoch 17/50\n",
      "881/881 [==============================] - 0s 78us/sample - loss: 0.0076 - val_loss: 0.0108\n",
      "Epoch 18/50\n",
      "881/881 [==============================] - 0s 77us/sample - loss: 0.0085 - val_loss: 0.0134\n",
      "Epoch 19/50\n",
      "881/881 [==============================] - 0s 77us/sample - loss: 0.0084 - val_loss: 0.0114\n",
      "Epoch 20/50\n",
      "881/881 [==============================] - 0s 77us/sample - loss: 0.0087 - val_loss: 0.0092\n",
      "Epoch 21/50\n",
      "881/881 [==============================] - 0s 77us/sample - loss: 0.0114 - val_loss: 0.0092\n",
      "Epoch 22/50\n",
      "881/881 [==============================] - 0s 77us/sample - loss: 0.0098 - val_loss: 0.0160\n",
      "Epoch 23/50\n",
      "881/881 [==============================] - 0s 78us/sample - loss: 0.0160 - val_loss: 0.0090\n",
      "Epoch 24/50\n",
      "881/881 [==============================] - 0s 79us/sample - loss: 0.0092 - val_loss: 0.0082\n",
      "Epoch 25/50\n",
      "881/881 [==============================] - 0s 84us/sample - loss: 0.0092 - val_loss: 0.0105\n",
      "Epoch 26/50\n",
      "881/881 [==============================] - 0s 85us/sample - loss: 0.0123 - val_loss: 0.0111\n",
      "Epoch 27/50\n",
      "881/881 [==============================] - 0s 87us/sample - loss: 0.0109 - val_loss: 0.0087\n",
      "Epoch 28/50\n",
      "881/881 [==============================] - 0s 82us/sample - loss: 0.0149 - val_loss: 0.0130\n",
      "Epoch 29/50\n",
      "881/881 [==============================] - 0s 86us/sample - loss: 0.0076 - val_loss: 0.0116\n",
      "Epoch 30/50\n",
      "881/881 [==============================] - 0s 86us/sample - loss: 0.0124 - val_loss: 0.0083\n",
      "Epoch 31/50\n",
      "881/881 [==============================] - 0s 79us/sample - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 32/50\n",
      "881/881 [==============================] - 0s 82us/sample - loss: 0.0100 - val_loss: 0.0113\n",
      "Epoch 33/50\n",
      "881/881 [==============================] - 0s 84us/sample - loss: 0.0118 - val_loss: 0.0097\n",
      "Epoch 34/50\n",
      "881/881 [==============================] - 0s 79us/sample - loss: 0.0094 - val_loss: 0.0083\n",
      "Epoch 35/50\n",
      "881/881 [==============================] - 0s 79us/sample - loss: 0.0133 - val_loss: 0.0125\n",
      "Epoch 36/50\n",
      "881/881 [==============================] - 0s 81us/sample - loss: 0.0073 - val_loss: 0.0111\n",
      "Epoch 37/50\n",
      "881/881 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0082\n",
      "Epoch 38/50\n",
      "881/881 [==============================] - 0s 79us/sample - loss: 0.0085 - val_loss: 0.0083\n",
      "Epoch 39/50\n",
      "881/881 [==============================] - 0s 78us/sample - loss: 0.0089 - val_loss: 0.0106\n",
      "Epoch 40/50\n",
      "881/881 [==============================] - 0s 77us/sample - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 41/50\n",
      "881/881 [==============================] - 0s 83us/sample - loss: 0.0089 - val_loss: 0.0085\n",
      "Epoch 42/50\n",
      "881/881 [==============================] - 0s 82us/sample - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 43/50\n",
      "881/881 [==============================] - 0s 83us/sample - loss: 0.0072 - val_loss: 0.0110\n",
      "Epoch 44/50\n",
      "881/881 [==============================] - 0s 85us/sample - loss: 0.0120 - val_loss: 0.0082\n",
      "Epoch 45/50\n",
      "881/881 [==============================] - 0s 84us/sample - loss: 0.0081 - val_loss: 0.0087\n",
      "Epoch 46/50\n",
      "881/881 [==============================] - 0s 88us/sample - loss: 0.0087 - val_loss: 0.0110\n",
      "Epoch 47/50\n",
      "881/881 [==============================] - 0s 84us/sample - loss: 0.0092 - val_loss: 0.0103\n",
      "Epoch 48/50\n",
      "881/881 [==============================] - 0s 82us/sample - loss: 0.0090 - val_loss: 0.0087\n",
      "Epoch 49/50\n",
      "881/881 [==============================] - 0s 83us/sample - loss: 0.0108 - val_loss: 0.0103\n",
      "Epoch 50/50\n",
      "881/881 [==============================] - 0s 80us/sample - loss: 0.0074 - val_loss: 0.0113\n",
      "第353个数，还剩3770个没有训练\n",
      "inv_hat [1.26922265 1.26258123 1.26258123 1.26258123 1.25589498 1.25493623\n",
      " 1.25493623 1.25780978 1.25493623 1.2587659  1.26638203 1.2682768\n",
      " 1.26732983 1.26067533 1.26160567 1.25873717 1.26065036 1.26256009\n",
      " 1.26636862 1.26065036 1.25969425 1.25586086 1.25297699 1.25201401\n",
      " 1.25105015 1.2539391  1.25297699 1.25105015 1.25008567 1.25105015]\n",
      "Test RMSE: 0.004\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0112 - val_loss: 0.0050\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0114 - val_loss: 0.0035\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0115 - val_loss: 0.0082\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0112 - val_loss: 0.0036\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0107 - val_loss: 0.0047\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0051\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0114 - val_loss: 0.0058\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0105 - val_loss: 0.0042\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0035\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0111 - val_loss: 0.0072\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0047\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0105 - val_loss: 0.0046\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0111 - val_loss: 0.0037\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0114 - val_loss: 0.0081\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0037\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0106 - val_loss: 0.0044\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0048\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0114 - val_loss: 0.0066\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0106 - val_loss: 0.0036\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0108 - val_loss: 0.0037\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0062\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0112 - val_loss: 0.0053\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0104 - val_loss: 0.0042\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0110 - val_loss: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0112 - val_loss: 0.0083\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0113 - val_loss: 0.0045\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0105 - val_loss: 0.0045\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0038\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0115 - val_loss: 0.0085\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0037\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0106 - val_loss: 0.0044\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0047\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0115 - val_loss: 0.0073\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0035\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0108 - val_loss: 0.0039\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0065\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0114 - val_loss: 0.0057\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0105 - val_loss: 0.0042\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0034\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0112 - val_loss: 0.0084\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0113 - val_loss: 0.0044\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0105 - val_loss: 0.0044\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0039\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0116 - val_loss: 0.0088\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0036\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0106 - val_loss: 0.0043\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0049\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0116 - val_loss: 0.0073\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0107 - val_loss: 0.0037\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0109 - val_loss: 0.0038\n",
      "第354个数，还剩3769个没有训练\n",
      "inv_hat [0.96204198 0.94412391 0.95108654 0.95009145 0.93716835 0.93617531\n",
      " 0.93319708 0.94611246 0.93716835 0.9431298  0.9530772  0.94909652\n",
      " 0.95208184 0.94114202 0.94014839 0.9351824  0.94114202 0.94412391\n",
      " 0.9530772  0.93816159 0.93319708 0.92228652 0.91337079 0.91337079\n",
      " 0.9015037  0.90051578 0.89952812 0.89656611 0.89459226 0.89952812]\n",
      "Test RMSE: 0.008\n",
      "Train on 807 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "807/807 [==============================] - 0s 84us/sample - loss: 0.0204 - val_loss: 0.0115\n",
      "Epoch 2/50\n",
      "807/807 [==============================] - 0s 83us/sample - loss: 0.0198 - val_loss: 0.0125\n",
      "Epoch 3/50\n",
      "807/807 [==============================] - 0s 83us/sample - loss: 0.0197 - val_loss: 0.0120\n",
      "Epoch 4/50\n",
      "807/807 [==============================] - 0s 86us/sample - loss: 0.0197 - val_loss: 0.0124\n",
      "Epoch 5/50\n",
      "807/807 [==============================] - 0s 83us/sample - loss: 0.0197 - val_loss: 0.0122\n",
      "Epoch 6/50\n",
      "807/807 [==============================] - 0s 84us/sample - loss: 0.0197 - val_loss: 0.0122\n",
      "Epoch 7/50\n",
      "807/807 [==============================] - 0s 83us/sample - loss: 0.0197 - val_loss: 0.0121\n",
      "Epoch 8/50\n",
      "807/807 [==============================] - 0s 83us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 9/50\n",
      "807/807 [==============================] - 0s 80us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 10/50\n",
      "807/807 [==============================] - 0s 85us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 11/50\n",
      "807/807 [==============================] - 0s 83us/sample - loss: 0.0196 - val_loss: 0.0121\n",
      "Epoch 12/50\n",
      "807/807 [==============================] - 0s 83us/sample - loss: 0.0196 - val_loss: 0.0121\n",
      "Epoch 13/50\n",
      "807/807 [==============================] - 0s 79us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 14/50\n",
      "807/807 [==============================] - 0s 81us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 15/50\n",
      "807/807 [==============================] - 0s 83us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 16/50\n",
      "807/807 [==============================] - 0s 82us/sample - loss: 0.0196 - val_loss: 0.0121\n",
      "Epoch 17/50\n",
      "807/807 [==============================] - 0s 78us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 18/50\n",
      "807/807 [==============================] - 0s 84us/sample - loss: 0.0196 - val_loss: 0.0121\n",
      "Epoch 19/50\n",
      "807/807 [==============================] - 0s 83us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 20/50\n",
      "807/807 [==============================] - 0s 84us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 21/50\n",
      "807/807 [==============================] - 0s 86us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 22/50\n",
      "807/807 [==============================] - 0s 83us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 23/50\n",
      "807/807 [==============================] - 0s 82us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 24/50\n",
      "807/807 [==============================] - 0s 83us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 25/50\n",
      "807/807 [==============================] - 0s 84us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 26/50\n",
      "807/807 [==============================] - 0s 85us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 27/50\n",
      "807/807 [==============================] - 0s 84us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 28/50\n",
      "807/807 [==============================] - 0s 84us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 29/50\n",
      "807/807 [==============================] - 0s 81us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 30/50\n",
      "807/807 [==============================] - 0s 82us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 31/50\n",
      "807/807 [==============================] - 0s 80us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 32/50\n",
      "807/807 [==============================] - 0s 81us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 33/50\n",
      "807/807 [==============================] - 0s 82us/sample - loss: 0.0196 - val_loss: 0.0121\n",
      "Epoch 34/50\n",
      "807/807 [==============================] - 0s 79us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 35/50\n",
      "807/807 [==============================] - 0s 81us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 36/50\n",
      "807/807 [==============================] - 0s 79us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 37/50\n",
      "807/807 [==============================] - 0s 85us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 38/50\n",
      "807/807 [==============================] - 0s 93us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 39/50\n",
      "807/807 [==============================] - 0s 86us/sample - loss: 0.0196 - val_loss: 0.0121\n",
      "Epoch 40/50\n",
      "807/807 [==============================] - 0s 84us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 41/50\n",
      "807/807 [==============================] - 0s 83us/sample - loss: 0.0196 - val_loss: 0.0121\n",
      "Epoch 42/50\n",
      "807/807 [==============================] - 0s 82us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 43/50\n",
      "807/807 [==============================] - 0s 81us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 44/50\n",
      "807/807 [==============================] - ETA: 0s - loss: 0.019 - 0s 81us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 45/50\n",
      "807/807 [==============================] - 0s 82us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 46/50\n",
      "807/807 [==============================] - 0s 83us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 47/50\n",
      "807/807 [==============================] - 0s 83us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 48/50\n",
      "807/807 [==============================] - 0s 84us/sample - loss: 0.0196 - val_loss: 0.0123\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "807/807 [==============================] - 0s 82us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 50/50\n",
      "807/807 [==============================] - 0s 87us/sample - loss: 0.0196 - val_loss: 0.0122\n",
      "第355个数，还剩3768个没有训练\n",
      "inv_hat [0.79873206 0.78889819 0.79184664 0.7898808  0.77908449 0.77908449\n",
      " 0.77908449 0.78496976 0.78006468 0.78300697 0.79381313 0.79282981\n",
      " 0.79086366 0.78398825 0.78496976 0.78104516 0.78398825 0.78693357\n",
      " 0.79282981 0.78496976 0.78595158 0.78202596 0.77712503 0.77712503\n",
      " 0.77418821 0.77614571 0.77614571 0.77418821 0.7722321  0.77516679]\n",
      "Test RMSE: 0.005\n",
      "Train on 491 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "491/491 [==============================] - 0s 84us/sample - loss: 0.0229 - val_loss: 0.0351\n",
      "Epoch 2/50\n",
      "491/491 [==============================] - 0s 85us/sample - loss: 0.0190 - val_loss: 0.0340\n",
      "Epoch 3/50\n",
      "491/491 [==============================] - 0s 82us/sample - loss: 0.0185 - val_loss: 0.0298\n",
      "Epoch 4/50\n",
      "491/491 [==============================] - 0s 84us/sample - loss: 0.0188 - val_loss: 0.0298\n",
      "Epoch 5/50\n",
      "491/491 [==============================] - 0s 86us/sample - loss: 0.0182 - val_loss: 0.0290\n",
      "Epoch 6/50\n",
      "491/491 [==============================] - 0s 81us/sample - loss: 0.0181 - val_loss: 0.0282\n",
      "Epoch 7/50\n",
      "491/491 [==============================] - 0s 81us/sample - loss: 0.0182 - val_loss: 0.0283\n",
      "Epoch 8/50\n",
      "491/491 [==============================] - 0s 87us/sample - loss: 0.0181 - val_loss: 0.0279\n",
      "Epoch 9/50\n",
      "491/491 [==============================] - 0s 88us/sample - loss: 0.0182 - val_loss: 0.0281\n",
      "Epoch 10/50\n",
      "491/491 [==============================] - 0s 84us/sample - loss: 0.0181 - val_loss: 0.0279\n",
      "Epoch 11/50\n",
      "491/491 [==============================] - 0s 87us/sample - loss: 0.0181 - val_loss: 0.0280\n",
      "Epoch 12/50\n",
      "491/491 [==============================] - 0s 81us/sample - loss: 0.0181 - val_loss: 0.0279\n",
      "Epoch 13/50\n",
      "491/491 [==============================] - 0s 82us/sample - loss: 0.0181 - val_loss: 0.0281\n",
      "Epoch 14/50\n",
      "491/491 [==============================] - 0s 82us/sample - loss: 0.0181 - val_loss: 0.0280\n",
      "Epoch 15/50\n",
      "491/491 [==============================] - 0s 85us/sample - loss: 0.0181 - val_loss: 0.0282\n",
      "Epoch 16/50\n",
      "491/491 [==============================] - 0s 79us/sample - loss: 0.0181 - val_loss: 0.0281\n",
      "Epoch 17/50\n",
      "491/491 [==============================] - 0s 82us/sample - loss: 0.0181 - val_loss: 0.0283\n",
      "Epoch 18/50\n",
      "491/491 [==============================] - 0s 80us/sample - loss: 0.0181 - val_loss: 0.0280\n",
      "Epoch 19/50\n",
      "491/491 [==============================] - 0s 78us/sample - loss: 0.0181 - val_loss: 0.0283\n",
      "Epoch 20/50\n",
      "491/491 [==============================] - 0s 80us/sample - loss: 0.0181 - val_loss: 0.0280\n",
      "Epoch 21/50\n",
      "491/491 [==============================] - 0s 80us/sample - loss: 0.0181 - val_loss: 0.0282\n",
      "Epoch 22/50\n",
      "491/491 [==============================] - 0s 83us/sample - loss: 0.0181 - val_loss: 0.0281\n",
      "Epoch 23/50\n",
      "491/491 [==============================] - 0s 81us/sample - loss: 0.0181 - val_loss: 0.0282\n",
      "Epoch 24/50\n",
      "491/491 [==============================] - 0s 84us/sample - loss: 0.0181 - val_loss: 0.0280\n",
      "Epoch 25/50\n",
      "491/491 [==============================] - 0s 84us/sample - loss: 0.0181 - val_loss: 0.0282\n",
      "Epoch 26/50\n",
      "491/491 [==============================] - 0s 82us/sample - loss: 0.0181 - val_loss: 0.0280\n",
      "Epoch 27/50\n",
      "491/491 [==============================] - 0s 82us/sample - loss: 0.0181 - val_loss: 0.0283\n",
      "Epoch 28/50\n",
      "491/491 [==============================] - 0s 79us/sample - loss: 0.0181 - val_loss: 0.0282\n",
      "Epoch 29/50\n",
      "491/491 [==============================] - 0s 80us/sample - loss: 0.0181 - val_loss: 0.0283\n",
      "Epoch 30/50\n",
      "491/491 [==============================] - 0s 79us/sample - loss: 0.0181 - val_loss: 0.0282\n",
      "Epoch 31/50\n",
      "491/491 [==============================] - 0s 81us/sample - loss: 0.0181 - val_loss: 0.0283\n",
      "Epoch 32/50\n",
      "491/491 [==============================] - 0s 80us/sample - loss: 0.0181 - val_loss: 0.0281\n",
      "Epoch 33/50\n",
      "491/491 [==============================] - 0s 84us/sample - loss: 0.0181 - val_loss: 0.0283\n",
      "Epoch 34/50\n",
      "491/491 [==============================] - 0s 79us/sample - loss: 0.0181 - val_loss: 0.0281\n",
      "Epoch 35/50\n",
      "491/491 [==============================] - 0s 82us/sample - loss: 0.0181 - val_loss: 0.0282\n",
      "Epoch 36/50\n",
      "491/491 [==============================] - 0s 80us/sample - loss: 0.0181 - val_loss: 0.0281\n",
      "Epoch 37/50\n",
      "491/491 [==============================] - 0s 83us/sample - loss: 0.0181 - val_loss: 0.0282\n",
      "Epoch 38/50\n",
      "491/491 [==============================] - 0s 88us/sample - loss: 0.0181 - val_loss: 0.0281\n",
      "Epoch 39/50\n",
      "491/491 [==============================] - 0s 81us/sample - loss: 0.0181 - val_loss: 0.0282\n",
      "Epoch 40/50\n",
      "491/491 [==============================] - 0s 86us/sample - loss: 0.0181 - val_loss: 0.0281\n",
      "Epoch 41/50\n",
      "491/491 [==============================] - 0s 79us/sample - loss: 0.0181 - val_loss: 0.0282\n",
      "Epoch 42/50\n",
      "491/491 [==============================] - 0s 85us/sample - loss: 0.0181 - val_loss: 0.0281\n",
      "Epoch 43/50\n",
      "491/491 [==============================] - 0s 80us/sample - loss: 0.0181 - val_loss: 0.0283\n",
      "Epoch 44/50\n",
      "491/491 [==============================] - 0s 84us/sample - loss: 0.0181 - val_loss: 0.0281\n",
      "Epoch 45/50\n",
      "491/491 [==============================] - 0s 83us/sample - loss: 0.0181 - val_loss: 0.0283\n",
      "Epoch 46/50\n",
      "491/491 [==============================] - 0s 82us/sample - loss: 0.0181 - val_loss: 0.0282\n",
      "Epoch 47/50\n",
      "491/491 [==============================] - 0s 84us/sample - loss: 0.0181 - val_loss: 0.0284\n",
      "Epoch 48/50\n",
      "491/491 [==============================] - 0s 83us/sample - loss: 0.0181 - val_loss: 0.0282\n",
      "Epoch 49/50\n",
      "491/491 [==============================] - 0s 83us/sample - loss: 0.0181 - val_loss: 0.0284\n",
      "Epoch 50/50\n",
      "491/491 [==============================] - 0s 84us/sample - loss: 0.0181 - val_loss: 0.0282\n",
      "第356个数，还剩3767个没有训练\n",
      "inv_hat [0.92821375 0.91856727 0.91430811 0.9119364  0.88822679 0.88515679\n",
      " 0.88928538 0.89683628 0.88726588 0.89469898 0.90878102 0.91134417\n",
      " 0.91312173 0.90563416 0.9042603  0.89654451 0.90102935 0.9004431\n",
      " 0.90651833 0.89131081 0.89324509 0.89063502 0.88105504 0.88153056\n",
      " 0.87378355 0.87906224 0.8706985  0.86394624 0.85874156 0.86348756]\n",
      "Test RMSE: 0.009\n",
      "Train on 1193 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0077 - val_loss: 0.0065\n",
      "Epoch 2/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 3/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0068 - val_loss: 0.0028\n",
      "Epoch 4/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0069 - val_loss: 0.0030\n",
      "Epoch 5/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 6/50\n",
      "1193/1193 [==============================] - 0s 74us/sample - loss: 0.0070 - val_loss: 0.0026\n",
      "Epoch 7/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0069 - val_loss: 0.0059\n",
      "Epoch 8/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0079 - val_loss: 0.0047\n",
      "Epoch 9/50\n",
      "1193/1193 [==============================] - 0s 75us/sample - loss: 0.0072 - val_loss: 0.0033\n",
      "Epoch 10/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0068 - val_loss: 0.0039\n",
      "Epoch 11/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0071 - val_loss: 0.0031\n",
      "Epoch 12/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0069 - val_loss: 0.0040\n",
      "Epoch 13/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0077 - val_loss: 0.0050\n",
      "Epoch 14/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0070 - val_loss: 0.0026\n",
      "Epoch 15/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0067 - val_loss: 0.0035\n",
      "Epoch 16/50\n",
      "1193/1193 [==============================] - 0s 86us/sample - loss: 0.0072 - val_loss: 0.0047\n",
      "Epoch 17/50\n",
      "1193/1193 [==============================] - 0s 86us/sample - loss: 0.0068 - val_loss: 0.0017\n",
      "Epoch 18/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0068 - val_loss: 0.0039\n",
      "Epoch 19/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0070 - val_loss: 0.0040\n",
      "Epoch 20/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0070 - val_loss: 0.0026\n",
      "Epoch 21/50\n",
      "1193/1193 [==============================] - 0s 85us/sample - loss: 0.0069 - val_loss: 0.0037\n",
      "Epoch 22/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0071 - val_loss: 0.0043\n",
      "Epoch 23/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0068 - val_loss: 0.0021\n",
      "Epoch 24/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0066 - val_loss: 0.0035\n",
      "Epoch 25/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 26/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0074 - val_loss: 0.0049\n",
      "Epoch 27/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0073 - val_loss: 0.0043\n",
      "Epoch 28/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0076 - val_loss: 0.0052\n",
      "Epoch 29/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0075 - val_loss: 0.0049\n",
      "Epoch 30/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0075 - val_loss: 0.0047\n",
      "Epoch 31/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0074 - val_loss: 0.0047\n",
      "Epoch 32/50\n",
      "1193/1193 [==============================] - 0s 75us/sample - loss: 0.0075 - val_loss: 0.0046\n",
      "Epoch 33/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0075 - val_loss: 0.0048\n",
      "Epoch 34/50\n",
      "1193/1193 [==============================] - 0s 75us/sample - loss: 0.0073 - val_loss: 0.0028\n",
      "Epoch 35/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 36/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0072 - val_loss: 0.0033\n",
      "Epoch 37/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0071 - val_loss: 0.0048\n",
      "Epoch 38/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0074 - val_loss: 0.0051\n",
      "Epoch 39/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0074 - val_loss: 0.0047\n",
      "Epoch 40/50\n",
      "1193/1193 [==============================] - 0s 83us/sample - loss: 0.0072 - val_loss: 0.0028\n",
      "Epoch 41/50\n",
      "1193/1193 [==============================] - 0s 84us/sample - loss: 0.0070 - val_loss: 0.0039\n",
      "Epoch 42/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0070 - val_loss: 0.0035\n",
      "Epoch 43/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0068 - val_loss: 0.0023\n",
      "Epoch 44/50\n",
      "1193/1193 [==============================] - 0s 75us/sample - loss: 0.0066 - val_loss: 0.0027\n",
      "Epoch 45/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0069 - val_loss: 0.0034\n",
      "Epoch 46/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0070 - val_loss: 0.0036\n",
      "Epoch 47/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0069 - val_loss: 0.0034\n",
      "Epoch 48/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0067 - val_loss: 0.0023\n",
      "Epoch 49/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0067 - val_loss: 0.0029\n",
      "Epoch 50/50\n",
      "1193/1193 [==============================] - 0s 84us/sample - loss: 0.0069 - val_loss: 0.0033\n",
      "第357个数，还剩3766个没有训练\n",
      "inv_hat [1.04456662 1.04477012 1.04487186 1.04507526 1.04517695 1.04558338\n",
      " 1.04568498 1.04588812 1.04598967 1.04619258 1.04659866 1.04670012\n",
      " 1.04680146 1.0470043  1.04710569 1.0475109  1.04771344 1.04781467\n",
      " 1.04791588 1.04811824 1.04852253 1.04862357 1.04882558 1.04892642\n",
      " 1.04902737 1.04943087 1.04963245 1.04973309 1.04993451 1.05003518]\n",
      "Test RMSE: 0.000\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0077 - val_loss: 0.0027\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0077 - val_loss: 0.0031\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0078 - val_loss: 0.0033\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0076 - val_loss: 0.0027\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0077 - val_loss: 0.0027\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0077 - val_loss: 0.0033\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0077 - val_loss: 0.0030\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0076 - val_loss: 0.0027\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0077 - val_loss: 0.0031\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0077 - val_loss: 0.0035\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0077 - val_loss: 0.0031\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0076 - val_loss: 0.0028\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0077 - val_loss: 0.0031\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0077 - val_loss: 0.0035\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0077 - val_loss: 0.0032\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0076 - val_loss: 0.0027\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0077 - val_loss: 0.0031\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0077 - val_loss: 0.0035\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0077 - val_loss: 0.0032\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0076 - val_loss: 0.0028\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0077 - val_loss: 0.0032\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0077 - val_loss: 0.0032\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0077 - val_loss: 0.0030\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0076 - val_loss: 0.0028\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0077 - val_loss: 0.0031\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0077 - val_loss: 0.0033\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0077 - val_loss: 0.0032\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0076 - val_loss: 0.0028\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0077 - val_loss: 0.0031\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0077 - val_loss: 0.0032\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0077 - val_loss: 0.0030\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0076 - val_loss: 0.0028\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0077 - val_loss: 0.0032\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0078 - val_loss: 0.0032\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0077 - val_loss: 0.0030\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 72us/sample - loss: 0.0076 - val_loss: 0.0028\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0077 - val_loss: 0.0031\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0079 - val_loss: 0.0036\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0077 - val_loss: 0.0032\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0077 - val_loss: 0.0028\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0077 - val_loss: 0.0031\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0081 - val_loss: 0.0040\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0078 - val_loss: 0.0032\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0077 - val_loss: 0.0027\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 87us/sample - loss: 0.0077 - val_loss: 0.0028\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0080 - val_loss: 0.0037\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0080 - val_loss: 0.0035\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0077 - val_loss: 0.0027\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0078 - val_loss: 0.0027\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0078 - val_loss: 0.0031\n",
      "第358个数，还剩3765个没有训练\n",
      "inv_hat [0.58932682 0.58210354 0.58309858 0.58268395 0.56978333 0.56978333\n",
      " 0.57052562 0.57647288 0.5692061  0.57300184 0.58467492 0.5879968\n",
      " 0.58691665 0.57539796 0.5754806  0.57184595 0.57639014 0.57556329\n",
      " 0.58086034 0.57192846 0.56838172 0.56508738 0.56130466 0.56163341\n",
      " 0.55638043 0.5583488  0.55818473 0.55720034 0.5532674  0.55498719]\n",
      "Test RMSE: 0.007\n",
      "Train on 824 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "824/824 [==============================] - 0s 82us/sample - loss: 0.0195 - val_loss: 0.0111\n",
      "Epoch 2/50\n",
      "824/824 [==============================] - 0s 80us/sample - loss: 0.0196 - val_loss: 0.0114\n",
      "Epoch 3/50\n",
      "824/824 [==============================] - 0s 78us/sample - loss: 0.0195 - val_loss: 0.0110\n",
      "Epoch 4/50\n",
      "824/824 [==============================] - 0s 78us/sample - loss: 0.0195 - val_loss: 0.0112\n",
      "Epoch 5/50\n",
      "824/824 [==============================] - 0s 79us/sample - loss: 0.0195 - val_loss: 0.0115\n",
      "Epoch 6/50\n",
      "824/824 [==============================] - 0s 84us/sample - loss: 0.0195 - val_loss: 0.0111\n",
      "Epoch 7/50\n",
      "824/824 [==============================] - 0s 85us/sample - loss: 0.0195 - val_loss: 0.0115\n",
      "Epoch 8/50\n",
      "824/824 [==============================] - 0s 84us/sample - loss: 0.0195 - val_loss: 0.0112\n",
      "Epoch 9/50\n",
      "824/824 [==============================] - 0s 83us/sample - loss: 0.0195 - val_loss: 0.0115\n",
      "Epoch 10/50\n",
      "824/824 [==============================] - 0s 75us/sample - loss: 0.0195 - val_loss: 0.0115\n",
      "Epoch 11/50\n",
      "824/824 [==============================] - 0s 79us/sample - loss: 0.0194 - val_loss: 0.0111\n",
      "Epoch 12/50\n",
      "824/824 [==============================] - 0s 75us/sample - loss: 0.0194 - val_loss: 0.0110\n",
      "Epoch 13/50\n",
      "824/824 [==============================] - 0s 79us/sample - loss: 0.0195 - val_loss: 0.0112\n",
      "Epoch 14/50\n",
      "824/824 [==============================] - 0s 79us/sample - loss: 0.0194 - val_loss: 0.0108\n",
      "Epoch 15/50\n",
      "824/824 [==============================] - 0s 75us/sample - loss: 0.0195 - val_loss: 0.0113\n",
      "Epoch 16/50\n",
      "824/824 [==============================] - 0s 81us/sample - loss: 0.0194 - val_loss: 0.0108\n",
      "Epoch 17/50\n",
      "824/824 [==============================] - 0s 81us/sample - loss: 0.0194 - val_loss: 0.0108\n",
      "Epoch 18/50\n",
      "824/824 [==============================] - 0s 78us/sample - loss: 0.0195 - val_loss: 0.0110\n",
      "Epoch 19/50\n",
      "824/824 [==============================] - 0s 80us/sample - loss: 0.0194 - val_loss: 0.0107\n",
      "Epoch 20/50\n",
      "824/824 [==============================] - 0s 83us/sample - loss: 0.0194 - val_loss: 0.0110\n",
      "Epoch 21/50\n",
      "824/824 [==============================] - 0s 83us/sample - loss: 0.0194 - val_loss: 0.0109\n",
      "Epoch 22/50\n",
      "824/824 [==============================] - 0s 78us/sample - loss: 0.0194 - val_loss: 0.0112\n",
      "Epoch 23/50\n",
      "824/824 [==============================] - 0s 85us/sample - loss: 0.0194 - val_loss: 0.0105\n",
      "Epoch 24/50\n",
      "824/824 [==============================] - 0s 80us/sample - loss: 0.0194 - val_loss: 0.0108\n",
      "Epoch 25/50\n",
      "824/824 [==============================] - 0s 79us/sample - loss: 0.0194 - val_loss: 0.0106\n",
      "Epoch 26/50\n",
      "824/824 [==============================] - 0s 87us/sample - loss: 0.0194 - val_loss: 0.0108\n",
      "Epoch 27/50\n",
      "824/824 [==============================] - 0s 88us/sample - loss: 0.0194 - val_loss: 0.0107\n",
      "Epoch 28/50\n",
      "824/824 [==============================] - 0s 78us/sample - loss: 0.0194 - val_loss: 0.0106\n",
      "Epoch 29/50\n",
      "824/824 [==============================] - 0s 78us/sample - loss: 0.0194 - val_loss: 0.0108\n",
      "Epoch 30/50\n",
      "824/824 [==============================] - 0s 75us/sample - loss: 0.0194 - val_loss: 0.0103\n",
      "Epoch 31/50\n",
      "824/824 [==============================] - 0s 79us/sample - loss: 0.0194 - val_loss: 0.0107\n",
      "Epoch 32/50\n",
      "824/824 [==============================] - 0s 82us/sample - loss: 0.0194 - val_loss: 0.0109\n",
      "Epoch 33/50\n",
      "824/824 [==============================] - 0s 84us/sample - loss: 0.0194 - val_loss: 0.0106\n",
      "Epoch 34/50\n",
      "824/824 [==============================] - 0s 80us/sample - loss: 0.0194 - val_loss: 0.0104\n",
      "Epoch 35/50\n",
      "824/824 [==============================] - 0s 80us/sample - loss: 0.0194 - val_loss: 0.0107\n",
      "Epoch 36/50\n",
      "824/824 [==============================] - 0s 81us/sample - loss: 0.0194 - val_loss: 0.0103\n",
      "Epoch 37/50\n",
      "824/824 [==============================] - 0s 79us/sample - loss: 0.0194 - val_loss: 0.0104\n",
      "Epoch 38/50\n",
      "824/824 [==============================] - 0s 78us/sample - loss: 0.0194 - val_loss: 0.0105\n",
      "Epoch 39/50\n",
      "824/824 [==============================] - 0s 83us/sample - loss: 0.0194 - val_loss: 0.0103\n",
      "Epoch 40/50\n",
      "824/824 [==============================] - 0s 81us/sample - loss: 0.0194 - val_loss: 0.0106\n",
      "Epoch 41/50\n",
      "824/824 [==============================] - 0s 80us/sample - loss: 0.0194 - val_loss: 0.0108\n",
      "Epoch 42/50\n",
      "824/824 [==============================] - 0s 80us/sample - loss: 0.0193 - val_loss: 0.0104\n",
      "Epoch 43/50\n",
      "824/824 [==============================] - 0s 80us/sample - loss: 0.0194 - val_loss: 0.0105\n",
      "Epoch 44/50\n",
      "824/824 [==============================] - 0s 80us/sample - loss: 0.0194 - val_loss: 0.0103\n",
      "Epoch 45/50\n",
      "824/824 [==============================] - 0s 78us/sample - loss: 0.0194 - val_loss: 0.0103\n",
      "Epoch 46/50\n",
      "824/824 [==============================] - 0s 78us/sample - loss: 0.0194 - val_loss: 0.0106\n",
      "Epoch 47/50\n",
      "824/824 [==============================] - 0s 79us/sample - loss: 0.0194 - val_loss: 0.0106\n",
      "Epoch 48/50\n",
      "824/824 [==============================] - 0s 82us/sample - loss: 0.0193 - val_loss: 0.0102\n",
      "Epoch 49/50\n",
      "824/824 [==============================] - 0s 81us/sample - loss: 0.0194 - val_loss: 0.0104\n",
      "Epoch 50/50\n",
      "824/824 [==============================] - 0s 84us/sample - loss: 0.0194 - val_loss: 0.0104\n",
      "第359个数，还剩3764个没有训练\n",
      "inv_hat [0.63326649 0.61891155 0.62081578 0.61986325 0.60943833 0.60849553\n",
      " 0.60849553 0.61416484 0.60943833 0.61606117 0.63038227 0.63230434\n",
      " 0.63230434 0.62081578 0.62081578 0.61891155 0.61891155 0.61891155\n",
      " 0.62750451 0.61701051 0.61038197 0.60943833 0.6000485  0.59724854\n",
      " 0.5926     0.59818101 0.59724854 0.59631702 0.59352788 0.59724854]\n",
      "Test RMSE: 0.007\n",
      "Train on 658 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "658/658 [==============================] - 0s 81us/sample - loss: 0.0261 - val_loss: 0.0088\n",
      "Epoch 2/50\n",
      "658/658 [==============================] - 0s 84us/sample - loss: 0.0261 - val_loss: 0.0087\n",
      "Epoch 3/50\n",
      "658/658 [==============================] - 0s 81us/sample - loss: 0.0262 - val_loss: 0.0097\n",
      "Epoch 4/50\n",
      "658/658 [==============================] - 0s 82us/sample - loss: 0.0261 - val_loss: 0.0092\n",
      "Epoch 5/50\n",
      "658/658 [==============================] - 0s 82us/sample - loss: 0.0261 - val_loss: 0.0087\n",
      "Epoch 6/50\n",
      "658/658 [==============================] - 0s 83us/sample - loss: 0.0261 - val_loss: 0.0089\n",
      "Epoch 7/50\n",
      "658/658 [==============================] - 0s 94us/sample - loss: 0.0261 - val_loss: 0.0092\n",
      "Epoch 8/50\n",
      "658/658 [==============================] - 0s 84us/sample - loss: 0.0261 - val_loss: 0.0091\n",
      "Epoch 9/50\n",
      "658/658 [==============================] - 0s 89us/sample - loss: 0.0261 - val_loss: 0.0087\n",
      "Epoch 10/50\n",
      "658/658 [==============================] - 0s 88us/sample - loss: 0.0261 - val_loss: 0.0092\n",
      "Epoch 11/50\n",
      "658/658 [==============================] - 0s 85us/sample - loss: 0.0261 - val_loss: 0.0090\n",
      "Epoch 12/50\n",
      "658/658 [==============================] - 0s 86us/sample - loss: 0.0260 - val_loss: 0.0087\n",
      "Epoch 13/50\n",
      "658/658 [==============================] - 0s 84us/sample - loss: 0.0261 - val_loss: 0.0091\n",
      "Epoch 14/50\n",
      "658/658 [==============================] - 0s 80us/sample - loss: 0.0261 - val_loss: 0.0090\n",
      "Epoch 15/50\n",
      "658/658 [==============================] - 0s 81us/sample - loss: 0.0261 - val_loss: 0.0087\n",
      "Epoch 16/50\n",
      "658/658 [==============================] - 0s 87us/sample - loss: 0.0261 - val_loss: 0.0093\n",
      "Epoch 17/50\n",
      "658/658 [==============================] - 0s 85us/sample - loss: 0.0261 - val_loss: 0.0092\n",
      "Epoch 18/50\n",
      "658/658 [==============================] - 0s 83us/sample - loss: 0.0261 - val_loss: 0.0086\n",
      "Epoch 19/50\n",
      "658/658 [==============================] - 0s 84us/sample - loss: 0.0261 - val_loss: 0.0087\n",
      "Epoch 20/50\n",
      "658/658 [==============================] - 0s 83us/sample - loss: 0.0260 - val_loss: 0.0087\n",
      "Epoch 21/50\n",
      "658/658 [==============================] - 0s 85us/sample - loss: 0.0261 - val_loss: 0.0088\n",
      "Epoch 22/50\n",
      "658/658 [==============================] - 0s 82us/sample - loss: 0.0261 - val_loss: 0.0094\n",
      "Epoch 23/50\n",
      "658/658 [==============================] - 0s 81us/sample - loss: 0.0261 - val_loss: 0.0093\n",
      "Epoch 24/50\n",
      "658/658 [==============================] - 0s 82us/sample - loss: 0.0261 - val_loss: 0.0087\n",
      "Epoch 25/50\n",
      "658/658 [==============================] - 0s 82us/sample - loss: 0.0260 - val_loss: 0.0086\n",
      "Epoch 26/50\n",
      "658/658 [==============================] - 0s 82us/sample - loss: 0.0261 - val_loss: 0.0088\n",
      "Epoch 27/50\n",
      "658/658 [==============================] - 0s 81us/sample - loss: 0.0261 - val_loss: 0.0089\n",
      "Epoch 28/50\n",
      "658/658 [==============================] - 0s 80us/sample - loss: 0.0261 - val_loss: 0.0087\n",
      "Epoch 29/50\n",
      "658/658 [==============================] - 0s 86us/sample - loss: 0.0262 - val_loss: 0.0097\n",
      "Epoch 30/50\n",
      "658/658 [==============================] - 0s 80us/sample - loss: 0.0261 - val_loss: 0.0094\n",
      "Epoch 31/50\n",
      "658/658 [==============================] - 0s 86us/sample - loss: 0.0261 - val_loss: 0.0087\n",
      "Epoch 32/50\n",
      "658/658 [==============================] - 0s 89us/sample - loss: 0.0260 - val_loss: 0.0087\n",
      "Epoch 33/50\n",
      "658/658 [==============================] - 0s 84us/sample - loss: 0.0262 - val_loss: 0.0097\n",
      "Epoch 34/50\n",
      "658/658 [==============================] - 0s 86us/sample - loss: 0.0261 - val_loss: 0.0095\n",
      "Epoch 35/50\n",
      "658/658 [==============================] - 0s 86us/sample - loss: 0.0261 - val_loss: 0.0090\n",
      "Epoch 36/50\n",
      "658/658 [==============================] - 0s 83us/sample - loss: 0.0260 - val_loss: 0.0086\n",
      "Epoch 37/50\n",
      "658/658 [==============================] - 0s 86us/sample - loss: 0.0261 - val_loss: 0.0086\n",
      "Epoch 38/50\n",
      "658/658 [==============================] - 0s 85us/sample - loss: 0.0260 - val_loss: 0.0087\n",
      "Epoch 39/50\n",
      "658/658 [==============================] - 0s 85us/sample - loss: 0.0261 - val_loss: 0.0089\n",
      "Epoch 40/50\n",
      "658/658 [==============================] - 0s 83us/sample - loss: 0.0260 - val_loss: 0.0087\n",
      "Epoch 41/50\n",
      "658/658 [==============================] - 0s 83us/sample - loss: 0.0260 - val_loss: 0.0086\n",
      "Epoch 42/50\n",
      "658/658 [==============================] - 0s 92us/sample - loss: 0.0261 - val_loss: 0.0093\n",
      "Epoch 43/50\n",
      "658/658 [==============================] - 0s 89us/sample - loss: 0.0261 - val_loss: 0.0093\n",
      "Epoch 44/50\n",
      "658/658 [==============================] - 0s 82us/sample - loss: 0.0261 - val_loss: 0.0087\n",
      "Epoch 45/50\n",
      "658/658 [==============================] - 0s 83us/sample - loss: 0.0260 - val_loss: 0.0087\n",
      "Epoch 46/50\n",
      "658/658 [==============================] - 0s 88us/sample - loss: 0.0262 - val_loss: 0.0095\n",
      "Epoch 47/50\n",
      "658/658 [==============================] - 0s 90us/sample - loss: 0.0261 - val_loss: 0.0094\n",
      "Epoch 48/50\n",
      "658/658 [==============================] - 0s 91us/sample - loss: 0.0261 - val_loss: 0.0089\n",
      "Epoch 49/50\n",
      "658/658 [==============================] - 0s 90us/sample - loss: 0.0260 - val_loss: 0.0088\n",
      "Epoch 50/50\n",
      "658/658 [==============================] - 0s 84us/sample - loss: 0.0261 - val_loss: 0.0094\n",
      "第360个数，还剩3763个没有训练\n",
      "inv_hat [0.89840671 0.8923575  0.89336182 0.8923575  0.88736114 0.88736114\n",
      " 0.88835689 0.88835689 0.88736114 0.88835689 0.89436775 0.89739478\n",
      " 0.89840671 0.89035374 0.89035374 0.88835689 0.89035374 0.89035374\n",
      " 0.8923575  0.88736114 0.8833967  0.88241046 0.88241046 0.88241046\n",
      " 0.88241046 0.88142621 0.88142621 0.88142621 0.88044396 0.88142621]\n",
      "Test RMSE: 0.003\n",
      "Train on 823 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "823/823 [==============================] - 0s 82us/sample - loss: 0.0269 - val_loss: 0.0246\n",
      "Epoch 2/50\n",
      "823/823 [==============================] - 0s 81us/sample - loss: 0.0264 - val_loss: 0.0245\n",
      "Epoch 3/50\n",
      "823/823 [==============================] - 0s 81us/sample - loss: 0.0262 - val_loss: 0.0244\n",
      "Epoch 4/50\n",
      "823/823 [==============================] - 0s 82us/sample - loss: 0.0262 - val_loss: 0.0245\n",
      "Epoch 5/50\n",
      "823/823 [==============================] - 0s 82us/sample - loss: 0.0261 - val_loss: 0.0245\n",
      "Epoch 6/50\n",
      "823/823 [==============================] - 0s 85us/sample - loss: 0.0261 - val_loss: 0.0244\n",
      "Epoch 7/50\n",
      "823/823 [==============================] - 0s 79us/sample - loss: 0.0261 - val_loss: 0.0245\n",
      "Epoch 8/50\n",
      "823/823 [==============================] - 0s 79us/sample - loss: 0.0261 - val_loss: 0.0244\n",
      "Epoch 9/50\n",
      "823/823 [==============================] - 0s 80us/sample - loss: 0.0261 - val_loss: 0.0245\n",
      "Epoch 10/50\n",
      "823/823 [==============================] - 0s 79us/sample - loss: 0.0261 - val_loss: 0.0245\n",
      "Epoch 11/50\n",
      "823/823 [==============================] - 0s 80us/sample - loss: 0.0261 - val_loss: 0.0245\n",
      "Epoch 12/50\n",
      "823/823 [==============================] - 0s 83us/sample - loss: 0.0261 - val_loss: 0.0245\n",
      "Epoch 13/50\n",
      "823/823 [==============================] - 0s 85us/sample - loss: 0.0261 - val_loss: 0.0245\n",
      "Epoch 14/50\n",
      "823/823 [==============================] - 0s 88us/sample - loss: 0.0261 - val_loss: 0.0245\n",
      "Epoch 15/50\n",
      "823/823 [==============================] - 0s 85us/sample - loss: 0.0261 - val_loss: 0.0245\n",
      "Epoch 16/50\n",
      "823/823 [==============================] - 0s 83us/sample - loss: 0.0261 - val_loss: 0.0246\n",
      "Epoch 17/50\n",
      "823/823 [==============================] - 0s 84us/sample - loss: 0.0261 - val_loss: 0.0246\n",
      "Epoch 18/50\n",
      "823/823 [==============================] - 0s 82us/sample - loss: 0.0261 - val_loss: 0.0246\n",
      "Epoch 19/50\n",
      "823/823 [==============================] - 0s 81us/sample - loss: 0.0261 - val_loss: 0.0246\n",
      "Epoch 20/50\n",
      "823/823 [==============================] - 0s 83us/sample - loss: 0.0261 - val_loss: 0.0246\n",
      "Epoch 21/50\n",
      "823/823 [==============================] - 0s 81us/sample - loss: 0.0261 - val_loss: 0.0246\n",
      "Epoch 22/50\n",
      "823/823 [==============================] - 0s 81us/sample - loss: 0.0261 - val_loss: 0.0246\n",
      "Epoch 23/50\n",
      "823/823 [==============================] - 0s 84us/sample - loss: 0.0261 - val_loss: 0.0246\n",
      "Epoch 24/50\n",
      "823/823 [==============================] - 0s 81us/sample - loss: 0.0261 - val_loss: 0.0246\n",
      "Epoch 25/50\n",
      "823/823 [==============================] - 0s 82us/sample - loss: 0.0261 - val_loss: 0.0246\n",
      "Epoch 26/50\n",
      "823/823 [==============================] - 0s 86us/sample - loss: 0.0261 - val_loss: 0.0246\n",
      "Epoch 27/50\n",
      "823/823 [==============================] - 0s 78us/sample - loss: 0.0261 - val_loss: 0.0246\n",
      "Epoch 28/50\n",
      "823/823 [==============================] - 0s 82us/sample - loss: 0.0261 - val_loss: 0.0246\n",
      "Epoch 29/50\n",
      "823/823 [==============================] - 0s 83us/sample - loss: 0.0260 - val_loss: 0.0246\n",
      "Epoch 30/50\n",
      "823/823 [==============================] - 0s 83us/sample - loss: 0.0260 - val_loss: 0.0246\n",
      "Epoch 31/50\n",
      "823/823 [==============================] - 0s 81us/sample - loss: 0.0260 - val_loss: 0.0246\n",
      "Epoch 32/50\n",
      "823/823 [==============================] - 0s 82us/sample - loss: 0.0260 - val_loss: 0.0246\n",
      "Epoch 33/50\n",
      "823/823 [==============================] - 0s 78us/sample - loss: 0.0260 - val_loss: 0.0246\n",
      "Epoch 34/50\n",
      "823/823 [==============================] - 0s 80us/sample - loss: 0.0260 - val_loss: 0.0246\n",
      "Epoch 35/50\n",
      "823/823 [==============================] - 0s 81us/sample - loss: 0.0260 - val_loss: 0.0246\n",
      "Epoch 36/50\n",
      "823/823 [==============================] - 0s 82us/sample - loss: 0.0260 - val_loss: 0.0246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "823/823 [==============================] - 0s 85us/sample - loss: 0.0260 - val_loss: 0.0246\n",
      "Epoch 38/50\n",
      "823/823 [==============================] - 0s 82us/sample - loss: 0.0260 - val_loss: 0.0246\n",
      "Epoch 39/50\n",
      "823/823 [==============================] - 0s 80us/sample - loss: 0.0260 - val_loss: 0.0246\n",
      "Epoch 40/50\n",
      "823/823 [==============================] - 0s 82us/sample - loss: 0.0260 - val_loss: 0.0246\n",
      "Epoch 41/50\n",
      "823/823 [==============================] - 0s 83us/sample - loss: 0.0260 - val_loss: 0.0246\n",
      "Epoch 42/50\n",
      "823/823 [==============================] - 0s 83us/sample - loss: 0.0260 - val_loss: 0.0246\n",
      "Epoch 43/50\n",
      "823/823 [==============================] - 0s 79us/sample - loss: 0.0260 - val_loss: 0.0246\n",
      "Epoch 44/50\n",
      "823/823 [==============================] - 0s 79us/sample - loss: 0.0260 - val_loss: 0.0246\n",
      "Epoch 45/50\n",
      "823/823 [==============================] - 0s 79us/sample - loss: 0.0260 - val_loss: 0.0246\n",
      "Epoch 46/50\n",
      "823/823 [==============================] - 0s 84us/sample - loss: 0.0260 - val_loss: 0.0246\n",
      "Epoch 47/50\n",
      "823/823 [==============================] - 0s 78us/sample - loss: 0.0260 - val_loss: 0.0246\n",
      "Epoch 48/50\n",
      "823/823 [==============================] - 0s 79us/sample - loss: 0.0260 - val_loss: 0.0246\n",
      "Epoch 49/50\n",
      "823/823 [==============================] - 0s 79us/sample - loss: 0.0260 - val_loss: 0.0246\n",
      "Epoch 50/50\n",
      "823/823 [==============================] - 0s 76us/sample - loss: 0.0260 - val_loss: 0.0246\n",
      "第361个数，还剩3762个没有训练\n",
      "inv_hat [0.86726995 0.80976979 0.81477611 0.80253157 0.73100088 0.7260877\n",
      " 0.73762423 0.77387433 0.73150244 0.75743433 0.81804463 0.82805029\n",
      " 0.81712542 0.76317805 0.76206931 0.74083802 0.75904607 0.76186771\n",
      " 0.78236475 0.72979739 0.71567101 0.70366994 0.67145339 0.67643305\n",
      " 0.66737215 0.68620051 0.66836737 0.64788304 0.62766916 0.62927392]\n",
      "Test RMSE: 0.029\n",
      "Train on 602 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "602/602 [==============================] - 0s 78us/sample - loss: 0.0167 - val_loss: 0.0058\n",
      "Epoch 2/50\n",
      "602/602 [==============================] - 0s 84us/sample - loss: 0.0158 - val_loss: 0.0056\n",
      "Epoch 3/50\n",
      "602/602 [==============================] - 0s 86us/sample - loss: 0.0150 - val_loss: 0.0053\n",
      "Epoch 4/50\n",
      "602/602 [==============================] - 0s 84us/sample - loss: 0.0147 - val_loss: 0.0057\n",
      "Epoch 5/50\n",
      "602/602 [==============================] - 0s 82us/sample - loss: 0.0149 - val_loss: 0.0062\n",
      "Epoch 6/50\n",
      "602/602 [==============================] - 0s 81us/sample - loss: 0.0153 - val_loss: 0.0056\n",
      "Epoch 7/50\n",
      "602/602 [==============================] - 0s 84us/sample - loss: 0.0150 - val_loss: 0.0060\n",
      "Epoch 8/50\n",
      "602/602 [==============================] - 0s 83us/sample - loss: 0.0150 - val_loss: 0.0054\n",
      "Epoch 9/50\n",
      "602/602 [==============================] - 0s 84us/sample - loss: 0.0151 - val_loss: 0.0055\n",
      "Epoch 10/50\n",
      "602/602 [==============================] - 0s 84us/sample - loss: 0.0151 - val_loss: 0.0056\n",
      "Epoch 11/50\n",
      "602/602 [==============================] - 0s 84us/sample - loss: 0.0150 - val_loss: 0.0055\n",
      "Epoch 12/50\n",
      "602/602 [==============================] - 0s 83us/sample - loss: 0.0150 - val_loss: 0.0063\n",
      "Epoch 13/50\n",
      "602/602 [==============================] - 0s 84us/sample - loss: 0.0154 - val_loss: 0.0059\n",
      "Epoch 14/50\n",
      "602/602 [==============================] - 0s 85us/sample - loss: 0.0148 - val_loss: 0.0062\n",
      "Epoch 15/50\n",
      "602/602 [==============================] - 0s 85us/sample - loss: 0.0151 - val_loss: 0.0056\n",
      "Epoch 16/50\n",
      "602/602 [==============================] - 0s 83us/sample - loss: 0.0149 - val_loss: 0.0064\n",
      "Epoch 17/50\n",
      "602/602 [==============================] - 0s 81us/sample - loss: 0.0151 - val_loss: 0.0062\n",
      "Epoch 18/50\n",
      "602/602 [==============================] - 0s 83us/sample - loss: 0.0150 - val_loss: 0.0068\n",
      "Epoch 19/50\n",
      "602/602 [==============================] - 0s 81us/sample - loss: 0.0159 - val_loss: 0.0071\n",
      "Epoch 20/50\n",
      "602/602 [==============================] - 0s 80us/sample - loss: 0.0163 - val_loss: 0.0089\n",
      "Epoch 21/50\n",
      "602/602 [==============================] - 0s 81us/sample - loss: 0.0157 - val_loss: 0.0060\n",
      "Epoch 22/50\n",
      "602/602 [==============================] - 0s 80us/sample - loss: 0.0161 - val_loss: 0.0081\n",
      "Epoch 23/50\n",
      "602/602 [==============================] - 0s 80us/sample - loss: 0.0157 - val_loss: 0.0059\n",
      "Epoch 24/50\n",
      "602/602 [==============================] - 0s 79us/sample - loss: 0.0156 - val_loss: 0.0071\n",
      "Epoch 25/50\n",
      "602/602 [==============================] - 0s 89us/sample - loss: 0.0155 - val_loss: 0.0076\n",
      "Epoch 26/50\n",
      "602/602 [==============================] - 0s 84us/sample - loss: 0.0160 - val_loss: 0.0057\n",
      "Epoch 27/50\n",
      "602/602 [==============================] - 0s 83us/sample - loss: 0.0157 - val_loss: 0.0070\n",
      "Epoch 28/50\n",
      "602/602 [==============================] - 0s 81us/sample - loss: 0.0150 - val_loss: 0.0055\n",
      "Epoch 29/50\n",
      "602/602 [==============================] - 0s 81us/sample - loss: 0.0149 - val_loss: 0.0053\n",
      "Epoch 30/50\n",
      "602/602 [==============================] - 0s 84us/sample - loss: 0.0145 - val_loss: 0.0054\n",
      "Epoch 31/50\n",
      "602/602 [==============================] - 0s 83us/sample - loss: 0.0147 - val_loss: 0.0055\n",
      "Epoch 32/50\n",
      "602/602 [==============================] - 0s 81us/sample - loss: 0.0147 - val_loss: 0.0053\n",
      "Epoch 33/50\n",
      "602/602 [==============================] - 0s 83us/sample - loss: 0.0146 - val_loss: 0.0055\n",
      "Epoch 34/50\n",
      "602/602 [==============================] - 0s 86us/sample - loss: 0.0145 - val_loss: 0.0058\n",
      "Epoch 35/50\n",
      "602/602 [==============================] - 0s 88us/sample - loss: 0.0147 - val_loss: 0.0056\n",
      "Epoch 36/50\n",
      "602/602 [==============================] - 0s 88us/sample - loss: 0.0146 - val_loss: 0.0060\n",
      "Epoch 37/50\n",
      "602/602 [==============================] - 0s 85us/sample - loss: 0.0148 - val_loss: 0.0054\n",
      "Epoch 38/50\n",
      "602/602 [==============================] - 0s 83us/sample - loss: 0.0145 - val_loss: 0.0053\n",
      "Epoch 39/50\n",
      "602/602 [==============================] - 0s 82us/sample - loss: 0.0144 - val_loss: 0.0053\n",
      "Epoch 40/50\n",
      "602/602 [==============================] - 0s 86us/sample - loss: 0.0146 - val_loss: 0.0054\n",
      "Epoch 41/50\n",
      "602/602 [==============================] - 0s 88us/sample - loss: 0.0144 - val_loss: 0.0056\n",
      "Epoch 42/50\n",
      "602/602 [==============================] - 0s 85us/sample - loss: 0.0146 - val_loss: 0.0056\n",
      "Epoch 43/50\n",
      "602/602 [==============================] - 0s 81us/sample - loss: 0.0145 - val_loss: 0.0054\n",
      "Epoch 44/50\n",
      "602/602 [==============================] - 0s 81us/sample - loss: 0.0145 - val_loss: 0.0053\n",
      "Epoch 45/50\n",
      "602/602 [==============================] - 0s 80us/sample - loss: 0.0144 - val_loss: 0.0053\n",
      "Epoch 46/50\n",
      "602/602 [==============================] - 0s 80us/sample - loss: 0.0144 - val_loss: 0.0052\n",
      "Epoch 47/50\n",
      "602/602 [==============================] - 0s 81us/sample - loss: 0.0146 - val_loss: 0.0057\n",
      "Epoch 48/50\n",
      "602/602 [==============================] - 0s 82us/sample - loss: 0.0147 - val_loss: 0.0054\n",
      "Epoch 49/50\n",
      "602/602 [==============================] - 0s 86us/sample - loss: 0.0144 - val_loss: 0.0054\n",
      "Epoch 50/50\n",
      "602/602 [==============================] - 0s 87us/sample - loss: 0.0145 - val_loss: 0.0058\n",
      "第362个数，还剩3761个没有训练\n",
      "inv_hat [1.01102701 1.01102701 1.01102701 1.01102701 1.01102701 1.01202843\n",
      " 1.01202843 1.01202843 1.01202843 1.01202843 1.01202843 1.01202843\n",
      " 1.01302589 1.01302589 1.01302589 1.01302589 1.01302589 1.01401991\n",
      " 1.01401991 1.01401991 1.01401991 1.01401991 1.01401991 1.01401991\n",
      " 1.01401991 1.01401991 1.01401991 1.01501636 1.01501636 1.01501636]\n",
      "Test RMSE: 0.000\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0128 - val_loss: 0.0084\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0128 - val_loss: 0.0087\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0128 - val_loss: 0.0091\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0128 - val_loss: 0.0092\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0127 - val_loss: 0.0087\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0128 - val_loss: 0.0091\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0127 - val_loss: 0.0089\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0128 - val_loss: 0.0091\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0127 - val_loss: 0.0089\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0128 - val_loss: 0.0090\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0127 - val_loss: 0.0089\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0128 - val_loss: 0.0091\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0127 - val_loss: 0.0089\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0128 - val_loss: 0.0092\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0127 - val_loss: 0.0088\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0128 - val_loss: 0.0092\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0128 - val_loss: 0.0092\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0127 - val_loss: 0.0088\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0128 - val_loss: 0.0092\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0127 - val_loss: 0.0089\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0128 - val_loss: 0.0091\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0127 - val_loss: 0.0090\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0128 - val_loss: 0.0091\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0127 - val_loss: 0.0090\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0127 - val_loss: 0.0091\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0127 - val_loss: 0.0090\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0128 - val_loss: 0.0092\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0127 - val_loss: 0.0090\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0127 - val_loss: 0.0092\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0128 - val_loss: 0.0092\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0127 - val_loss: 0.0090\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0128 - val_loss: 0.0092\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0128 - val_loss: 0.0092\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0127 - val_loss: 0.0091\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0128 - val_loss: 0.0092\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0127 - val_loss: 0.0091\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0127 - val_loss: 0.0092\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0128 - val_loss: 0.0092\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0127 - val_loss: 0.0092\n",
      "第363个数，还剩3760个没有训练\n",
      "inv_hat [1.70591973 1.68143187 1.68686743 1.67846758 1.65008971 1.64702526\n",
      " 1.65127631 1.66888095 1.64831036 1.65849471 1.69367803 1.68943397\n",
      " 1.68746025 1.65987936 1.65829684 1.64920008 1.66235186 1.66235186\n",
      " 1.68044383 1.64910123 1.63585655 1.62123464 1.59960802 1.59743599\n",
      " 1.58627925 1.60049646 1.59822568 1.59062343 1.57996044 1.58776026]\n",
      "Test RMSE: 0.017\n",
      "Train on 850 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "850/850 [==============================] - 0s 81us/sample - loss: 0.0206 - val_loss: 0.0201\n",
      "Epoch 2/50\n",
      "850/850 [==============================] - 0s 81us/sample - loss: 0.0232 - val_loss: 0.0311\n",
      "Epoch 3/50\n",
      "850/850 [==============================] - 0s 79us/sample - loss: 0.0231 - val_loss: 0.0177\n",
      "Epoch 4/50\n",
      "850/850 [==============================] - 0s 80us/sample - loss: 0.0230 - val_loss: 0.0208\n",
      "Epoch 5/50\n",
      "850/850 [==============================] - 0s 81us/sample - loss: 0.0242 - val_loss: 0.0305\n",
      "Epoch 6/50\n",
      "850/850 [==============================] - 0s 79us/sample - loss: 0.0251 - val_loss: 0.0189\n",
      "Epoch 7/50\n",
      "850/850 [==============================] - 0s 79us/sample - loss: 0.0204 - val_loss: 0.0175\n",
      "Epoch 8/50\n",
      "850/850 [==============================] - 0s 79us/sample - loss: 0.0209 - val_loss: 0.0179\n",
      "Epoch 9/50\n",
      "850/850 [==============================] - 0s 74us/sample - loss: 0.0211 - val_loss: 0.0225\n",
      "Epoch 10/50\n",
      "850/850 [==============================] - 0s 75us/sample - loss: 0.0213 - val_loss: 0.0177\n",
      "Epoch 11/50\n",
      "850/850 [==============================] - 0s 77us/sample - loss: 0.0203 - val_loss: 0.0174\n",
      "Epoch 12/50\n",
      "850/850 [==============================] - 0s 78us/sample - loss: 0.0210 - val_loss: 0.0213\n",
      "Epoch 13/50\n",
      "850/850 [==============================] - 0s 82us/sample - loss: 0.0209 - val_loss: 0.0193\n",
      "Epoch 14/50\n",
      "850/850 [==============================] - 0s 78us/sample - loss: 0.0203 - val_loss: 0.0175\n",
      "Epoch 15/50\n",
      "850/850 [==============================] - 0s 81us/sample - loss: 0.0207 - val_loss: 0.0188\n",
      "Epoch 16/50\n",
      "850/850 [==============================] - 0s 83us/sample - loss: 0.0208 - val_loss: 0.0209\n",
      "Epoch 17/50\n",
      "850/850 [==============================] - 0s 83us/sample - loss: 0.0206 - val_loss: 0.0181\n",
      "Epoch 18/50\n",
      "850/850 [==============================] - 0s 88us/sample - loss: 0.0202 - val_loss: 0.0175\n",
      "Epoch 19/50\n",
      "850/850 [==============================] - 0s 83us/sample - loss: 0.0205 - val_loss: 0.0201\n",
      "Epoch 20/50\n",
      "850/850 [==============================] - 0s 82us/sample - loss: 0.0207 - val_loss: 0.0196\n",
      "Epoch 21/50\n",
      "850/850 [==============================] - 0s 80us/sample - loss: 0.0203 - val_loss: 0.0175\n",
      "Epoch 22/50\n",
      "850/850 [==============================] - 0s 77us/sample - loss: 0.0204 - val_loss: 0.0182\n",
      "Epoch 23/50\n",
      "850/850 [==============================] - 0s 79us/sample - loss: 0.0205 - val_loss: 0.0203\n",
      "Epoch 24/50\n",
      "850/850 [==============================] - 0s 74us/sample - loss: 0.0206 - val_loss: 0.0187\n",
      "Epoch 25/50\n",
      "850/850 [==============================] - 0s 76us/sample - loss: 0.0202 - val_loss: 0.0175\n",
      "Epoch 26/50\n",
      "850/850 [==============================] - 0s 77us/sample - loss: 0.0205 - val_loss: 0.0196\n",
      "Epoch 27/50\n",
      "850/850 [==============================] - 0s 73us/sample - loss: 0.0205 - val_loss: 0.0199\n",
      "Epoch 28/50\n",
      "850/850 [==============================] - 0s 74us/sample - loss: 0.0204 - val_loss: 0.0179\n",
      "Epoch 29/50\n",
      "850/850 [==============================] - 0s 77us/sample - loss: 0.0202 - val_loss: 0.0178\n",
      "Epoch 30/50\n",
      "850/850 [==============================] - 0s 83us/sample - loss: 0.0203 - val_loss: 0.0192\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850/850 [==============================] - 0s 77us/sample - loss: 0.0205 - val_loss: 0.0199\n",
      "Epoch 32/50\n",
      "850/850 [==============================] - 0s 80us/sample - loss: 0.0204 - val_loss: 0.0179\n",
      "Epoch 33/50\n",
      "850/850 [==============================] - 0s 82us/sample - loss: 0.0202 - val_loss: 0.0175\n",
      "Epoch 34/50\n",
      "850/850 [==============================] - 0s 83us/sample - loss: 0.0206 - val_loss: 0.0201\n",
      "Epoch 35/50\n",
      "850/850 [==============================] - 0s 80us/sample - loss: 0.0206 - val_loss: 0.0196\n",
      "Epoch 36/50\n",
      "850/850 [==============================] - 0s 79us/sample - loss: 0.0203 - val_loss: 0.0176\n",
      "Epoch 37/50\n",
      "850/850 [==============================] - 0s 81us/sample - loss: 0.0203 - val_loss: 0.0181\n",
      "Epoch 38/50\n",
      "850/850 [==============================] - 0s 78us/sample - loss: 0.0205 - val_loss: 0.0203\n",
      "Epoch 39/50\n",
      "850/850 [==============================] - 0s 82us/sample - loss: 0.0206 - val_loss: 0.0188\n",
      "Epoch 40/50\n",
      "850/850 [==============================] - 0s 83us/sample - loss: 0.0202 - val_loss: 0.0174\n",
      "Epoch 41/50\n",
      "850/850 [==============================] - 0s 79us/sample - loss: 0.0205 - val_loss: 0.0196\n",
      "Epoch 42/50\n",
      "850/850 [==============================] - 0s 76us/sample - loss: 0.0206 - val_loss: 0.0201\n",
      "Epoch 43/50\n",
      "850/850 [==============================] - 0s 73us/sample - loss: 0.0205 - val_loss: 0.0176\n",
      "Epoch 44/50\n",
      "850/850 [==============================] - 0s 76us/sample - loss: 0.0203 - val_loss: 0.0177\n",
      "Epoch 45/50\n",
      "850/850 [==============================] - 0s 79us/sample - loss: 0.0205 - val_loss: 0.0202\n",
      "Epoch 46/50\n",
      "850/850 [==============================] - 0s 75us/sample - loss: 0.0206 - val_loss: 0.0194\n",
      "Epoch 47/50\n",
      "850/850 [==============================] - 0s 79us/sample - loss: 0.0203 - val_loss: 0.0175\n",
      "Epoch 48/50\n",
      "850/850 [==============================] - 0s 77us/sample - loss: 0.0204 - val_loss: 0.0187\n",
      "Epoch 49/50\n",
      "850/850 [==============================] - 0s 74us/sample - loss: 0.0205 - val_loss: 0.0198\n",
      "Epoch 50/50\n",
      "850/850 [==============================] - 0s 77us/sample - loss: 0.0205 - val_loss: 0.0185\n",
      "第364个数，还剩3759个没有训练\n",
      "inv_hat [0.91113889 0.89516335 0.89717038 0.89415977 0.87407507 0.87206535\n",
      " 0.87206535 0.88311613 0.87608456 0.88512461 0.90415713 0.90814383\n",
      " 0.90814383 0.89415977 0.89215235 0.88813691 0.89415977 0.89717038\n",
      " 0.90914169 0.89415977 0.89014474 0.8841204  0.86804545 0.86804545\n",
      " 0.85698851 0.8660353  0.86402499 0.86301983 0.85899896 0.86503019]\n",
      "Test RMSE: 0.009\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0111 - val_loss: 0.0054\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0115 - val_loss: 0.0054\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0124 - val_loss: 0.0070\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0130 - val_loss: 0.0074\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0061\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0118 - val_loss: 0.0054\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0116 - val_loss: 0.0054\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0119 - val_loss: 0.0055\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0119 - val_loss: 0.0054\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0116 - val_loss: 0.0051\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0115 - val_loss: 0.0052\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0117 - val_loss: 0.0053\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0117 - val_loss: 0.0051\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0115 - val_loss: 0.0050\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0115 - val_loss: 0.0050\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0115 - val_loss: 0.0050\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0115 - val_loss: 0.0050\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0115 - val_loss: 0.0050\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0114 - val_loss: 0.0049\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0114 - val_loss: 0.0049\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0113 - val_loss: 0.0050\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0113 - val_loss: 0.0050\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0113 - val_loss: 0.0050\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0113 - val_loss: 0.0050\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0113 - val_loss: 0.0050\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0113 - val_loss: 0.0050\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0050\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0050\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0113 - val_loss: 0.0050\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0114 - val_loss: 0.0049\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0113 - val_loss: 0.0050\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0113 - val_loss: 0.0050\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0050\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0113 - val_loss: 0.0049\n",
      "第365个数，还剩3758个没有训练\n",
      "inv_hat [1.03668992 1.01630275 1.01533492 1.01340019 0.99700165 0.99796392\n",
      " 1.00181598 1.00953421 0.99988937 1.00663768 1.02793788 1.02890932\n",
      " 1.02599595 1.00856834 1.00663768 1.00181598 1.00470812 1.0056727\n",
      " 1.01727086 1.00470812 0.99796392 0.9931556  0.9835618  0.9835618\n",
      " 0.97686468 0.98451977 0.98260408 0.97973301 0.97495413 0.97686468]\n",
      "Test RMSE: 0.009\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0102 - val_loss: 0.0054\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0100 - val_loss: 0.0056\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0099 - val_loss: 0.0057\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0099 - val_loss: 0.0056\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0099 - val_loss: 0.0056\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0099 - val_loss: 0.0056\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0099 - val_loss: 0.0056\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0099 - val_loss: 0.0056\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0099 - val_loss: 0.0054\n",
      "第366个数，还剩3757个没有训练\n",
      "inv_hat [1.20356277 1.18802213 1.1964714  1.19794745 1.1764672  1.17265826\n",
      " 1.17500165 1.17930275 1.17676034 1.18077057 1.2107687  1.21452605\n",
      " 1.21432817 1.19352146 1.18557038 1.17461089 1.18272872 1.18077057\n",
      " 1.18949419 1.17334157 1.16301202 1.15766706 1.13966744 1.13966744\n",
      " 1.12946361 1.14043917 1.13745012 1.13677565 1.135716   1.14130767]\n",
      "Test RMSE: 0.011\n",
      "Train on 1013 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1013/1013 [==============================] - 0s 82us/sample - loss: 0.0093 - val_loss: 0.0038\n",
      "Epoch 2/50\n",
      "1013/1013 [==============================] - 0s 83us/sample - loss: 0.0122 - val_loss: 0.0083\n",
      "Epoch 3/50\n",
      "1013/1013 [==============================] - 0s 85us/sample - loss: 0.0152 - val_loss: 0.0048\n",
      "Epoch 4/50\n",
      "1013/1013 [==============================] - 0s 83us/sample - loss: 0.0103 - val_loss: 0.0075\n",
      "Epoch 5/50\n",
      "1013/1013 [==============================] - 0s 82us/sample - loss: 0.0093 - val_loss: 0.0035\n",
      "Epoch 6/50\n",
      "1013/1013 [==============================] - 0s 80us/sample - loss: 0.0114 - val_loss: 0.0049\n",
      "Epoch 7/50\n",
      "1013/1013 [==============================] - 0s 84us/sample - loss: 0.0082 - val_loss: 0.0018\n",
      "Epoch 8/50\n",
      "1013/1013 [==============================] - 0s 83us/sample - loss: 0.0083 - val_loss: 0.0020\n",
      "Epoch 9/50\n",
      "1013/1013 [==============================] - 0s 83us/sample - loss: 0.0116 - val_loss: 0.0045\n",
      "Epoch 10/50\n",
      "1013/1013 [==============================] - 0s 84us/sample - loss: 0.0126 - val_loss: 0.0049\n",
      "Epoch 11/50\n",
      "1013/1013 [==============================] - 0s 85us/sample - loss: 0.0091 - val_loss: 0.0011\n",
      "Epoch 12/50\n",
      "1013/1013 [==============================] - 0s 85us/sample - loss: 0.0112 - val_loss: 0.0034\n",
      "Epoch 13/50\n",
      "1013/1013 [==============================] - 0s 83us/sample - loss: 0.0107 - val_loss: 0.0057\n",
      "Epoch 14/50\n",
      "1013/1013 [==============================] - 0s 84us/sample - loss: 0.0096 - val_loss: 0.0021\n",
      "Epoch 15/50\n",
      "1013/1013 [==============================] - 0s 83us/sample - loss: 0.0106 - val_loss: 0.0020\n",
      "Epoch 16/50\n",
      "1013/1013 [==============================] - 0s 91us/sample - loss: 0.0093 - val_loss: 0.0025\n",
      "Epoch 17/50\n",
      "1013/1013 [==============================] - 0s 82us/sample - loss: 0.0085 - val_loss: 0.0011\n",
      "Epoch 18/50\n",
      "1013/1013 [==============================] - 0s 81us/sample - loss: 0.0099 - val_loss: 0.0049\n",
      "Epoch 19/50\n",
      "1013/1013 [==============================] - 0s 80us/sample - loss: 0.0092 - val_loss: 0.0024\n",
      "Epoch 20/50\n",
      "1013/1013 [==============================] - 0s 82us/sample - loss: 0.0081 - val_loss: 6.9205e-04\n",
      "Epoch 21/50\n",
      "1013/1013 [==============================] - 0s 78us/sample - loss: 0.0082 - val_loss: 6.0473e-04\n",
      "Epoch 22/50\n",
      "1013/1013 [==============================] - 0s 78us/sample - loss: 0.0086 - val_loss: 0.0025\n",
      "Epoch 23/50\n",
      "1013/1013 [==============================] - 0s 79us/sample - loss: 0.0084 - val_loss: 9.1986e-04\n",
      "Epoch 24/50\n",
      "1013/1013 [==============================] - 0s 79us/sample - loss: 0.0094 - val_loss: 0.0037\n",
      "Epoch 25/50\n",
      "1013/1013 [==============================] - 0s 79us/sample - loss: 0.0095 - val_loss: 0.0040\n",
      "Epoch 26/50\n",
      "1013/1013 [==============================] - 0s 82us/sample - loss: 0.0079 - val_loss: 6.4160e-04\n",
      "Epoch 27/50\n",
      "1013/1013 [==============================] - 0s 78us/sample - loss: 0.0079 - val_loss: 7.5206e-04\n",
      "Epoch 28/50\n",
      "1013/1013 [==============================] - 0s 84us/sample - loss: 0.0085 - val_loss: 5.4151e-04\n",
      "Epoch 29/50\n",
      "1013/1013 [==============================] - 0s 81us/sample - loss: 0.0090 - val_loss: 4.9327e-04\n",
      "Epoch 30/50\n",
      "1013/1013 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0043\n",
      "Epoch 31/50\n",
      "1013/1013 [==============================] - 0s 78us/sample - loss: 0.0084 - val_loss: 7.8311e-04\n",
      "Epoch 32/50\n",
      "1013/1013 [==============================] - 0s 80us/sample - loss: 0.0083 - val_loss: 6.0641e-04\n",
      "Epoch 33/50\n",
      "1013/1013 [==============================] - 0s 78us/sample - loss: 0.0084 - val_loss: 8.4494e-04\n",
      "Epoch 34/50\n",
      "1013/1013 [==============================] - 0s 82us/sample - loss: 0.0081 - val_loss: 4.8296e-04\n",
      "Epoch 35/50\n",
      "1013/1013 [==============================] - 0s 80us/sample - loss: 0.0082 - val_loss: 5.0874e-04\n",
      "Epoch 36/50\n",
      "1013/1013 [==============================] - 0s 79us/sample - loss: 0.0083 - val_loss: 6.3289e-04\n",
      "Epoch 37/50\n",
      "1013/1013 [==============================] - 0s 78us/sample - loss: 0.0081 - val_loss: 0.0011\n",
      "Epoch 38/50\n",
      "1013/1013 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 4.9740e-04\n",
      "Epoch 39/50\n",
      "1013/1013 [==============================] - 0s 85us/sample - loss: 0.0079 - val_loss: 5.5005e-04\n",
      "Epoch 40/50\n",
      "1013/1013 [==============================] - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0018\n",
      "Epoch 41/50\n",
      "1013/1013 [==============================] - 0s 80us/sample - loss: 0.0082 - val_loss: 5.0389e-04\n",
      "Epoch 42/50\n",
      "1013/1013 [==============================] - 0s 85us/sample - loss: 0.0084 - val_loss: 4.9467e-04\n",
      "Epoch 43/50\n",
      "1013/1013 [==============================] - 0s 83us/sample - loss: 0.0089 - val_loss: 0.0034\n",
      "Epoch 44/50\n",
      "1013/1013 [==============================] - 0s 83us/sample - loss: 0.0078 - val_loss: 4.8741e-04\n",
      "Epoch 45/50\n",
      "1013/1013 [==============================] - 0s 80us/sample - loss: 0.0085 - val_loss: 0.0032\n",
      "Epoch 46/50\n",
      "1013/1013 [==============================] - 0s 85us/sample - loss: 0.0078 - val_loss: 8.4110e-04\n",
      "Epoch 47/50\n",
      "1013/1013 [==============================] - 0s 85us/sample - loss: 0.0088 - val_loss: 0.0033\n",
      "Epoch 48/50\n",
      "1013/1013 [==============================] - 0s 81us/sample - loss: 0.0082 - val_loss: 0.0012\n",
      "Epoch 49/50\n",
      "1013/1013 [==============================] - 0s 80us/sample - loss: 0.0079 - val_loss: 6.6600e-04\n",
      "Epoch 50/50\n",
      "1013/1013 [==============================] - 0s 79us/sample - loss: 0.0079 - val_loss: 5.2270e-04\n",
      "第367个数，还剩3756个没有训练\n",
      "inv_hat [1.03560085 1.03539568 1.03539568 1.03549826 1.03549826 1.03560085\n",
      " 1.03560085 1.03570332 1.03570332 1.03590852 1.03621636 1.03631898\n",
      " 1.03642147 1.03642147 1.03631898 1.03642147 1.03652411 1.03652411\n",
      " 1.03652411 1.03631898 1.03621636 1.03590852 1.03580592 1.03611374\n",
      " 1.03611374 1.03601113 1.03611374 1.03601113 1.03621636 1.03683202]\n",
      "Test RMSE: 0.000\n",
      "Train on 833 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "833/833 [==============================] - 0s 75us/sample - loss: 0.0291 - val_loss: 0.0210\n",
      "Epoch 2/50\n",
      "833/833 [==============================] - 0s 75us/sample - loss: 0.0291 - val_loss: 0.0208\n",
      "Epoch 3/50\n",
      "833/833 [==============================] - 0s 75us/sample - loss: 0.0290 - val_loss: 0.0199\n",
      "Epoch 4/50\n",
      "833/833 [==============================] - 0s 84us/sample - loss: 0.0290 - val_loss: 0.0200\n",
      "Epoch 5/50\n",
      "833/833 [==============================] - 0s 83us/sample - loss: 0.0290 - val_loss: 0.0201\n",
      "Epoch 6/50\n",
      "833/833 [==============================] - 0s 79us/sample - loss: 0.0290 - val_loss: 0.0200\n",
      "Epoch 7/50\n",
      "833/833 [==============================] - 0s 78us/sample - loss: 0.0290 - val_loss: 0.0202\n",
      "Epoch 8/50\n",
      "833/833 [==============================] - 0s 73us/sample - loss: 0.0290 - val_loss: 0.0201\n",
      "Epoch 9/50\n",
      "833/833 [==============================] - 0s 79us/sample - loss: 0.0290 - val_loss: 0.0202\n",
      "Epoch 10/50\n",
      "833/833 [==============================] - 0s 80us/sample - loss: 0.0289 - val_loss: 0.0199\n",
      "Epoch 11/50\n",
      "833/833 [==============================] - 0s 82us/sample - loss: 0.0290 - val_loss: 0.0205\n",
      "Epoch 12/50\n",
      "833/833 [==============================] - 0s 82us/sample - loss: 0.0290 - val_loss: 0.0198\n",
      "Epoch 13/50\n",
      "833/833 [==============================] - 0s 82us/sample - loss: 0.0290 - val_loss: 0.0202\n",
      "Epoch 14/50\n",
      "833/833 [==============================] - 0s 83us/sample - loss: 0.0289 - val_loss: 0.0199\n",
      "Epoch 15/50\n",
      "833/833 [==============================] - 0s 79us/sample - loss: 0.0289 - val_loss: 0.0199\n",
      "Epoch 16/50\n",
      "833/833 [==============================] - 0s 79us/sample - loss: 0.0290 - val_loss: 0.0202\n",
      "Epoch 17/50\n",
      "833/833 [==============================] - 0s 83us/sample - loss: 0.0289 - val_loss: 0.0201\n",
      "Epoch 18/50\n",
      "833/833 [==============================] - 0s 79us/sample - loss: 0.0289 - val_loss: 0.0201\n",
      "Epoch 19/50\n",
      "833/833 [==============================] - 0s 78us/sample - loss: 0.0289 - val_loss: 0.0199\n",
      "Epoch 20/50\n",
      "833/833 [==============================] - 0s 80us/sample - loss: 0.0289 - val_loss: 0.0202\n",
      "Epoch 21/50\n",
      "833/833 [==============================] - 0s 80us/sample - loss: 0.0289 - val_loss: 0.0201\n",
      "Epoch 22/50\n",
      "833/833 [==============================] - 0s 83us/sample - loss: 0.0290 - val_loss: 0.0200\n",
      "Epoch 23/50\n",
      "833/833 [==============================] - 0s 78us/sample - loss: 0.0289 - val_loss: 0.0200\n",
      "Epoch 24/50\n",
      "833/833 [==============================] - 0s 80us/sample - loss: 0.0290 - val_loss: 0.0202\n",
      "Epoch 25/50\n",
      "833/833 [==============================] - 0s 80us/sample - loss: 0.0289 - val_loss: 0.0202\n",
      "Epoch 26/50\n",
      "833/833 [==============================] - 0s 78us/sample - loss: 0.0289 - val_loss: 0.0200\n",
      "Epoch 27/50\n",
      "833/833 [==============================] - 0s 76us/sample - loss: 0.0289 - val_loss: 0.0201\n",
      "Epoch 28/50\n",
      "833/833 [==============================] - 0s 77us/sample - loss: 0.0289 - val_loss: 0.0202\n",
      "Epoch 29/50\n",
      "833/833 [==============================] - 0s 78us/sample - loss: 0.0289 - val_loss: 0.0200\n",
      "Epoch 30/50\n",
      "833/833 [==============================] - 0s 79us/sample - loss: 0.0289 - val_loss: 0.0201\n",
      "Epoch 31/50\n",
      "833/833 [==============================] - 0s 83us/sample - loss: 0.0289 - val_loss: 0.0202\n",
      "Epoch 32/50\n",
      "833/833 [==============================] - 0s 74us/sample - loss: 0.0289 - val_loss: 0.0198\n",
      "Epoch 33/50\n",
      "833/833 [==============================] - 0s 73us/sample - loss: 0.0290 - val_loss: 0.0201\n",
      "Epoch 34/50\n",
      "833/833 [==============================] - 0s 78us/sample - loss: 0.0289 - val_loss: 0.0201\n",
      "Epoch 35/50\n",
      "833/833 [==============================] - 0s 74us/sample - loss: 0.0289 - val_loss: 0.0199\n",
      "Epoch 36/50\n",
      "833/833 [==============================] - 0s 78us/sample - loss: 0.0289 - val_loss: 0.0202\n",
      "Epoch 37/50\n",
      "833/833 [==============================] - 0s 80us/sample - loss: 0.0289 - val_loss: 0.0202\n",
      "Epoch 38/50\n",
      "833/833 [==============================] - 0s 82us/sample - loss: 0.0289 - val_loss: 0.0198\n",
      "Epoch 39/50\n",
      "833/833 [==============================] - 0s 84us/sample - loss: 0.0289 - val_loss: 0.0201\n",
      "Epoch 40/50\n",
      "833/833 [==============================] - 0s 83us/sample - loss: 0.0289 - val_loss: 0.0203\n",
      "Epoch 41/50\n",
      "833/833 [==============================] - 0s 85us/sample - loss: 0.0289 - val_loss: 0.0200\n",
      "Epoch 42/50\n",
      "833/833 [==============================] - 0s 78us/sample - loss: 0.0289 - val_loss: 0.0201\n",
      "Epoch 43/50\n",
      "833/833 [==============================] - 0s 75us/sample - loss: 0.0289 - val_loss: 0.0201\n",
      "Epoch 44/50\n",
      "833/833 [==============================] - 0s 77us/sample - loss: 0.0289 - val_loss: 0.0201\n",
      "Epoch 45/50\n",
      "833/833 [==============================] - 0s 77us/sample - loss: 0.0289 - val_loss: 0.0203\n",
      "Epoch 46/50\n",
      "833/833 [==============================] - 0s 83us/sample - loss: 0.0289 - val_loss: 0.0201\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833/833 [==============================] - 0s 82us/sample - loss: 0.0289 - val_loss: 0.0200\n",
      "Epoch 48/50\n",
      "833/833 [==============================] - 0s 83us/sample - loss: 0.0289 - val_loss: 0.0204\n",
      "Epoch 49/50\n",
      "833/833 [==============================] - 0s 82us/sample - loss: 0.0289 - val_loss: 0.0201\n",
      "Epoch 50/50\n",
      "833/833 [==============================] - 0s 81us/sample - loss: 0.0289 - val_loss: 0.0200\n",
      "第368个数，还剩3755个没有训练\n",
      "inv_hat [0.92289592 0.9010626  0.89807143 0.89407903 0.86804962 0.86002882\n",
      " 0.86002882 0.8700547  0.85601936 0.86103134 0.88107724 0.88508138\n",
      " 0.87707053 0.86905216 0.88007569 0.8710572  0.8700547  0.8710572\n",
      " 0.87606851 0.84838013 0.84937218 0.83800534 0.82803447 0.82803447\n",
      " 0.82107866 0.82306372 0.80817634 0.80020444 0.79821148 0.79721494]\n",
      "Test RMSE: 0.011\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0077 - val_loss: 0.0058\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0078 - val_loss: 0.0058\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0097 - val_loss: 0.0058\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0104 - val_loss: 0.0057\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0094 - val_loss: 0.0062\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0128 - val_loss: 0.0079\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0085 - val_loss: 0.0060\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0076 - val_loss: 0.0057\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0088 - val_loss: 0.0058\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 72us/sample - loss: 0.0087 - val_loss: 0.0058\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0063\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0085 - val_loss: 0.0058\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0080 - val_loss: 0.0061\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0079 - val_loss: 0.0057\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0081 - val_loss: 0.0059\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0077 - val_loss: 0.0057\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0081 - val_loss: 0.0058\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0079 - val_loss: 0.0059\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0085 - val_loss: 0.0058\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0079 - val_loss: 0.0060\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0076 - val_loss: 0.0060\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0085 - val_loss: 0.0059\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0078 - val_loss: 0.0057\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0080 - val_loss: 0.0058\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0081 - val_loss: 0.0057\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0078 - val_loss: 0.0060\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0076 - val_loss: 0.0061\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0086 - val_loss: 0.0059\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0077 - val_loss: 0.0057\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0079 - val_loss: 0.0059\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0082 - val_loss: 0.0058\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0078 - val_loss: 0.0060\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0075 - val_loss: 0.0058\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0084 - val_loss: 0.0058\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0079 - val_loss: 0.0058\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0077 - val_loss: 0.0057\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0081 - val_loss: 0.0057\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0077 - val_loss: 0.0061\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0075 - val_loss: 0.0060\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0085 - val_loss: 0.0058\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0077 - val_loss: 0.0057\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0078 - val_loss: 0.0058\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0078 - val_loss: 0.0057\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0076 - val_loss: 0.0061\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0076 - val_loss: 0.0061\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0086 - val_loss: 0.0058\n",
      "第369个数，还剩3754个没有训练\n",
      "inv_hat [1.03356698 1.02453435 1.02503463 1.02343425 1.01854536 1.01794803\n",
      " 1.01814715 1.02153638 1.02083785 1.02133673 1.02884296 1.02954559\n",
      " 1.03125332 1.03024856 1.03085136 1.02713793 1.02713793 1.02804035\n",
      " 1.03155495 1.02844154 1.0259357  1.02173607 1.01834617 1.01427095\n",
      " 1.01030892 1.01209006 1.01030892 1.00882681 1.00764252 1.0105066 ]\n",
      "Test RMSE: 0.003\n",
      "Train on 864 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "864/864 [==============================] - 0s 77us/sample - loss: 0.0146 - val_loss: 0.0159\n",
      "Epoch 2/50\n",
      "864/864 [==============================] - 0s 77us/sample - loss: 0.0146 - val_loss: 0.0155\n",
      "Epoch 3/50\n",
      "864/864 [==============================] - 0s 78us/sample - loss: 0.0146 - val_loss: 0.0159\n",
      "Epoch 4/50\n",
      "864/864 [==============================] - 0s 81us/sample - loss: 0.0145 - val_loss: 0.0154\n",
      "Epoch 5/50\n",
      "864/864 [==============================] - 0s 75us/sample - loss: 0.0145 - val_loss: 0.0161\n",
      "Epoch 6/50\n",
      "864/864 [==============================] - 0s 74us/sample - loss: 0.0145 - val_loss: 0.0154\n",
      "Epoch 7/50\n",
      "864/864 [==============================] - 0s 79us/sample - loss: 0.0143 - val_loss: 0.0160\n",
      "Epoch 8/50\n",
      "864/864 [==============================] - 0s 78us/sample - loss: 0.0146 - val_loss: 0.0156\n",
      "Epoch 9/50\n",
      "864/864 [==============================] - 0s 74us/sample - loss: 0.0147 - val_loss: 0.0158\n",
      "Epoch 10/50\n",
      "864/864 [==============================] - 0s 75us/sample - loss: 0.0147 - val_loss: 0.0156\n",
      "Epoch 11/50\n",
      "864/864 [==============================] - 0s 77us/sample - loss: 0.0145 - val_loss: 0.0159\n",
      "Epoch 12/50\n",
      "864/864 [==============================] - 0s 77us/sample - loss: 0.0145 - val_loss: 0.0155\n",
      "Epoch 13/50\n",
      "864/864 [==============================] - 0s 79us/sample - loss: 0.0145 - val_loss: 0.0161\n",
      "Epoch 14/50\n",
      "864/864 [==============================] - 0s 78us/sample - loss: 0.0147 - val_loss: 0.0156\n",
      "Epoch 15/50\n",
      "864/864 [==============================] - 0s 77us/sample - loss: 0.0146 - val_loss: 0.0160\n",
      "Epoch 16/50\n",
      "864/864 [==============================] - ETA: 0s - loss: 0.013 - 0s 81us/sample - loss: 0.0147 - val_loss: 0.0156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "864/864 [==============================] - 0s 80us/sample - loss: 0.0147 - val_loss: 0.0160\n",
      "Epoch 18/50\n",
      "864/864 [==============================] - 0s 83us/sample - loss: 0.0147 - val_loss: 0.0157\n",
      "Epoch 19/50\n",
      "864/864 [==============================] - 0s 82us/sample - loss: 0.0147 - val_loss: 0.0163\n",
      "Epoch 20/50\n",
      "864/864 [==============================] - 0s 78us/sample - loss: 0.0144 - val_loss: 0.0154\n",
      "Epoch 21/50\n",
      "864/864 [==============================] - 0s 78us/sample - loss: 0.0144 - val_loss: 0.0160\n",
      "Epoch 22/50\n",
      "864/864 [==============================] - 0s 75us/sample - loss: 0.0146 - val_loss: 0.0155\n",
      "Epoch 23/50\n",
      "864/864 [==============================] - 0s 76us/sample - loss: 0.0149 - val_loss: 0.0161\n",
      "Epoch 24/50\n",
      "864/864 [==============================] - 0s 77us/sample - loss: 0.0144 - val_loss: 0.0154\n",
      "Epoch 25/50\n",
      "864/864 [==============================] - 0s 75us/sample - loss: 0.0144 - val_loss: 0.0158\n",
      "Epoch 26/50\n",
      "864/864 [==============================] - 0s 71us/sample - loss: 0.0145 - val_loss: 0.0156\n",
      "Epoch 27/50\n",
      "864/864 [==============================] - 0s 70us/sample - loss: 0.0150 - val_loss: 0.0162\n",
      "Epoch 28/50\n",
      "864/864 [==============================] - 0s 72us/sample - loss: 0.0145 - val_loss: 0.0155\n",
      "Epoch 29/50\n",
      "864/864 [==============================] - 0s 74us/sample - loss: 0.0145 - val_loss: 0.0157\n",
      "Epoch 30/50\n",
      "864/864 [==============================] - 0s 73us/sample - loss: 0.0145 - val_loss: 0.0156\n",
      "Epoch 31/50\n",
      "864/864 [==============================] - 0s 71us/sample - loss: 0.0150 - val_loss: 0.0165\n",
      "Epoch 32/50\n",
      "864/864 [==============================] - 0s 72us/sample - loss: 0.0145 - val_loss: 0.0155\n",
      "Epoch 33/50\n",
      "864/864 [==============================] - 0s 75us/sample - loss: 0.0145 - val_loss: 0.0157\n",
      "Epoch 34/50\n",
      "864/864 [==============================] - 0s 76us/sample - loss: 0.0145 - val_loss: 0.0156\n",
      "Epoch 35/50\n",
      "864/864 [==============================] - 0s 75us/sample - loss: 0.0149 - val_loss: 0.0160\n",
      "Epoch 36/50\n",
      "864/864 [==============================] - 0s 76us/sample - loss: 0.0144 - val_loss: 0.0154\n",
      "Epoch 37/50\n",
      "864/864 [==============================] - 0s 82us/sample - loss: 0.0144 - val_loss: 0.0158\n",
      "Epoch 38/50\n",
      "864/864 [==============================] - 0s 81us/sample - loss: 0.0146 - val_loss: 0.0156\n",
      "Epoch 39/50\n",
      "864/864 [==============================] - 0s 77us/sample - loss: 0.0149 - val_loss: 0.0161\n",
      "Epoch 40/50\n",
      "864/864 [==============================] - 0s 79us/sample - loss: 0.0144 - val_loss: 0.0154\n",
      "Epoch 41/50\n",
      "864/864 [==============================] - 0s 77us/sample - loss: 0.0144 - val_loss: 0.0157\n",
      "Epoch 42/50\n",
      "864/864 [==============================] - 0s 74us/sample - loss: 0.0145 - val_loss: 0.0156\n",
      "Epoch 43/50\n",
      "864/864 [==============================] - 0s 74us/sample - loss: 0.0148 - val_loss: 0.0159\n",
      "Epoch 44/50\n",
      "864/864 [==============================] - 0s 77us/sample - loss: 0.0144 - val_loss: 0.0155\n",
      "Epoch 45/50\n",
      "864/864 [==============================] - 0s 76us/sample - loss: 0.0145 - val_loss: 0.0159\n",
      "Epoch 46/50\n",
      "864/864 [==============================] - 0s 81us/sample - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 47/50\n",
      "864/864 [==============================] - 0s 77us/sample - loss: 0.0151 - val_loss: 0.0163\n",
      "Epoch 48/50\n",
      "864/864 [==============================] - 0s 79us/sample - loss: 0.0143 - val_loss: 0.0154\n",
      "Epoch 49/50\n",
      "864/864 [==============================] - 0s 81us/sample - loss: 0.0143 - val_loss: 0.0155\n",
      "Epoch 50/50\n",
      "864/864 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0156\n",
      "第370个数，还剩3753个没有训练\n",
      "inv_hat [1.0193938  1.01455866 1.01552226 1.01359711 1.01072484 1.01072484\n",
      " 1.01072484 1.01167998 1.00977195 1.01072484 1.01455866 1.01648757\n",
      " 1.01552226 1.01167998 1.01240738 1.01337302 1.01434035 1.01530949\n",
      " 1.01628013 1.01144362 1.00952226 1.00760966 1.00570667 1.00665686\n",
      " 1.004759   1.00570667 1.00381406 1.00381406 1.00287209 1.00381406]\n",
      "Test RMSE: 0.002\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0075 - val_loss: 0.0055\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0073 - val_loss: 0.0076\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0070 - val_loss: 0.0068\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0070 - val_loss: 0.0077\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0059 - val_loss: 0.0064\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0063 - val_loss: 0.0069\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0066 - val_loss: 0.0083\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0059 - val_loss: 0.0070\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0057 - val_loss: 0.0064\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0054 - val_loss: 0.0066\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0056 - val_loss: 0.0066\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0052 - val_loss: 0.0063\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0056 - val_loss: 0.0066\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0053 - val_loss: 0.0065\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0055 - val_loss: 0.0066\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0053 - val_loss: 0.0065\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0054 - val_loss: 0.0065\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0052 - val_loss: 0.0062\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0054 - val_loss: 0.0065\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0053 - val_loss: 0.0066\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0051 - val_loss: 0.0063\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0052 - val_loss: 0.0063\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0052 - val_loss: 0.0064\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0051 - val_loss: 0.0063\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0050 - val_loss: 0.0060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0052 - val_loss: 0.0063\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0051 - val_loss: 0.0062\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0051 - val_loss: 0.0062\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0051 - val_loss: 0.0063\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0051 - val_loss: 0.0063\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0050 - val_loss: 0.0060\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0050 - val_loss: 0.0057\n",
      "第371个数，还剩3752个没有训练\n",
      "inv_hat [1.3860806  1.38153213 1.38114416 1.38085325 1.37589555 1.3769665\n",
      " 1.37745296 1.37910566 1.3792028  1.38007682 1.38405038 1.38598398\n",
      " 1.3868531  1.38356651 1.38298556 1.38240437 1.38511423 1.38530757\n",
      " 1.38839667 1.38191987 1.3797855  1.37609023 1.37394593 1.37306771\n",
      " 1.37062492 1.37170039 1.37160262 1.37287246 1.37199346 1.37540836]\n",
      "Test RMSE: 0.003\n",
      "Train on 748 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "748/748 [==============================] - 0s 83us/sample - loss: 0.0207 - val_loss: 0.0298\n",
      "Epoch 2/50\n",
      "748/748 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0311\n",
      "Epoch 3/50\n",
      "748/748 [==============================] - 0s 84us/sample - loss: 0.0167 - val_loss: 0.0283\n",
      "Epoch 4/50\n",
      "748/748 [==============================] - 0s 82us/sample - loss: 0.0141 - val_loss: 0.0282\n",
      "Epoch 5/50\n",
      "748/748 [==============================] - 0s 83us/sample - loss: 0.0147 - val_loss: 0.0286\n",
      "Epoch 6/50\n",
      "748/748 [==============================] - 0s 82us/sample - loss: 0.0159 - val_loss: 0.0265\n",
      "Epoch 7/50\n",
      "748/748 [==============================] - 0s 79us/sample - loss: 0.0138 - val_loss: 0.0269\n",
      "Epoch 8/50\n",
      "748/748 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0274\n",
      "Epoch 9/50\n",
      "748/748 [==============================] - 0s 79us/sample - loss: 0.0151 - val_loss: 0.0266\n",
      "Epoch 10/50\n",
      "748/748 [==============================] - 0s 81us/sample - loss: 0.0146 - val_loss: 0.0263\n",
      "Epoch 11/50\n",
      "748/748 [==============================] - 0s 84us/sample - loss: 0.0142 - val_loss: 0.0265\n",
      "Epoch 12/50\n",
      "748/748 [==============================] - 0s 80us/sample - loss: 0.0146 - val_loss: 0.0262\n",
      "Epoch 13/50\n",
      "748/748 [==============================] - 0s 81us/sample - loss: 0.0142 - val_loss: 0.0263\n",
      "Epoch 14/50\n",
      "748/748 [==============================] - 0s 81us/sample - loss: 0.0141 - val_loss: 0.0266\n",
      "Epoch 15/50\n",
      "748/748 [==============================] - 0s 77us/sample - loss: 0.0148 - val_loss: 0.0259\n",
      "Epoch 16/50\n",
      "748/748 [==============================] - 0s 81us/sample - loss: 0.0139 - val_loss: 0.0263\n",
      "Epoch 17/50\n",
      "748/748 [==============================] - 0s 79us/sample - loss: 0.0141 - val_loss: 0.0265\n",
      "Epoch 18/50\n",
      "748/748 [==============================] - 0s 79us/sample - loss: 0.0148 - val_loss: 0.0257\n",
      "Epoch 19/50\n",
      "748/748 [==============================] - 0s 80us/sample - loss: 0.0138 - val_loss: 0.0256\n",
      "Epoch 20/50\n",
      "748/748 [==============================] - 0s 80us/sample - loss: 0.0136 - val_loss: 0.0257\n",
      "Epoch 21/50\n",
      "748/748 [==============================] - 0s 81us/sample - loss: 0.0136 - val_loss: 0.0259\n",
      "Epoch 22/50\n",
      "748/748 [==============================] - 0s 77us/sample - loss: 0.0138 - val_loss: 0.0268\n",
      "Epoch 23/50\n",
      "748/748 [==============================] - 0s 83us/sample - loss: 0.0148 - val_loss: 0.0258\n",
      "Epoch 24/50\n",
      "748/748 [==============================] - 0s 78us/sample - loss: 0.0137 - val_loss: 0.0257\n",
      "Epoch 25/50\n",
      "748/748 [==============================] - 0s 78us/sample - loss: 0.0135 - val_loss: 0.0258\n",
      "Epoch 26/50\n",
      "748/748 [==============================] - 0s 85us/sample - loss: 0.0135 - val_loss: 0.0259\n",
      "Epoch 27/50\n",
      "748/748 [==============================] - 0s 85us/sample - loss: 0.0136 - val_loss: 0.0264\n",
      "Epoch 28/50\n",
      "748/748 [==============================] - 0s 78us/sample - loss: 0.0137 - val_loss: 0.0268\n",
      "Epoch 29/50\n",
      "748/748 [==============================] - 0s 78us/sample - loss: 0.0141 - val_loss: 0.0268\n",
      "Epoch 30/50\n",
      "748/748 [==============================] - 0s 79us/sample - loss: 0.0146 - val_loss: 0.0258\n",
      "Epoch 31/50\n",
      "748/748 [==============================] - 0s 79us/sample - loss: 0.0137 - val_loss: 0.0256\n",
      "Epoch 32/50\n",
      "748/748 [==============================] - 0s 81us/sample - loss: 0.0135 - val_loss: 0.0256\n",
      "Epoch 33/50\n",
      "748/748 [==============================] - 0s 83us/sample - loss: 0.0137 - val_loss: 0.0254\n",
      "Epoch 34/50\n",
      "748/748 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0254\n",
      "Epoch 35/50\n",
      "748/748 [==============================] - 0s 84us/sample - loss: 0.0146 - val_loss: 0.0259\n",
      "Epoch 36/50\n",
      "748/748 [==============================] - 0s 81us/sample - loss: 0.0135 - val_loss: 0.0261\n",
      "Epoch 37/50\n",
      "748/748 [==============================] - 0s 80us/sample - loss: 0.0135 - val_loss: 0.0264\n",
      "Epoch 38/50\n",
      "748/748 [==============================] - 0s 85us/sample - loss: 0.0136 - val_loss: 0.0269\n",
      "Epoch 39/50\n",
      "748/748 [==============================] - 0s 81us/sample - loss: 0.0139 - val_loss: 0.0270\n",
      "Epoch 40/50\n",
      "748/748 [==============================] - 0s 82us/sample - loss: 0.0147 - val_loss: 0.0258\n",
      "Epoch 41/50\n",
      "748/748 [==============================] - 0s 83us/sample - loss: 0.0135 - val_loss: 0.0258\n",
      "Epoch 42/50\n",
      "748/748 [==============================] - 0s 84us/sample - loss: 0.0135 - val_loss: 0.0263\n",
      "Epoch 43/50\n",
      "748/748 [==============================] - 0s 81us/sample - loss: 0.0136 - val_loss: 0.0265\n",
      "Epoch 44/50\n",
      "748/748 [==============================] - 0s 80us/sample - loss: 0.0140 - val_loss: 0.0262\n",
      "Epoch 45/50\n",
      "748/748 [==============================] - 0s 82us/sample - loss: 0.0138 - val_loss: 0.0263\n",
      "Epoch 46/50\n",
      "748/748 [==============================] - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0260\n",
      "Epoch 47/50\n",
      "748/748 [==============================] - 0s 77us/sample - loss: 0.0137 - val_loss: 0.0258\n",
      "Epoch 48/50\n",
      "748/748 [==============================] - 0s 84us/sample - loss: 0.0136 - val_loss: 0.0261\n",
      "Epoch 49/50\n",
      "748/748 [==============================] - 0s 82us/sample - loss: 0.0137 - val_loss: 0.0265\n",
      "Epoch 50/50\n",
      "748/748 [==============================] - 0s 79us/sample - loss: 0.0144 - val_loss: 0.0259\n",
      "第372个数，还剩3751个没有训练\n",
      "inv_hat [0.86006744 0.83309506 0.83901165 0.83629061 0.81345644 0.81355039\n",
      " 0.81902301 0.83561173 0.82377814 0.83658173 0.85857822 0.85718994\n",
      " 0.85907439 0.83755285 0.83396535 0.8254981  0.83319172 0.83755285\n",
      " 0.84457696 0.82578516 0.81148725 0.8079407  0.79825831 0.79898974\n",
      " 0.79534333 0.80266264 0.79816694 0.79172414 0.78634797 0.78608088]\n",
      "Test RMSE: 0.012\n",
      "Train on 963 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "963/963 [==============================] - 0s 79us/sample - loss: 0.0188 - val_loss: 0.0103\n",
      "Epoch 2/50\n",
      "963/963 [==============================] - 0s 81us/sample - loss: 0.0187 - val_loss: 0.0102\n",
      "Epoch 3/50\n",
      "963/963 [==============================] - 0s 83us/sample - loss: 0.0187 - val_loss: 0.0103\n",
      "Epoch 4/50\n",
      "963/963 [==============================] - 0s 82us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 5/50\n",
      "963/963 [==============================] - 0s 81us/sample - loss: 0.0186 - val_loss: 0.0102\n",
      "Epoch 6/50\n",
      "963/963 [==============================] - 0s 81us/sample - loss: 0.0186 - val_loss: 0.0102\n",
      "Epoch 7/50\n",
      "963/963 [==============================] - 0s 78us/sample - loss: 0.0186 - val_loss: 0.0102\n",
      "Epoch 8/50\n",
      "963/963 [==============================] - 0s 79us/sample - loss: 0.0186 - val_loss: 0.0102\n",
      "Epoch 9/50\n",
      "963/963 [==============================] - 0s 78us/sample - loss: 0.0186 - val_loss: 0.0102\n",
      "Epoch 10/50\n",
      "963/963 [==============================] - 0s 80us/sample - loss: 0.0186 - val_loss: 0.0102\n",
      "Epoch 11/50\n",
      "963/963 [==============================] - 0s 80us/sample - loss: 0.0186 - val_loss: 0.0102\n",
      "Epoch 12/50\n",
      "963/963 [==============================] - 0s 79us/sample - loss: 0.0186 - val_loss: 0.0102\n",
      "Epoch 13/50\n",
      "963/963 [==============================] - 0s 75us/sample - loss: 0.0186 - val_loss: 0.0102\n",
      "Epoch 14/50\n",
      "963/963 [==============================] - 0s 79us/sample - loss: 0.0186 - val_loss: 0.0102\n",
      "Epoch 15/50\n",
      "963/963 [==============================] - 0s 79us/sample - loss: 0.0186 - val_loss: 0.0102\n",
      "Epoch 16/50\n",
      "963/963 [==============================] - 0s 80us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 17/50\n",
      "963/963 [==============================] - 0s 84us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 18/50\n",
      "963/963 [==============================] - 0s 83us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 19/50\n",
      "963/963 [==============================] - 0s 77us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 20/50\n",
      "963/963 [==============================] - 0s 76us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 21/50\n",
      "963/963 [==============================] - 0s 79us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 22/50\n",
      "963/963 [==============================] - 0s 82us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 23/50\n",
      "963/963 [==============================] - 0s 81us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 24/50\n",
      "963/963 [==============================] - 0s 82us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 25/50\n",
      "963/963 [==============================] - 0s 80us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 26/50\n",
      "963/963 [==============================] - 0s 79us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 27/50\n",
      "963/963 [==============================] - 0s 76us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 28/50\n",
      "963/963 [==============================] - 0s 80us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 29/50\n",
      "963/963 [==============================] - 0s 80us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 30/50\n",
      "963/963 [==============================] - 0s 81us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 31/50\n",
      "963/963 [==============================] - 0s 81us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 32/50\n",
      "963/963 [==============================] - 0s 80us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 33/50\n",
      "963/963 [==============================] - 0s 84us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 34/50\n",
      "963/963 [==============================] - 0s 78us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 35/50\n",
      "963/963 [==============================] - 0s 78us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 36/50\n",
      "963/963 [==============================] - 0s 79us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 37/50\n",
      "963/963 [==============================] - 0s 82us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 38/50\n",
      "963/963 [==============================] - 0s 84us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 39/50\n",
      "963/963 [==============================] - 0s 80us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 40/50\n",
      "963/963 [==============================] - 0s 76us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 41/50\n",
      "963/963 [==============================] - 0s 78us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 42/50\n",
      "963/963 [==============================] - 0s 77us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 43/50\n",
      "963/963 [==============================] - 0s 77us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 44/50\n",
      "963/963 [==============================] - 0s 78us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 45/50\n",
      "963/963 [==============================] - 0s 78us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 46/50\n",
      "963/963 [==============================] - 0s 76us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 47/50\n",
      "963/963 [==============================] - 0s 81us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 48/50\n",
      "963/963 [==============================] - 0s 86us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 49/50\n",
      "963/963 [==============================] - 0s 83us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 50/50\n",
      "963/963 [==============================] - 0s 83us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "第373个数，还剩3750个没有训练\n",
      "inv_hat [0.77997485 0.72200175 0.7319905  0.73598672 0.668457   0.66433444\n",
      " 0.67882216 0.72499807 0.668457   0.67260173 0.72200175 0.72999245\n",
      " 0.72100316 0.68297129 0.69101655 0.69501522 0.71700863 0.71101615\n",
      " 0.72599688 0.69001687 0.68400882 0.67156541 0.64498925 0.6551683\n",
      " 0.65415016 0.65415016 0.63176564 0.62973228 0.60738334 0.60738334]\n",
      "Test RMSE: 0.026\n",
      "Train on 824 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "824/824 [==============================] - 0s 83us/sample - loss: 0.0081 - val_loss: 0.0017\n",
      "Epoch 2/50\n",
      "824/824 [==============================] - 0s 79us/sample - loss: 0.0078 - val_loss: 0.0030\n",
      "Epoch 3/50\n",
      "824/824 [==============================] - 0s 82us/sample - loss: 0.0071 - val_loss: 0.0019\n",
      "Epoch 4/50\n",
      "824/824 [==============================] - 0s 80us/sample - loss: 0.0067 - val_loss: 0.0020\n",
      "Epoch 5/50\n",
      "824/824 [==============================] - 0s 79us/sample - loss: 0.0070 - val_loss: 0.0017\n",
      "Epoch 6/50\n",
      "824/824 [==============================] - 0s 79us/sample - loss: 0.0067 - val_loss: 0.0024\n",
      "Epoch 7/50\n",
      "824/824 [==============================] - 0s 80us/sample - loss: 0.0067 - val_loss: 0.0018\n",
      "Epoch 8/50\n",
      "824/824 [==============================] - 0s 81us/sample - loss: 0.0065 - val_loss: 0.0020\n",
      "Epoch 9/50\n",
      "824/824 [==============================] - 0s 79us/sample - loss: 0.0069 - val_loss: 0.0017\n",
      "Epoch 10/50\n",
      "824/824 [==============================] - 0s 84us/sample - loss: 0.0066 - val_loss: 0.0020\n",
      "Epoch 11/50\n",
      "824/824 [==============================] - 0s 81us/sample - loss: 0.0069 - val_loss: 0.0025\n",
      "Epoch 12/50\n",
      "824/824 [==============================] - 0s 78us/sample - loss: 0.0069 - val_loss: 0.0025\n",
      "Epoch 13/50\n",
      "824/824 [==============================] - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0017\n",
      "Epoch 14/50\n",
      "824/824 [==============================] - 0s 78us/sample - loss: 0.0063 - val_loss: 0.0018\n",
      "Epoch 15/50\n",
      "824/824 [==============================] - 0s 77us/sample - loss: 0.0062 - val_loss: 0.0017\n",
      "Epoch 16/50\n",
      "824/824 [==============================] - 0s 74us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 17/50\n",
      "824/824 [==============================] - 0s 75us/sample - loss: 0.0063 - val_loss: 0.0016\n",
      "Epoch 18/50\n",
      "824/824 [==============================] - 0s 75us/sample - loss: 0.0062 - val_loss: 0.0017\n",
      "Epoch 19/50\n",
      "824/824 [==============================] - 0s 81us/sample - loss: 0.0062 - val_loss: 0.0017\n",
      "Epoch 20/50\n",
      "824/824 [==============================] - 0s 80us/sample - loss: 0.0064 - val_loss: 0.0019\n",
      "Epoch 21/50\n",
      "824/824 [==============================] - 0s 87us/sample - loss: 0.0064 - val_loss: 0.0018\n",
      "Epoch 22/50\n",
      "824/824 [==============================] - 0s 87us/sample - loss: 0.0063 - val_loss: 0.0018\n",
      "Epoch 23/50\n",
      "824/824 [==============================] - 0s 85us/sample - loss: 0.0063 - val_loss: 0.0018\n",
      "Epoch 24/50\n",
      "824/824 [==============================] - 0s 84us/sample - loss: 0.0063 - val_loss: 0.0018\n",
      "Epoch 25/50\n",
      "824/824 [==============================] - 0s 78us/sample - loss: 0.0065 - val_loss: 0.0018\n",
      "Epoch 26/50\n",
      "824/824 [==============================] - 0s 79us/sample - loss: 0.0065 - val_loss: 0.0018\n",
      "Epoch 27/50\n",
      "824/824 [==============================] - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0017\n",
      "Epoch 28/50\n",
      "824/824 [==============================] - 0s 77us/sample - loss: 0.0064 - val_loss: 0.0019\n",
      "Epoch 29/50\n",
      "824/824 [==============================] - 0s 76us/sample - loss: 0.0065 - val_loss: 0.0017\n",
      "Epoch 30/50\n",
      "824/824 [==============================] - 0s 75us/sample - loss: 0.0066 - val_loss: 0.0020\n",
      "Epoch 31/50\n",
      "824/824 [==============================] - 0s 81us/sample - loss: 0.0067 - val_loss: 0.0018\n",
      "Epoch 32/50\n",
      "824/824 [==============================] - 0s 83us/sample - loss: 0.0066 - val_loss: 0.0021\n",
      "Epoch 33/50\n",
      "824/824 [==============================] - 0s 87us/sample - loss: 0.0068 - val_loss: 0.0019\n",
      "Epoch 34/50\n",
      "824/824 [==============================] - 0s 86us/sample - loss: 0.0068 - val_loss: 0.0025\n",
      "Epoch 35/50\n",
      "824/824 [==============================] - 0s 82us/sample - loss: 0.0066 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "824/824 [==============================] - 0s 82us/sample - loss: 0.0066 - val_loss: 0.0020\n",
      "Epoch 37/50\n",
      "824/824 [==============================] - 0s 81us/sample - loss: 0.0066 - val_loss: 0.0017\n",
      "Epoch 38/50\n",
      "824/824 [==============================] - 0s 85us/sample - loss: 0.0064 - val_loss: 0.0020\n",
      "Epoch 39/50\n",
      "824/824 [==============================] - 0s 85us/sample - loss: 0.0067 - val_loss: 0.0019\n",
      "Epoch 40/50\n",
      "824/824 [==============================] - 0s 83us/sample - loss: 0.0068 - val_loss: 0.0026\n",
      "Epoch 41/50\n",
      "824/824 [==============================] - 0s 79us/sample - loss: 0.0066 - val_loss: 0.0019\n",
      "Epoch 42/50\n",
      "824/824 [==============================] - 0s 80us/sample - loss: 0.0066 - val_loss: 0.0019\n",
      "Epoch 43/50\n",
      "824/824 [==============================] - 0s 78us/sample - loss: 0.0067 - val_loss: 0.0025\n",
      "Epoch 44/50\n",
      "824/824 [==============================] - 0s 81us/sample - loss: 0.0071 - val_loss: 0.0026\n",
      "Epoch 45/50\n",
      "824/824 [==============================] - 0s 82us/sample - loss: 0.0063 - val_loss: 0.0017\n",
      "Epoch 46/50\n",
      "824/824 [==============================] - 0s 85us/sample - loss: 0.0064 - val_loss: 0.0020\n",
      "Epoch 47/50\n",
      "824/824 [==============================] - 0s 82us/sample - loss: 0.0066 - val_loss: 0.0017\n",
      "Epoch 48/50\n",
      "824/824 [==============================] - 0s 84us/sample - loss: 0.0066 - val_loss: 0.0022\n",
      "Epoch 49/50\n",
      "824/824 [==============================] - 0s 81us/sample - loss: 0.0067 - val_loss: 0.0017\n",
      "Epoch 50/50\n",
      "824/824 [==============================] - 0s 80us/sample - loss: 0.0067 - val_loss: 0.0020\n",
      "第374个数，还剩3749个没有训练\n",
      "inv_hat [1.00398128 1.00408102 1.00428045 1.00438024 1.00448005 1.00487931\n",
      " 1.00497919 1.00507908 1.00527889 1.00537881 1.00567819 1.00587731\n",
      " 1.00597693 1.0060766  1.00617631 1.00657532 1.00667519 1.00687502\n",
      " 1.00697499 1.00707488 1.00747491 1.00757494 1.00767501 1.00777498\n",
      " 1.00797524 1.00827583 1.00847622 1.00857651 1.00867683 1.00877717]\n",
      "Test RMSE: 0.000\n",
      "Train on 510 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "510/510 [==============================] - 0s 93us/sample - loss: 0.0136 - val_loss: 0.0293\n",
      "Epoch 2/50\n",
      "510/510 [==============================] - 0s 89us/sample - loss: 0.0136 - val_loss: 0.0298\n",
      "Epoch 3/50\n",
      "510/510 [==============================] - 0s 89us/sample - loss: 0.0134 - val_loss: 0.0294\n",
      "Epoch 4/50\n",
      "510/510 [==============================] - 0s 91us/sample - loss: 0.0134 - val_loss: 0.0296\n",
      "Epoch 5/50\n",
      "510/510 [==============================] - 0s 94us/sample - loss: 0.0132 - val_loss: 0.0294\n",
      "Epoch 6/50\n",
      "510/510 [==============================] - 0s 88us/sample - loss: 0.0133 - val_loss: 0.0299\n",
      "Epoch 7/50\n",
      "510/510 [==============================] - 0s 86us/sample - loss: 0.0133 - val_loss: 0.0295\n",
      "Epoch 8/50\n",
      "510/510 [==============================] - 0s 85us/sample - loss: 0.0132 - val_loss: 0.0299\n",
      "Epoch 9/50\n",
      "510/510 [==============================] - 0s 88us/sample - loss: 0.0133 - val_loss: 0.0296\n",
      "Epoch 10/50\n",
      "510/510 [==============================] - 0s 86us/sample - loss: 0.0131 - val_loss: 0.0297\n",
      "Epoch 11/50\n",
      "510/510 [==============================] - 0s 87us/sample - loss: 0.0132 - val_loss: 0.0296\n",
      "Epoch 12/50\n",
      "510/510 [==============================] - 0s 86us/sample - loss: 0.0131 - val_loss: 0.0297\n",
      "Epoch 13/50\n",
      "510/510 [==============================] - 0s 83us/sample - loss: 0.0132 - val_loss: 0.0296\n",
      "Epoch 14/50\n",
      "510/510 [==============================] - 0s 83us/sample - loss: 0.0131 - val_loss: 0.0297\n",
      "Epoch 15/50\n",
      "510/510 [==============================] - 0s 82us/sample - loss: 0.0131 - val_loss: 0.0296\n",
      "Epoch 16/50\n",
      "510/510 [==============================] - 0s 83us/sample - loss: 0.0131 - val_loss: 0.0296\n",
      "Epoch 17/50\n",
      "510/510 [==============================] - 0s 86us/sample - loss: 0.0131 - val_loss: 0.0297\n",
      "Epoch 18/50\n",
      "510/510 [==============================] - 0s 87us/sample - loss: 0.0131 - val_loss: 0.0297\n",
      "Epoch 19/50\n",
      "510/510 [==============================] - 0s 93us/sample - loss: 0.0131 - val_loss: 0.0297\n",
      "Epoch 20/50\n",
      "510/510 [==============================] - 0s 91us/sample - loss: 0.0131 - val_loss: 0.0296\n",
      "Epoch 21/50\n",
      "510/510 [==============================] - 0s 94us/sample - loss: 0.0131 - val_loss: 0.0297\n",
      "Epoch 22/50\n",
      "510/510 [==============================] - 0s 88us/sample - loss: 0.0131 - val_loss: 0.0296\n",
      "Epoch 23/50\n",
      "510/510 [==============================] - 0s 87us/sample - loss: 0.0131 - val_loss: 0.0297\n",
      "Epoch 24/50\n",
      "510/510 [==============================] - 0s 88us/sample - loss: 0.0131 - val_loss: 0.0296\n",
      "Epoch 25/50\n",
      "510/510 [==============================] - 0s 88us/sample - loss: 0.0131 - val_loss: 0.0297\n",
      "Epoch 26/50\n",
      "510/510 [==============================] - 0s 91us/sample - loss: 0.0131 - val_loss: 0.0296\n",
      "Epoch 27/50\n",
      "510/510 [==============================] - 0s 101us/sample - loss: 0.0131 - val_loss: 0.0296\n",
      "Epoch 28/50\n",
      "510/510 [==============================] - 0s 92us/sample - loss: 0.0131 - val_loss: 0.0296\n",
      "Epoch 29/50\n",
      "510/510 [==============================] - 0s 90us/sample - loss: 0.0131 - val_loss: 0.0296\n",
      "Epoch 30/50\n",
      "510/510 [==============================] - 0s 87us/sample - loss: 0.0131 - val_loss: 0.0296\n",
      "Epoch 31/50\n",
      "510/510 [==============================] - 0s 86us/sample - loss: 0.0131 - val_loss: 0.0296\n",
      "Epoch 32/50\n",
      "510/510 [==============================] - 0s 88us/sample - loss: 0.0131 - val_loss: 0.0297\n",
      "Epoch 33/50\n",
      "510/510 [==============================] - 0s 89us/sample - loss: 0.0131 - val_loss: 0.0297\n",
      "Epoch 34/50\n",
      "510/510 [==============================] - 0s 86us/sample - loss: 0.0131 - val_loss: 0.0297\n",
      "Epoch 35/50\n",
      "510/510 [==============================] - 0s 89us/sample - loss: 0.0131 - val_loss: 0.0297\n",
      "Epoch 36/50\n",
      "510/510 [==============================] - 0s 87us/sample - loss: 0.0131 - val_loss: 0.0297\n",
      "Epoch 37/50\n",
      "510/510 [==============================] - 0s 94us/sample - loss: 0.0131 - val_loss: 0.0296\n",
      "Epoch 38/50\n",
      "510/510 [==============================] - 0s 93us/sample - loss: 0.0131 - val_loss: 0.0297\n",
      "Epoch 39/50\n",
      "510/510 [==============================] - 0s 85us/sample - loss: 0.0132 - val_loss: 0.0295\n",
      "Epoch 40/50\n",
      "510/510 [==============================] - 0s 87us/sample - loss: 0.0131 - val_loss: 0.0296\n",
      "Epoch 41/50\n",
      "510/510 [==============================] - 0s 91us/sample - loss: 0.0131 - val_loss: 0.0296\n",
      "Epoch 42/50\n",
      "510/510 [==============================] - 0s 89us/sample - loss: 0.0131 - val_loss: 0.0296\n",
      "Epoch 43/50\n",
      "510/510 [==============================] - 0s 90us/sample - loss: 0.0131 - val_loss: 0.0296\n",
      "Epoch 44/50\n",
      "510/510 [==============================] - 0s 87us/sample - loss: 0.0131 - val_loss: 0.0296\n",
      "Epoch 45/50\n",
      "510/510 [==============================] - 0s 89us/sample - loss: 0.0131 - val_loss: 0.0296\n",
      "Epoch 46/50\n",
      "510/510 [==============================] - 0s 91us/sample - loss: 0.0131 - val_loss: 0.0297\n",
      "Epoch 47/50\n",
      "510/510 [==============================] - 0s 89us/sample - loss: 0.0131 - val_loss: 0.0295\n",
      "Epoch 48/50\n",
      "510/510 [==============================] - 0s 94us/sample - loss: 0.0130 - val_loss: 0.0296\n",
      "Epoch 49/50\n",
      "510/510 [==============================] - 0s 93us/sample - loss: 0.0131 - val_loss: 0.0296\n",
      "Epoch 50/50\n",
      "510/510 [==============================] - 0s 96us/sample - loss: 0.0130 - val_loss: 0.0296\n",
      "第375个数，还剩3748个没有训练\n",
      "inv_hat [1.04468218 1.04367227 1.03357234 1.02953208 0.97820916 0.96826514\n",
      " 0.97721182 0.98520615 0.99021848 1.00329228 1.02953208 1.03155221\n",
      " 1.03660255 1.02852198 1.02448198 1.02044246 1.02953208 1.02852198\n",
      " 1.02751188 1.00027091 1.00228488 1.00732374 0.99926431 0.99725186\n",
      " 0.98720976 0.98320438 0.98287754 0.98587644 0.98287754 0.99788388]\n",
      "Test RMSE: 0.013\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 72us/sample - loss: 0.0058 - val_loss: 0.0036\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0061 - val_loss: 0.0040\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0096 - val_loss: 0.0025\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0121 - val_loss: 0.0081\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0061 - val_loss: 0.0024\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0114 - val_loss: 0.0079\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0066 - val_loss: 0.0047\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0074 - val_loss: 0.0030\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.0100\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0053 - val_loss: 0.0027\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0063 - val_loss: 0.0036\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0102 - val_loss: 0.0070\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0064 - val_loss: 0.0041\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0065 - val_loss: 0.0032\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0098 - val_loss: 0.0069\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0062 - val_loss: 0.0038\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0058 - val_loss: 0.0032\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0087 - val_loss: 0.0057\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0067 - val_loss: 0.0026\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0063 - val_loss: 0.0032\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0079 - val_loss: 0.0035\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0067 - val_loss: 0.0030\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0059 - val_loss: 0.0027\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0086 - val_loss: 0.0050\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0050 - val_loss: 0.0023\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0052 - val_loss: 0.0029\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0053 - val_loss: 0.0026\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0077 - val_loss: 0.0044\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0053 - val_loss: 0.0029\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0061 - val_loss: 0.0025\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0072 - val_loss: 0.0031\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0050 - val_loss: 0.0028\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0050 - val_loss: 0.0025\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0058 - val_loss: 0.0027\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0060 - val_loss: 0.0028\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0060 - val_loss: 0.0031\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0054 - val_loss: 0.0032\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0051 - val_loss: 0.0028\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0051 - val_loss: 0.0028\n",
      "第376个数，还剩3747个没有训练\n",
      "inv_hat [1.51223943 1.50880286 1.51011695 1.50900497 1.5067807  1.50587071\n",
      " 1.50556732 1.5068818  1.50445495 1.50597185 1.51011695 1.51082453\n",
      " 1.51102669 1.51001585 1.50595364 1.50504996 1.50535119 1.50655609\n",
      " 1.507259   1.50535119 1.50374482 1.50143576 1.49942827 1.49832429\n",
      " 1.49571505 1.4981236  1.49822393 1.49974282 1.49925133 1.50121729]\n",
      "Test RMSE: 0.003\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0122 - val_loss: 0.0088\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0127 - val_loss: 0.0098\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0138 - val_loss: 0.0091\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0121 - val_loss: 0.0094\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0127 - val_loss: 0.0084\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0142 - val_loss: 0.0117\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 72us/sample - loss: 0.0125 - val_loss: 0.0091\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0137 - val_loss: 0.0083\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0135 - val_loss: 0.0134\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0134 - val_loss: 0.0084\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0122 - val_loss: 0.0084\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0124 - val_loss: 0.0095\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0131 - val_loss: 0.0101\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0120 - val_loss: 0.0085\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0126 - val_loss: 0.0084\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0127 - val_loss: 0.0107\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0124 - val_loss: 0.0086\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0122 - val_loss: 0.0082\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0123 - val_loss: 0.0099\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0130 - val_loss: 0.0100\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0120 - val_loss: 0.0084\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0126 - val_loss: 0.0085\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0127 - val_loss: 0.0111\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0123 - val_loss: 0.0084\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0123 - val_loss: 0.0082\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0124 - val_loss: 0.0105\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0128 - val_loss: 0.0098\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0119 - val_loss: 0.0084\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0125 - val_loss: 0.0087\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0128 - val_loss: 0.0113\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0122 - val_loss: 0.0083\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0125 - val_loss: 0.0082\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0125 - val_loss: 0.0111\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0120 - val_loss: 0.0085\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0125 - val_loss: 0.0092\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0130 - val_loss: 0.0114\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0122 - val_loss: 0.0083\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0126 - val_loss: 0.0082\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0125 - val_loss: 0.0113\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 73us/sample - loss: 0.0128 - val_loss: 0.0095\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0120 - val_loss: 0.0084\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0125 - val_loss: 0.0093\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0129 - val_loss: 0.0112\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0121 - val_loss: 0.0083\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0125 - val_loss: 0.0082\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0125 - val_loss: 0.0112\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0127 - val_loss: 0.0093\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0120 - val_loss: 0.0083\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0124 - val_loss: 0.0094\n",
      "第377个数，还剩3746个没有训练\n",
      "inv_hat [1.52958179 1.48992618 1.49917983 1.50234015 1.46990772 1.46736695\n",
      " 1.47127568 1.49012139 1.47547641 1.48641255 1.52158981 1.51793853\n",
      " 1.51349682 1.48563171 1.48680315 1.47811355 1.48758382 1.4862173\n",
      " 1.50253757 1.48641255 1.47528103 1.46453248 1.44790727 1.44722228\n",
      " 1.44399309 1.45866676 1.45240758 1.45984002 1.44555874 1.45084228]\n",
      "Test RMSE: 0.017\n",
      "Train on 534 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "534/534 [==============================] - 0s 80us/sample - loss: 0.0195 - val_loss: 0.0327\n",
      "Epoch 2/50\n",
      "534/534 [==============================] - 0s 83us/sample - loss: 0.0189 - val_loss: 0.0326\n",
      "Epoch 3/50\n",
      "534/534 [==============================] - 0s 84us/sample - loss: 0.0190 - val_loss: 0.0326\n",
      "Epoch 4/50\n",
      "534/534 [==============================] - 0s 88us/sample - loss: 0.0185 - val_loss: 0.0325\n",
      "Epoch 5/50\n",
      "534/534 [==============================] - 0s 91us/sample - loss: 0.0190 - val_loss: 0.0333\n",
      "Epoch 6/50\n",
      "534/534 [==============================] - 0s 88us/sample - loss: 0.0195 - val_loss: 0.0327\n",
      "Epoch 7/50\n",
      "534/534 [==============================] - 0s 89us/sample - loss: 0.0190 - val_loss: 0.0344\n",
      "Epoch 8/50\n",
      "534/534 [==============================] - 0s 88us/sample - loss: 0.0197 - val_loss: 0.0323\n",
      "Epoch 9/50\n",
      "534/534 [==============================] - 0s 85us/sample - loss: 0.0198 - val_loss: 0.0350\n",
      "Epoch 10/50\n",
      "534/534 [==============================] - 0s 85us/sample - loss: 0.0210 - val_loss: 0.0325\n",
      "Epoch 11/50\n",
      "534/534 [==============================] - 0s 84us/sample - loss: 0.0211 - val_loss: 0.0342\n",
      "Epoch 12/50\n",
      "534/534 [==============================] - 0s 90us/sample - loss: 0.0202 - val_loss: 0.0321\n",
      "Epoch 13/50\n",
      "534/534 [==============================] - 0s 89us/sample - loss: 0.0201 - val_loss: 0.0347\n",
      "Epoch 14/50\n",
      "534/534 [==============================] - 0s 82us/sample - loss: 0.0202 - val_loss: 0.0322\n",
      "Epoch 15/50\n",
      "534/534 [==============================] - 0s 81us/sample - loss: 0.0209 - val_loss: 0.0346\n",
      "Epoch 16/50\n",
      "534/534 [==============================] - 0s 83us/sample - loss: 0.0204 - val_loss: 0.0321\n",
      "Epoch 17/50\n",
      "534/534 [==============================] - 0s 80us/sample - loss: 0.0199 - val_loss: 0.0347\n",
      "Epoch 18/50\n",
      "534/534 [==============================] - 0s 79us/sample - loss: 0.0201 - val_loss: 0.0321\n",
      "Epoch 19/50\n",
      "534/534 [==============================] - 0s 79us/sample - loss: 0.0206 - val_loss: 0.0342\n",
      "Epoch 20/50\n",
      "534/534 [==============================] - 0s 86us/sample - loss: 0.0195 - val_loss: 0.0321\n",
      "Epoch 21/50\n",
      "534/534 [==============================] - 0s 89us/sample - loss: 0.0197 - val_loss: 0.0345\n",
      "Epoch 22/50\n",
      "534/534 [==============================] - 0s 84us/sample - loss: 0.0198 - val_loss: 0.0321\n",
      "Epoch 23/50\n",
      "534/534 [==============================] - 0s 85us/sample - loss: 0.0199 - val_loss: 0.0348\n",
      "Epoch 24/50\n",
      "534/534 [==============================] - 0s 85us/sample - loss: 0.0203 - val_loss: 0.0321\n",
      "Epoch 25/50\n",
      "534/534 [==============================] - 0s 88us/sample - loss: 0.0207 - val_loss: 0.0344\n",
      "Epoch 26/50\n",
      "534/534 [==============================] - 0s 87us/sample - loss: 0.0201 - val_loss: 0.0321\n",
      "Epoch 27/50\n",
      "534/534 [==============================] - 0s 93us/sample - loss: 0.0200 - val_loss: 0.0345\n",
      "Epoch 28/50\n",
      "534/534 [==============================] - 0s 84us/sample - loss: 0.0198 - val_loss: 0.0321\n",
      "Epoch 29/50\n",
      "534/534 [==============================] - 0s 83us/sample - loss: 0.0204 - val_loss: 0.0341\n",
      "Epoch 30/50\n",
      "534/534 [==============================] - 0s 84us/sample - loss: 0.0194 - val_loss: 0.0321\n",
      "Epoch 31/50\n",
      "534/534 [==============================] - 0s 88us/sample - loss: 0.0198 - val_loss: 0.0343\n",
      "Epoch 32/50\n",
      "534/534 [==============================] - 0s 90us/sample - loss: 0.0198 - val_loss: 0.0321\n",
      "Epoch 33/50\n",
      "534/534 [==============================] - 0s 86us/sample - loss: 0.0199 - val_loss: 0.0345\n",
      "Epoch 34/50\n",
      "534/534 [==============================] - 0s 88us/sample - loss: 0.0200 - val_loss: 0.0321\n",
      "Epoch 35/50\n",
      "534/534 [==============================] - 0s 84us/sample - loss: 0.0208 - val_loss: 0.0342\n",
      "Epoch 36/50\n",
      "534/534 [==============================] - 0s 84us/sample - loss: 0.0198 - val_loss: 0.0321\n",
      "Epoch 37/50\n",
      "534/534 [==============================] - 0s 91us/sample - loss: 0.0199 - val_loss: 0.0344\n",
      "Epoch 38/50\n",
      "534/534 [==============================] - 0s 83us/sample - loss: 0.0198 - val_loss: 0.0320\n",
      "Epoch 39/50\n",
      "534/534 [==============================] - 0s 89us/sample - loss: 0.0203 - val_loss: 0.0341\n",
      "Epoch 40/50\n",
      "534/534 [==============================] - 0s 88us/sample - loss: 0.0194 - val_loss: 0.0321\n",
      "Epoch 41/50\n",
      "534/534 [==============================] - 0s 81us/sample - loss: 0.0198 - val_loss: 0.0344\n",
      "Epoch 42/50\n",
      "534/534 [==============================] - 0s 84us/sample - loss: 0.0200 - val_loss: 0.0321\n",
      "Epoch 43/50\n",
      "534/534 [==============================] - 0s 87us/sample - loss: 0.0204 - val_loss: 0.0341\n",
      "Epoch 44/50\n",
      "534/534 [==============================] - 0s 81us/sample - loss: 0.0201 - val_loss: 0.0321\n",
      "Epoch 45/50\n",
      "534/534 [==============================] - 0s 86us/sample - loss: 0.0198 - val_loss: 0.0339\n",
      "Epoch 46/50\n",
      "534/534 [==============================] - 0s 84us/sample - loss: 0.0193 - val_loss: 0.0321\n",
      "Epoch 47/50\n",
      "534/534 [==============================] - 0s 85us/sample - loss: 0.0194 - val_loss: 0.0348\n",
      "Epoch 48/50\n",
      "534/534 [==============================] - 0s 84us/sample - loss: 0.0208 - val_loss: 0.0321\n",
      "Epoch 49/50\n",
      "534/534 [==============================] - 0s 83us/sample - loss: 0.0199 - val_loss: 0.0338\n",
      "Epoch 50/50\n",
      "534/534 [==============================] - 0s 86us/sample - loss: 0.0192 - val_loss: 0.0321\n",
      "第378个数，还剩3745个没有训练\n",
      "inv_hat [0.99394509 0.98806015 0.98903643 0.98806015 0.98322471 0.98226958\n",
      " 0.98322471 0.98806015 0.98514823 0.98806015 0.99394509 0.99493057\n",
      " 0.99493057 0.99197717 0.99197717 0.9909952  0.9909952  0.99197717\n",
      " 0.99493057 0.9909952  0.9909952  0.99001486 0.98806015 0.98903643\n",
      " 0.98611571 0.98708648 0.98611571 0.98611571 0.98418445 0.98708648]\n",
      "Test RMSE: 0.003\n",
      "Train on 1086 samples, validate on 30 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1086/1086 [==============================] - 0s 83us/sample - loss: 0.0066 - val_loss: 0.0034\n",
      "Epoch 2/50\n",
      "1086/1086 [==============================] - 0s 79us/sample - loss: 0.0057 - val_loss: 0.0031\n",
      "Epoch 3/50\n",
      "1086/1086 [==============================] - 0s 81us/sample - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 4/50\n",
      "1086/1086 [==============================] - 0s 84us/sample - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 5/50\n",
      "1086/1086 [==============================] - 0s 85us/sample - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 6/50\n",
      "1086/1086 [==============================] - 0s 83us/sample - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 7/50\n",
      "1086/1086 [==============================] - 0s 82us/sample - loss: 0.0059 - val_loss: 0.0037\n",
      "Epoch 8/50\n",
      "1086/1086 [==============================] - 0s 81us/sample - loss: 0.0060 - val_loss: 0.0036\n",
      "Epoch 9/50\n",
      "1086/1086 [==============================] - 0s 83us/sample - loss: 0.0056 - val_loss: 0.0034\n",
      "Epoch 10/50\n",
      "1086/1086 [==============================] - 0s 81us/sample - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 11/50\n",
      "1086/1086 [==============================] - 0s 84us/sample - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 12/50\n",
      "1086/1086 [==============================] - 0s 80us/sample - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 13/50\n",
      "1086/1086 [==============================] - 0s 83us/sample - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 14/50\n",
      "1086/1086 [==============================] - 0s 85us/sample - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 15/50\n",
      "1086/1086 [==============================] - 0s 82us/sample - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 16/50\n",
      "1086/1086 [==============================] - 0s 79us/sample - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 17/50\n",
      "1086/1086 [==============================] - 0s 82us/sample - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 18/50\n",
      "1086/1086 [==============================] - 0s 85us/sample - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 19/50\n",
      "1086/1086 [==============================] - 0s 85us/sample - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 20/50\n",
      "1086/1086 [==============================] - 0s 83us/sample - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 21/50\n",
      "1086/1086 [==============================] - 0s 82us/sample - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 22/50\n",
      "1086/1086 [==============================] - 0s 81us/sample - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 23/50\n",
      "1086/1086 [==============================] - 0s 82us/sample - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 24/50\n",
      "1086/1086 [==============================] - 0s 80us/sample - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 25/50\n",
      "1086/1086 [==============================] - 0s 77us/sample - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 26/50\n",
      "1086/1086 [==============================] - 0s 79us/sample - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 27/50\n",
      "1086/1086 [==============================] - 0s 83us/sample - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 28/50\n",
      "1086/1086 [==============================] - 0s 84us/sample - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 29/50\n",
      "1086/1086 [==============================] - 0s 85us/sample - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 30/50\n",
      "1086/1086 [==============================] - 0s 81us/sample - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 31/50\n",
      "1086/1086 [==============================] - 0s 84us/sample - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 32/50\n",
      "1086/1086 [==============================] - 0s 84us/sample - loss: 0.0054 - val_loss: 0.0033\n",
      "Epoch 33/50\n",
      "1086/1086 [==============================] - 0s 83us/sample - loss: 0.0054 - val_loss: 0.0033\n",
      "Epoch 34/50\n",
      "1086/1086 [==============================] - 0s 84us/sample - loss: 0.0055 - val_loss: 0.0034\n",
      "Epoch 35/50\n",
      "1086/1086 [==============================] - 0s 81us/sample - loss: 0.0057 - val_loss: 0.0034\n",
      "Epoch 36/50\n",
      "1086/1086 [==============================] - 0s 82us/sample - loss: 0.0057 - val_loss: 0.0032\n",
      "Epoch 37/50\n",
      "1086/1086 [==============================] - 0s 78us/sample - loss: 0.0054 - val_loss: 0.0032\n",
      "Epoch 38/50\n",
      "1086/1086 [==============================] - 0s 80us/sample - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 39/50\n",
      "1086/1086 [==============================] - 0s 78us/sample - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 40/50\n",
      "1086/1086 [==============================] - 0s 80us/sample - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 41/50\n",
      "1086/1086 [==============================] - 0s 81us/sample - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 42/50\n",
      "1086/1086 [==============================] - 0s 79us/sample - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 43/50\n",
      "1086/1086 [==============================] - 0s 82us/sample - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 44/50\n",
      "1086/1086 [==============================] - 0s 81us/sample - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 45/50\n",
      "1086/1086 [==============================] - 0s 85us/sample - loss: 0.0051 - val_loss: 0.0033\n",
      "Epoch 46/50\n",
      "1086/1086 [==============================] - 0s 83us/sample - loss: 0.0055 - val_loss: 0.0033\n",
      "Epoch 47/50\n",
      "1086/1086 [==============================] - 0s 85us/sample - loss: 0.0055 - val_loss: 0.0032\n",
      "Epoch 48/50\n",
      "1086/1086 [==============================] - 0s 85us/sample - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 49/50\n",
      "1086/1086 [==============================] - 0s 83us/sample - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 50/50\n",
      "1086/1086 [==============================] - 0s 82us/sample - loss: 0.0054 - val_loss: 0.0032\n",
      "第379个数，还剩3744个没有训练\n",
      "inv_hat [1.07850797 1.07820727 1.0783075  1.07850797 1.07850797 1.07890876\n",
      " 1.07890876 1.07880852 1.07880852 1.07930963 1.07940972 1.07971035\n",
      " 1.07971035 1.0807122  1.08081238 1.08151351 1.08201423 1.08231459\n",
      " 1.08261506 1.08311568 1.08311568 1.08301553 1.08331597 1.08331597\n",
      " 1.08311568 1.08321583 1.08321583 1.08331597 1.08381655 1.08351625]\n",
      "Test RMSE: 0.001\n",
      "Train on 822 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "822/822 [==============================] - 0s 80us/sample - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 2/50\n",
      "822/822 [==============================] - 0s 82us/sample - loss: 0.0063 - val_loss: 0.0094\n",
      "Epoch 3/50\n",
      "822/822 [==============================] - 0s 83us/sample - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 4/50\n",
      "822/822 [==============================] - 0s 82us/sample - loss: 0.0069 - val_loss: 0.0078\n",
      "Epoch 5/50\n",
      "822/822 [==============================] - 0s 83us/sample - loss: 0.0061 - val_loss: 0.0093\n",
      "Epoch 6/50\n",
      "822/822 [==============================] - 0s 79us/sample - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 7/50\n",
      "822/822 [==============================] - 0s 79us/sample - loss: 0.0074 - val_loss: 0.0078\n",
      "Epoch 8/50\n",
      "822/822 [==============================] - 0s 80us/sample - loss: 0.0063 - val_loss: 0.0088\n",
      "Epoch 9/50\n",
      "822/822 [==============================] - 0s 79us/sample - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 10/50\n",
      "822/822 [==============================] - 0s 80us/sample - loss: 0.0071 - val_loss: 0.0086\n",
      "Epoch 11/50\n",
      "822/822 [==============================] - 0s 86us/sample - loss: 0.0060 - val_loss: 0.0082\n",
      "Epoch 12/50\n",
      "822/822 [==============================] - 0s 85us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 13/50\n",
      "822/822 [==============================] - 0s 75us/sample - loss: 0.0071 - val_loss: 0.0091\n",
      "Epoch 14/50\n",
      "822/822 [==============================] - 0s 78us/sample - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 15/50\n",
      "822/822 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 16/50\n",
      "822/822 [==============================] - 0s 78us/sample - loss: 0.0059 - val_loss: 0.0091\n",
      "Epoch 17/50\n",
      "822/822 [==============================] - 0s 75us/sample - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 18/50\n",
      "822/822 [==============================] - 0s 75us/sample - loss: 0.0054 - val_loss: 0.0078\n",
      "Epoch 19/50\n",
      "822/822 [==============================] - 0s 75us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 20/50\n",
      "822/822 [==============================] - 0s 86us/sample - loss: 0.0062 - val_loss: 0.0091\n",
      "Epoch 21/50\n",
      "822/822 [==============================] - 0s 81us/sample - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 22/50\n",
      "822/822 [==============================] - 0s 83us/sample - loss: 0.0070 - val_loss: 0.0078\n",
      "Epoch 23/50\n",
      "822/822 [==============================] - 0s 84us/sample - loss: 0.0055 - val_loss: 0.0084\n",
      "Epoch 24/50\n",
      "822/822 [==============================] - 0s 84us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "822/822 [==============================] - 0s 80us/sample - loss: 0.0056 - val_loss: 0.0078\n",
      "Epoch 26/50\n",
      "822/822 [==============================] - 0s 83us/sample - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 27/50\n",
      "822/822 [==============================] - 0s 79us/sample - loss: 0.0075 - val_loss: 0.0094\n",
      "Epoch 28/50\n",
      "822/822 [==============================] - 0s 81us/sample - loss: 0.0073 - val_loss: 0.0089\n",
      "Epoch 29/50\n",
      "822/822 [==============================] - 0s 77us/sample - loss: 0.0090 - val_loss: 0.0098\n",
      "Epoch 30/50\n",
      "822/822 [==============================] - 0s 80us/sample - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 31/50\n",
      "822/822 [==============================] - 0s 84us/sample - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 32/50\n",
      "822/822 [==============================] - 0s 87us/sample - loss: 0.0058 - val_loss: 0.0083\n",
      "Epoch 33/50\n",
      "822/822 [==============================] - 0s 83us/sample - loss: 0.0057 - val_loss: 0.0078\n",
      "Epoch 34/50\n",
      "822/822 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0087\n",
      "Epoch 35/50\n",
      "822/822 [==============================] - 0s 83us/sample - loss: 0.0062 - val_loss: 0.0087\n",
      "Epoch 36/50\n",
      "822/822 [==============================] - 0s 85us/sample - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 37/50\n",
      "822/822 [==============================] - 0s 84us/sample - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 38/50\n",
      "822/822 [==============================] - 0s 79us/sample - loss: 0.0062 - val_loss: 0.0078\n",
      "Epoch 39/50\n",
      "822/822 [==============================] - 0s 83us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 40/50\n",
      "822/822 [==============================] - 0s 83us/sample - loss: 0.0060 - val_loss: 0.0079\n",
      "Epoch 41/50\n",
      "822/822 [==============================] - 0s 83us/sample - loss: 0.0067 - val_loss: 0.0080\n",
      "Epoch 42/50\n",
      "822/822 [==============================] - 0s 81us/sample - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 43/50\n",
      "822/822 [==============================] - 0s 83us/sample - loss: 0.0082 - val_loss: 0.0094\n",
      "Epoch 44/50\n",
      "822/822 [==============================] - 0s 80us/sample - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 45/50\n",
      "822/822 [==============================] - 0s 75us/sample - loss: 0.0072 - val_loss: 0.0085\n",
      "Epoch 46/50\n",
      "822/822 [==============================] - 0s 84us/sample - loss: 0.0058 - val_loss: 0.0081\n",
      "Epoch 47/50\n",
      "822/822 [==============================] - 0s 87us/sample - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 48/50\n",
      "822/822 [==============================] - 0s 84us/sample - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 49/50\n",
      "822/822 [==============================] - 0s 82us/sample - loss: 0.0063 - val_loss: 0.0088\n",
      "Epoch 50/50\n",
      "822/822 [==============================] - 0s 83us/sample - loss: 0.0065 - val_loss: 0.0078\n",
      "第380个数，还剩3743个没有训练\n",
      "inv_hat [1.15114746 1.14821391 1.14918717 1.14918717 1.1472423  1.14626889\n",
      " 1.14626889 1.1472423  1.14626889 1.1472423  1.15114746 1.152125\n",
      " 1.15114746 1.14821391 1.1472423  1.14529374 1.14626889 1.14626889\n",
      " 1.14821391 1.14626889 1.14626889 1.14529374 1.14431671 1.14333802\n",
      " 1.14235745 1.14333802 1.14235745 1.14137517 1.14235745 1.14333802]\n",
      "Test RMSE: 0.002\n",
      "Train on 610 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "610/610 [==============================] - 0s 85us/sample - loss: 0.0226 - val_loss: 0.0258\n",
      "Epoch 2/50\n",
      "610/610 [==============================] - 0s 83us/sample - loss: 0.0221 - val_loss: 0.0260\n",
      "Epoch 3/50\n",
      "610/610 [==============================] - 0s 79us/sample - loss: 0.0215 - val_loss: 0.0259\n",
      "Epoch 4/50\n",
      "610/610 [==============================] - 0s 80us/sample - loss: 0.0217 - val_loss: 0.0257\n",
      "Epoch 5/50\n",
      "610/610 [==============================] - 0s 86us/sample - loss: 0.0217 - val_loss: 0.0256\n",
      "Epoch 6/50\n",
      "610/610 [==============================] - 0s 79us/sample - loss: 0.0217 - val_loss: 0.0257\n",
      "Epoch 7/50\n",
      "610/610 [==============================] - 0s 85us/sample - loss: 0.0216 - val_loss: 0.0258\n",
      "Epoch 8/50\n",
      "610/610 [==============================] - 0s 84us/sample - loss: 0.0215 - val_loss: 0.0258\n",
      "Epoch 9/50\n",
      "610/610 [==============================] - 0s 81us/sample - loss: 0.0216 - val_loss: 0.0257\n",
      "Epoch 10/50\n",
      "610/610 [==============================] - 0s 82us/sample - loss: 0.0215 - val_loss: 0.0257\n",
      "Epoch 11/50\n",
      "610/610 [==============================] - 0s 80us/sample - loss: 0.0215 - val_loss: 0.0257\n",
      "Epoch 12/50\n",
      "610/610 [==============================] - 0s 79us/sample - loss: 0.0216 - val_loss: 0.0257\n",
      "Epoch 13/50\n",
      "610/610 [==============================] - 0s 81us/sample - loss: 0.0215 - val_loss: 0.0256\n",
      "Epoch 14/50\n",
      "610/610 [==============================] - 0s 88us/sample - loss: 0.0215 - val_loss: 0.0257\n",
      "Epoch 15/50\n",
      "610/610 [==============================] - 0s 85us/sample - loss: 0.0215 - val_loss: 0.0256\n",
      "Epoch 16/50\n",
      "610/610 [==============================] - 0s 85us/sample - loss: 0.0215 - val_loss: 0.0256\n",
      "Epoch 17/50\n",
      "610/610 [==============================] - 0s 82us/sample - loss: 0.0215 - val_loss: 0.0256\n",
      "Epoch 18/50\n",
      "610/610 [==============================] - 0s 78us/sample - loss: 0.0215 - val_loss: 0.0256\n",
      "Epoch 19/50\n",
      "610/610 [==============================] - 0s 83us/sample - loss: 0.0215 - val_loss: 0.0255\n",
      "Epoch 20/50\n",
      "610/610 [==============================] - 0s 86us/sample - loss: 0.0215 - val_loss: 0.0256\n",
      "Epoch 21/50\n",
      "610/610 [==============================] - 0s 83us/sample - loss: 0.0215 - val_loss: 0.0255\n",
      "Epoch 22/50\n",
      "610/610 [==============================] - 0s 84us/sample - loss: 0.0215 - val_loss: 0.0255\n",
      "Epoch 23/50\n",
      "610/610 [==============================] - 0s 82us/sample - loss: 0.0215 - val_loss: 0.0256\n",
      "Epoch 24/50\n",
      "610/610 [==============================] - 0s 83us/sample - loss: 0.0215 - val_loss: 0.0255\n",
      "Epoch 25/50\n",
      "610/610 [==============================] - 0s 82us/sample - loss: 0.0215 - val_loss: 0.0255\n",
      "Epoch 26/50\n",
      "610/610 [==============================] - 0s 79us/sample - loss: 0.0215 - val_loss: 0.0256\n",
      "Epoch 27/50\n",
      "610/610 [==============================] - 0s 79us/sample - loss: 0.0215 - val_loss: 0.0255\n",
      "Epoch 28/50\n",
      "610/610 [==============================] - 0s 84us/sample - loss: 0.0214 - val_loss: 0.0255\n",
      "Epoch 29/50\n",
      "610/610 [==============================] - 0s 85us/sample - loss: 0.0216 - val_loss: 0.0254\n",
      "Epoch 30/50\n",
      "610/610 [==============================] - 0s 83us/sample - loss: 0.0215 - val_loss: 0.0255\n",
      "Epoch 31/50\n",
      "610/610 [==============================] - 0s 90us/sample - loss: 0.0215 - val_loss: 0.0255\n",
      "Epoch 32/50\n",
      "610/610 [==============================] - 0s 88us/sample - loss: 0.0215 - val_loss: 0.0255\n",
      "Epoch 33/50\n",
      "610/610 [==============================] - 0s 84us/sample - loss: 0.0214 - val_loss: 0.0255\n",
      "Epoch 34/50\n",
      "610/610 [==============================] - 0s 86us/sample - loss: 0.0215 - val_loss: 0.0254\n",
      "Epoch 35/50\n",
      "610/610 [==============================] - 0s 84us/sample - loss: 0.0215 - val_loss: 0.0255\n",
      "Epoch 36/50\n",
      "610/610 [==============================] - 0s 78us/sample - loss: 0.0215 - val_loss: 0.0255\n",
      "Epoch 37/50\n",
      "610/610 [==============================] - 0s 85us/sample - loss: 0.0215 - val_loss: 0.0255\n",
      "Epoch 38/50\n",
      "610/610 [==============================] - 0s 83us/sample - loss: 0.0214 - val_loss: 0.0255\n",
      "Epoch 39/50\n",
      "610/610 [==============================] - 0s 81us/sample - loss: 0.0215 - val_loss: 0.0255\n",
      "Epoch 40/50\n",
      "610/610 [==============================] - 0s 81us/sample - loss: 0.0215 - val_loss: 0.0255\n",
      "Epoch 41/50\n",
      "610/610 [==============================] - 0s 81us/sample - loss: 0.0215 - val_loss: 0.0254\n",
      "Epoch 42/50\n",
      "610/610 [==============================] - 0s 85us/sample - loss: 0.0214 - val_loss: 0.0255\n",
      "Epoch 43/50\n",
      "610/610 [==============================] - 0s 84us/sample - loss: 0.0215 - val_loss: 0.0255\n",
      "Epoch 44/50\n",
      "610/610 [==============================] - 0s 79us/sample - loss: 0.0215 - val_loss: 0.0254\n",
      "Epoch 45/50\n",
      "610/610 [==============================] - 0s 80us/sample - loss: 0.0214 - val_loss: 0.0255\n",
      "Epoch 46/50\n",
      "610/610 [==============================] - 0s 77us/sample - loss: 0.0215 - val_loss: 0.0255\n",
      "Epoch 47/50\n",
      "610/610 [==============================] - 0s 78us/sample - loss: 0.0215 - val_loss: 0.0255\n",
      "Epoch 48/50\n",
      "610/610 [==============================] - 0s 79us/sample - loss: 0.0215 - val_loss: 0.0255\n",
      "Epoch 49/50\n",
      "610/610 [==============================] - 0s 83us/sample - loss: 0.0214 - val_loss: 0.0255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "610/610 [==============================] - 0s 82us/sample - loss: 0.0215 - val_loss: 0.0255\n",
      "第381个数，还剩3742个没有训练\n",
      "inv_hat [1.06006013 1.05839704 1.05957101 1.05683156 1.05624448 1.06015798\n",
      " 1.05986444 1.05771218 1.05516795 1.05526583 1.05203533 1.05154556\n",
      " 1.04752696 1.04909599 1.05076189 1.05037003 1.05467863 1.05203533\n",
      " 1.05027204 1.05183943 1.05379765 1.05507006 1.05614661 1.05722289\n",
      " 1.06074494 1.05800563 1.05555946 1.05438495 1.05614661 1.06045152]\n",
      "Test RMSE: 0.002\n",
      "Train on 857 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "857/857 [==============================] - 0s 79us/sample - loss: 0.0146 - val_loss: 0.0257\n",
      "Epoch 2/50\n",
      "857/857 [==============================] - 0s 78us/sample - loss: 0.0150 - val_loss: 0.0262\n",
      "Epoch 3/50\n",
      "857/857 [==============================] - 0s 84us/sample - loss: 0.0142 - val_loss: 0.0261\n",
      "Epoch 4/50\n",
      "857/857 [==============================] - 0s 79us/sample - loss: 0.0143 - val_loss: 0.0265\n",
      "Epoch 5/50\n",
      "857/857 [==============================] - 0s 77us/sample - loss: 0.0145 - val_loss: 0.0262\n",
      "Epoch 6/50\n",
      "857/857 [==============================] - 0s 78us/sample - loss: 0.0142 - val_loss: 0.0262\n",
      "Epoch 7/50\n",
      "857/857 [==============================] - 0s 72us/sample - loss: 0.0141 - val_loss: 0.0262\n",
      "Epoch 8/50\n",
      "857/857 [==============================] - 0s 78us/sample - loss: 0.0140 - val_loss: 0.0260\n",
      "Epoch 9/50\n",
      "857/857 [==============================] - 0s 77us/sample - loss: 0.0144 - val_loss: 0.0257\n",
      "Epoch 10/50\n",
      "857/857 [==============================] - 0s 76us/sample - loss: 0.0149 - val_loss: 0.0263\n",
      "Epoch 11/50\n",
      "857/857 [==============================] - 0s 76us/sample - loss: 0.0141 - val_loss: 0.0263\n",
      "Epoch 12/50\n",
      "857/857 [==============================] - 0s 76us/sample - loss: 0.0144 - val_loss: 0.0264\n",
      "Epoch 13/50\n",
      "857/857 [==============================] - 0s 76us/sample - loss: 0.0145 - val_loss: 0.0260\n",
      "Epoch 14/50\n",
      "857/857 [==============================] - 0s 79us/sample - loss: 0.0141 - val_loss: 0.0259\n",
      "Epoch 15/50\n",
      "857/857 [==============================] - 0s 80us/sample - loss: 0.0142 - val_loss: 0.0259\n",
      "Epoch 16/50\n",
      "857/857 [==============================] - 0s 75us/sample - loss: 0.0144 - val_loss: 0.0261\n",
      "Epoch 17/50\n",
      "857/857 [==============================] - 0s 79us/sample - loss: 0.0145 - val_loss: 0.0267\n",
      "Epoch 18/50\n",
      "857/857 [==============================] - 0s 83us/sample - loss: 0.0147 - val_loss: 0.0259\n",
      "Epoch 19/50\n",
      "857/857 [==============================] - 0s 80us/sample - loss: 0.0140 - val_loss: 0.0259\n",
      "Epoch 20/50\n",
      "857/857 [==============================] - 0s 78us/sample - loss: 0.0140 - val_loss: 0.0259\n",
      "Epoch 21/50\n",
      "857/857 [==============================] - 0s 82us/sample - loss: 0.0140 - val_loss: 0.0262\n",
      "Epoch 22/50\n",
      "857/857 [==============================] - 0s 80us/sample - loss: 0.0142 - val_loss: 0.0265\n",
      "Epoch 23/50\n",
      "857/857 [==============================] - 0s 85us/sample - loss: 0.0145 - val_loss: 0.0259\n",
      "Epoch 24/50\n",
      "857/857 [==============================] - 0s 85us/sample - loss: 0.0140 - val_loss: 0.0263\n",
      "Epoch 25/50\n",
      "857/857 [==============================] - 0s 84us/sample - loss: 0.0142 - val_loss: 0.0262\n",
      "Epoch 26/50\n",
      "857/857 [==============================] - 0s 81us/sample - loss: 0.0141 - val_loss: 0.0261\n",
      "Epoch 27/50\n",
      "857/857 [==============================] - 0s 78us/sample - loss: 0.0141 - val_loss: 0.0259\n",
      "Epoch 28/50\n",
      "857/857 [==============================] - 0s 72us/sample - loss: 0.0143 - val_loss: 0.0258\n",
      "Epoch 29/50\n",
      "857/857 [==============================] - 0s 77us/sample - loss: 0.0146 - val_loss: 0.0263\n",
      "Epoch 30/50\n",
      "857/857 [==============================] - 0s 73us/sample - loss: 0.0142 - val_loss: 0.0266\n",
      "Epoch 31/50\n",
      "857/857 [==============================] - 0s 80us/sample - loss: 0.0145 - val_loss: 0.0259\n",
      "Epoch 32/50\n",
      "857/857 [==============================] - 0s 76us/sample - loss: 0.0142 - val_loss: 0.0258\n",
      "Epoch 33/50\n",
      "857/857 [==============================] - 0s 73us/sample - loss: 0.0145 - val_loss: 0.0263\n",
      "Epoch 34/50\n",
      "857/857 [==============================] - 0s 75us/sample - loss: 0.0143 - val_loss: 0.0266\n",
      "Epoch 35/50\n",
      "857/857 [==============================] - 0s 77us/sample - loss: 0.0145 - val_loss: 0.0259\n",
      "Epoch 36/50\n",
      "857/857 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0258\n",
      "Epoch 37/50\n",
      "857/857 [==============================] - 0s 77us/sample - loss: 0.0146 - val_loss: 0.0264\n",
      "Epoch 38/50\n",
      "857/857 [==============================] - 0s 76us/sample - loss: 0.0143 - val_loss: 0.0265\n",
      "Epoch 39/50\n",
      "857/857 [==============================] - 0s 77us/sample - loss: 0.0145 - val_loss: 0.0259\n",
      "Epoch 40/50\n",
      "857/857 [==============================] - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0259\n",
      "Epoch 41/50\n",
      "857/857 [==============================] - 0s 81us/sample - loss: 0.0141 - val_loss: 0.0258\n",
      "Epoch 42/50\n",
      "857/857 [==============================] - 0s 84us/sample - loss: 0.0144 - val_loss: 0.0263\n",
      "Epoch 43/50\n",
      "857/857 [==============================] - 0s 80us/sample - loss: 0.0143 - val_loss: 0.0266\n",
      "Epoch 44/50\n",
      "857/857 [==============================] - 0s 80us/sample - loss: 0.0146 - val_loss: 0.0259\n",
      "Epoch 45/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 0.007 - 0s 72us/sample - loss: 0.0140 - val_loss: 0.0262\n",
      "Epoch 46/50\n",
      "857/857 [==============================] - 0s 73us/sample - loss: 0.0142 - val_loss: 0.0264\n",
      "Epoch 47/50\n",
      "857/857 [==============================] - 0s 76us/sample - loss: 0.0142 - val_loss: 0.0259\n",
      "Epoch 48/50\n",
      "857/857 [==============================] - 0s 78us/sample - loss: 0.0143 - val_loss: 0.0258\n",
      "Epoch 49/50\n",
      "857/857 [==============================] - 0s 78us/sample - loss: 0.0147 - val_loss: 0.0264\n",
      "Epoch 50/50\n",
      "857/857 [==============================] - 0s 77us/sample - loss: 0.0142 - val_loss: 0.0264\n",
      "第382个数，还剩3741个没有训练\n",
      "inv_hat [1.00980143 1.00340652 1.00549709 1.00639558 0.99935175 0.99885999\n",
      " 0.99856526 1.00469967 0.9994502  1.00251321 1.01201367 1.01292018\n",
      " 1.01292018 1.00649539 1.00809627 1.00410243 1.00749549 1.01070575\n",
      " 1.01645298 1.00889818 1.00799608 1.00380401 0.99905664 0.99778043\n",
      " 0.99446505 1.0004358  0.99954861 0.99787845 0.99709514 0.99915495]\n",
      "Test RMSE: 0.004\n",
      "Train on 883 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "883/883 [==============================] - 0s 88us/sample - loss: 0.0110 - val_loss: 0.0056\n",
      "Epoch 2/50\n",
      "883/883 [==============================] - 0s 86us/sample - loss: 0.0116 - val_loss: 0.0059\n",
      "Epoch 3/50\n",
      "883/883 [==============================] - 0s 85us/sample - loss: 0.0111 - val_loss: 0.0037\n",
      "Epoch 4/50\n",
      "883/883 [==============================] - 0s 89us/sample - loss: 0.0113 - val_loss: 0.0035\n",
      "Epoch 5/50\n",
      "883/883 [==============================] - 0s 88us/sample - loss: 0.0112 - val_loss: 0.0037\n",
      "Epoch 6/50\n",
      "883/883 [==============================] - 0s 87us/sample - loss: 0.0112 - val_loss: 0.0045\n",
      "Epoch 7/50\n",
      "883/883 [==============================] - 0s 80us/sample - loss: 0.0112 - val_loss: 0.0039\n",
      "Epoch 8/50\n",
      "883/883 [==============================] - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0035\n",
      "Epoch 9/50\n",
      "883/883 [==============================] - 0s 81us/sample - loss: 0.0114 - val_loss: 0.0035\n",
      "Epoch 10/50\n",
      "883/883 [==============================] - 0s 83us/sample - loss: 0.0112 - val_loss: 0.0046\n",
      "Epoch 11/50\n",
      "883/883 [==============================] - 0s 81us/sample - loss: 0.0117 - val_loss: 0.0052\n",
      "Epoch 12/50\n",
      "883/883 [==============================] - 0s 82us/sample - loss: 0.0110 - val_loss: 0.0035\n",
      "Epoch 13/50\n",
      "883/883 [==============================] - 0s 80us/sample - loss: 0.0112 - val_loss: 0.0035\n",
      "Epoch 14/50\n",
      "883/883 [==============================] - 0s 77us/sample - loss: 0.0111 - val_loss: 0.0038\n",
      "Epoch 15/50\n",
      "883/883 [==============================] - 0s 78us/sample - loss: 0.0117 - val_loss: 0.0053\n",
      "Epoch 16/50\n",
      "883/883 [==============================] - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0035\n",
      "Epoch 17/50\n",
      "883/883 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0035\n",
      "Epoch 18/50\n",
      "883/883 [==============================] - 0s 83us/sample - loss: 0.0111 - val_loss: 0.0035\n",
      "Epoch 19/50\n",
      "883/883 [==============================] - 0s 83us/sample - loss: 0.0116 - val_loss: 0.0053\n",
      "Epoch 20/50\n",
      "883/883 [==============================] - 0s 76us/sample - loss: 0.0110 - val_loss: 0.0036\n",
      "Epoch 21/50\n",
      "883/883 [==============================] - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0035\n",
      "Epoch 22/50\n",
      "883/883 [==============================] - 0s 76us/sample - loss: 0.0112 - val_loss: 0.0035\n",
      "Epoch 23/50\n",
      "883/883 [==============================] - 0s 78us/sample - loss: 0.0115 - val_loss: 0.0048\n",
      "Epoch 24/50\n",
      "883/883 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0036\n",
      "Epoch 25/50\n",
      "883/883 [==============================] - 0s 81us/sample - loss: 0.0110 - val_loss: 0.0035\n",
      "Epoch 26/50\n",
      "883/883 [==============================] - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0035\n",
      "Epoch 27/50\n",
      "883/883 [==============================] - 0s 81us/sample - loss: 0.0112 - val_loss: 0.0045\n",
      "Epoch 28/50\n",
      "883/883 [==============================] - 0s 82us/sample - loss: 0.0117 - val_loss: 0.0051\n",
      "Epoch 29/50\n",
      "883/883 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0035\n",
      "Epoch 30/50\n",
      "883/883 [==============================] - 0s 81us/sample - loss: 0.0112 - val_loss: 0.0035\n",
      "Epoch 31/50\n",
      "883/883 [==============================] - 0s 80us/sample - loss: 0.0111 - val_loss: 0.0037\n",
      "Epoch 32/50\n",
      "883/883 [==============================] - 0s 76us/sample - loss: 0.0117 - val_loss: 0.0052\n",
      "Epoch 33/50\n",
      "883/883 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0036\n",
      "Epoch 34/50\n",
      "883/883 [==============================] - 0s 83us/sample - loss: 0.0111 - val_loss: 0.0034\n",
      "Epoch 35/50\n",
      "883/883 [==============================] - 0s 83us/sample - loss: 0.0111 - val_loss: 0.0034\n",
      "Epoch 36/50\n",
      "883/883 [==============================] - 0s 83us/sample - loss: 0.0116 - val_loss: 0.0050\n",
      "Epoch 37/50\n",
      "883/883 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0037\n",
      "Epoch 38/50\n",
      "883/883 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0034\n",
      "Epoch 39/50\n",
      "883/883 [==============================] - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0034\n",
      "Epoch 40/50\n",
      "883/883 [==============================] - 0s 80us/sample - loss: 0.0117 - val_loss: 0.0051\n",
      "Epoch 41/50\n",
      "883/883 [==============================] - 0s 82us/sample - loss: 0.0110 - val_loss: 0.0036\n",
      "Epoch 42/50\n",
      "883/883 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0034\n",
      "Epoch 43/50\n",
      "883/883 [==============================] - 0s 77us/sample - loss: 0.0113 - val_loss: 0.0035\n",
      "Epoch 44/50\n",
      "883/883 [==============================] - 0s 81us/sample - loss: 0.0116 - val_loss: 0.0052\n",
      "Epoch 45/50\n",
      "883/883 [==============================] - 0s 82us/sample - loss: 0.0110 - val_loss: 0.0036\n",
      "Epoch 46/50\n",
      "883/883 [==============================] - 0s 82us/sample - loss: 0.0110 - val_loss: 0.0035\n",
      "Epoch 47/50\n",
      "883/883 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0034\n",
      "Epoch 48/50\n",
      "883/883 [==============================] - 0s 79us/sample - loss: 0.0110 - val_loss: 0.0036\n",
      "Epoch 49/50\n",
      "883/883 [==============================] - 0s 79us/sample - loss: 0.0111 - val_loss: 0.0036\n",
      "Epoch 50/50\n",
      "883/883 [==============================] - 0s 86us/sample - loss: 0.0109 - val_loss: 0.0034\n",
      "第383个数，还剩3740个没有训练\n",
      "inv_hat [0.5399511  0.53010902 0.53001087 0.52863736 0.51973617 0.51866335\n",
      " 0.51993133 0.52198157 0.51603303 0.51934597 0.52785299 0.52706897\n",
      " 0.52785299 0.51690931 0.51515713 0.51068784 0.51214389 0.51107599\n",
      " 0.51476806 0.50700512 0.50439354 0.50091825 0.49562378 0.49639279\n",
      " 0.49293549 0.49745075 0.49773939 0.49562378 0.49293549 0.49351115]\n",
      "Test RMSE: 0.004\n",
      "Train on 1119 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1119/1119 [==============================] - 0s 77us/sample - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 2/50\n",
      "1119/1119 [==============================] - 0s 79us/sample - loss: 0.0085 - val_loss: 0.0037\n",
      "Epoch 3/50\n",
      "1119/1119 [==============================] - 0s 80us/sample - loss: 0.0084 - val_loss: 0.0036\n",
      "Epoch 4/50\n",
      "1119/1119 [==============================] - 0s 84us/sample - loss: 0.0085 - val_loss: 0.0042\n",
      "Epoch 5/50\n",
      "1119/1119 [==============================] - 0s 79us/sample - loss: 0.0084 - val_loss: 0.0040\n",
      "Epoch 6/50\n",
      "1119/1119 [==============================] - 0s 77us/sample - loss: 0.0084 - val_loss: 0.0038\n",
      "Epoch 7/50\n",
      "1119/1119 [==============================] - 0s 76us/sample - loss: 0.0085 - val_loss: 0.0036\n",
      "Epoch 8/50\n",
      "1119/1119 [==============================] - 0s 76us/sample - loss: 0.0085 - val_loss: 0.0036\n",
      "Epoch 9/50\n",
      "1119/1119 [==============================] - 0s 76us/sample - loss: 0.0084 - val_loss: 0.0036\n",
      "Epoch 10/50\n",
      "1119/1119 [==============================] - 0s 75us/sample - loss: 0.0085 - val_loss: 0.0036\n",
      "Epoch 11/50\n",
      "1119/1119 [==============================] - 0s 74us/sample - loss: 0.0085 - val_loss: 0.0036\n",
      "Epoch 12/50\n",
      "1119/1119 [==============================] - 0s 76us/sample - loss: 0.0084 - val_loss: 0.0037\n",
      "Epoch 13/50\n",
      "1119/1119 [==============================] - 0s 79us/sample - loss: 0.0084 - val_loss: 0.0039\n",
      "Epoch 14/50\n",
      "1119/1119 [==============================] - 0s 76us/sample - loss: 0.0084 - val_loss: 0.0039\n",
      "Epoch 15/50\n",
      "1119/1119 [==============================] - 0s 79us/sample - loss: 0.0084 - val_loss: 0.0037\n",
      "Epoch 16/50\n",
      "1119/1119 [==============================] - 0s 77us/sample - loss: 0.0085 - val_loss: 0.0036\n",
      "Epoch 17/50\n",
      "1119/1119 [==============================] - 0s 76us/sample - loss: 0.0084 - val_loss: 0.0037\n",
      "Epoch 18/50\n",
      "1119/1119 [==============================] - 0s 78us/sample - loss: 0.0084 - val_loss: 0.0038\n",
      "Epoch 19/50\n",
      "1119/1119 [==============================] - 0s 77us/sample - loss: 0.0084 - val_loss: 0.0036\n",
      "Epoch 20/50\n",
      "1119/1119 [==============================] - 0s 83us/sample - loss: 0.0085 - val_loss: 0.0036\n",
      "Epoch 21/50\n",
      "1119/1119 [==============================] - 0s 80us/sample - loss: 0.0084 - val_loss: 0.0037\n",
      "Epoch 22/50\n",
      "1119/1119 [==============================] - 0s 79us/sample - loss: 0.0083 - val_loss: 0.0036\n",
      "Epoch 23/50\n",
      "1119/1119 [==============================] - 0s 81us/sample - loss: 0.0084 - val_loss: 0.0038\n",
      "Epoch 24/50\n",
      "1119/1119 [==============================] - 0s 78us/sample - loss: 0.0083 - val_loss: 0.0036\n",
      "Epoch 25/50\n",
      "1119/1119 [==============================] - 0s 77us/sample - loss: 0.0083 - val_loss: 0.0036\n",
      "Epoch 26/50\n",
      "1119/1119 [==============================] - 0s 82us/sample - loss: 0.0084 - val_loss: 0.0042\n",
      "Epoch 27/50\n",
      "1119/1119 [==============================] - 0s 79us/sample - loss: 0.0084 - val_loss: 0.0039\n",
      "Epoch 28/50\n",
      "1119/1119 [==============================] - 0s 82us/sample - loss: 0.0084 - val_loss: 0.0037\n",
      "Epoch 29/50\n",
      "1119/1119 [==============================] - 0s 79us/sample - loss: 0.0085 - val_loss: 0.0036\n",
      "Epoch 30/50\n",
      "1119/1119 [==============================] - 0s 83us/sample - loss: 0.0084 - val_loss: 0.0037\n",
      "Epoch 31/50\n",
      "1119/1119 [==============================] - 0s 80us/sample - loss: 0.0084 - val_loss: 0.0040\n",
      "Epoch 32/50\n",
      "1119/1119 [==============================] - 0s 79us/sample - loss: 0.0084 - val_loss: 0.0037\n",
      "Epoch 33/50\n",
      "1119/1119 [==============================] - 0s 85us/sample - loss: 0.0085 - val_loss: 0.0036\n",
      "Epoch 34/50\n",
      "1119/1119 [==============================] - 0s 84us/sample - loss: 0.0084 - val_loss: 0.0037\n",
      "Epoch 35/50\n",
      "1119/1119 [==============================] - 0s 83us/sample - loss: 0.0084 - val_loss: 0.0040\n",
      "Epoch 36/50\n",
      "1119/1119 [==============================] - 0s 80us/sample - loss: 0.0084 - val_loss: 0.0038\n",
      "Epoch 37/50\n",
      "1119/1119 [==============================] - 0s 83us/sample - loss: 0.0085 - val_loss: 0.0036\n",
      "Epoch 38/50\n",
      "1119/1119 [==============================] - 0s 82us/sample - loss: 0.0084 - val_loss: 0.0038\n",
      "Epoch 39/50\n",
      "1119/1119 [==============================] - 0s 79us/sample - loss: 0.0084 - val_loss: 0.0037\n",
      "Epoch 40/50\n",
      "1119/1119 [==============================] - 0s 78us/sample - loss: 0.0085 - val_loss: 0.0036\n",
      "Epoch 41/50\n",
      "1119/1119 [==============================] - 0s 82us/sample - loss: 0.0084 - val_loss: 0.0038\n",
      "Epoch 42/50\n",
      "1119/1119 [==============================] - 0s 81us/sample - loss: 0.0084 - val_loss: 0.0037\n",
      "Epoch 43/50\n",
      "1119/1119 [==============================] - 0s 79us/sample - loss: 0.0084 - val_loss: 0.0038\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119/1119 [==============================] - 0s 82us/sample - loss: 0.0084 - val_loss: 0.0036\n",
      "Epoch 45/50\n",
      "1119/1119 [==============================] - 0s 77us/sample - loss: 0.0084 - val_loss: 0.0038\n",
      "Epoch 46/50\n",
      "1119/1119 [==============================] - 0s 76us/sample - loss: 0.0084 - val_loss: 0.0039\n",
      "Epoch 47/50\n",
      "1119/1119 [==============================] - 0s 74us/sample - loss: 0.0084 - val_loss: 0.0038\n",
      "Epoch 48/50\n",
      "1119/1119 [==============================] - 0s 74us/sample - loss: 0.0084 - val_loss: 0.0037\n",
      "Epoch 49/50\n",
      "1119/1119 [==============================] - 0s 78us/sample - loss: 0.0084 - val_loss: 0.0038\n",
      "Epoch 50/50\n",
      "1119/1119 [==============================] - 0s 79us/sample - loss: 0.0084 - val_loss: 0.0038\n",
      "第384个数，还剩3739个没有训练\n",
      "inv_hat [0.9781419  0.9721418  0.97314154 0.97114217 0.96714481 0.96814395\n",
      " 0.96814395 0.97014266 0.96614472 0.96914321 0.97514141 0.97514141\n",
      " 0.97514141 0.9721418  0.97114217 0.97014266 0.97014266 0.9721418\n",
      " 0.97714165 0.97314154 0.9721418  0.96914321 0.96614472 0.96314385\n",
      " 0.95914497 0.95914497 0.95814571 0.95614766 0.95514894 0.95614766]\n",
      "Test RMSE: 0.003\n",
      "Train on 1193 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0072 - val_loss: 0.0021\n",
      "Epoch 2/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0064 - val_loss: 0.0018\n",
      "Epoch 3/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 4/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 5/50\n",
      "1193/1193 [==============================] - 0s 74us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 6/50\n",
      "1193/1193 [==============================] - 0s 75us/sample - loss: 0.0065 - val_loss: 0.0028\n",
      "Epoch 7/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 8/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0026\n",
      "Epoch 9/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0029\n",
      "Epoch 10/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0064 - val_loss: 0.0019\n",
      "Epoch 11/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0025\n",
      "Epoch 12/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0065 - val_loss: 0.0018\n",
      "Epoch 13/50\n",
      "1193/1193 [==============================] - 0s 75us/sample - loss: 0.0064 - val_loss: 0.0018\n",
      "Epoch 14/50\n",
      "1193/1193 [==============================] - 0s 75us/sample - loss: 0.0063 - val_loss: 0.0018\n",
      "Epoch 15/50\n",
      "1193/1193 [==============================] - 0s 75us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 16/50\n",
      "1193/1193 [==============================] - 0s 75us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 17/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 18/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 19/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 20/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 21/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 22/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 23/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 24/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 25/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 26/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 27/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 28/50\n",
      "1193/1193 [==============================] - 0s 75us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 29/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 30/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 31/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 32/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 33/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 34/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 35/50\n",
      "1193/1193 [==============================] - 0s 78us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 36/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0065 - val_loss: 0.0030\n",
      "Epoch 37/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0068 - val_loss: 0.0025\n",
      "Epoch 38/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0067 - val_loss: 0.0019\n",
      "Epoch 39/50\n",
      "1193/1193 [==============================] - 0s 80us/sample - loss: 0.0066 - val_loss: 0.0024\n",
      "Epoch 40/50\n",
      "1193/1193 [==============================] - 0s 75us/sample - loss: 0.0066 - val_loss: 0.0021\n",
      "Epoch 41/50\n",
      "1193/1193 [==============================] - 0s 75us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 42/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0064 - val_loss: 0.0024\n",
      "Epoch 43/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0064 - val_loss: 0.0026\n",
      "Epoch 44/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0065 - val_loss: 0.0022\n",
      "Epoch 45/50\n",
      "1193/1193 [==============================] - 0s 79us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 46/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 47/50\n",
      "1193/1193 [==============================] - 0s 82us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 48/50\n",
      "1193/1193 [==============================] - 0s 77us/sample - loss: 0.0063 - val_loss: 0.0018\n",
      "Epoch 49/50\n",
      "1193/1193 [==============================] - 0s 76us/sample - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 50/50\n",
      "1193/1193 [==============================] - 0s 81us/sample - loss: 0.0063 - val_loss: 0.0020\n",
      "第385个数，还剩3738个没有训练\n",
      "inv_hat [1.03270327 1.03280333 1.03290329 1.03310344 1.03320352 1.03360389\n",
      " 1.03380398 1.03390409 1.0340042  1.03420445 1.03460488 1.03470503\n",
      " 1.03490535 1.03500551 1.03510556 1.0355063  1.0357067  1.03580679\n",
      " 1.03600723 1.03610745 1.0365083  1.03660855 1.03680908 1.03690935\n",
      " 1.03700963 1.037511   1.03761132 1.03771165 1.03791232 1.03801253]\n",
      "Test RMSE: 0.000\n",
      "Train on 607 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "607/607 [==============================] - 0s 83us/sample - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 2/50\n",
      "607/607 [==============================] - 0s 83us/sample - loss: 0.0083 - val_loss: 0.0096\n",
      "Epoch 3/50\n",
      "607/607 [==============================] - 0s 83us/sample - loss: 0.0158 - val_loss: 0.0118\n",
      "Epoch 4/50\n",
      "607/607 [==============================] - 0s 80us/sample - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 5/50\n",
      "607/607 [==============================] - 0s 81us/sample - loss: 0.0094 - val_loss: 0.0091\n",
      "Epoch 6/50\n",
      "607/607 [==============================] - 0s 81us/sample - loss: 0.0078 - val_loss: 0.0084\n",
      "Epoch 7/50\n",
      "607/607 [==============================] - 0s 88us/sample - loss: 0.0076 - val_loss: 0.0084\n",
      "Epoch 8/50\n",
      "607/607 [==============================] - 0s 87us/sample - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 9/50\n",
      "607/607 [==============================] - 0s 85us/sample - loss: 0.0077 - val_loss: 0.0085\n",
      "Epoch 10/50\n",
      "607/607 [==============================] - 0s 82us/sample - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 11/50\n",
      "607/607 [==============================] - 0s 86us/sample - loss: 0.0085 - val_loss: 0.0091\n",
      "Epoch 12/50\n",
      "607/607 [==============================] - 0s 83us/sample - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 13/50\n",
      "607/607 [==============================] - 0s 87us/sample - loss: 0.0077 - val_loss: 0.0077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "607/607 [==============================] - 0s 81us/sample - loss: 0.0083 - val_loss: 0.0090\n",
      "Epoch 15/50\n",
      "607/607 [==============================] - 0s 85us/sample - loss: 0.0077 - val_loss: 0.0078\n",
      "Epoch 16/50\n",
      "607/607 [==============================] - 0s 84us/sample - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 17/50\n",
      "607/607 [==============================] - 0s 83us/sample - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 18/50\n",
      "607/607 [==============================] - 0s 85us/sample - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 19/50\n",
      "607/607 [==============================] - 0s 83us/sample - loss: 0.0089 - val_loss: 0.0107\n",
      "Epoch 20/50\n",
      "607/607 [==============================] - 0s 82us/sample - loss: 0.0077 - val_loss: 0.0085\n",
      "Epoch 21/50\n",
      "607/607 [==============================] - 0s 86us/sample - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 22/50\n",
      "607/607 [==============================] - 0s 86us/sample - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 23/50\n",
      "607/607 [==============================] - 0s 89us/sample - loss: 0.0075 - val_loss: 0.0078\n",
      "Epoch 24/50\n",
      "607/607 [==============================] - 0s 82us/sample - loss: 0.0079 - val_loss: 0.0084\n",
      "Epoch 25/50\n",
      "607/607 [==============================] - 0s 86us/sample - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 26/50\n",
      "607/607 [==============================] - 0s 86us/sample - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 27/50\n",
      "607/607 [==============================] - 0s 85us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 28/50\n",
      "607/607 [==============================] - 0s 85us/sample - loss: 0.0076 - val_loss: 0.0078\n",
      "Epoch 29/50\n",
      "607/607 [==============================] - 0s 81us/sample - loss: 0.0073 - val_loss: 0.0077\n",
      "Epoch 30/50\n",
      "607/607 [==============================] - 0s 80us/sample - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 31/50\n",
      "607/607 [==============================] - 0s 83us/sample - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 32/50\n",
      "607/607 [==============================] - 0s 83us/sample - loss: 0.0073 - val_loss: 0.0077\n",
      "Epoch 33/50\n",
      "607/607 [==============================] - 0s 83us/sample - loss: 0.0085 - val_loss: 0.0106\n",
      "Epoch 34/50\n",
      "607/607 [==============================] - 0s 80us/sample - loss: 0.0076 - val_loss: 0.0077\n",
      "Epoch 35/50\n",
      "607/607 [==============================] - 0s 83us/sample - loss: 0.0076 - val_loss: 0.0077\n",
      "Epoch 36/50\n",
      "607/607 [==============================] - 0s 87us/sample - loss: 0.0079 - val_loss: 0.0090\n",
      "Epoch 37/50\n",
      "607/607 [==============================] - 0s 87us/sample - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 38/50\n",
      "607/607 [==============================] - 0s 87us/sample - loss: 0.0074 - val_loss: 0.0077\n",
      "Epoch 39/50\n",
      "607/607 [==============================] - 0s 86us/sample - loss: 0.0081 - val_loss: 0.0092\n",
      "Epoch 40/50\n",
      "607/607 [==============================] - 0s 88us/sample - loss: 0.0075 - val_loss: 0.0077\n",
      "Epoch 41/50\n",
      "607/607 [==============================] - 0s 83us/sample - loss: 0.0074 - val_loss: 0.0077\n",
      "Epoch 42/50\n",
      "607/607 [==============================] - 0s 83us/sample - loss: 0.0079 - val_loss: 0.0092\n",
      "Epoch 43/50\n",
      "607/607 [==============================] - 0s 84us/sample - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 44/50\n",
      "607/607 [==============================] - 0s 84us/sample - loss: 0.0075 - val_loss: 0.0077\n",
      "Epoch 45/50\n",
      "607/607 [==============================] - 0s 82us/sample - loss: 0.0079 - val_loss: 0.0089\n",
      "Epoch 46/50\n",
      "607/607 [==============================] - 0s 85us/sample - loss: 0.0074 - val_loss: 0.0077\n",
      "Epoch 47/50\n",
      "607/607 [==============================] - 0s 85us/sample - loss: 0.0078 - val_loss: 0.0079\n",
      "Epoch 48/50\n",
      "607/607 [==============================] - 0s 86us/sample - loss: 0.0075 - val_loss: 0.0077\n",
      "Epoch 49/50\n",
      "607/607 [==============================] - 0s 84us/sample - loss: 0.0074 - val_loss: 0.0078\n",
      "Epoch 50/50\n",
      "607/607 [==============================] - 0s 83us/sample - loss: 0.0078 - val_loss: 0.0086\n",
      "第386个数，还剩3737个没有训练\n",
      "inv_hat [1.03697232 1.03668497 1.03649303 1.03658903 1.03678084 1.03658903\n",
      " 1.03668497 1.03639698 1.03697232 1.03716366 1.03706802 1.03716366\n",
      " 1.03687667 1.03745024 1.03754565 1.03802165 1.03802165 1.03802165\n",
      " 1.03764099 1.03725925 1.03630087 1.03649303 1.03658903 1.03716366\n",
      " 1.03783139 1.03830659 1.03868552 1.03906344 1.0393463  1.04000393]\n",
      "Test RMSE: 0.000\n",
      "Train on 862 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "862/862 [==============================] - 0s 84us/sample - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 2/50\n",
      "862/862 [==============================] - 0s 82us/sample - loss: 0.0166 - val_loss: 0.0135\n",
      "Epoch 3/50\n",
      "862/862 [==============================] - 0s 79us/sample - loss: 0.0165 - val_loss: 0.0135\n",
      "Epoch 4/50\n",
      "862/862 [==============================] - 0s 79us/sample - loss: 0.0165 - val_loss: 0.0135\n",
      "Epoch 5/50\n",
      "862/862 [==============================] - 0s 84us/sample - loss: 0.0165 - val_loss: 0.0134\n",
      "Epoch 6/50\n",
      "862/862 [==============================] - 0s 82us/sample - loss: 0.0165 - val_loss: 0.0134\n",
      "Epoch 7/50\n",
      "862/862 [==============================] - 0s 81us/sample - loss: 0.0165 - val_loss: 0.0133\n",
      "Epoch 8/50\n",
      "862/862 [==============================] - 0s 79us/sample - loss: 0.0165 - val_loss: 0.0133\n",
      "Epoch 9/50\n",
      "862/862 [==============================] - 0s 83us/sample - loss: 0.0165 - val_loss: 0.0133\n",
      "Epoch 10/50\n",
      "862/862 [==============================] - 0s 80us/sample - loss: 0.0165 - val_loss: 0.0134\n",
      "Epoch 11/50\n",
      "862/862 [==============================] - 0s 81us/sample - loss: 0.0165 - val_loss: 0.0133\n",
      "Epoch 12/50\n",
      "862/862 [==============================] - 0s 78us/sample - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 13/50\n",
      "862/862 [==============================] - 0s 80us/sample - loss: 0.0165 - val_loss: 0.0133\n",
      "Epoch 14/50\n",
      "862/862 [==============================] - 0s 78us/sample - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 15/50\n",
      "862/862 [==============================] - 0s 77us/sample - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 16/50\n",
      "862/862 [==============================] - 0s 78us/sample - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 17/50\n",
      "862/862 [==============================] - 0s 81us/sample - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 18/50\n",
      "862/862 [==============================] - 0s 77us/sample - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 19/50\n",
      "862/862 [==============================] - 0s 81us/sample - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 20/50\n",
      "862/862 [==============================] - 0s 81us/sample - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 21/50\n",
      "862/862 [==============================] - 0s 79us/sample - loss: 0.0165 - val_loss: 0.0131\n",
      "Epoch 22/50\n",
      "862/862 [==============================] - 0s 79us/sample - loss: 0.0165 - val_loss: 0.0131\n",
      "Epoch 23/50\n",
      "862/862 [==============================] - 0s 77us/sample - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 24/50\n",
      "862/862 [==============================] - 0s 78us/sample - loss: 0.0165 - val_loss: 0.0131\n",
      "Epoch 25/50\n",
      "862/862 [==============================] - 0s 78us/sample - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 26/50\n",
      "862/862 [==============================] - 0s 76us/sample - loss: 0.0165 - val_loss: 0.0131\n",
      "Epoch 27/50\n",
      "862/862 [==============================] - 0s 77us/sample - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 28/50\n",
      "862/862 [==============================] - 0s 74us/sample - loss: 0.0165 - val_loss: 0.0130\n",
      "Epoch 29/50\n",
      "862/862 [==============================] - 0s 79us/sample - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 30/50\n",
      "862/862 [==============================] - 0s 75us/sample - loss: 0.0165 - val_loss: 0.0130\n",
      "Epoch 31/50\n",
      "862/862 [==============================] - 0s 75us/sample - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 32/50\n",
      "862/862 [==============================] - 0s 76us/sample - loss: 0.0165 - val_loss: 0.0130\n",
      "Epoch 33/50\n",
      "862/862 [==============================] - 0s 74us/sample - loss: 0.0165 - val_loss: 0.0131\n",
      "Epoch 34/50\n",
      "862/862 [==============================] - 0s 80us/sample - loss: 0.0165 - val_loss: 0.0130\n",
      "Epoch 35/50\n",
      "862/862 [==============================] - 0s 75us/sample - loss: 0.0165 - val_loss: 0.0131\n",
      "Epoch 36/50\n",
      "862/862 [==============================] - 0s 77us/sample - loss: 0.0165 - val_loss: 0.0129\n",
      "Epoch 37/50\n",
      "862/862 [==============================] - 0s 76us/sample - loss: 0.0165 - val_loss: 0.0131\n",
      "Epoch 38/50\n",
      "862/862 [==============================] - 0s 78us/sample - loss: 0.0165 - val_loss: 0.0129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "862/862 [==============================] - 0s 78us/sample - loss: 0.0165 - val_loss: 0.0131\n",
      "Epoch 40/50\n",
      "862/862 [==============================] - 0s 78us/sample - loss: 0.0165 - val_loss: 0.0129\n",
      "Epoch 41/50\n",
      "862/862 [==============================] - 0s 77us/sample - loss: 0.0165 - val_loss: 0.0130\n",
      "Epoch 42/50\n",
      "862/862 [==============================] - 0s 75us/sample - loss: 0.0165 - val_loss: 0.0129\n",
      "Epoch 43/50\n",
      "862/862 [==============================] - 0s 76us/sample - loss: 0.0165 - val_loss: 0.0130\n",
      "Epoch 44/50\n",
      "862/862 [==============================] - 0s 78us/sample - loss: 0.0165 - val_loss: 0.0128\n",
      "Epoch 45/50\n",
      "862/862 [==============================] - 0s 76us/sample - loss: 0.0165 - val_loss: 0.0130\n",
      "Epoch 46/50\n",
      "862/862 [==============================] - 0s 78us/sample - loss: 0.0165 - val_loss: 0.0128\n",
      "Epoch 47/50\n",
      "862/862 [==============================] - 0s 81us/sample - loss: 0.0165 - val_loss: 0.0129\n",
      "Epoch 48/50\n",
      "862/862 [==============================] - 0s 80us/sample - loss: 0.0165 - val_loss: 0.0128\n",
      "Epoch 49/50\n",
      "862/862 [==============================] - 0s 81us/sample - loss: 0.0165 - val_loss: 0.0128\n",
      "Epoch 50/50\n",
      "862/862 [==============================] - 0s 81us/sample - loss: 0.0165 - val_loss: 0.0129\n",
      "第387个数，还剩3736个没有训练\n",
      "inv_hat [0.57218502 0.51237813 0.50876044 0.50670794 0.45818756 0.45071322\n",
      " 0.45265368 0.48328932 0.45071322 0.47355333 0.53514127 0.53125618\n",
      " 0.51757385 0.47141155 0.47910149 0.46664379 0.47452706 0.4730665\n",
      " 0.49206262 0.45488604 0.44102079 0.42767352 0.41079793 0.41513179\n",
      " 0.39906866 0.41715559 0.41320513 0.40214225 0.38449855 0.37885662]\n",
      "Test RMSE: 0.025\n",
      "Train on 771 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "771/771 [==============================] - 0s 79us/sample - loss: 0.0175 - val_loss: 0.0409\n",
      "Epoch 2/50\n",
      "771/771 [==============================] - 0s 83us/sample - loss: 0.0177 - val_loss: 0.0413\n",
      "Epoch 3/50\n",
      "771/771 [==============================] - 0s 88us/sample - loss: 0.0175 - val_loss: 0.0409\n",
      "Epoch 4/50\n",
      "771/771 [==============================] - 0s 85us/sample - loss: 0.0177 - val_loss: 0.0414\n",
      "Epoch 5/50\n",
      "771/771 [==============================] - 0s 88us/sample - loss: 0.0175 - val_loss: 0.0409\n",
      "Epoch 6/50\n",
      "771/771 [==============================] - 0s 88us/sample - loss: 0.0177 - val_loss: 0.0414\n",
      "Epoch 7/50\n",
      "771/771 [==============================] - 0s 82us/sample - loss: 0.0175 - val_loss: 0.0409\n",
      "Epoch 8/50\n",
      "771/771 [==============================] - 0s 77us/sample - loss: 0.0177 - val_loss: 0.0413\n",
      "Epoch 9/50\n",
      "771/771 [==============================] - 0s 80us/sample - loss: 0.0175 - val_loss: 0.0409\n",
      "Epoch 10/50\n",
      "771/771 [==============================] - 0s 81us/sample - loss: 0.0177 - val_loss: 0.0413\n",
      "Epoch 11/50\n",
      "771/771 [==============================] - 0s 77us/sample - loss: 0.0175 - val_loss: 0.0409\n",
      "Epoch 12/50\n",
      "771/771 [==============================] - 0s 79us/sample - loss: 0.0177 - val_loss: 0.0413\n",
      "Epoch 13/50\n",
      "771/771 [==============================] - 0s 76us/sample - loss: 0.0175 - val_loss: 0.0409\n",
      "Epoch 14/50\n",
      "771/771 [==============================] - 0s 75us/sample - loss: 0.0177 - val_loss: 0.0413\n",
      "Epoch 15/50\n",
      "771/771 [==============================] - 0s 74us/sample - loss: 0.0175 - val_loss: 0.0409\n",
      "Epoch 16/50\n",
      "771/771 [==============================] - 0s 73us/sample - loss: 0.0177 - val_loss: 0.0413\n",
      "Epoch 17/50\n",
      "771/771 [==============================] - 0s 80us/sample - loss: 0.0175 - val_loss: 0.0408\n",
      "Epoch 18/50\n",
      "771/771 [==============================] - 0s 78us/sample - loss: 0.0177 - val_loss: 0.0412\n",
      "Epoch 19/50\n",
      "771/771 [==============================] - 0s 76us/sample - loss: 0.0175 - val_loss: 0.0409\n",
      "Epoch 20/50\n",
      "771/771 [==============================] - 0s 77us/sample - loss: 0.0177 - val_loss: 0.0412\n",
      "Epoch 21/50\n",
      "771/771 [==============================] - 0s 79us/sample - loss: 0.0175 - val_loss: 0.0408\n",
      "Epoch 22/50\n",
      "771/771 [==============================] - 0s 80us/sample - loss: 0.0176 - val_loss: 0.0411\n",
      "Epoch 23/50\n",
      "771/771 [==============================] - 0s 78us/sample - loss: 0.0175 - val_loss: 0.0408\n",
      "Epoch 24/50\n",
      "771/771 [==============================] - 0s 78us/sample - loss: 0.0175 - val_loss: 0.0411\n",
      "Epoch 25/50\n",
      "771/771 [==============================] - 0s 80us/sample - loss: 0.0175 - val_loss: 0.0408\n",
      "Epoch 26/50\n",
      "771/771 [==============================] - 0s 78us/sample - loss: 0.0176 - val_loss: 0.0412\n",
      "Epoch 27/50\n",
      "771/771 [==============================] - 0s 73us/sample - loss: 0.0175 - val_loss: 0.0408\n",
      "Epoch 28/50\n",
      "771/771 [==============================] - 0s 77us/sample - loss: 0.0175 - val_loss: 0.0411\n",
      "Epoch 29/50\n",
      "771/771 [==============================] - 0s 77us/sample - loss: 0.0174 - val_loss: 0.0408\n",
      "Epoch 30/50\n",
      "771/771 [==============================] - 0s 79us/sample - loss: 0.0175 - val_loss: 0.0410\n",
      "Epoch 31/50\n",
      "771/771 [==============================] - 0s 80us/sample - loss: 0.0175 - val_loss: 0.0408\n",
      "Epoch 32/50\n",
      "771/771 [==============================] - 0s 78us/sample - loss: 0.0175 - val_loss: 0.0411\n",
      "Epoch 33/50\n",
      "771/771 [==============================] - 0s 75us/sample - loss: 0.0175 - val_loss: 0.0408\n",
      "Epoch 34/50\n",
      "771/771 [==============================] - 0s 77us/sample - loss: 0.0175 - val_loss: 0.0410\n",
      "Epoch 35/50\n",
      "771/771 [==============================] - 0s 77us/sample - loss: 0.0174 - val_loss: 0.0408\n",
      "Epoch 36/50\n",
      "771/771 [==============================] - 0s 75us/sample - loss: 0.0175 - val_loss: 0.0410\n",
      "Epoch 37/50\n",
      "771/771 [==============================] - 0s 78us/sample - loss: 0.0174 - val_loss: 0.0409\n",
      "Epoch 38/50\n",
      "771/771 [==============================] - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0410\n",
      "Epoch 39/50\n",
      "771/771 [==============================] - 0s 80us/sample - loss: 0.0175 - val_loss: 0.0409\n",
      "Epoch 40/50\n",
      "771/771 [==============================] - 0s 84us/sample - loss: 0.0175 - val_loss: 0.0410\n",
      "Epoch 41/50\n",
      "771/771 [==============================] - 0s 76us/sample - loss: 0.0175 - val_loss: 0.0409\n",
      "Epoch 42/50\n",
      "771/771 [==============================] - 0s 79us/sample - loss: 0.0175 - val_loss: 0.0409\n",
      "Epoch 43/50\n",
      "771/771 [==============================] - 0s 76us/sample - loss: 0.0175 - val_loss: 0.0409\n",
      "Epoch 44/50\n",
      "771/771 [==============================] - 0s 80us/sample - loss: 0.0175 - val_loss: 0.0409\n",
      "Epoch 45/50\n",
      "771/771 [==============================] - 0s 78us/sample - loss: 0.0175 - val_loss: 0.0409\n",
      "Epoch 46/50\n",
      "771/771 [==============================] - 0s 76us/sample - loss: 0.0175 - val_loss: 0.0409\n",
      "Epoch 47/50\n",
      "771/771 [==============================] - 0s 76us/sample - loss: 0.0175 - val_loss: 0.0409\n",
      "Epoch 48/50\n",
      "771/771 [==============================] - 0s 76us/sample - loss: 0.0175 - val_loss: 0.0409\n",
      "Epoch 49/50\n",
      "771/771 [==============================] - 0s 75us/sample - loss: 0.0175 - val_loss: 0.0409\n",
      "Epoch 50/50\n",
      "771/771 [==============================] - 0s 79us/sample - loss: 0.0175 - val_loss: 0.0409\n",
      "第388个数，还剩3735个没有训练\n",
      "inv_hat [0.40212516 0.39843463 0.40212516 0.36999215 0.37730512 0.39290741\n",
      " 0.32387594 0.33284381 0.30605867 0.27783724 0.29279216 0.25776557\n",
      " 1.00105347 1.07063969 1.04381025 1.03188202 1.02193946 1.01398403\n",
      " 1.00005857 1.0129894  1.07858661 1.09249147 1.12823388 1.13021901\n",
      " 1.12426321 1.1093721  1.1034147  1.09348463 1.11930004 1.13518179]\n",
      "Test RMSE: 0.139\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0143 - val_loss: 0.0113\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0143 - val_loss: 0.0113\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0145 - val_loss: 0.0113\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0144 - val_loss: 0.0113\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0143 - val_loss: 0.0115\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0143 - val_loss: 0.0115\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0143 - val_loss: 0.0120\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0142 - val_loss: 0.0121\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0142 - val_loss: 0.0122\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0118\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0116\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0142 - val_loss: 0.0115\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0143 - val_loss: 0.0118\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0118\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0142 - val_loss: 0.0117\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0142 - val_loss: 0.0116\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0142 - val_loss: 0.0116\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0142 - val_loss: 0.0118\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 85us/sample - loss: 0.0142 - val_loss: 0.0117\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0142 - val_loss: 0.0116\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0143 - val_loss: 0.0118\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0142 - val_loss: 0.0115\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0143 - val_loss: 0.0117\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0142 - val_loss: 0.0119\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0118\n",
      "Epoch 32/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0142 - val_loss: 0.0117\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0142 - val_loss: 0.0117\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0142 - val_loss: 0.0119\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0142 - val_loss: 0.0117\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0142 - val_loss: 0.0117\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0142 - val_loss: 0.0118\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0142 - val_loss: 0.0118\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0142 - val_loss: 0.0116\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0142 - val_loss: 0.0119\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0142 - val_loss: 0.0116\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0142 - val_loss: 0.0121\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0142 - val_loss: 0.0116\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0142 - val_loss: 0.0118\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0142 - val_loss: 0.0115\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0142 - val_loss: 0.0117\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0142 - val_loss: 0.0116\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0142 - val_loss: 0.0115\n",
      "第389个数，还剩3734个没有训练\n",
      "inv_hat [1.25424797 1.22717177 1.24021122 1.2351966  1.22215548 1.21914558\n",
      " 1.22014886 1.23218751 1.22416218 1.23619963 1.2652825  1.27130018\n",
      " 1.27731641 1.24823303 1.2382055  1.23218751 1.2351966  1.23218751\n",
      " 1.25324558 1.23218751 1.22616866 1.2161354  1.19606469 1.19706825\n",
      " 1.17800055 1.19907537 1.19807187 1.20007902 1.19405738 1.19807187]\n",
      "Test RMSE: 0.014\n",
      "Train on 1195 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0106 - val_loss: 0.0063\n",
      "Epoch 2/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0076\n",
      "Epoch 3/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0064\n",
      "Epoch 4/50\n",
      "1195/1195 [==============================] - 0s 74us/sample - loss: 0.0109 - val_loss: 0.0069\n",
      "Epoch 5/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0109 - val_loss: 0.0067\n",
      "Epoch 6/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0110 - val_loss: 0.0070\n",
      "Epoch 7/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0111 - val_loss: 0.0068\n",
      "Epoch 8/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0113 - val_loss: 0.0066\n",
      "Epoch 9/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0116 - val_loss: 0.0069\n",
      "Epoch 10/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0121 - val_loss: 0.0066\n",
      "Epoch 11/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0123 - val_loss: 0.0067\n",
      "Epoch 12/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0130 - val_loss: 0.0070\n",
      "Epoch 13/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0127 - val_loss: 0.0067\n",
      "Epoch 14/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0115 - val_loss: 0.0067\n",
      "Epoch 15/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0112 - val_loss: 0.0069\n",
      "Epoch 16/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0112 - val_loss: 0.0067\n",
      "Epoch 17/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0112 - val_loss: 0.0070\n",
      "Epoch 18/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0112 - val_loss: 0.0069\n",
      "Epoch 19/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0112 - val_loss: 0.0069\n",
      "Epoch 20/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0111 - val_loss: 0.0069\n",
      "Epoch 21/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0067\n",
      "Epoch 22/50\n",
      "1195/1195 [==============================] - 0s 75us/sample - loss: 0.0110 - val_loss: 0.0070\n",
      "Epoch 23/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0069\n",
      "Epoch 24/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0068\n",
      "Epoch 25/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0108 - val_loss: 0.0069\n",
      "Epoch 26/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0069\n",
      "Epoch 27/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0069\n",
      "Epoch 28/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0109 - val_loss: 0.0070\n",
      "Epoch 29/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0109 - val_loss: 0.0069\n",
      "Epoch 30/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 31/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0109 - val_loss: 0.0070\n",
      "Epoch 33/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0069\n",
      "Epoch 34/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 35/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0108 - val_loss: 0.0069\n",
      "Epoch 36/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0108 - val_loss: 0.0069\n",
      "Epoch 37/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0108 - val_loss: 0.0069\n",
      "Epoch 38/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0109 - val_loss: 0.0069\n",
      "Epoch 39/50\n",
      "1195/1195 [==============================] - 0s 76us/sample - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 40/50\n",
      "1195/1195 [==============================] - 0s 77us/sample - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 41/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0109 - val_loss: 0.0069\n",
      "Epoch 42/50\n",
      "1195/1195 [==============================] - 0s 82us/sample - loss: 0.0108 - val_loss: 0.0069\n",
      "Epoch 43/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0108 - val_loss: 0.0069\n",
      "Epoch 44/50\n",
      "1195/1195 [==============================] - 0s 81us/sample - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 45/50\n",
      "1195/1195 [==============================] - 0s 84us/sample - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 46/50\n",
      "1195/1195 [==============================] - 0s 80us/sample - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 47/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 48/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 49/50\n",
      "1195/1195 [==============================] - 0s 79us/sample - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 50/50\n",
      "1195/1195 [==============================] - 0s 78us/sample - loss: 0.0108 - val_loss: 0.0070\n",
      "第390个数，还剩3733个没有训练\n",
      "inv_hat [1.29085107 1.25286598 1.25685078 1.25485797 1.20629694 1.20432598\n",
      " 1.21122831 1.22803624 1.19841848 1.20728282 1.24590048 1.25087485\n",
      " 1.24590048 1.21814165 1.21913006 1.20531142 1.21715332 1.21517749\n",
      " 1.22803624 1.19940244 1.19251902 1.18662781 1.16900448 1.17193642\n",
      " 1.16509859 1.17584904 1.16412267 1.15729825 1.14368508 1.14465579]\n",
      "Test RMSE: 0.019\n",
      "Train on 923 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "923/923 [==============================] - 0s 80us/sample - loss: 0.0087 - val_loss: 0.0151\n",
      "Epoch 2/50\n",
      "923/923 [==============================] - 0s 79us/sample - loss: 0.0093 - val_loss: 0.0164\n",
      "Epoch 3/50\n",
      "923/923 [==============================] - 0s 81us/sample - loss: 0.0087 - val_loss: 0.0155\n",
      "Epoch 4/50\n",
      "923/923 [==============================] - 0s 81us/sample - loss: 0.0083 - val_loss: 0.0151\n",
      "Epoch 5/50\n",
      "923/923 [==============================] - 0s 76us/sample - loss: 0.0082 - val_loss: 0.0157\n",
      "Epoch 6/50\n",
      "923/923 [==============================] - 0s 74us/sample - loss: 0.0083 - val_loss: 0.0158\n",
      "Epoch 7/50\n",
      "923/923 [==============================] - 0s 74us/sample - loss: 0.0088 - val_loss: 0.0163\n",
      "Epoch 8/50\n",
      "923/923 [==============================] - 0s 76us/sample - loss: 0.0083 - val_loss: 0.0157\n",
      "Epoch 9/50\n",
      "923/923 [==============================] - 0s 79us/sample - loss: 0.0083 - val_loss: 0.0153\n",
      "Epoch 10/50\n",
      "923/923 [==============================] - 0s 77us/sample - loss: 0.0082 - val_loss: 0.0155\n",
      "Epoch 11/50\n",
      "923/923 [==============================] - 0s 80us/sample - loss: 0.0082 - val_loss: 0.0158\n",
      "Epoch 12/50\n",
      "923/923 [==============================] - 0s 85us/sample - loss: 0.0085 - val_loss: 0.0152\n",
      "Epoch 13/50\n",
      "923/923 [==============================] - 0s 79us/sample - loss: 0.0087 - val_loss: 0.0163\n",
      "Epoch 14/50\n",
      "923/923 [==============================] - 0s 79us/sample - loss: 0.0084 - val_loss: 0.0156\n",
      "Epoch 15/50\n",
      "923/923 [==============================] - 0s 79us/sample - loss: 0.0086 - val_loss: 0.0167\n",
      "Epoch 16/50\n",
      "923/923 [==============================] - 0s 84us/sample - loss: 0.0087 - val_loss: 0.0166\n",
      "Epoch 17/50\n",
      "923/923 [==============================] - 0s 77us/sample - loss: 0.0087 - val_loss: 0.0162\n",
      "Epoch 18/50\n",
      "923/923 [==============================] - 0s 76us/sample - loss: 0.0087 - val_loss: 0.0159\n",
      "Epoch 19/50\n",
      "923/923 [==============================] - 0s 74us/sample - loss: 0.0094 - val_loss: 0.0153\n",
      "Epoch 20/50\n",
      "923/923 [==============================] - 0s 75us/sample - loss: 0.0104 - val_loss: 0.0156\n",
      "Epoch 21/50\n",
      "923/923 [==============================] - 0s 78us/sample - loss: 0.0136 - val_loss: 0.0158\n",
      "Epoch 22/50\n",
      "923/923 [==============================] - 0s 75us/sample - loss: 0.0114 - val_loss: 0.0158\n",
      "Epoch 23/50\n",
      "923/923 [==============================] - 0s 77us/sample - loss: 0.0104 - val_loss: 0.0160\n",
      "Epoch 24/50\n",
      "923/923 [==============================] - 0s 75us/sample - loss: 0.0094 - val_loss: 0.0158\n",
      "Epoch 25/50\n",
      "923/923 [==============================] - 0s 75us/sample - loss: 0.0097 - val_loss: 0.0167\n",
      "Epoch 26/50\n",
      "923/923 [==============================] - 0s 83us/sample - loss: 0.0123 - val_loss: 0.0151\n",
      "Epoch 27/50\n",
      "923/923 [==============================] - 0s 81us/sample - loss: 0.0097 - val_loss: 0.0155\n",
      "Epoch 28/50\n",
      "923/923 [==============================] - 0s 79us/sample - loss: 0.0087 - val_loss: 0.0157\n",
      "Epoch 29/50\n",
      "923/923 [==============================] - 0s 80us/sample - loss: 0.0089 - val_loss: 0.0152\n",
      "Epoch 30/50\n",
      "923/923 [==============================] - 0s 75us/sample - loss: 0.0096 - val_loss: 0.0155\n",
      "Epoch 31/50\n",
      "923/923 [==============================] - 0s 76us/sample - loss: 0.0118 - val_loss: 0.0153\n",
      "Epoch 32/50\n",
      "923/923 [==============================] - 0s 78us/sample - loss: 0.0101 - val_loss: 0.0151\n",
      "Epoch 33/50\n",
      "923/923 [==============================] - 0s 77us/sample - loss: 0.0094 - val_loss: 0.0157\n",
      "Epoch 34/50\n",
      "923/923 [==============================] - 0s 76us/sample - loss: 0.0087 - val_loss: 0.0154\n",
      "Epoch 35/50\n",
      "923/923 [==============================] - 0s 83us/sample - loss: 0.0091 - val_loss: 0.0164\n",
      "Epoch 36/50\n",
      "923/923 [==============================] - 0s 81us/sample - loss: 0.0103 - val_loss: 0.0156\n",
      "Epoch 37/50\n",
      "923/923 [==============================] - 0s 82us/sample - loss: 0.0097 - val_loss: 0.0154\n",
      "Epoch 38/50\n",
      "923/923 [==============================] - 0s 81us/sample - loss: 0.0091 - val_loss: 0.0151\n",
      "Epoch 39/50\n",
      "923/923 [==============================] - 0s 80us/sample - loss: 0.0102 - val_loss: 0.0151\n",
      "Epoch 40/50\n",
      "923/923 [==============================] - 0s 79us/sample - loss: 0.0122 - val_loss: 0.0174\n",
      "Epoch 41/50\n",
      "923/923 [==============================] - 0s 80us/sample - loss: 0.0090 - val_loss: 0.0156\n",
      "Epoch 42/50\n",
      "923/923 [==============================] - 0s 76us/sample - loss: 0.0085 - val_loss: 0.0153\n",
      "Epoch 43/50\n",
      "923/923 [==============================] - 0s 79us/sample - loss: 0.0085 - val_loss: 0.0159\n",
      "Epoch 44/50\n",
      "923/923 [==============================] - 0s 82us/sample - loss: 0.0086 - val_loss: 0.0162\n",
      "Epoch 45/50\n",
      "923/923 [==============================] - 0s 78us/sample - loss: 0.0086 - val_loss: 0.0160\n",
      "Epoch 46/50\n",
      "923/923 [==============================] - 0s 77us/sample - loss: 0.0084 - val_loss: 0.0156\n",
      "Epoch 47/50\n",
      "923/923 [==============================] - 0s 79us/sample - loss: 0.0082 - val_loss: 0.0155\n",
      "Epoch 48/50\n",
      "923/923 [==============================] - 0s 76us/sample - loss: 0.0085 - val_loss: 0.0159\n",
      "Epoch 49/50\n",
      "923/923 [==============================] - 0s 77us/sample - loss: 0.0087 - val_loss: 0.0158\n",
      "Epoch 50/50\n",
      "923/923 [==============================] - 0s 79us/sample - loss: 0.0090 - val_loss: 0.0151\n",
      "第391个数，还剩3732个没有训练\n",
      "inv_hat [1.23062341 1.22477194 1.22379341 1.22183331 1.20801076 1.20701686\n",
      " 1.20999586 1.2149437  1.2129672  1.21593071 1.22867688 1.23159523\n",
      " 1.22770207 1.22085183 1.22183331 1.22085183 1.22477194 1.22477194\n",
      " 1.23062341 1.22085183 1.22085183 1.21691679 1.21098717 1.20900374\n",
      " 1.20003763 1.20203561 1.197035   1.19603275 1.19402597 1.20103707]\n",
      "Test RMSE: 0.005\n",
      "Train on 871 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "871/871 [==============================] - 0s 83us/sample - loss: 0.0174 - val_loss: 0.0144\n",
      "Epoch 2/50\n",
      "871/871 [==============================] - 0s 84us/sample - loss: 0.0171 - val_loss: 0.0140\n",
      "Epoch 3/50\n",
      "871/871 [==============================] - 0s 81us/sample - loss: 0.0170 - val_loss: 0.0139\n",
      "Epoch 4/50\n",
      "871/871 [==============================] - 0s 79us/sample - loss: 0.0167 - val_loss: 0.0138\n",
      "Epoch 5/50\n",
      "871/871 [==============================] - 0s 82us/sample - loss: 0.0168 - val_loss: 0.0138\n",
      "Epoch 6/50\n",
      "871/871 [==============================] - 0s 82us/sample - loss: 0.0167 - val_loss: 0.0138\n",
      "Epoch 7/50\n",
      "871/871 [==============================] - 0s 85us/sample - loss: 0.0167 - val_loss: 0.0138\n",
      "Epoch 8/50\n",
      "871/871 [==============================] - 0s 83us/sample - loss: 0.0167 - val_loss: 0.0138\n",
      "Epoch 9/50\n",
      "871/871 [==============================] - 0s 84us/sample - loss: 0.0167 - val_loss: 0.0138\n",
      "Epoch 10/50\n",
      "871/871 [==============================] - 0s 82us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 11/50\n",
      "871/871 [==============================] - 0s 84us/sample - loss: 0.0167 - val_loss: 0.0138\n",
      "Epoch 12/50\n",
      "871/871 [==============================] - 0s 84us/sample - loss: 0.0167 - val_loss: 0.0138\n",
      "Epoch 13/50\n",
      "871/871 [==============================] - 0s 81us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 14/50\n",
      "871/871 [==============================] - 0s 83us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 15/50\n",
      "871/871 [==============================] - 0s 81us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 16/50\n",
      "871/871 [==============================] - 0s 83us/sample - loss: 0.0167 - val_loss: 0.0138\n",
      "Epoch 17/50\n",
      "871/871 [==============================] - 0s 81us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 18/50\n",
      "871/871 [==============================] - 0s 86us/sample - loss: 0.0167 - val_loss: 0.0138\n",
      "Epoch 19/50\n",
      "871/871 [==============================] - 0s 82us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 20/50\n",
      "871/871 [==============================] - 0s 82us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 21/50\n",
      "871/871 [==============================] - 0s 84us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 22/50\n",
      "871/871 [==============================] - 0s 82us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 23/50\n",
      "871/871 [==============================] - 0s 85us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 24/50\n",
      "871/871 [==============================] - 0s 78us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 25/50\n",
      "871/871 [==============================] - 0s 80us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 26/50\n",
      "871/871 [==============================] - 0s 82us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 27/50\n",
      "871/871 [==============================] - 0s 83us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 28/50\n",
      "871/871 [==============================] - 0s 81us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 29/50\n",
      "871/871 [==============================] - 0s 79us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 30/50\n",
      "871/871 [==============================] - 0s 82us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 31/50\n",
      "871/871 [==============================] - 0s 81us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 32/50\n",
      "871/871 [==============================] - 0s 83us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 33/50\n",
      "871/871 [==============================] - 0s 84us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 34/50\n",
      "871/871 [==============================] - 0s 87us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 35/50\n",
      "871/871 [==============================] - 0s 83us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 36/50\n",
      "871/871 [==============================] - 0s 79us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 37/50\n",
      "871/871 [==============================] - 0s 85us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 38/50\n",
      "871/871 [==============================] - 0s 86us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 39/50\n",
      "871/871 [==============================] - 0s 83us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 40/50\n",
      "871/871 [==============================] - 0s 81us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 41/50\n",
      "871/871 [==============================] - 0s 84us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 42/50\n",
      "871/871 [==============================] - 0s 86us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 43/50\n",
      "871/871 [==============================] - 0s 83us/sample - loss: 0.0166 - val_loss: 0.0139\n",
      "Epoch 44/50\n",
      "871/871 [==============================] - 0s 85us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 45/50\n",
      "871/871 [==============================] - 0s 85us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 46/50\n",
      "871/871 [==============================] - 0s 80us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 47/50\n",
      "871/871 [==============================] - 0s 79us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 48/50\n",
      "871/871 [==============================] - 0s 79us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 49/50\n",
      "871/871 [==============================] - 0s 81us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 50/50\n",
      "871/871 [==============================] - 0s 81us/sample - loss: 0.0166 - val_loss: 0.0138\n",
      "第392个数，还剩3731个没有训练\n",
      "inv_hat [1.06155954 1.03551816 1.04352887 1.04352887 1.01750273 1.0145015\n",
      " 1.01050064 1.02550791 1.02550791 1.05354486 1.09964429 1.09964429\n",
      " 1.10565929 1.07759244 1.08160156 1.0695755  1.0805992  1.09362956\n",
      " 1.11067208 1.09663685 1.0876153  1.08260371 1.06757134 1.05955566\n",
      " 1.04352887 1.05554837 1.05053983 1.03151354 1.02851064 1.04052458]\n",
      "Test RMSE: 0.016\n",
      "Train on 810 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "810/810 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0145\n",
      "Epoch 2/50\n",
      "810/810 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0146\n",
      "Epoch 3/50\n",
      "810/810 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0145\n",
      "Epoch 4/50\n",
      "810/810 [==============================] - 0s 84us/sample - loss: 0.0156 - val_loss: 0.0148\n",
      "Epoch 5/50\n",
      "810/810 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0144\n",
      "Epoch 6/50\n",
      "810/810 [==============================] - 0s 79us/sample - loss: 0.0156 - val_loss: 0.0148\n",
      "Epoch 7/50\n",
      "810/810 [==============================] - 0s 84us/sample - loss: 0.0156 - val_loss: 0.0144\n",
      "Epoch 8/50\n",
      "810/810 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 9/50\n",
      "810/810 [==============================] - 0s 85us/sample - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 10/50\n",
      "810/810 [==============================] - 0s 87us/sample - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 11/50\n",
      "810/810 [==============================] - 0s 84us/sample - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 12/50\n",
      "810/810 [==============================] - 0s 89us/sample - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 13/50\n",
      "810/810 [==============================] - 0s 89us/sample - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 14/50\n",
      "810/810 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0148\n",
      "Epoch 15/50\n",
      "810/810 [==============================] - 0s 85us/sample - loss: 0.0156 - val_loss: 0.0144\n",
      "Epoch 16/50\n",
      "810/810 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 17/50\n",
      "810/810 [==============================] - 0s 81us/sample - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 18/50\n",
      "810/810 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 19/50\n",
      "810/810 [==============================] - 0s 84us/sample - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 20/50\n",
      "810/810 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 21/50\n",
      "810/810 [==============================] - 0s 77us/sample - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 22/50\n",
      "810/810 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0148\n",
      "Epoch 23/50\n",
      "810/810 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0144\n",
      "Epoch 24/50\n",
      "810/810 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0148\n",
      "Epoch 25/50\n",
      "810/810 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0145\n",
      "Epoch 26/50\n",
      "810/810 [==============================] - 0s 76us/sample - loss: 0.0156 - val_loss: 0.0148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "810/810 [==============================] - 0s 79us/sample - loss: 0.0156 - val_loss: 0.0145\n",
      "Epoch 28/50\n",
      "810/810 [==============================] - 0s 77us/sample - loss: 0.0156 - val_loss: 0.0147\n",
      "Epoch 29/50\n",
      "810/810 [==============================] - 0s 79us/sample - loss: 0.0156 - val_loss: 0.0145\n",
      "Epoch 30/50\n",
      "810/810 [==============================] - 0s 79us/sample - loss: 0.0156 - val_loss: 0.0148\n",
      "Epoch 31/50\n",
      "810/810 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0144\n",
      "Epoch 32/50\n",
      "810/810 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 33/50\n",
      "810/810 [==============================] - 0s 85us/sample - loss: 0.0156 - val_loss: 0.0144\n",
      "Epoch 34/50\n",
      "810/810 [==============================] - 0s 79us/sample - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 35/50\n",
      "810/810 [==============================] - 0s 85us/sample - loss: 0.0156 - val_loss: 0.0144\n",
      "Epoch 36/50\n",
      "810/810 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 37/50\n",
      "810/810 [==============================] - 0s 88us/sample - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 38/50\n",
      "810/810 [==============================] - 0s 80us/sample - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 39/50\n",
      "810/810 [==============================] - 0s 80us/sample - loss: 0.0156 - val_loss: 0.0144\n",
      "Epoch 40/50\n",
      "810/810 [==============================] - 0s 76us/sample - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 41/50\n",
      "810/810 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0144\n",
      "Epoch 42/50\n",
      "810/810 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 43/50\n",
      "810/810 [==============================] - ETA: 0s - loss: 0.014 - 0s 87us/sample - loss: 0.0156 - val_loss: 0.0144\n",
      "Epoch 44/50\n",
      "810/810 [==============================] - 0s 84us/sample - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 45/50\n",
      "810/810 [==============================] - 0s 78us/sample - loss: 0.0157 - val_loss: 0.0145\n",
      "Epoch 46/50\n",
      "810/810 [==============================] - 0s 80us/sample - loss: 0.0156 - val_loss: 0.0147\n",
      "Epoch 47/50\n",
      "810/810 [==============================] - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0147\n",
      "Epoch 48/50\n",
      "810/810 [==============================] - 0s 79us/sample - loss: 0.0156 - val_loss: 0.0147\n",
      "Epoch 49/50\n",
      "810/810 [==============================] - 0s 79us/sample - loss: 0.0156 - val_loss: 0.0147\n",
      "Epoch 50/50\n",
      "810/810 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0145\n",
      "第393个数，还剩3730个没有训练\n",
      "inv_hat [1.16323263 1.13832099 1.14907793 1.14648747 1.1209119  1.11544708\n",
      " 1.11266641 1.12926452 1.1236953  1.14499321 1.18986979 1.19286365\n",
      " 1.1935624  1.16462873 1.16782006 1.15416027 1.16522704 1.17460312\n",
      " 1.19525901 1.1787934  1.16991461 1.16213575 1.14270243 1.13981447\n",
      " 1.1270762  1.13782312 1.13443874 1.12558447 1.12399361 1.13951574]\n",
      "Test RMSE: 0.016\n",
      "Train on 502 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "502/502 [==============================] - 0s 78us/sample - loss: 0.0103 - val_loss: 0.0222\n",
      "Epoch 2/50\n",
      "502/502 [==============================] - 0s 80us/sample - loss: 0.0112 - val_loss: 0.0206\n",
      "Epoch 3/50\n",
      "502/502 [==============================] - 0s 76us/sample - loss: 0.0084 - val_loss: 0.0200\n",
      "Epoch 4/50\n",
      "502/502 [==============================] - 0s 81us/sample - loss: 0.0081 - val_loss: 0.0199\n",
      "Epoch 5/50\n",
      "502/502 [==============================] - 0s 76us/sample - loss: 0.0088 - val_loss: 0.0205\n",
      "Epoch 6/50\n",
      "502/502 [==============================] - 0s 76us/sample - loss: 0.0081 - val_loss: 0.0206\n",
      "Epoch 7/50\n",
      "502/502 [==============================] - 0s 77us/sample - loss: 0.0079 - val_loss: 0.0204\n",
      "Epoch 8/50\n",
      "502/502 [==============================] - 0s 78us/sample - loss: 0.0079 - val_loss: 0.0197\n",
      "Epoch 9/50\n",
      "502/502 [==============================] - 0s 75us/sample - loss: 0.0080 - val_loss: 0.0195\n",
      "Epoch 10/50\n",
      "502/502 [==============================] - 0s 78us/sample - loss: 0.0083 - val_loss: 0.0197\n",
      "Epoch 11/50\n",
      "502/502 [==============================] - ETA: 0s - loss: 0.003 - 0s 76us/sample - loss: 0.0089 - val_loss: 0.0205\n",
      "Epoch 12/50\n",
      "502/502 [==============================] - 0s 75us/sample - loss: 0.0082 - val_loss: 0.0210\n",
      "Epoch 13/50\n",
      "502/502 [==============================] - 0s 75us/sample - loss: 0.0080 - val_loss: 0.0209\n",
      "Epoch 14/50\n",
      "502/502 [==============================] - 0s 78us/sample - loss: 0.0080 - val_loss: 0.0200\n",
      "Epoch 15/50\n",
      "502/502 [==============================] - 0s 84us/sample - loss: 0.0088 - val_loss: 0.0205\n",
      "Epoch 16/50\n",
      "502/502 [==============================] - 0s 79us/sample - loss: 0.0082 - val_loss: 0.0205\n",
      "Epoch 17/50\n",
      "502/502 [==============================] - 0s 79us/sample - loss: 0.0080 - val_loss: 0.0204\n",
      "Epoch 18/50\n",
      "502/502 [==============================] - 0s 76us/sample - loss: 0.0084 - val_loss: 0.0210\n",
      "Epoch 19/50\n",
      "502/502 [==============================] - 0s 79us/sample - loss: 0.0082 - val_loss: 0.0215\n",
      "Epoch 20/50\n",
      "502/502 [==============================] - 0s 78us/sample - loss: 0.0080 - val_loss: 0.0212\n",
      "Epoch 21/50\n",
      "502/502 [==============================] - 0s 77us/sample - loss: 0.0079 - val_loss: 0.0207\n",
      "Epoch 22/50\n",
      "502/502 [==============================] - 0s 80us/sample - loss: 0.0080 - val_loss: 0.0199\n",
      "Epoch 23/50\n",
      "502/502 [==============================] - 0s 78us/sample - loss: 0.0078 - val_loss: 0.0197\n",
      "Epoch 24/50\n",
      "502/502 [==============================] - 0s 80us/sample - loss: 0.0089 - val_loss: 0.0203\n",
      "Epoch 25/50\n",
      "502/502 [==============================] - 0s 84us/sample - loss: 0.0083 - val_loss: 0.0210\n",
      "Epoch 26/50\n",
      "502/502 [==============================] - 0s 81us/sample - loss: 0.0083 - val_loss: 0.0205\n",
      "Epoch 27/50\n",
      "502/502 [==============================] - 0s 86us/sample - loss: 0.0082 - val_loss: 0.0201\n",
      "Epoch 28/50\n",
      "502/502 [==============================] - 0s 83us/sample - loss: 0.0089 - val_loss: 0.0206\n",
      "Epoch 29/50\n",
      "502/502 [==============================] - 0s 78us/sample - loss: 0.0080 - val_loss: 0.0211\n",
      "Epoch 30/50\n",
      "502/502 [==============================] - 0s 78us/sample - loss: 0.0082 - val_loss: 0.0220\n",
      "Epoch 31/50\n",
      "502/502 [==============================] - 0s 76us/sample - loss: 0.0078 - val_loss: 0.0216\n",
      "Epoch 32/50\n",
      "502/502 [==============================] - 0s 77us/sample - loss: 0.0077 - val_loss: 0.0209\n",
      "Epoch 33/50\n",
      "502/502 [==============================] - 0s 79us/sample - loss: 0.0080 - val_loss: 0.0202\n",
      "Epoch 34/50\n",
      "502/502 [==============================] - 0s 78us/sample - loss: 0.0088 - val_loss: 0.0208\n",
      "Epoch 35/50\n",
      "502/502 [==============================] - 0s 82us/sample - loss: 0.0079 - val_loss: 0.0210\n",
      "Epoch 36/50\n",
      "502/502 [==============================] - 0s 77us/sample - loss: 0.0078 - val_loss: 0.0208\n",
      "Epoch 37/50\n",
      "502/502 [==============================] - 0s 75us/sample - loss: 0.0086 - val_loss: 0.0216\n",
      "Epoch 38/50\n",
      "502/502 [==============================] - 0s 77us/sample - loss: 0.0079 - val_loss: 0.0218\n",
      "Epoch 39/50\n",
      "502/502 [==============================] - 0s 81us/sample - loss: 0.0079 - val_loss: 0.0218\n",
      "Epoch 40/50\n",
      "502/502 [==============================] - 0s 82us/sample - loss: 0.0082 - val_loss: 0.0221\n",
      "Epoch 41/50\n",
      "502/502 [==============================] - 0s 75us/sample - loss: 0.0078 - val_loss: 0.0219\n",
      "Epoch 42/50\n",
      "502/502 [==============================] - 0s 77us/sample - loss: 0.0080 - val_loss: 0.0206\n",
      "Epoch 43/50\n",
      "502/502 [==============================] - 0s 73us/sample - loss: 0.0085 - val_loss: 0.0209\n",
      "Epoch 44/50\n",
      "502/502 [==============================] - 0s 78us/sample - loss: 0.0079 - val_loss: 0.0211\n",
      "Epoch 45/50\n",
      "502/502 [==============================] - 0s 77us/sample - loss: 0.0080 - val_loss: 0.0203\n",
      "Epoch 46/50\n",
      "502/502 [==============================] - 0s 82us/sample - loss: 0.0085 - val_loss: 0.0206\n",
      "Epoch 47/50\n",
      "502/502 [==============================] - 0s 86us/sample - loss: 0.0081 - val_loss: 0.0212\n",
      "Epoch 48/50\n",
      "502/502 [==============================] - 0s 84us/sample - loss: 0.0081 - val_loss: 0.0208\n",
      "Epoch 49/50\n",
      "502/502 [==============================] - 0s 79us/sample - loss: 0.0080 - val_loss: 0.0203\n",
      "Epoch 50/50\n",
      "502/502 [==============================] - 0s 80us/sample - loss: 0.0087 - val_loss: 0.0209\n",
      "第394个数，还剩3729个没有训练\n",
      "inv_hat [0.84308604 0.82343693 0.82644763 0.82043139 0.80956021 0.8120464\n",
      " 0.80936154 0.82223406 0.80916291 0.81683209 0.82845756 0.82614634\n",
      " 0.82594553 0.81403851 0.81483615 0.80519607 0.81214589 0.81543465\n",
      " 0.82634723 0.79014734 0.79004973 0.77638528 0.76930321 0.76446146\n",
      " 0.753018   0.75060589 0.74811134 0.74507712 0.74224163 0.74535228]\n",
      "Test RMSE: 0.011\n",
      "Train on 699 samples, validate on 30 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699/699 [==============================] - 0s 81us/sample - loss: 0.0186 - val_loss: 0.0214\n",
      "Epoch 2/50\n",
      "699/699 [==============================] - 0s 79us/sample - loss: 0.0186 - val_loss: 0.0214\n",
      "Epoch 3/50\n",
      "699/699 [==============================] - 0s 77us/sample - loss: 0.0185 - val_loss: 0.0213\n",
      "Epoch 4/50\n",
      "699/699 [==============================] - 0s 77us/sample - loss: 0.0184 - val_loss: 0.0214\n",
      "Epoch 5/50\n",
      "699/699 [==============================] - 0s 76us/sample - loss: 0.0184 - val_loss: 0.0214\n",
      "Epoch 6/50\n",
      "699/699 [==============================] - 0s 77us/sample - loss: 0.0184 - val_loss: 0.0214\n",
      "Epoch 7/50\n",
      "699/699 [==============================] - 0s 78us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 8/50\n",
      "699/699 [==============================] - 0s 79us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 9/50\n",
      "699/699 [==============================] - 0s 77us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 10/50\n",
      "699/699 [==============================] - 0s 79us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 11/50\n",
      "699/699 [==============================] - 0s 77us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 12/50\n",
      "699/699 [==============================] - 0s 81us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 13/50\n",
      "699/699 [==============================] - 0s 77us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 14/50\n",
      "699/699 [==============================] - 0s 76us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 15/50\n",
      "699/699 [==============================] - 0s 74us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 16/50\n",
      "699/699 [==============================] - 0s 78us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 17/50\n",
      "699/699 [==============================] - 0s 75us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 18/50\n",
      "699/699 [==============================] - 0s 76us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 19/50\n",
      "699/699 [==============================] - 0s 80us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 20/50\n",
      "699/699 [==============================] - 0s 83us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 21/50\n",
      "699/699 [==============================] - 0s 78us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 22/50\n",
      "699/699 [==============================] - 0s 79us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 23/50\n",
      "699/699 [==============================] - 0s 85us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 24/50\n",
      "699/699 [==============================] - 0s 84us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 25/50\n",
      "699/699 [==============================] - 0s 84us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 26/50\n",
      "699/699 [==============================] - 0s 79us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 27/50\n",
      "699/699 [==============================] - 0s 84us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 28/50\n",
      "699/699 [==============================] - 0s 82us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 29/50\n",
      "699/699 [==============================] - 0s 81us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 30/50\n",
      "699/699 [==============================] - 0s 79us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 31/50\n",
      "699/699 [==============================] - 0s 81us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 32/50\n",
      "699/699 [==============================] - 0s 85us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 33/50\n",
      "699/699 [==============================] - 0s 84us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 34/50\n",
      "699/699 [==============================] - 0s 82us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 35/50\n",
      "699/699 [==============================] - 0s 80us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 36/50\n",
      "699/699 [==============================] - 0s 84us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 37/50\n",
      "699/699 [==============================] - 0s 76us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 38/50\n",
      "699/699 [==============================] - 0s 85us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 39/50\n",
      "699/699 [==============================] - 0s 83us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 40/50\n",
      "699/699 [==============================] - 0s 84us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 41/50\n",
      "699/699 [==============================] - 0s 78us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 42/50\n",
      "699/699 [==============================] - 0s 78us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 43/50\n",
      "699/699 [==============================] - 0s 76us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 44/50\n",
      "699/699 [==============================] - 0s 81us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 45/50\n",
      "699/699 [==============================] - 0s 78us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 46/50\n",
      "699/699 [==============================] - 0s 81us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 47/50\n",
      "699/699 [==============================] - 0s 83us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 48/50\n",
      "699/699 [==============================] - 0s 82us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 49/50\n",
      "699/699 [==============================] - 0s 80us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "Epoch 50/50\n",
      "699/699 [==============================] - 0s 81us/sample - loss: 0.0183 - val_loss: 0.0214\n",
      "第395个数，还剩3728个没有训练\n",
      "inv_hat [0.83535208 0.78153142 0.80740941 0.79437673 0.82253109 0.80402645\n",
      " 0.79547091 0.85344903 0.85325014 0.81596789 0.84400163 0.80502133\n",
      " 0.77525549 0.78481947 0.81278316 0.81457451 0.76350423 0.81487311\n",
      " 0.82054379 0.81686359 0.82342541 0.80870296 0.79507301 0.83386114\n",
      " 0.86140687 0.88350075 0.87822468 0.86051159 0.85404577 0.85155935]\n",
      "Test RMSE: 0.028\n",
      "Train on 551 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "551/551 [==============================] - 0s 84us/sample - loss: 0.0157 - val_loss: 0.0099\n",
      "Epoch 2/50\n",
      "551/551 [==============================] - 0s 84us/sample - loss: 0.0158 - val_loss: 0.0100\n",
      "Epoch 3/50\n",
      "551/551 [==============================] - 0s 89us/sample - loss: 0.0156 - val_loss: 0.0103\n",
      "Epoch 4/50\n",
      "551/551 [==============================] - 0s 83us/sample - loss: 0.0155 - val_loss: 0.0100\n",
      "Epoch 5/50\n",
      "551/551 [==============================] - 0s 84us/sample - loss: 0.0155 - val_loss: 0.0099\n",
      "Epoch 6/50\n",
      "551/551 [==============================] - 0s 87us/sample - loss: 0.0156 - val_loss: 0.0101\n",
      "Epoch 7/50\n",
      "551/551 [==============================] - 0s 86us/sample - loss: 0.0155 - val_loss: 0.0100\n",
      "Epoch 8/50\n",
      "551/551 [==============================] - 0s 84us/sample - loss: 0.0156 - val_loss: 0.0101\n",
      "Epoch 9/50\n",
      "551/551 [==============================] - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0101\n",
      "Epoch 10/50\n",
      "551/551 [==============================] - 0s 84us/sample - loss: 0.0157 - val_loss: 0.0103\n",
      "Epoch 11/50\n",
      "551/551 [==============================] - 0s 82us/sample - loss: 0.0156 - val_loss: 0.0100\n",
      "Epoch 12/50\n",
      "551/551 [==============================] - 0s 84us/sample - loss: 0.0157 - val_loss: 0.0103\n",
      "Epoch 13/50\n",
      "551/551 [==============================] - 0s 80us/sample - loss: 0.0155 - val_loss: 0.0099\n",
      "Epoch 14/50\n",
      "551/551 [==============================] - 0s 80us/sample - loss: 0.0155 - val_loss: 0.0101\n",
      "Epoch 15/50\n",
      "551/551 [==============================] - 0s 82us/sample - loss: 0.0154 - val_loss: 0.0098\n",
      "Epoch 16/50\n",
      "551/551 [==============================] - 0s 78us/sample - loss: 0.0155 - val_loss: 0.0100\n",
      "Epoch 17/50\n",
      "551/551 [==============================] - 0s 82us/sample - loss: 0.0154 - val_loss: 0.0098\n",
      "Epoch 18/50\n",
      "551/551 [==============================] - 0s 79us/sample - loss: 0.0154 - val_loss: 0.0100\n",
      "Epoch 19/50\n",
      "551/551 [==============================] - 0s 77us/sample - loss: 0.0154 - val_loss: 0.0098\n",
      "Epoch 20/50\n",
      "551/551 [==============================] - 0s 79us/sample - loss: 0.0154 - val_loss: 0.0099\n",
      "Epoch 21/50\n",
      "551/551 [==============================] - 0s 78us/sample - loss: 0.0153 - val_loss: 0.0098\n",
      "Epoch 22/50\n",
      "551/551 [==============================] - 0s 78us/sample - loss: 0.0154 - val_loss: 0.0099\n",
      "Epoch 23/50\n",
      "551/551 [==============================] - 0s 81us/sample - loss: 0.0153 - val_loss: 0.0098\n",
      "Epoch 24/50\n",
      "551/551 [==============================] - 0s 79us/sample - loss: 0.0154 - val_loss: 0.0099\n",
      "Epoch 25/50\n",
      "551/551 [==============================] - 0s 90us/sample - loss: 0.0153 - val_loss: 0.0098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "551/551 [==============================] - 0s 82us/sample - loss: 0.0153 - val_loss: 0.0098\n",
      "Epoch 27/50\n",
      "551/551 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0099\n",
      "Epoch 28/50\n",
      "551/551 [==============================] - 0s 85us/sample - loss: 0.0153 - val_loss: 0.0098\n",
      "Epoch 29/50\n",
      "551/551 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0099\n",
      "Epoch 30/50\n",
      "551/551 [==============================] - 0s 81us/sample - loss: 0.0153 - val_loss: 0.0099\n",
      "Epoch 31/50\n",
      "551/551 [==============================] - 0s 80us/sample - loss: 0.0153 - val_loss: 0.0099\n",
      "Epoch 32/50\n",
      "551/551 [==============================] - 0s 78us/sample - loss: 0.0153 - val_loss: 0.0099\n",
      "Epoch 33/50\n",
      "551/551 [==============================] - 0s 80us/sample - loss: 0.0153 - val_loss: 0.0098\n",
      "Epoch 34/50\n",
      "551/551 [==============================] - 0s 80us/sample - loss: 0.0153 - val_loss: 0.0099\n",
      "Epoch 35/50\n",
      "551/551 [==============================] - 0s 80us/sample - loss: 0.0153 - val_loss: 0.0098\n",
      "Epoch 36/50\n",
      "551/551 [==============================] - 0s 77us/sample - loss: 0.0153 - val_loss: 0.0099\n",
      "Epoch 37/50\n",
      "551/551 [==============================] - 0s 78us/sample - loss: 0.0153 - val_loss: 0.0099\n",
      "Epoch 38/50\n",
      "551/551 [==============================] - 0s 77us/sample - loss: 0.0153 - val_loss: 0.0098\n",
      "Epoch 39/50\n",
      "551/551 [==============================] - 0s 80us/sample - loss: 0.0153 - val_loss: 0.0099\n",
      "Epoch 40/50\n",
      "551/551 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0098\n",
      "Epoch 41/50\n",
      "551/551 [==============================] - 0s 81us/sample - loss: 0.0153 - val_loss: 0.0099\n",
      "Epoch 42/50\n",
      "551/551 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0098\n",
      "Epoch 43/50\n",
      "551/551 [==============================] - 0s 86us/sample - loss: 0.0153 - val_loss: 0.0098\n",
      "Epoch 44/50\n",
      "551/551 [==============================] - 0s 82us/sample - loss: 0.0153 - val_loss: 0.0098\n",
      "Epoch 45/50\n",
      "551/551 [==============================] - 0s 85us/sample - loss: 0.0153 - val_loss: 0.0098\n",
      "Epoch 46/50\n",
      "551/551 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0099\n",
      "Epoch 47/50\n",
      "551/551 [==============================] - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0098\n",
      "Epoch 48/50\n",
      "551/551 [==============================] - 0s 82us/sample - loss: 0.0153 - val_loss: 0.0098\n",
      "Epoch 49/50\n",
      "551/551 [==============================] - 0s 81us/sample - loss: 0.0153 - val_loss: 0.0098\n",
      "Epoch 50/50\n",
      "551/551 [==============================] - 0s 82us/sample - loss: 0.0153 - val_loss: 0.0098\n",
      "第396个数，还剩3727个没有训练\n",
      "inv_hat [1.06203852 1.06010205 1.06087761 1.06087761 1.05883906 1.0592281\n",
      " 1.05864444 1.05951956 1.05815765 1.0592281  1.06155513 1.06203852\n",
      " 1.06232817 1.06029609 1.06136173 1.06107133 1.06155513 1.06271422\n",
      " 1.0639662  1.06252124 1.06203852 1.06029609 1.05981095 1.05961672\n",
      " 1.05883906 1.05913088 1.05942239 1.05913088 1.05893636 1.06194188]\n",
      "Test RMSE: 0.001\n",
      "Train on 564 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "564/564 [==============================] - 0s 81us/sample - loss: 0.0212 - val_loss: 0.0115\n",
      "Epoch 2/50\n",
      "564/564 [==============================] - 0s 82us/sample - loss: 0.0213 - val_loss: 0.0118\n",
      "Epoch 3/50\n",
      "564/564 [==============================] - 0s 79us/sample - loss: 0.0212 - val_loss: 0.0114\n",
      "Epoch 4/50\n",
      "564/564 [==============================] - 0s 75us/sample - loss: 0.0214 - val_loss: 0.0119\n",
      "Epoch 5/50\n",
      "564/564 [==============================] - 0s 79us/sample - loss: 0.0212 - val_loss: 0.0114\n",
      "Epoch 6/50\n",
      "564/564 [==============================] - 0s 80us/sample - loss: 0.0213 - val_loss: 0.0118\n",
      "Epoch 7/50\n",
      "564/564 [==============================] - 0s 84us/sample - loss: 0.0212 - val_loss: 0.0114\n",
      "Epoch 8/50\n",
      "564/564 [==============================] - 0s 81us/sample - loss: 0.0213 - val_loss: 0.0118\n",
      "Epoch 9/50\n",
      "564/564 [==============================] - 0s 77us/sample - loss: 0.0212 - val_loss: 0.0114\n",
      "Epoch 10/50\n",
      "564/564 [==============================] - 0s 77us/sample - loss: 0.0214 - val_loss: 0.0118\n",
      "Epoch 11/50\n",
      "564/564 [==============================] - 0s 78us/sample - loss: 0.0212 - val_loss: 0.0114\n",
      "Epoch 12/50\n",
      "564/564 [==============================] - 0s 75us/sample - loss: 0.0213 - val_loss: 0.0118\n",
      "Epoch 13/50\n",
      "564/564 [==============================] - 0s 75us/sample - loss: 0.0212 - val_loss: 0.0115\n",
      "Epoch 14/50\n",
      "564/564 [==============================] - 0s 80us/sample - loss: 0.0213 - val_loss: 0.0119\n",
      "Epoch 15/50\n",
      "564/564 [==============================] - 0s 81us/sample - loss: 0.0212 - val_loss: 0.0114\n",
      "Epoch 16/50\n",
      "564/564 [==============================] - 0s 80us/sample - loss: 0.0214 - val_loss: 0.0119\n",
      "Epoch 17/50\n",
      "564/564 [==============================] - 0s 78us/sample - loss: 0.0212 - val_loss: 0.0114\n",
      "Epoch 18/50\n",
      "564/564 [==============================] - 0s 79us/sample - loss: 0.0214 - val_loss: 0.0118\n",
      "Epoch 19/50\n",
      "564/564 [==============================] - 0s 82us/sample - loss: 0.0212 - val_loss: 0.0113\n",
      "Epoch 20/50\n",
      "564/564 [==============================] - 0s 80us/sample - loss: 0.0214 - val_loss: 0.0118\n",
      "Epoch 21/50\n",
      "564/564 [==============================] - 0s 84us/sample - loss: 0.0212 - val_loss: 0.0114\n",
      "Epoch 22/50\n",
      "564/564 [==============================] - 0s 79us/sample - loss: 0.0213 - val_loss: 0.0119\n",
      "Epoch 23/50\n",
      "564/564 [==============================] - 0s 77us/sample - loss: 0.0212 - val_loss: 0.0113\n",
      "Epoch 24/50\n",
      "564/564 [==============================] - 0s 82us/sample - loss: 0.0214 - val_loss: 0.0117\n",
      "Epoch 25/50\n",
      "564/564 [==============================] - 0s 82us/sample - loss: 0.0212 - val_loss: 0.0120\n",
      "Epoch 26/50\n",
      "564/564 [==============================] - 0s 80us/sample - loss: 0.0212 - val_loss: 0.0115\n",
      "Epoch 27/50\n",
      "564/564 [==============================] - 0s 81us/sample - loss: 0.0213 - val_loss: 0.0118\n",
      "Epoch 28/50\n",
      "564/564 [==============================] - 0s 81us/sample - loss: 0.0212 - val_loss: 0.0114\n",
      "Epoch 29/50\n",
      "564/564 [==============================] - 0s 83us/sample - loss: 0.0213 - val_loss: 0.0118\n",
      "Epoch 30/50\n",
      "564/564 [==============================] - 0s 80us/sample - loss: 0.0211 - val_loss: 0.0113\n",
      "Epoch 31/50\n",
      "564/564 [==============================] - 0s 79us/sample - loss: 0.0214 - val_loss: 0.0117\n",
      "Epoch 32/50\n",
      "564/564 [==============================] - 0s 77us/sample - loss: 0.0212 - val_loss: 0.0119\n",
      "Epoch 33/50\n",
      "564/564 [==============================] - 0s 76us/sample - loss: 0.0212 - val_loss: 0.0116\n",
      "Epoch 34/50\n",
      "564/564 [==============================] - 0s 76us/sample - loss: 0.0213 - val_loss: 0.0119\n",
      "Epoch 35/50\n",
      "564/564 [==============================] - 0s 78us/sample - loss: 0.0212 - val_loss: 0.0114\n",
      "Epoch 36/50\n",
      "564/564 [==============================] - 0s 78us/sample - loss: 0.0213 - val_loss: 0.0118\n",
      "Epoch 37/50\n",
      "564/564 [==============================] - 0s 76us/sample - loss: 0.0212 - val_loss: 0.0115\n",
      "Epoch 38/50\n",
      "564/564 [==============================] - 0s 78us/sample - loss: 0.0213 - val_loss: 0.0120\n",
      "Epoch 39/50\n",
      "564/564 [==============================] - 0s 76us/sample - loss: 0.0212 - val_loss: 0.0114\n",
      "Epoch 40/50\n",
      "564/564 [==============================] - 0s 79us/sample - loss: 0.0213 - val_loss: 0.0119\n",
      "Epoch 41/50\n",
      "564/564 [==============================] - 0s 78us/sample - loss: 0.0212 - val_loss: 0.0113\n",
      "Epoch 42/50\n",
      "564/564 [==============================] - 0s 77us/sample - loss: 0.0214 - val_loss: 0.0118\n",
      "Epoch 43/50\n",
      "564/564 [==============================] - 0s 77us/sample - loss: 0.0212 - val_loss: 0.0116\n",
      "Epoch 44/50\n",
      "564/564 [==============================] - 0s 81us/sample - loss: 0.0213 - val_loss: 0.0122\n",
      "Epoch 45/50\n",
      "564/564 [==============================] - 0s 83us/sample - loss: 0.0212 - val_loss: 0.0115\n",
      "Epoch 46/50\n",
      "564/564 [==============================] - 0s 83us/sample - loss: 0.0213 - val_loss: 0.0119\n",
      "Epoch 47/50\n",
      "564/564 [==============================] - 0s 83us/sample - loss: 0.0212 - val_loss: 0.0113\n",
      "Epoch 48/50\n",
      "564/564 [==============================] - 0s 82us/sample - loss: 0.0214 - val_loss: 0.0117\n",
      "Epoch 49/50\n",
      "564/564 [==============================] - 0s 78us/sample - loss: 0.0212 - val_loss: 0.0118\n",
      "Epoch 50/50\n",
      "564/564 [==============================] - 0s 76us/sample - loss: 0.0213 - val_loss: 0.0116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第397个数，还剩3726个没有训练\n",
      "inv_hat [0.99778547 0.98896329 0.98993801 0.98798995 0.98121946 0.98218197\n",
      " 0.98218197 0.98701815 0.98218197 0.98604785 0.99483268 0.99581563\n",
      " 0.99189173 0.98411181 0.98314607 0.98025859 0.98218197 0.98314607\n",
      " 0.98701815 0.98025859 0.97834175 0.97452858 0.96980218 0.96980218\n",
      " 0.9669887  0.97014036 0.97101472 0.97014036 0.96839967 0.96667002]\n",
      "Test RMSE: 0.004\n",
      "Train on 514 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "514/514 [==============================] - 0s 84us/sample - loss: 0.0324 - val_loss: 0.0311\n",
      "Epoch 2/50\n",
      "514/514 [==============================] - 0s 86us/sample - loss: 0.0324 - val_loss: 0.0309\n",
      "Epoch 3/50\n",
      "514/514 [==============================] - 0s 84us/sample - loss: 0.0324 - val_loss: 0.0307\n",
      "Epoch 4/50\n",
      "514/514 [==============================] - 0s 82us/sample - loss: 0.0323 - val_loss: 0.0311\n",
      "Epoch 5/50\n",
      "514/514 [==============================] - 0s 88us/sample - loss: 0.0323 - val_loss: 0.0309\n",
      "Epoch 6/50\n",
      "514/514 [==============================] - 0s 87us/sample - loss: 0.0324 - val_loss: 0.0308\n",
      "Epoch 7/50\n",
      "514/514 [==============================] - 0s 91us/sample - loss: 0.0323 - val_loss: 0.0310\n",
      "Epoch 8/50\n",
      "514/514 [==============================] - 0s 91us/sample - loss: 0.0324 - val_loss: 0.0308\n",
      "Epoch 9/50\n",
      "514/514 [==============================] - 0s 97us/sample - loss: 0.0323 - val_loss: 0.0310\n",
      "Epoch 10/50\n",
      "514/514 [==============================] - 0s 92us/sample - loss: 0.0324 - val_loss: 0.0308\n",
      "Epoch 11/50\n",
      "514/514 [==============================] - 0s 92us/sample - loss: 0.0323 - val_loss: 0.0310\n",
      "Epoch 12/50\n",
      "514/514 [==============================] - 0s 88us/sample - loss: 0.0324 - val_loss: 0.0308\n",
      "Epoch 13/50\n",
      "514/514 [==============================] - 0s 91us/sample - loss: 0.0323 - val_loss: 0.0309\n",
      "Epoch 14/50\n",
      "514/514 [==============================] - 0s 90us/sample - loss: 0.0324 - val_loss: 0.0308\n",
      "Epoch 15/50\n",
      "514/514 [==============================] - 0s 91us/sample - loss: 0.0323 - val_loss: 0.0309\n",
      "Epoch 16/50\n",
      "514/514 [==============================] - 0s 88us/sample - loss: 0.0324 - val_loss: 0.0308\n",
      "Epoch 17/50\n",
      "514/514 [==============================] - 0s 85us/sample - loss: 0.0323 - val_loss: 0.0309\n",
      "Epoch 18/50\n",
      "514/514 [==============================] - 0s 83us/sample - loss: 0.0324 - val_loss: 0.0308\n",
      "Epoch 19/50\n",
      "514/514 [==============================] - 0s 83us/sample - loss: 0.0323 - val_loss: 0.0310\n",
      "Epoch 20/50\n",
      "514/514 [==============================] - 0s 86us/sample - loss: 0.0324 - val_loss: 0.0308\n",
      "Epoch 21/50\n",
      "514/514 [==============================] - 0s 90us/sample - loss: 0.0323 - val_loss: 0.0310\n",
      "Epoch 22/50\n",
      "514/514 [==============================] - 0s 88us/sample - loss: 0.0324 - val_loss: 0.0308\n",
      "Epoch 23/50\n",
      "514/514 [==============================] - 0s 82us/sample - loss: 0.0323 - val_loss: 0.0310\n",
      "Epoch 24/50\n",
      "514/514 [==============================] - 0s 90us/sample - loss: 0.0324 - val_loss: 0.0308\n",
      "Epoch 25/50\n",
      "514/514 [==============================] - 0s 88us/sample - loss: 0.0323 - val_loss: 0.0309\n",
      "Epoch 26/50\n",
      "514/514 [==============================] - 0s 86us/sample - loss: 0.0324 - val_loss: 0.0308\n",
      "Epoch 27/50\n",
      "514/514 [==============================] - 0s 90us/sample - loss: 0.0323 - val_loss: 0.0310\n",
      "Epoch 28/50\n",
      "514/514 [==============================] - 0s 87us/sample - loss: 0.0324 - val_loss: 0.0307\n",
      "Epoch 29/50\n",
      "514/514 [==============================] - 0s 84us/sample - loss: 0.0323 - val_loss: 0.0314\n",
      "Epoch 30/50\n",
      "514/514 [==============================] - 0s 90us/sample - loss: 0.0324 - val_loss: 0.0308\n",
      "Epoch 31/50\n",
      "514/514 [==============================] - 0s 85us/sample - loss: 0.0324 - val_loss: 0.0307\n",
      "Epoch 32/50\n",
      "514/514 [==============================] - 0s 86us/sample - loss: 0.0323 - val_loss: 0.0309\n",
      "Epoch 33/50\n",
      "514/514 [==============================] - 0s 91us/sample - loss: 0.0323 - val_loss: 0.0308\n",
      "Epoch 34/50\n",
      "514/514 [==============================] - 0s 92us/sample - loss: 0.0323 - val_loss: 0.0309\n",
      "Epoch 35/50\n",
      "514/514 [==============================] - 0s 97us/sample - loss: 0.0324 - val_loss: 0.0308\n",
      "Epoch 36/50\n",
      "514/514 [==============================] - 0s 95us/sample - loss: 0.0323 - val_loss: 0.0308\n",
      "Epoch 37/50\n",
      "514/514 [==============================] - 0s 92us/sample - loss: 0.0323 - val_loss: 0.0309\n",
      "Epoch 38/50\n",
      "514/514 [==============================] - 0s 90us/sample - loss: 0.0324 - val_loss: 0.0307\n",
      "Epoch 39/50\n",
      "514/514 [==============================] - 0s 86us/sample - loss: 0.0323 - val_loss: 0.0311\n",
      "Epoch 40/50\n",
      "514/514 [==============================] - 0s 95us/sample - loss: 0.0324 - val_loss: 0.0307\n",
      "Epoch 41/50\n",
      "514/514 [==============================] - 0s 88us/sample - loss: 0.0323 - val_loss: 0.0310\n",
      "Epoch 42/50\n",
      "514/514 [==============================] - 0s 86us/sample - loss: 0.0324 - val_loss: 0.0307\n",
      "Epoch 43/50\n",
      "514/514 [==============================] - 0s 90us/sample - loss: 0.0323 - val_loss: 0.0310\n",
      "Epoch 44/50\n",
      "514/514 [==============================] - 0s 86us/sample - loss: 0.0324 - val_loss: 0.0307\n",
      "Epoch 45/50\n",
      "514/514 [==============================] - 0s 84us/sample - loss: 0.0323 - val_loss: 0.0310\n",
      "Epoch 46/50\n",
      "514/514 [==============================] - 0s 86us/sample - loss: 0.0324 - val_loss: 0.0307\n",
      "Epoch 47/50\n",
      "514/514 [==============================] - 0s 85us/sample - loss: 0.0323 - val_loss: 0.0309\n",
      "Epoch 48/50\n",
      "514/514 [==============================] - 0s 83us/sample - loss: 0.0324 - val_loss: 0.0307\n",
      "Epoch 49/50\n",
      "514/514 [==============================] - 0s 82us/sample - loss: 0.0323 - val_loss: 0.0308\n",
      "Epoch 50/50\n",
      "514/514 [==============================] - 0s 91us/sample - loss: 0.0323 - val_loss: 0.0308\n",
      "第398个数，还剩3725个没有训练\n",
      "inv_hat [0.96508631 0.97007861 0.94352858 0.96012173 0.96210391 0.96210391\n",
      " 0.95519065 0.95322896 0.96210391 0.96012173 0.97710363 0.98012407\n",
      " 0.97107986 0.96309686 0.94932599 0.93404376 0.93498119 0.9512739\n",
      " 0.94065832 0.93875627 0.94065832 0.9408668  0.93896593 0.93991514\n",
      " 0.93896593 0.93991514 0.93991514 0.94277728 0.94277728 0.94373607]\n",
      "Test RMSE: 0.009\n",
      "Train on 495 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "495/495 [==============================] - 0s 75us/sample - loss: 0.0204 - val_loss: 0.0248\n",
      "Epoch 2/50\n",
      "495/495 [==============================] - 0s 78us/sample - loss: 0.0204 - val_loss: 0.0254\n",
      "Epoch 3/50\n",
      "495/495 [==============================] - 0s 79us/sample - loss: 0.0203 - val_loss: 0.0240\n",
      "Epoch 4/50\n",
      "495/495 [==============================] - 0s 85us/sample - loss: 0.0205 - val_loss: 0.0248\n",
      "Epoch 5/50\n",
      "495/495 [==============================] - 0s 82us/sample - loss: 0.0203 - val_loss: 0.0238\n",
      "Epoch 6/50\n",
      "495/495 [==============================] - 0s 82us/sample - loss: 0.0205 - val_loss: 0.0247\n",
      "Epoch 7/50\n",
      "495/495 [==============================] - 0s 80us/sample - loss: 0.0203 - val_loss: 0.0238\n",
      "Epoch 8/50\n",
      "495/495 [==============================] - 0s 84us/sample - loss: 0.0205 - val_loss: 0.0246\n",
      "Epoch 9/50\n",
      "495/495 [==============================] - 0s 82us/sample - loss: 0.0203 - val_loss: 0.0238\n",
      "Epoch 10/50\n",
      "495/495 [==============================] - 0s 77us/sample - loss: 0.0205 - val_loss: 0.0246\n",
      "Epoch 11/50\n",
      "495/495 [==============================] - 0s 77us/sample - loss: 0.0203 - val_loss: 0.0237\n",
      "Epoch 12/50\n",
      "495/495 [==============================] - 0s 80us/sample - loss: 0.0204 - val_loss: 0.0245\n",
      "Epoch 13/50\n",
      "495/495 [==============================] - 0s 80us/sample - loss: 0.0203 - val_loss: 0.0236\n",
      "Epoch 14/50\n",
      "495/495 [==============================] - 0s 79us/sample - loss: 0.0204 - val_loss: 0.0243\n",
      "Epoch 15/50\n",
      "495/495 [==============================] - 0s 77us/sample - loss: 0.0203 - val_loss: 0.0236\n",
      "Epoch 16/50\n",
      "495/495 [==============================] - 0s 80us/sample - loss: 0.0204 - val_loss: 0.0243\n",
      "Epoch 17/50\n",
      "495/495 [==============================] - 0s 78us/sample - loss: 0.0203 - val_loss: 0.0236\n",
      "Epoch 18/50\n",
      "495/495 [==============================] - 0s 79us/sample - loss: 0.0204 - val_loss: 0.0243\n",
      "Epoch 19/50\n",
      "495/495 [==============================] - 0s 77us/sample - loss: 0.0203 - val_loss: 0.0234\n",
      "Epoch 20/50\n",
      "495/495 [==============================] - 0s 80us/sample - loss: 0.0205 - val_loss: 0.0245\n",
      "Epoch 21/50\n",
      "495/495 [==============================] - 0s 80us/sample - loss: 0.0203 - val_loss: 0.0235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "495/495 [==============================] - 0s 80us/sample - loss: 0.0204 - val_loss: 0.0244\n",
      "Epoch 23/50\n",
      "495/495 [==============================] - 0s 82us/sample - loss: 0.0203 - val_loss: 0.0235\n",
      "Epoch 24/50\n",
      "495/495 [==============================] - 0s 80us/sample - loss: 0.0204 - val_loss: 0.0243\n",
      "Epoch 25/50\n",
      "495/495 [==============================] - 0s 78us/sample - loss: 0.0203 - val_loss: 0.0234\n",
      "Epoch 26/50\n",
      "495/495 [==============================] - 0s 77us/sample - loss: 0.0204 - val_loss: 0.0241\n",
      "Epoch 27/50\n",
      "495/495 [==============================] - 0s 83us/sample - loss: 0.0203 - val_loss: 0.0233\n",
      "Epoch 28/50\n",
      "495/495 [==============================] - 0s 82us/sample - loss: 0.0204 - val_loss: 0.0241\n",
      "Epoch 29/50\n",
      "495/495 [==============================] - 0s 82us/sample - loss: 0.0203 - val_loss: 0.0233\n",
      "Epoch 30/50\n",
      "495/495 [==============================] - 0s 78us/sample - loss: 0.0204 - val_loss: 0.0240\n",
      "Epoch 31/50\n",
      "495/495 [==============================] - 0s 81us/sample - loss: 0.0203 - val_loss: 0.0232\n",
      "Epoch 32/50\n",
      "495/495 [==============================] - 0s 81us/sample - loss: 0.0204 - val_loss: 0.0240\n",
      "Epoch 33/50\n",
      "495/495 [==============================] - 0s 79us/sample - loss: 0.0203 - val_loss: 0.0232\n",
      "Epoch 34/50\n",
      " 72/495 [===>..........................] - ETA: 0s - loss: 0.0079"
     ]
    }
   ],
   "source": [
    "start_time = time.clock()\n",
    "print('-----------starting-----------')\n",
    "# 设计网络\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(1, 3)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "daily_non_filter_len = len(daily_non_filter)\n",
    "\n",
    "y_predict = []\n",
    "\n",
    "for i in range(daily_non_filter_len):\n",
    "    \n",
    "\n",
    "    values = daily_non_filter[i].set_index('datetime')        #取第一个元素测试\n",
    "    encoder = LabelEncoder()              # 整数编码方向 \n",
    "\n",
    "    values['subscribe_status'] = encoder.fit_transform(values['subscribe_status'])\n",
    "    values['redeem_status'] = encoder.fit_transform(values['redeem_status'])\n",
    "    values = values.astype('float32')          # 确保所有数据是浮动的\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))        # 归一化特征\n",
    "    scaled = scaler.fit_transform(values)\n",
    "\n",
    "    reframed = series_to_supervised(scaled, 1, 1)       # 构建成监督学习问题\n",
    "\n",
    "    reframed = reframed.drop(reframed.columns[[4,5]], axis=1)       # 丢弃不想预测的列\n",
    "    # print(reframed.head())\n",
    "   \n",
    "    values = reframed.values\n",
    "#     split_pos = int(len(values) * 0.9)\n",
    "    train = values[:-30, :]\n",
    "    test = values[-30:, :]\n",
    "    \n",
    "    train_X, train_y = train[:, :-1], train[:, -1]\n",
    "    test_X, test_y = test[:, :-1], test[:, -1]\n",
    "    # 把输入重塑成3D格式 [样例， 时间步, 特征]\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    # print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "\n",
    "    \n",
    "    # 拟合网络\n",
    "    history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=1, shuffle=False)\n",
    "    # 绘制历史数据\n",
    "#     pyplot.plot(history.history['loss'], label='train')\n",
    "#     pyplot.plot(history.history['val_loss'], label='test')\n",
    "#     pyplot.legend()\n",
    "#     pyplot.show()\n",
    "\n",
    "    # 预测\n",
    "    yhat = model.predict(test_X)\n",
    "    test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "    # 反向缩放预测值\n",
    "    inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "    inv_yhat = inv_yhat[:,0]\n",
    "    # 反向缩放实际值\n",
    "    test_y = test_y.reshape((len(test_y), 1))\n",
    "    inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "    inv_y = scaler.inverse_transform(inv_y)\n",
    "    inv_y = inv_y[:,0]\n",
    "    # 计算RMSE\n",
    "    rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "    y_predict.append(inv_yhat)\n",
    "    if i%50==0:\n",
    "        y_predict_df = pd.DataFrame(y_predict)\n",
    "        y_predict_df.to_csv('../output/price_30.csv', mode = 'a', header = False)\n",
    "        del y_predict,y_predict_df\n",
    "        y_predict = []\n",
    "\n",
    "    print('第%s个数，还剩%s个没有训练' % (i,daily_non_filter_len-i))\n",
    "    print('inv_hat', inv_yhat)\n",
    "    print('Test RMSE: %.3f' % rmse)\n",
    "    \n",
    "    \n",
    "y_predict_df = pd.DataFrame(y_predict)\n",
    "y_predict_df.to_csv('../output/price_30.csv', mode = 'a', header = False)\n",
    "\n",
    "end_time = time.clock()\n",
    "used_time = start_time - end_time\n",
    "print('----------finished------------')\n",
    "print('used time:%s s'% used_time)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.192499</td>\n",
       "      <td>1.186400</td>\n",
       "      <td>1.189450</td>\n",
       "      <td>1.189450</td>\n",
       "      <td>1.182332</td>\n",
       "      <td>1.181315</td>\n",
       "      <td>1.180298</td>\n",
       "      <td>1.185384</td>\n",
       "      <td>1.182332</td>\n",
       "      <td>1.187417</td>\n",
       "      <td>...</td>\n",
       "      <td>1.176227</td>\n",
       "      <td>1.171137</td>\n",
       "      <td>1.165027</td>\n",
       "      <td>1.164009</td>\n",
       "      <td>1.156880</td>\n",
       "      <td>1.160954</td>\n",
       "      <td>1.159936</td>\n",
       "      <td>1.158917</td>\n",
       "      <td>1.155862</td>\n",
       "      <td>1.160954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.114926</td>\n",
       "      <td>1.110909</td>\n",
       "      <td>1.112918</td>\n",
       "      <td>1.112918</td>\n",
       "      <td>1.108900</td>\n",
       "      <td>1.108900</td>\n",
       "      <td>1.108900</td>\n",
       "      <td>1.109905</td>\n",
       "      <td>1.107894</td>\n",
       "      <td>1.110909</td>\n",
       "      <td>...</td>\n",
       "      <td>1.112918</td>\n",
       "      <td>1.110909</td>\n",
       "      <td>1.108900</td>\n",
       "      <td>1.108900</td>\n",
       "      <td>1.107894</td>\n",
       "      <td>1.107894</td>\n",
       "      <td>1.106889</td>\n",
       "      <td>1.106889</td>\n",
       "      <td>1.106889</td>\n",
       "      <td>1.108900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.016363</td>\n",
       "      <td>0.994545</td>\n",
       "      <td>0.997518</td>\n",
       "      <td>0.995536</td>\n",
       "      <td>0.969805</td>\n",
       "      <td>0.969805</td>\n",
       "      <td>0.969805</td>\n",
       "      <td>0.983653</td>\n",
       "      <td>0.969805</td>\n",
       "      <td>0.981673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976727</td>\n",
       "      <td>0.969805</td>\n",
       "      <td>0.951042</td>\n",
       "      <td>0.946110</td>\n",
       "      <td>0.934283</td>\n",
       "      <td>0.941180</td>\n",
       "      <td>0.942166</td>\n",
       "      <td>0.939209</td>\n",
       "      <td>0.932313</td>\n",
       "      <td>0.935268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.125664</td>\n",
       "      <td>1.124714</td>\n",
       "      <td>1.126614</td>\n",
       "      <td>1.123764</td>\n",
       "      <td>1.121865</td>\n",
       "      <td>1.119967</td>\n",
       "      <td>1.120916</td>\n",
       "      <td>1.123764</td>\n",
       "      <td>1.127564</td>\n",
       "      <td>1.127564</td>\n",
       "      <td>...</td>\n",
       "      <td>1.133270</td>\n",
       "      <td>1.134222</td>\n",
       "      <td>1.138030</td>\n",
       "      <td>1.141841</td>\n",
       "      <td>1.140888</td>\n",
       "      <td>1.140888</td>\n",
       "      <td>1.142795</td>\n",
       "      <td>1.138983</td>\n",
       "      <td>1.140888</td>\n",
       "      <td>1.147563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.034265</td>\n",
       "      <td>1.015009</td>\n",
       "      <td>1.027443</td>\n",
       "      <td>1.026553</td>\n",
       "      <td>1.005757</td>\n",
       "      <td>1.002317</td>\n",
       "      <td>1.004086</td>\n",
       "      <td>1.008019</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>1.004479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967031</td>\n",
       "      <td>0.966059</td>\n",
       "      <td>0.943982</td>\n",
       "      <td>0.941090</td>\n",
       "      <td>0.929841</td>\n",
       "      <td>0.940319</td>\n",
       "      <td>0.936277</td>\n",
       "      <td>0.933778</td>\n",
       "      <td>0.922083</td>\n",
       "      <td>0.922562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.921727</td>\n",
       "      <td>0.920743</td>\n",
       "      <td>0.920743</td>\n",
       "      <td>0.920743</td>\n",
       "      <td>0.918775</td>\n",
       "      <td>0.918775</td>\n",
       "      <td>0.918775</td>\n",
       "      <td>0.918775</td>\n",
       "      <td>0.918775</td>\n",
       "      <td>0.918775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894401</td>\n",
       "      <td>0.893435</td>\n",
       "      <td>0.889577</td>\n",
       "      <td>0.889577</td>\n",
       "      <td>0.889577</td>\n",
       "      <td>0.889577</td>\n",
       "      <td>0.889577</td>\n",
       "      <td>0.888614</td>\n",
       "      <td>0.887652</td>\n",
       "      <td>0.888614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.998998</td>\n",
       "      <td>0.995050</td>\n",
       "      <td>0.994066</td>\n",
       "      <td>0.994066</td>\n",
       "      <td>0.990147</td>\n",
       "      <td>0.991124</td>\n",
       "      <td>0.991124</td>\n",
       "      <td>0.993084</td>\n",
       "      <td>0.989171</td>\n",
       "      <td>0.991124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987225</td>\n",
       "      <td>0.984321</td>\n",
       "      <td>0.982394</td>\n",
       "      <td>0.980475</td>\n",
       "      <td>0.979519</td>\n",
       "      <td>0.980475</td>\n",
       "      <td>0.979519</td>\n",
       "      <td>0.979519</td>\n",
       "      <td>0.976664</td>\n",
       "      <td>0.978565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.517229</td>\n",
       "      <td>2.508119</td>\n",
       "      <td>2.508119</td>\n",
       "      <td>2.506094</td>\n",
       "      <td>2.499006</td>\n",
       "      <td>2.499006</td>\n",
       "      <td>2.502044</td>\n",
       "      <td>2.504069</td>\n",
       "      <td>2.495968</td>\n",
       "      <td>2.501032</td>\n",
       "      <td>...</td>\n",
       "      <td>2.502044</td>\n",
       "      <td>2.495968</td>\n",
       "      <td>2.492930</td>\n",
       "      <td>2.491917</td>\n",
       "      <td>2.487866</td>\n",
       "      <td>2.491917</td>\n",
       "      <td>2.489892</td>\n",
       "      <td>2.487866</td>\n",
       "      <td>2.486853</td>\n",
       "      <td>2.488879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.644589</td>\n",
       "      <td>1.642603</td>\n",
       "      <td>1.643596</td>\n",
       "      <td>1.640617</td>\n",
       "      <td>1.637637</td>\n",
       "      <td>1.635649</td>\n",
       "      <td>1.635649</td>\n",
       "      <td>1.639624</td>\n",
       "      <td>1.639624</td>\n",
       "      <td>1.642603</td>\n",
       "      <td>...</td>\n",
       "      <td>1.642603</td>\n",
       "      <td>1.641610</td>\n",
       "      <td>1.641610</td>\n",
       "      <td>1.642603</td>\n",
       "      <td>1.640617</td>\n",
       "      <td>1.640617</td>\n",
       "      <td>1.642603</td>\n",
       "      <td>1.642603</td>\n",
       "      <td>1.643596</td>\n",
       "      <td>1.645581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.001386</td>\n",
       "      <td>0.996423</td>\n",
       "      <td>0.996423</td>\n",
       "      <td>0.995435</td>\n",
       "      <td>0.991504</td>\n",
       "      <td>0.990526</td>\n",
       "      <td>0.989551</td>\n",
       "      <td>0.991504</td>\n",
       "      <td>0.989551</td>\n",
       "      <td>0.992484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995435</td>\n",
       "      <td>0.992484</td>\n",
       "      <td>0.990526</td>\n",
       "      <td>0.988578</td>\n",
       "      <td>0.986639</td>\n",
       "      <td>0.987607</td>\n",
       "      <td>0.986639</td>\n",
       "      <td>0.987607</td>\n",
       "      <td>0.986639</td>\n",
       "      <td>0.987607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.095821</td>\n",
       "      <td>1.095722</td>\n",
       "      <td>1.095722</td>\n",
       "      <td>1.095722</td>\n",
       "      <td>1.095821</td>\n",
       "      <td>1.095921</td>\n",
       "      <td>1.095821</td>\n",
       "      <td>1.095921</td>\n",
       "      <td>1.096020</td>\n",
       "      <td>1.096120</td>\n",
       "      <td>...</td>\n",
       "      <td>1.097561</td>\n",
       "      <td>1.097166</td>\n",
       "      <td>1.097364</td>\n",
       "      <td>1.097857</td>\n",
       "      <td>1.098153</td>\n",
       "      <td>1.098350</td>\n",
       "      <td>1.098547</td>\n",
       "      <td>1.098646</td>\n",
       "      <td>1.098941</td>\n",
       "      <td>1.099729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.777017</td>\n",
       "      <td>1.755887</td>\n",
       "      <td>1.762928</td>\n",
       "      <td>1.762928</td>\n",
       "      <td>1.751863</td>\n",
       "      <td>1.763297</td>\n",
       "      <td>1.757898</td>\n",
       "      <td>1.679565</td>\n",
       "      <td>1.670547</td>\n",
       "      <td>1.667543</td>\n",
       "      <td>...</td>\n",
       "      <td>1.627545</td>\n",
       "      <td>1.611582</td>\n",
       "      <td>1.598630</td>\n",
       "      <td>1.584699</td>\n",
       "      <td>1.574760</td>\n",
       "      <td>1.573767</td>\n",
       "      <td>1.571342</td>\n",
       "      <td>1.571342</td>\n",
       "      <td>1.564832</td>\n",
       "      <td>1.564832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.587856</td>\n",
       "      <td>0.574327</td>\n",
       "      <td>0.571430</td>\n",
       "      <td>0.568534</td>\n",
       "      <td>0.551178</td>\n",
       "      <td>0.549252</td>\n",
       "      <td>0.551178</td>\n",
       "      <td>0.558888</td>\n",
       "      <td>0.545400</td>\n",
       "      <td>0.551178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546363</td>\n",
       "      <td>0.545400</td>\n",
       "      <td>0.539625</td>\n",
       "      <td>0.540588</td>\n",
       "      <td>0.537701</td>\n",
       "      <td>0.539625</td>\n",
       "      <td>0.537701</td>\n",
       "      <td>0.535778</td>\n",
       "      <td>0.530970</td>\n",
       "      <td>0.532893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.059781</td>\n",
       "      <td>1.059781</td>\n",
       "      <td>1.059781</td>\n",
       "      <td>1.059618</td>\n",
       "      <td>1.058770</td>\n",
       "      <td>1.058770</td>\n",
       "      <td>1.058770</td>\n",
       "      <td>1.007474</td>\n",
       "      <td>1.008499</td>\n",
       "      <td>1.008499</td>\n",
       "      <td>...</td>\n",
       "      <td>1.009524</td>\n",
       "      <td>1.009524</td>\n",
       "      <td>1.011577</td>\n",
       "      <td>1.012604</td>\n",
       "      <td>1.012604</td>\n",
       "      <td>1.012604</td>\n",
       "      <td>1.012604</td>\n",
       "      <td>1.013632</td>\n",
       "      <td>1.013632</td>\n",
       "      <td>1.016718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.508569</td>\n",
       "      <td>1.507534</td>\n",
       "      <td>1.507534</td>\n",
       "      <td>1.507534</td>\n",
       "      <td>1.507534</td>\n",
       "      <td>1.507534</td>\n",
       "      <td>1.507534</td>\n",
       "      <td>1.507534</td>\n",
       "      <td>1.507534</td>\n",
       "      <td>1.507534</td>\n",
       "      <td>...</td>\n",
       "      <td>1.508569</td>\n",
       "      <td>1.507534</td>\n",
       "      <td>1.507534</td>\n",
       "      <td>1.507534</td>\n",
       "      <td>1.507534</td>\n",
       "      <td>1.507534</td>\n",
       "      <td>1.507534</td>\n",
       "      <td>1.506500</td>\n",
       "      <td>1.505465</td>\n",
       "      <td>1.507534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.240218</td>\n",
       "      <td>1.239236</td>\n",
       "      <td>1.239236</td>\n",
       "      <td>1.239236</td>\n",
       "      <td>1.240218</td>\n",
       "      <td>1.240218</td>\n",
       "      <td>1.240218</td>\n",
       "      <td>1.240218</td>\n",
       "      <td>1.240218</td>\n",
       "      <td>1.240218</td>\n",
       "      <td>...</td>\n",
       "      <td>1.241457</td>\n",
       "      <td>1.241457</td>\n",
       "      <td>1.241457</td>\n",
       "      <td>1.241457</td>\n",
       "      <td>1.241457</td>\n",
       "      <td>1.241457</td>\n",
       "      <td>1.241457</td>\n",
       "      <td>1.241457</td>\n",
       "      <td>1.242440</td>\n",
       "      <td>1.243421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.051280</td>\n",
       "      <td>1.051377</td>\n",
       "      <td>1.051573</td>\n",
       "      <td>1.051671</td>\n",
       "      <td>1.051866</td>\n",
       "      <td>1.052257</td>\n",
       "      <td>1.052452</td>\n",
       "      <td>1.052550</td>\n",
       "      <td>1.052745</td>\n",
       "      <td>1.052843</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000779</td>\n",
       "      <td>1.000877</td>\n",
       "      <td>1.001073</td>\n",
       "      <td>1.001171</td>\n",
       "      <td>1.001366</td>\n",
       "      <td>1.001759</td>\n",
       "      <td>1.001955</td>\n",
       "      <td>1.002053</td>\n",
       "      <td>1.002249</td>\n",
       "      <td>1.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.038430</td>\n",
       "      <td>1.037853</td>\n",
       "      <td>1.038238</td>\n",
       "      <td>1.037757</td>\n",
       "      <td>1.036604</td>\n",
       "      <td>1.036412</td>\n",
       "      <td>1.036892</td>\n",
       "      <td>1.036700</td>\n",
       "      <td>1.037277</td>\n",
       "      <td>1.037181</td>\n",
       "      <td>...</td>\n",
       "      <td>1.039585</td>\n",
       "      <td>1.039392</td>\n",
       "      <td>1.039296</td>\n",
       "      <td>1.040547</td>\n",
       "      <td>1.040932</td>\n",
       "      <td>1.040932</td>\n",
       "      <td>1.041413</td>\n",
       "      <td>1.041606</td>\n",
       "      <td>1.041895</td>\n",
       "      <td>1.045074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.064746</td>\n",
       "      <td>1.060373</td>\n",
       "      <td>1.061737</td>\n",
       "      <td>1.061932</td>\n",
       "      <td>1.058322</td>\n",
       "      <td>1.058029</td>\n",
       "      <td>1.057735</td>\n",
       "      <td>1.059495</td>\n",
       "      <td>1.057637</td>\n",
       "      <td>1.059104</td>\n",
       "      <td>...</td>\n",
       "      <td>1.058909</td>\n",
       "      <td>1.056756</td>\n",
       "      <td>1.054695</td>\n",
       "      <td>1.054105</td>\n",
       "      <td>1.052825</td>\n",
       "      <td>1.053711</td>\n",
       "      <td>1.052333</td>\n",
       "      <td>1.051840</td>\n",
       "      <td>1.051544</td>\n",
       "      <td>1.052628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.602262</td>\n",
       "      <td>0.605212</td>\n",
       "      <td>0.597741</td>\n",
       "      <td>0.594794</td>\n",
       "      <td>0.586549</td>\n",
       "      <td>0.587824</td>\n",
       "      <td>0.584587</td>\n",
       "      <td>0.568919</td>\n",
       "      <td>0.579883</td>\n",
       "      <td>0.572441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.528568</td>\n",
       "      <td>0.534312</td>\n",
       "      <td>0.519046</td>\n",
       "      <td>0.525554</td>\n",
       "      <td>0.522250</td>\n",
       "      <td>0.528958</td>\n",
       "      <td>0.521862</td>\n",
       "      <td>0.517397</td>\n",
       "      <td>0.537431</td>\n",
       "      <td>0.537333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.842742</td>\n",
       "      <td>1.834693</td>\n",
       "      <td>1.828656</td>\n",
       "      <td>1.826644</td>\n",
       "      <td>1.807534</td>\n",
       "      <td>1.807534</td>\n",
       "      <td>1.804518</td>\n",
       "      <td>1.813568</td>\n",
       "      <td>1.806529</td>\n",
       "      <td>1.815580</td>\n",
       "      <td>...</td>\n",
       "      <td>1.850792</td>\n",
       "      <td>1.838717</td>\n",
       "      <td>1.820609</td>\n",
       "      <td>1.812563</td>\n",
       "      <td>1.797479</td>\n",
       "      <td>1.803512</td>\n",
       "      <td>1.799490</td>\n",
       "      <td>1.803512</td>\n",
       "      <td>1.797479</td>\n",
       "      <td>1.811557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.457483</td>\n",
       "      <td>0.442599</td>\n",
       "      <td>0.442599</td>\n",
       "      <td>0.442599</td>\n",
       "      <td>0.427757</td>\n",
       "      <td>0.427757</td>\n",
       "      <td>0.429734</td>\n",
       "      <td>0.436657</td>\n",
       "      <td>0.425782</td>\n",
       "      <td>0.428745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422820</td>\n",
       "      <td>0.419859</td>\n",
       "      <td>0.414930</td>\n",
       "      <td>0.415915</td>\n",
       "      <td>0.413945</td>\n",
       "      <td>0.417887</td>\n",
       "      <td>0.416901</td>\n",
       "      <td>0.413945</td>\n",
       "      <td>0.409021</td>\n",
       "      <td>0.407053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.791556</td>\n",
       "      <td>1.790559</td>\n",
       "      <td>1.788564</td>\n",
       "      <td>1.784573</td>\n",
       "      <td>1.784573</td>\n",
       "      <td>1.784573</td>\n",
       "      <td>1.782577</td>\n",
       "      <td>1.781579</td>\n",
       "      <td>1.782577</td>\n",
       "      <td>1.783575</td>\n",
       "      <td>...</td>\n",
       "      <td>1.792553</td>\n",
       "      <td>1.793550</td>\n",
       "      <td>1.794547</td>\n",
       "      <td>1.794547</td>\n",
       "      <td>1.795544</td>\n",
       "      <td>1.795544</td>\n",
       "      <td>1.795544</td>\n",
       "      <td>1.794547</td>\n",
       "      <td>1.794547</td>\n",
       "      <td>1.795544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.073849</td>\n",
       "      <td>1.071858</td>\n",
       "      <td>1.071758</td>\n",
       "      <td>1.071758</td>\n",
       "      <td>1.070161</td>\n",
       "      <td>1.070261</td>\n",
       "      <td>1.069962</td>\n",
       "      <td>1.070960</td>\n",
       "      <td>1.070261</td>\n",
       "      <td>1.070860</td>\n",
       "      <td>...</td>\n",
       "      <td>1.073153</td>\n",
       "      <td>1.072456</td>\n",
       "      <td>1.072256</td>\n",
       "      <td>1.072456</td>\n",
       "      <td>1.072057</td>\n",
       "      <td>1.072256</td>\n",
       "      <td>1.072057</td>\n",
       "      <td>1.072157</td>\n",
       "      <td>1.072256</td>\n",
       "      <td>1.073750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.041261</td>\n",
       "      <td>1.041261</td>\n",
       "      <td>1.041261</td>\n",
       "      <td>1.042295</td>\n",
       "      <td>1.042295</td>\n",
       "      <td>1.042295</td>\n",
       "      <td>1.042295</td>\n",
       "      <td>1.042295</td>\n",
       "      <td>1.043328</td>\n",
       "      <td>1.042295</td>\n",
       "      <td>...</td>\n",
       "      <td>1.041261</td>\n",
       "      <td>1.040228</td>\n",
       "      <td>1.041261</td>\n",
       "      <td>1.041261</td>\n",
       "      <td>1.041261</td>\n",
       "      <td>1.042295</td>\n",
       "      <td>1.042295</td>\n",
       "      <td>1.042295</td>\n",
       "      <td>1.041261</td>\n",
       "      <td>1.042295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.053432</td>\n",
       "      <td>1.029613</td>\n",
       "      <td>1.034892</td>\n",
       "      <td>1.029711</td>\n",
       "      <td>1.005878</td>\n",
       "      <td>1.003264</td>\n",
       "      <td>1.004039</td>\n",
       "      <td>1.014902</td>\n",
       "      <td>1.002394</td>\n",
       "      <td>1.011600</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006750</td>\n",
       "      <td>0.998430</td>\n",
       "      <td>0.990522</td>\n",
       "      <td>0.985904</td>\n",
       "      <td>0.979186</td>\n",
       "      <td>0.982063</td>\n",
       "      <td>0.976217</td>\n",
       "      <td>0.974112</td>\n",
       "      <td>0.970576</td>\n",
       "      <td>0.972104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.882259</td>\n",
       "      <td>0.870303</td>\n",
       "      <td>0.875278</td>\n",
       "      <td>0.871297</td>\n",
       "      <td>0.856432</td>\n",
       "      <td>0.851502</td>\n",
       "      <td>0.853472</td>\n",
       "      <td>0.860385</td>\n",
       "      <td>0.854458</td>\n",
       "      <td>0.860385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851502</td>\n",
       "      <td>0.845604</td>\n",
       "      <td>0.834850</td>\n",
       "      <td>0.832903</td>\n",
       "      <td>0.825144</td>\n",
       "      <td>0.834850</td>\n",
       "      <td>0.834850</td>\n",
       "      <td>0.831930</td>\n",
       "      <td>0.829018</td>\n",
       "      <td>0.835824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.034258</td>\n",
       "      <td>1.010419</td>\n",
       "      <td>1.001010</td>\n",
       "      <td>0.993846</td>\n",
       "      <td>0.956018</td>\n",
       "      <td>0.952956</td>\n",
       "      <td>0.966085</td>\n",
       "      <td>0.974545</td>\n",
       "      <td>0.949133</td>\n",
       "      <td>0.958220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939693</td>\n",
       "      <td>0.934557</td>\n",
       "      <td>0.922706</td>\n",
       "      <td>0.928862</td>\n",
       "      <td>0.926113</td>\n",
       "      <td>0.935698</td>\n",
       "      <td>0.932088</td>\n",
       "      <td>0.924788</td>\n",
       "      <td>0.909122</td>\n",
       "      <td>0.901515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.249798</td>\n",
       "      <td>1.242039</td>\n",
       "      <td>1.240095</td>\n",
       "      <td>1.240095</td>\n",
       "      <td>1.235229</td>\n",
       "      <td>1.232304</td>\n",
       "      <td>1.234254</td>\n",
       "      <td>1.233279</td>\n",
       "      <td>1.235229</td>\n",
       "      <td>1.235229</td>\n",
       "      <td>...</td>\n",
       "      <td>1.242039</td>\n",
       "      <td>1.242039</td>\n",
       "      <td>1.244952</td>\n",
       "      <td>1.243010</td>\n",
       "      <td>1.243010</td>\n",
       "      <td>1.243010</td>\n",
       "      <td>1.239123</td>\n",
       "      <td>1.243010</td>\n",
       "      <td>1.241067</td>\n",
       "      <td>1.238150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.990656</td>\n",
       "      <td>0.968952</td>\n",
       "      <td>0.971149</td>\n",
       "      <td>0.967753</td>\n",
       "      <td>0.947910</td>\n",
       "      <td>0.947213</td>\n",
       "      <td>0.946018</td>\n",
       "      <td>0.957675</td>\n",
       "      <td>0.946118</td>\n",
       "      <td>0.955880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.953089</td>\n",
       "      <td>0.943928</td>\n",
       "      <td>0.933588</td>\n",
       "      <td>0.927035</td>\n",
       "      <td>0.916427</td>\n",
       "      <td>0.918904</td>\n",
       "      <td>0.913160</td>\n",
       "      <td>0.908806</td>\n",
       "      <td>0.905543</td>\n",
       "      <td>0.911180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4093</th>\n",
       "      <td>0.744658</td>\n",
       "      <td>0.726391</td>\n",
       "      <td>0.727348</td>\n",
       "      <td>0.727348</td>\n",
       "      <td>0.706416</td>\n",
       "      <td>0.704526</td>\n",
       "      <td>0.706416</td>\n",
       "      <td>0.716850</td>\n",
       "      <td>0.706416</td>\n",
       "      <td>0.711150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682740</td>\n",
       "      <td>0.678969</td>\n",
       "      <td>0.670514</td>\n",
       "      <td>0.671452</td>\n",
       "      <td>0.666770</td>\n",
       "      <td>0.670514</td>\n",
       "      <td>0.663967</td>\n",
       "      <td>0.662101</td>\n",
       "      <td>0.656515</td>\n",
       "      <td>0.658375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4094</th>\n",
       "      <td>1.069869</td>\n",
       "      <td>1.030931</td>\n",
       "      <td>1.030931</td>\n",
       "      <td>1.019862</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>0.994587</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>1.014819</td>\n",
       "      <td>0.990530</td>\n",
       "      <td>1.002691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984440</td>\n",
       "      <td>0.971228</td>\n",
       "      <td>0.963092</td>\n",
       "      <td>0.963092</td>\n",
       "      <td>0.947835</td>\n",
       "      <td>0.941736</td>\n",
       "      <td>0.923476</td>\n",
       "      <td>0.916396</td>\n",
       "      <td>0.912358</td>\n",
       "      <td>0.922463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4095</th>\n",
       "      <td>0.848482</td>\n",
       "      <td>0.840955</td>\n",
       "      <td>0.836634</td>\n",
       "      <td>0.830901</td>\n",
       "      <td>0.801859</td>\n",
       "      <td>0.794098</td>\n",
       "      <td>0.799266</td>\n",
       "      <td>0.809862</td>\n",
       "      <td>0.803436</td>\n",
       "      <td>0.822358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829662</td>\n",
       "      <td>0.833382</td>\n",
       "      <td>0.819998</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.805388</td>\n",
       "      <td>0.808089</td>\n",
       "      <td>0.800099</td>\n",
       "      <td>0.801118</td>\n",
       "      <td>0.789778</td>\n",
       "      <td>0.793730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4096</th>\n",
       "      <td>0.456715</td>\n",
       "      <td>0.452863</td>\n",
       "      <td>0.453825</td>\n",
       "      <td>0.452863</td>\n",
       "      <td>0.448067</td>\n",
       "      <td>0.447110</td>\n",
       "      <td>0.447110</td>\n",
       "      <td>0.449983</td>\n",
       "      <td>0.446153</td>\n",
       "      <td>0.448067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.445198</td>\n",
       "      <td>0.443289</td>\n",
       "      <td>0.440431</td>\n",
       "      <td>0.440431</td>\n",
       "      <td>0.437580</td>\n",
       "      <td>0.439480</td>\n",
       "      <td>0.439480</td>\n",
       "      <td>0.437580</td>\n",
       "      <td>0.435682</td>\n",
       "      <td>0.434734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4097</th>\n",
       "      <td>1.205817</td>\n",
       "      <td>1.174556</td>\n",
       "      <td>1.179157</td>\n",
       "      <td>1.178857</td>\n",
       "      <td>1.139595</td>\n",
       "      <td>1.137488</td>\n",
       "      <td>1.141099</td>\n",
       "      <td>1.153030</td>\n",
       "      <td>1.134077</td>\n",
       "      <td>1.142704</td>\n",
       "      <td>...</td>\n",
       "      <td>1.141701</td>\n",
       "      <td>1.135683</td>\n",
       "      <td>1.121832</td>\n",
       "      <td>1.123639</td>\n",
       "      <td>1.115004</td>\n",
       "      <td>1.126350</td>\n",
       "      <td>1.114702</td>\n",
       "      <td>1.109580</td>\n",
       "      <td>1.099232</td>\n",
       "      <td>1.100839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4098</th>\n",
       "      <td>1.157945</td>\n",
       "      <td>1.156950</td>\n",
       "      <td>1.157945</td>\n",
       "      <td>1.157945</td>\n",
       "      <td>1.157945</td>\n",
       "      <td>1.157945</td>\n",
       "      <td>1.157945</td>\n",
       "      <td>1.157945</td>\n",
       "      <td>1.157945</td>\n",
       "      <td>1.157945</td>\n",
       "      <td>...</td>\n",
       "      <td>1.161924</td>\n",
       "      <td>1.160929</td>\n",
       "      <td>1.160929</td>\n",
       "      <td>1.161924</td>\n",
       "      <td>1.161924</td>\n",
       "      <td>1.161924</td>\n",
       "      <td>1.162918</td>\n",
       "      <td>1.161924</td>\n",
       "      <td>1.162918</td>\n",
       "      <td>1.164908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4099</th>\n",
       "      <td>1.409482</td>\n",
       "      <td>1.376991</td>\n",
       "      <td>1.380483</td>\n",
       "      <td>1.375395</td>\n",
       "      <td>1.345031</td>\n",
       "      <td>1.344032</td>\n",
       "      <td>1.342232</td>\n",
       "      <td>1.360120</td>\n",
       "      <td>1.342432</td>\n",
       "      <td>1.357423</td>\n",
       "      <td>...</td>\n",
       "      <td>1.352028</td>\n",
       "      <td>1.338132</td>\n",
       "      <td>1.322128</td>\n",
       "      <td>1.311924</td>\n",
       "      <td>1.295620</td>\n",
       "      <td>1.299320</td>\n",
       "      <td>1.290421</td>\n",
       "      <td>1.283925</td>\n",
       "      <td>1.278931</td>\n",
       "      <td>1.287523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4100</th>\n",
       "      <td>0.873191</td>\n",
       "      <td>0.851804</td>\n",
       "      <td>0.854715</td>\n",
       "      <td>0.851804</td>\n",
       "      <td>0.833404</td>\n",
       "      <td>0.829538</td>\n",
       "      <td>0.836305</td>\n",
       "      <td>0.849864</td>\n",
       "      <td>0.838240</td>\n",
       "      <td>0.847925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835338</td>\n",
       "      <td>0.828572</td>\n",
       "      <td>0.812174</td>\n",
       "      <td>0.808322</td>\n",
       "      <td>0.798701</td>\n",
       "      <td>0.809284</td>\n",
       "      <td>0.808322</td>\n",
       "      <td>0.799663</td>\n",
       "      <td>0.798701</td>\n",
       "      <td>0.800624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4101</th>\n",
       "      <td>1.223423</td>\n",
       "      <td>1.214319</td>\n",
       "      <td>1.220521</td>\n",
       "      <td>1.217320</td>\n",
       "      <td>1.206219</td>\n",
       "      <td>1.206619</td>\n",
       "      <td>1.201921</td>\n",
       "      <td>1.207019</td>\n",
       "      <td>1.205919</td>\n",
       "      <td>1.212619</td>\n",
       "      <td>...</td>\n",
       "      <td>1.214719</td>\n",
       "      <td>1.213719</td>\n",
       "      <td>1.207819</td>\n",
       "      <td>1.211919</td>\n",
       "      <td>1.210019</td>\n",
       "      <td>1.213019</td>\n",
       "      <td>1.214719</td>\n",
       "      <td>1.216820</td>\n",
       "      <td>1.216520</td>\n",
       "      <td>1.218120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4102</th>\n",
       "      <td>1.004877</td>\n",
       "      <td>1.004977</td>\n",
       "      <td>1.005177</td>\n",
       "      <td>1.005277</td>\n",
       "      <td>1.005477</td>\n",
       "      <td>1.005878</td>\n",
       "      <td>1.006078</td>\n",
       "      <td>1.006179</td>\n",
       "      <td>1.006380</td>\n",
       "      <td>1.006480</td>\n",
       "      <td>...</td>\n",
       "      <td>1.009097</td>\n",
       "      <td>1.009197</td>\n",
       "      <td>1.009399</td>\n",
       "      <td>1.009499</td>\n",
       "      <td>1.009701</td>\n",
       "      <td>1.010103</td>\n",
       "      <td>1.010304</td>\n",
       "      <td>1.010404</td>\n",
       "      <td>1.010605</td>\n",
       "      <td>1.010706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4103</th>\n",
       "      <td>0.745000</td>\n",
       "      <td>0.728714</td>\n",
       "      <td>0.731884</td>\n",
       "      <td>0.732280</td>\n",
       "      <td>0.701466</td>\n",
       "      <td>0.699804</td>\n",
       "      <td>0.712049</td>\n",
       "      <td>0.722685</td>\n",
       "      <td>0.710478</td>\n",
       "      <td>0.725451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727923</td>\n",
       "      <td>0.727032</td>\n",
       "      <td>0.716770</td>\n",
       "      <td>0.717360</td>\n",
       "      <td>0.707143</td>\n",
       "      <td>0.711951</td>\n",
       "      <td>0.702737</td>\n",
       "      <td>0.696194</td>\n",
       "      <td>0.689574</td>\n",
       "      <td>0.690935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4104</th>\n",
       "      <td>0.888780</td>\n",
       "      <td>0.867955</td>\n",
       "      <td>0.876945</td>\n",
       "      <td>0.876747</td>\n",
       "      <td>0.856679</td>\n",
       "      <td>0.853018</td>\n",
       "      <td>0.849356</td>\n",
       "      <td>0.862615</td>\n",
       "      <td>0.865285</td>\n",
       "      <td>0.891144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892578</td>\n",
       "      <td>0.888842</td>\n",
       "      <td>0.871315</td>\n",
       "      <td>0.862714</td>\n",
       "      <td>0.848465</td>\n",
       "      <td>0.854502</td>\n",
       "      <td>0.852424</td>\n",
       "      <td>0.839558</td>\n",
       "      <td>0.836392</td>\n",
       "      <td>0.849851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105</th>\n",
       "      <td>1.248958</td>\n",
       "      <td>1.219030</td>\n",
       "      <td>1.223015</td>\n",
       "      <td>1.220026</td>\n",
       "      <td>1.194167</td>\n",
       "      <td>1.184247</td>\n",
       "      <td>1.186230</td>\n",
       "      <td>1.207086</td>\n",
       "      <td>1.190197</td>\n",
       "      <td>1.209075</td>\n",
       "      <td>...</td>\n",
       "      <td>1.202114</td>\n",
       "      <td>1.191190</td>\n",
       "      <td>1.179293</td>\n",
       "      <td>1.180284</td>\n",
       "      <td>1.163468</td>\n",
       "      <td>1.173354</td>\n",
       "      <td>1.169398</td>\n",
       "      <td>1.160506</td>\n",
       "      <td>1.147691</td>\n",
       "      <td>1.145722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4106</th>\n",
       "      <td>0.989656</td>\n",
       "      <td>0.991584</td>\n",
       "      <td>0.988695</td>\n",
       "      <td>0.986781</td>\n",
       "      <td>0.985827</td>\n",
       "      <td>0.982031</td>\n",
       "      <td>0.983925</td>\n",
       "      <td>0.989656</td>\n",
       "      <td>0.985827</td>\n",
       "      <td>0.986781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993521</td>\n",
       "      <td>0.992551</td>\n",
       "      <td>0.993521</td>\n",
       "      <td>0.993521</td>\n",
       "      <td>0.994494</td>\n",
       "      <td>0.994494</td>\n",
       "      <td>0.994494</td>\n",
       "      <td>0.994494</td>\n",
       "      <td>0.994494</td>\n",
       "      <td>0.994494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4107</th>\n",
       "      <td>1.071074</td>\n",
       "      <td>1.071074</td>\n",
       "      <td>1.071074</td>\n",
       "      <td>1.071074</td>\n",
       "      <td>1.071074</td>\n",
       "      <td>1.071074</td>\n",
       "      <td>1.071074</td>\n",
       "      <td>1.071074</td>\n",
       "      <td>1.072075</td>\n",
       "      <td>1.072075</td>\n",
       "      <td>...</td>\n",
       "      <td>1.074078</td>\n",
       "      <td>1.073077</td>\n",
       "      <td>1.073077</td>\n",
       "      <td>1.074078</td>\n",
       "      <td>1.074078</td>\n",
       "      <td>1.075080</td>\n",
       "      <td>1.075080</td>\n",
       "      <td>1.075080</td>\n",
       "      <td>1.075080</td>\n",
       "      <td>1.076082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108</th>\n",
       "      <td>0.971344</td>\n",
       "      <td>0.969768</td>\n",
       "      <td>0.968392</td>\n",
       "      <td>0.967410</td>\n",
       "      <td>0.966430</td>\n",
       "      <td>0.962620</td>\n",
       "      <td>0.961646</td>\n",
       "      <td>0.960187</td>\n",
       "      <td>0.959702</td>\n",
       "      <td>0.958634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947560</td>\n",
       "      <td>0.947560</td>\n",
       "      <td>0.947273</td>\n",
       "      <td>0.947369</td>\n",
       "      <td>0.947656</td>\n",
       "      <td>0.946604</td>\n",
       "      <td>0.946795</td>\n",
       "      <td>0.946700</td>\n",
       "      <td>0.946508</td>\n",
       "      <td>0.951684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4109</th>\n",
       "      <td>1.096011</td>\n",
       "      <td>1.094493</td>\n",
       "      <td>1.094290</td>\n",
       "      <td>1.096922</td>\n",
       "      <td>1.093582</td>\n",
       "      <td>1.093886</td>\n",
       "      <td>1.093784</td>\n",
       "      <td>1.093784</td>\n",
       "      <td>1.091051</td>\n",
       "      <td>1.090444</td>\n",
       "      <td>...</td>\n",
       "      <td>1.092772</td>\n",
       "      <td>1.092064</td>\n",
       "      <td>1.090545</td>\n",
       "      <td>1.091051</td>\n",
       "      <td>1.091051</td>\n",
       "      <td>1.091355</td>\n",
       "      <td>1.091659</td>\n",
       "      <td>1.091557</td>\n",
       "      <td>1.090646</td>\n",
       "      <td>1.092367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4110</th>\n",
       "      <td>1.124149</td>\n",
       "      <td>1.124149</td>\n",
       "      <td>1.124149</td>\n",
       "      <td>1.124149</td>\n",
       "      <td>1.124149</td>\n",
       "      <td>1.124149</td>\n",
       "      <td>1.125155</td>\n",
       "      <td>1.125155</td>\n",
       "      <td>1.125155</td>\n",
       "      <td>1.126161</td>\n",
       "      <td>...</td>\n",
       "      <td>1.129176</td>\n",
       "      <td>1.128171</td>\n",
       "      <td>1.128171</td>\n",
       "      <td>1.128171</td>\n",
       "      <td>1.128171</td>\n",
       "      <td>1.128171</td>\n",
       "      <td>1.128171</td>\n",
       "      <td>1.128171</td>\n",
       "      <td>1.128171</td>\n",
       "      <td>1.129176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4111</th>\n",
       "      <td>1.009457</td>\n",
       "      <td>0.988691</td>\n",
       "      <td>0.991653</td>\n",
       "      <td>0.987704</td>\n",
       "      <td>0.966034</td>\n",
       "      <td>0.962103</td>\n",
       "      <td>0.963085</td>\n",
       "      <td>0.979814</td>\n",
       "      <td>0.966034</td>\n",
       "      <td>0.974889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967017</td>\n",
       "      <td>0.959156</td>\n",
       "      <td>0.946407</td>\n",
       "      <td>0.942490</td>\n",
       "      <td>0.934665</td>\n",
       "      <td>0.942490</td>\n",
       "      <td>0.940533</td>\n",
       "      <td>0.933687</td>\n",
       "      <td>0.928803</td>\n",
       "      <td>0.934665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4112</th>\n",
       "      <td>0.795891</td>\n",
       "      <td>0.788727</td>\n",
       "      <td>0.790119</td>\n",
       "      <td>0.789224</td>\n",
       "      <td>0.784752</td>\n",
       "      <td>0.785646</td>\n",
       "      <td>0.785745</td>\n",
       "      <td>0.790716</td>\n",
       "      <td>0.786540</td>\n",
       "      <td>0.787932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788230</td>\n",
       "      <td>0.784156</td>\n",
       "      <td>0.781079</td>\n",
       "      <td>0.778202</td>\n",
       "      <td>0.773939</td>\n",
       "      <td>0.777012</td>\n",
       "      <td>0.777012</td>\n",
       "      <td>0.775921</td>\n",
       "      <td>0.774534</td>\n",
       "      <td>0.777507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4113</th>\n",
       "      <td>1.012987</td>\n",
       "      <td>1.010979</td>\n",
       "      <td>1.011983</td>\n",
       "      <td>1.011983</td>\n",
       "      <td>1.011983</td>\n",
       "      <td>1.010979</td>\n",
       "      <td>1.009974</td>\n",
       "      <td>1.009974</td>\n",
       "      <td>1.010979</td>\n",
       "      <td>1.011983</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011983</td>\n",
       "      <td>1.010979</td>\n",
       "      <td>1.010979</td>\n",
       "      <td>1.010979</td>\n",
       "      <td>1.011983</td>\n",
       "      <td>1.011983</td>\n",
       "      <td>1.011983</td>\n",
       "      <td>1.011983</td>\n",
       "      <td>1.010979</td>\n",
       "      <td>1.010413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4114</th>\n",
       "      <td>1.038028</td>\n",
       "      <td>1.011129</td>\n",
       "      <td>1.017101</td>\n",
       "      <td>1.015110</td>\n",
       "      <td>0.990245</td>\n",
       "      <td>0.988258</td>\n",
       "      <td>0.994221</td>\n",
       "      <td>1.002175</td>\n",
       "      <td>0.988258</td>\n",
       "      <td>0.993227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986272</td>\n",
       "      <td>0.981306</td>\n",
       "      <td>0.967411</td>\n",
       "      <td>0.971380</td>\n",
       "      <td>0.968403</td>\n",
       "      <td>0.976342</td>\n",
       "      <td>0.972372</td>\n",
       "      <td>0.967411</td>\n",
       "      <td>0.964436</td>\n",
       "      <td>0.965428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4115</th>\n",
       "      <td>1.025732</td>\n",
       "      <td>1.002550</td>\n",
       "      <td>1.002550</td>\n",
       "      <td>1.000635</td>\n",
       "      <td>0.967233</td>\n",
       "      <td>0.967233</td>\n",
       "      <td>0.962486</td>\n",
       "      <td>0.977704</td>\n",
       "      <td>0.959642</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945482</td>\n",
       "      <td>0.943604</td>\n",
       "      <td>0.928685</td>\n",
       "      <td>0.930537</td>\n",
       "      <td>0.924991</td>\n",
       "      <td>0.937051</td>\n",
       "      <td>0.934254</td>\n",
       "      <td>0.927760</td>\n",
       "      <td>0.916745</td>\n",
       "      <td>0.916745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4116</th>\n",
       "      <td>1.070177</td>\n",
       "      <td>1.070131</td>\n",
       "      <td>1.070177</td>\n",
       "      <td>1.070223</td>\n",
       "      <td>1.070177</td>\n",
       "      <td>1.070223</td>\n",
       "      <td>1.070269</td>\n",
       "      <td>1.070361</td>\n",
       "      <td>1.070361</td>\n",
       "      <td>1.070407</td>\n",
       "      <td>...</td>\n",
       "      <td>1.069428</td>\n",
       "      <td>1.069327</td>\n",
       "      <td>1.069227</td>\n",
       "      <td>1.069127</td>\n",
       "      <td>1.068926</td>\n",
       "      <td>1.068926</td>\n",
       "      <td>1.068826</td>\n",
       "      <td>1.068024</td>\n",
       "      <td>1.068024</td>\n",
       "      <td>1.068024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4117</th>\n",
       "      <td>1.183072</td>\n",
       "      <td>1.180090</td>\n",
       "      <td>1.180090</td>\n",
       "      <td>1.180090</td>\n",
       "      <td>1.176111</td>\n",
       "      <td>1.175116</td>\n",
       "      <td>1.175116</td>\n",
       "      <td>1.178101</td>\n",
       "      <td>1.175116</td>\n",
       "      <td>1.177106</td>\n",
       "      <td>...</td>\n",
       "      <td>1.177106</td>\n",
       "      <td>1.174121</td>\n",
       "      <td>1.172131</td>\n",
       "      <td>1.172131</td>\n",
       "      <td>1.171135</td>\n",
       "      <td>1.174121</td>\n",
       "      <td>1.173126</td>\n",
       "      <td>1.173126</td>\n",
       "      <td>1.172131</td>\n",
       "      <td>1.173126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4118</th>\n",
       "      <td>0.801082</td>\n",
       "      <td>0.778902</td>\n",
       "      <td>0.778902</td>\n",
       "      <td>0.777894</td>\n",
       "      <td>0.753735</td>\n",
       "      <td>0.751726</td>\n",
       "      <td>0.757755</td>\n",
       "      <td>0.766811</td>\n",
       "      <td>0.751726</td>\n",
       "      <td>0.760772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733354</td>\n",
       "      <td>0.724708</td>\n",
       "      <td>0.714760</td>\n",
       "      <td>0.716747</td>\n",
       "      <td>0.714760</td>\n",
       "      <td>0.724708</td>\n",
       "      <td>0.722715</td>\n",
       "      <td>0.715753</td>\n",
       "      <td>0.708810</td>\n",
       "      <td>0.706830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4119</th>\n",
       "      <td>0.819522</td>\n",
       "      <td>0.802874</td>\n",
       "      <td>0.804822</td>\n",
       "      <td>0.802874</td>\n",
       "      <td>0.780701</td>\n",
       "      <td>0.779747</td>\n",
       "      <td>0.778794</td>\n",
       "      <td>0.785485</td>\n",
       "      <td>0.776890</td>\n",
       "      <td>0.782612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.817553</td>\n",
       "      <td>0.805797</td>\n",
       "      <td>0.798987</td>\n",
       "      <td>0.787404</td>\n",
       "      <td>0.782612</td>\n",
       "      <td>0.780701</td>\n",
       "      <td>0.765533</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>0.756156</td>\n",
       "      <td>0.762712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4120</th>\n",
       "      <td>1.203269</td>\n",
       "      <td>1.204266</td>\n",
       "      <td>1.204266</td>\n",
       "      <td>1.204266</td>\n",
       "      <td>1.204748</td>\n",
       "      <td>1.204748</td>\n",
       "      <td>1.204748</td>\n",
       "      <td>1.204748</td>\n",
       "      <td>1.204266</td>\n",
       "      <td>1.204748</td>\n",
       "      <td>...</td>\n",
       "      <td>1.205206</td>\n",
       "      <td>1.204748</td>\n",
       "      <td>1.204748</td>\n",
       "      <td>1.205206</td>\n",
       "      <td>1.205206</td>\n",
       "      <td>1.205206</td>\n",
       "      <td>1.205206</td>\n",
       "      <td>1.205206</td>\n",
       "      <td>1.205661</td>\n",
       "      <td>1.206113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4121</th>\n",
       "      <td>1.007637</td>\n",
       "      <td>1.000955</td>\n",
       "      <td>1.001049</td>\n",
       "      <td>1.000488</td>\n",
       "      <td>0.995721</td>\n",
       "      <td>0.995631</td>\n",
       "      <td>0.995541</td>\n",
       "      <td>0.998176</td>\n",
       "      <td>0.995002</td>\n",
       "      <td>0.996897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999837</td>\n",
       "      <td>0.997718</td>\n",
       "      <td>0.995811</td>\n",
       "      <td>0.994020</td>\n",
       "      <td>0.991898</td>\n",
       "      <td>0.994020</td>\n",
       "      <td>0.994465</td>\n",
       "      <td>0.993753</td>\n",
       "      <td>0.992426</td>\n",
       "      <td>0.994198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4122</th>\n",
       "      <td>0.872590</td>\n",
       "      <td>0.855761</td>\n",
       "      <td>0.853780</td>\n",
       "      <td>0.851800</td>\n",
       "      <td>0.823121</td>\n",
       "      <td>0.814262</td>\n",
       "      <td>0.817212</td>\n",
       "      <td>0.829043</td>\n",
       "      <td>0.821150</td>\n",
       "      <td>0.836951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.843878</td>\n",
       "      <td>0.838929</td>\n",
       "      <td>0.827068</td>\n",
       "      <td>0.824108</td>\n",
       "      <td>0.810333</td>\n",
       "      <td>0.815245</td>\n",
       "      <td>0.807384</td>\n",
       "      <td>0.795576</td>\n",
       "      <td>0.783728</td>\n",
       "      <td>0.781748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4122 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1         2         3         4         5         6         7   \\\n",
       "1     1.192499  1.186400  1.189450  1.189450  1.182332  1.181315  1.180298   \n",
       "2     1.114926  1.110909  1.112918  1.112918  1.108900  1.108900  1.108900   \n",
       "3     1.016363  0.994545  0.997518  0.995536  0.969805  0.969805  0.969805   \n",
       "4     1.125664  1.124714  1.126614  1.123764  1.121865  1.119967  1.120916   \n",
       "5     1.034265  1.015009  1.027443  1.026553  1.005757  1.002317  1.004086   \n",
       "6     0.921727  0.920743  0.920743  0.920743  0.918775  0.918775  0.918775   \n",
       "7     0.998998  0.995050  0.994066  0.994066  0.990147  0.991124  0.991124   \n",
       "8     2.517229  2.508119  2.508119  2.506094  2.499006  2.499006  2.502044   \n",
       "9     1.644589  1.642603  1.643596  1.640617  1.637637  1.635649  1.635649   \n",
       "10    1.001386  0.996423  0.996423  0.995435  0.991504  0.990526  0.989551   \n",
       "11    1.095821  1.095722  1.095722  1.095722  1.095821  1.095921  1.095821   \n",
       "12    1.777017  1.755887  1.762928  1.762928  1.751863  1.763297  1.757898   \n",
       "13    0.587856  0.574327  0.571430  0.568534  0.551178  0.549252  0.551178   \n",
       "14    1.059781  1.059781  1.059781  1.059618  1.058770  1.058770  1.058770   \n",
       "15    1.508569  1.507534  1.507534  1.507534  1.507534  1.507534  1.507534   \n",
       "16    1.240218  1.239236  1.239236  1.239236  1.240218  1.240218  1.240218   \n",
       "17    1.051280  1.051377  1.051573  1.051671  1.051866  1.052257  1.052452   \n",
       "18    1.038430  1.037853  1.038238  1.037757  1.036604  1.036412  1.036892   \n",
       "19    1.064746  1.060373  1.061737  1.061932  1.058322  1.058029  1.057735   \n",
       "20    0.602262  0.605212  0.597741  0.594794  0.586549  0.587824  0.584587   \n",
       "21    1.842742  1.834693  1.828656  1.826644  1.807534  1.807534  1.804518   \n",
       "22    0.457483  0.442599  0.442599  0.442599  0.427757  0.427757  0.429734   \n",
       "23    1.791556  1.790559  1.788564  1.784573  1.784573  1.784573  1.782577   \n",
       "24    1.073849  1.071858  1.071758  1.071758  1.070161  1.070261  1.069962   \n",
       "25    1.041261  1.041261  1.041261  1.042295  1.042295  1.042295  1.042295   \n",
       "26    1.053432  1.029613  1.034892  1.029711  1.005878  1.003264  1.004039   \n",
       "27    0.882259  0.870303  0.875278  0.871297  0.856432  0.851502  0.853472   \n",
       "28    1.034258  1.010419  1.001010  0.993846  0.956018  0.952956  0.966085   \n",
       "29    1.249798  1.242039  1.240095  1.240095  1.235229  1.232304  1.234254   \n",
       "30    0.990656  0.968952  0.971149  0.967753  0.947910  0.947213  0.946018   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4093  0.744658  0.726391  0.727348  0.727348  0.706416  0.704526  0.706416   \n",
       "4094  1.069869  1.030931  1.030931  1.019862  0.995600  0.994587  0.995600   \n",
       "4095  0.848482  0.840955  0.836634  0.830901  0.801859  0.794098  0.799266   \n",
       "4096  0.456715  0.452863  0.453825  0.452863  0.448067  0.447110  0.447110   \n",
       "4097  1.205817  1.174556  1.179157  1.178857  1.139595  1.137488  1.141099   \n",
       "4098  1.157945  1.156950  1.157945  1.157945  1.157945  1.157945  1.157945   \n",
       "4099  1.409482  1.376991  1.380483  1.375395  1.345031  1.344032  1.342232   \n",
       "4100  0.873191  0.851804  0.854715  0.851804  0.833404  0.829538  0.836305   \n",
       "4101  1.223423  1.214319  1.220521  1.217320  1.206219  1.206619  1.201921   \n",
       "4102  1.004877  1.004977  1.005177  1.005277  1.005477  1.005878  1.006078   \n",
       "4103  0.745000  0.728714  0.731884  0.732280  0.701466  0.699804  0.712049   \n",
       "4104  0.888780  0.867955  0.876945  0.876747  0.856679  0.853018  0.849356   \n",
       "4105  1.248958  1.219030  1.223015  1.220026  1.194167  1.184247  1.186230   \n",
       "4106  0.989656  0.991584  0.988695  0.986781  0.985827  0.982031  0.983925   \n",
       "4107  1.071074  1.071074  1.071074  1.071074  1.071074  1.071074  1.071074   \n",
       "4108  0.971344  0.969768  0.968392  0.967410  0.966430  0.962620  0.961646   \n",
       "4109  1.096011  1.094493  1.094290  1.096922  1.093582  1.093886  1.093784   \n",
       "4110  1.124149  1.124149  1.124149  1.124149  1.124149  1.124149  1.125155   \n",
       "4111  1.009457  0.988691  0.991653  0.987704  0.966034  0.962103  0.963085   \n",
       "4112  0.795891  0.788727  0.790119  0.789224  0.784752  0.785646  0.785745   \n",
       "4113  1.012987  1.010979  1.011983  1.011983  1.011983  1.010979  1.009974   \n",
       "4114  1.038028  1.011129  1.017101  1.015110  0.990245  0.988258  0.994221   \n",
       "4115  1.025732  1.002550  1.002550  1.000635  0.967233  0.967233  0.962486   \n",
       "4116  1.070177  1.070131  1.070177  1.070223  1.070177  1.070223  1.070269   \n",
       "4117  1.183072  1.180090  1.180090  1.180090  1.176111  1.175116  1.175116   \n",
       "4118  0.801082  0.778902  0.778902  0.777894  0.753735  0.751726  0.757755   \n",
       "4119  0.819522  0.802874  0.804822  0.802874  0.780701  0.779747  0.778794   \n",
       "4120  1.203269  1.204266  1.204266  1.204266  1.204748  1.204748  1.204748   \n",
       "4121  1.007637  1.000955  1.001049  1.000488  0.995721  0.995631  0.995541   \n",
       "4122  0.872590  0.855761  0.853780  0.851800  0.823121  0.814262  0.817212   \n",
       "\n",
       "            8         9         10    ...           21        22        23  \\\n",
       "1     1.185384  1.182332  1.187417    ...     1.176227  1.171137  1.165027   \n",
       "2     1.109905  1.107894  1.110909    ...     1.112918  1.110909  1.108900   \n",
       "3     0.983653  0.969805  0.981673    ...     0.976727  0.969805  0.951042   \n",
       "4     1.123764  1.127564  1.127564    ...     1.133270  1.134222  1.138030   \n",
       "5     1.008019  0.999961  1.004479    ...     0.967031  0.966059  0.943982   \n",
       "6     0.918775  0.918775  0.918775    ...     0.894401  0.893435  0.889577   \n",
       "7     0.993084  0.989171  0.991124    ...     0.987225  0.984321  0.982394   \n",
       "8     2.504069  2.495968  2.501032    ...     2.502044  2.495968  2.492930   \n",
       "9     1.639624  1.639624  1.642603    ...     1.642603  1.641610  1.641610   \n",
       "10    0.991504  0.989551  0.992484    ...     0.995435  0.992484  0.990526   \n",
       "11    1.095921  1.096020  1.096120    ...     1.097561  1.097166  1.097364   \n",
       "12    1.679565  1.670547  1.667543    ...     1.627545  1.611582  1.598630   \n",
       "13    0.558888  0.545400  0.551178    ...     0.546363  0.545400  0.539625   \n",
       "14    1.007474  1.008499  1.008499    ...     1.009524  1.009524  1.011577   \n",
       "15    1.507534  1.507534  1.507534    ...     1.508569  1.507534  1.507534   \n",
       "16    1.240218  1.240218  1.240218    ...     1.241457  1.241457  1.241457   \n",
       "17    1.052550  1.052745  1.052843    ...     1.000779  1.000877  1.001073   \n",
       "18    1.036700  1.037277  1.037181    ...     1.039585  1.039392  1.039296   \n",
       "19    1.059495  1.057637  1.059104    ...     1.058909  1.056756  1.054695   \n",
       "20    0.568919  0.579883  0.572441    ...     0.528568  0.534312  0.519046   \n",
       "21    1.813568  1.806529  1.815580    ...     1.850792  1.838717  1.820609   \n",
       "22    0.436657  0.425782  0.428745    ...     0.422820  0.419859  0.414930   \n",
       "23    1.781579  1.782577  1.783575    ...     1.792553  1.793550  1.794547   \n",
       "24    1.070960  1.070261  1.070860    ...     1.073153  1.072456  1.072256   \n",
       "25    1.042295  1.043328  1.042295    ...     1.041261  1.040228  1.041261   \n",
       "26    1.014902  1.002394  1.011600    ...     1.006750  0.998430  0.990522   \n",
       "27    0.860385  0.854458  0.860385    ...     0.851502  0.845604  0.834850   \n",
       "28    0.974545  0.949133  0.958220    ...     0.939693  0.934557  0.922706   \n",
       "29    1.233279  1.235229  1.235229    ...     1.242039  1.242039  1.244952   \n",
       "30    0.957675  0.946118  0.955880    ...     0.953089  0.943928  0.933588   \n",
       "...        ...       ...       ...    ...          ...       ...       ...   \n",
       "4093  0.716850  0.706416  0.711150    ...     0.682740  0.678969  0.670514   \n",
       "4094  1.014819  0.990530  1.002691    ...     0.984440  0.971228  0.963092   \n",
       "4095  0.809862  0.803436  0.822358    ...     0.829662  0.833382  0.819998   \n",
       "4096  0.449983  0.446153  0.448067    ...     0.445198  0.443289  0.440431   \n",
       "4097  1.153030  1.134077  1.142704    ...     1.141701  1.135683  1.121832   \n",
       "4098  1.157945  1.157945  1.157945    ...     1.161924  1.160929  1.160929   \n",
       "4099  1.360120  1.342432  1.357423    ...     1.352028  1.338132  1.322128   \n",
       "4100  0.849864  0.838240  0.847925    ...     0.835338  0.828572  0.812174   \n",
       "4101  1.207019  1.205919  1.212619    ...     1.214719  1.213719  1.207819   \n",
       "4102  1.006179  1.006380  1.006480    ...     1.009097  1.009197  1.009399   \n",
       "4103  0.722685  0.710478  0.725451    ...     0.727923  0.727032  0.716770   \n",
       "4104  0.862615  0.865285  0.891144    ...     0.892578  0.888842  0.871315   \n",
       "4105  1.207086  1.190197  1.209075    ...     1.202114  1.191190  1.179293   \n",
       "4106  0.989656  0.985827  0.986781    ...     0.993521  0.992551  0.993521   \n",
       "4107  1.071074  1.072075  1.072075    ...     1.074078  1.073077  1.073077   \n",
       "4108  0.960187  0.959702  0.958634    ...     0.947560  0.947560  0.947273   \n",
       "4109  1.093784  1.091051  1.090444    ...     1.092772  1.092064  1.090545   \n",
       "4110  1.125155  1.125155  1.126161    ...     1.129176  1.128171  1.128171   \n",
       "4111  0.979814  0.966034  0.974889    ...     0.967017  0.959156  0.946407   \n",
       "4112  0.790716  0.786540  0.787932    ...     0.788230  0.784156  0.781079   \n",
       "4113  1.009974  1.010979  1.011983    ...     1.011983  1.010979  1.010979   \n",
       "4114  1.002175  0.988258  0.993227    ...     0.986272  0.981306  0.967411   \n",
       "4115  0.977704  0.959642  0.965333    ...     0.945482  0.943604  0.928685   \n",
       "4116  1.070361  1.070361  1.070407    ...     1.069428  1.069327  1.069227   \n",
       "4117  1.178101  1.175116  1.177106    ...     1.177106  1.174121  1.172131   \n",
       "4118  0.766811  0.751726  0.760772    ...     0.733354  0.724708  0.714760   \n",
       "4119  0.785485  0.776890  0.782612    ...     0.817553  0.805797  0.798987   \n",
       "4120  1.204748  1.204266  1.204748    ...     1.205206  1.204748  1.204748   \n",
       "4121  0.998176  0.995002  0.996897    ...     0.999837  0.997718  0.995811   \n",
       "4122  0.829043  0.821150  0.836951    ...     0.843878  0.838929  0.827068   \n",
       "\n",
       "            24        25        26        27        28        29        30  \n",
       "1     1.164009  1.156880  1.160954  1.159936  1.158917  1.155862  1.160954  \n",
       "2     1.108900  1.107894  1.107894  1.106889  1.106889  1.106889  1.108900  \n",
       "3     0.946110  0.934283  0.941180  0.942166  0.939209  0.932313  0.935268  \n",
       "4     1.141841  1.140888  1.140888  1.142795  1.138983  1.140888  1.147563  \n",
       "5     0.941090  0.929841  0.940319  0.936277  0.933778  0.922083  0.922562  \n",
       "6     0.889577  0.889577  0.889577  0.889577  0.888614  0.887652  0.888614  \n",
       "7     0.980475  0.979519  0.980475  0.979519  0.979519  0.976664  0.978565  \n",
       "8     2.491917  2.487866  2.491917  2.489892  2.487866  2.486853  2.488879  \n",
       "9     1.642603  1.640617  1.640617  1.642603  1.642603  1.643596  1.645581  \n",
       "10    0.988578  0.986639  0.987607  0.986639  0.987607  0.986639  0.987607  \n",
       "11    1.097857  1.098153  1.098350  1.098547  1.098646  1.098941  1.099729  \n",
       "12    1.584699  1.574760  1.573767  1.571342  1.571342  1.564832  1.564832  \n",
       "13    0.540588  0.537701  0.539625  0.537701  0.535778  0.530970  0.532893  \n",
       "14    1.012604  1.012604  1.012604  1.012604  1.013632  1.013632  1.016718  \n",
       "15    1.507534  1.507534  1.507534  1.507534  1.506500  1.505465  1.507534  \n",
       "16    1.241457  1.241457  1.241457  1.241457  1.241457  1.242440  1.243421  \n",
       "17    1.001171  1.001366  1.001759  1.001955  1.002053  1.002249  1.002347  \n",
       "18    1.040547  1.040932  1.040932  1.041413  1.041606  1.041895  1.045074  \n",
       "19    1.054105  1.052825  1.053711  1.052333  1.051840  1.051544  1.052628  \n",
       "20    0.525554  0.522250  0.528958  0.521862  0.517397  0.537431  0.537333  \n",
       "21    1.812563  1.797479  1.803512  1.799490  1.803512  1.797479  1.811557  \n",
       "22    0.415915  0.413945  0.417887  0.416901  0.413945  0.409021  0.407053  \n",
       "23    1.794547  1.795544  1.795544  1.795544  1.794547  1.794547  1.795544  \n",
       "24    1.072456  1.072057  1.072256  1.072057  1.072157  1.072256  1.073750  \n",
       "25    1.041261  1.041261  1.042295  1.042295  1.042295  1.041261  1.042295  \n",
       "26    0.985904  0.979186  0.982063  0.976217  0.974112  0.970576  0.972104  \n",
       "27    0.832903  0.825144  0.834850  0.834850  0.831930  0.829018  0.835824  \n",
       "28    0.928862  0.926113  0.935698  0.932088  0.924788  0.909122  0.901515  \n",
       "29    1.243010  1.243010  1.243010  1.239123  1.243010  1.241067  1.238150  \n",
       "30    0.927035  0.916427  0.918904  0.913160  0.908806  0.905543  0.911180  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4093  0.671452  0.666770  0.670514  0.663967  0.662101  0.656515  0.658375  \n",
       "4094  0.963092  0.947835  0.941736  0.923476  0.916396  0.912358  0.922463  \n",
       "4095  0.818772  0.805388  0.808089  0.800099  0.801118  0.789778  0.793730  \n",
       "4096  0.440431  0.437580  0.439480  0.439480  0.437580  0.435682  0.434734  \n",
       "4097  1.123639  1.115004  1.126350  1.114702  1.109580  1.099232  1.100839  \n",
       "4098  1.161924  1.161924  1.161924  1.162918  1.161924  1.162918  1.164908  \n",
       "4099  1.311924  1.295620  1.299320  1.290421  1.283925  1.278931  1.287523  \n",
       "4100  0.808322  0.798701  0.809284  0.808322  0.799663  0.798701  0.800624  \n",
       "4101  1.211919  1.210019  1.213019  1.214719  1.216820  1.216520  1.218120  \n",
       "4102  1.009499  1.009701  1.010103  1.010304  1.010404  1.010605  1.010706  \n",
       "4103  0.717360  0.707143  0.711951  0.702737  0.696194  0.689574  0.690935  \n",
       "4104  0.862714  0.848465  0.854502  0.852424  0.839558  0.836392  0.849851  \n",
       "4105  1.180284  1.163468  1.173354  1.169398  1.160506  1.147691  1.145722  \n",
       "4106  0.993521  0.994494  0.994494  0.994494  0.994494  0.994494  0.994494  \n",
       "4107  1.074078  1.074078  1.075080  1.075080  1.075080  1.075080  1.076082  \n",
       "4108  0.947369  0.947656  0.946604  0.946795  0.946700  0.946508  0.951684  \n",
       "4109  1.091051  1.091051  1.091355  1.091659  1.091557  1.090646  1.092367  \n",
       "4110  1.128171  1.128171  1.128171  1.128171  1.128171  1.128171  1.129176  \n",
       "4111  0.942490  0.934665  0.942490  0.940533  0.933687  0.928803  0.934665  \n",
       "4112  0.778202  0.773939  0.777012  0.777012  0.775921  0.774534  0.777507  \n",
       "4113  1.010979  1.011983  1.011983  1.011983  1.011983  1.010979  1.010413  \n",
       "4114  0.971380  0.968403  0.976342  0.972372  0.967411  0.964436  0.965428  \n",
       "4115  0.930537  0.924991  0.937051  0.934254  0.927760  0.916745  0.916745  \n",
       "4116  1.069127  1.068926  1.068926  1.068826  1.068024  1.068024  1.068024  \n",
       "4117  1.172131  1.171135  1.174121  1.173126  1.173126  1.172131  1.173126  \n",
       "4118  0.716747  0.714760  0.724708  0.722715  0.715753  0.708810  0.706830  \n",
       "4119  0.787404  0.782612  0.780701  0.765533  0.762712  0.756156  0.762712  \n",
       "4120  1.205206  1.205206  1.205206  1.205206  1.205206  1.205661  1.206113  \n",
       "4121  0.994020  0.991898  0.994020  0.994465  0.993753  0.992426  0.994198  \n",
       "4122  0.824108  0.810333  0.815245  0.807384  0.795576  0.783728  0.781748  \n",
       "\n",
       "[4122 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y = pd.read_csv('../output/price_30.csv', header = None)\n",
    "predict_y.drop(axis=0, index=0, inplace=True)\n",
    "predict_y.drop([0],axis=1, inplace=True)\n",
    "\n",
    "predict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table = predict_y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_pct: 0.0\n",
      "time_men 0.0\n",
      "time_cov 1.2999999999999998\n"
     ]
    }
   ],
   "source": [
    "start_time = time.clock()\n",
    "returns = table.pct_change()\n",
    "\n",
    "time_pct = time.clock()\n",
    "mean_returns = returns.mean()\n",
    "\n",
    "time_men = time.clock()\n",
    "cov_matrix = returns.cov()\n",
    "time_cov = time.clock()\n",
    "\n",
    "num_portfolios = 25000\n",
    "risk_free_rate = 0.0178\n",
    "print('time_pct:',time_pct-start_time)\n",
    "print('time_men',time_men-time_pct)\n",
    "print('time_cov',time_cov-time_men)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>4113</th>\n",
       "      <th>4114</th>\n",
       "      <th>4115</th>\n",
       "      <th>4116</th>\n",
       "      <th>4117</th>\n",
       "      <th>4118</th>\n",
       "      <th>4119</th>\n",
       "      <th>4120</th>\n",
       "      <th>4121</th>\n",
       "      <th>4122</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.568744e-05</td>\n",
       "      <td>5.224974e-06</td>\n",
       "      <td>4.250895e-05</td>\n",
       "      <td>7.418458e-07</td>\n",
       "      <td>4.404731e-05</td>\n",
       "      <td>8.788399e-06</td>\n",
       "      <td>9.047729e-06</td>\n",
       "      <td>6.591271e-06</td>\n",
       "      <td>2.880643e-06</td>\n",
       "      <td>8.345950e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>7.605373e-09</td>\n",
       "      <td>3.434817e-05</td>\n",
       "      <td>4.311914e-05</td>\n",
       "      <td>3.750477e-08</td>\n",
       "      <td>6.303670e-06</td>\n",
       "      <td>5.159674e-05</td>\n",
       "      <td>3.162165e-05</td>\n",
       "      <td>-3.619137e-08</td>\n",
       "      <td>1.017623e-05</td>\n",
       "      <td>3.997685e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.224974e-06</td>\n",
       "      <td>2.588201e-06</td>\n",
       "      <td>1.626361e-05</td>\n",
       "      <td>4.338848e-07</td>\n",
       "      <td>1.426579e-05</td>\n",
       "      <td>2.137112e-06</td>\n",
       "      <td>3.393895e-06</td>\n",
       "      <td>2.688773e-06</td>\n",
       "      <td>1.156395e-06</td>\n",
       "      <td>3.420878e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.662288e-07</td>\n",
       "      <td>1.455464e-05</td>\n",
       "      <td>1.675443e-05</td>\n",
       "      <td>2.522211e-08</td>\n",
       "      <td>2.312782e-06</td>\n",
       "      <td>1.994313e-05</td>\n",
       "      <td>1.551247e-05</td>\n",
       "      <td>-6.556827e-08</td>\n",
       "      <td>4.018776e-06</td>\n",
       "      <td>1.634418e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.250895e-05</td>\n",
       "      <td>1.626361e-05</td>\n",
       "      <td>1.393627e-04</td>\n",
       "      <td>-6.169997e-07</td>\n",
       "      <td>1.281993e-04</td>\n",
       "      <td>2.518835e-05</td>\n",
       "      <td>2.822921e-05</td>\n",
       "      <td>2.134629e-05</td>\n",
       "      <td>8.970613e-06</td>\n",
       "      <td>2.727159e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.345247e-07</td>\n",
       "      <td>1.170551e-04</td>\n",
       "      <td>1.474027e-04</td>\n",
       "      <td>1.920412e-07</td>\n",
       "      <td>2.002937e-05</td>\n",
       "      <td>1.726787e-04</td>\n",
       "      <td>1.138861e-04</td>\n",
       "      <td>-4.596297e-07</td>\n",
       "      <td>3.324988e-05</td>\n",
       "      <td>1.327023e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.418458e-07</td>\n",
       "      <td>4.338848e-07</td>\n",
       "      <td>-6.169997e-07</td>\n",
       "      <td>8.757740e-06</td>\n",
       "      <td>1.528506e-06</td>\n",
       "      <td>-6.887282e-07</td>\n",
       "      <td>-1.320159e-06</td>\n",
       "      <td>-3.263381e-07</td>\n",
       "      <td>2.567877e-06</td>\n",
       "      <td>-1.163435e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.491191e-08</td>\n",
       "      <td>2.526525e-06</td>\n",
       "      <td>-9.075807e-07</td>\n",
       "      <td>9.678345e-08</td>\n",
       "      <td>2.096404e-07</td>\n",
       "      <td>9.634211e-07</td>\n",
       "      <td>-6.051356e-06</td>\n",
       "      <td>4.906621e-08</td>\n",
       "      <td>-4.956119e-07</td>\n",
       "      <td>2.486381e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.404731e-05</td>\n",
       "      <td>1.426579e-05</td>\n",
       "      <td>1.281993e-04</td>\n",
       "      <td>1.528506e-06</td>\n",
       "      <td>1.581213e-04</td>\n",
       "      <td>3.290108e-05</td>\n",
       "      <td>2.524953e-05</td>\n",
       "      <td>1.855228e-05</td>\n",
       "      <td>7.742040e-06</td>\n",
       "      <td>2.264926e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.715533e-07</td>\n",
       "      <td>1.109097e-04</td>\n",
       "      <td>1.293060e-04</td>\n",
       "      <td>-5.239562e-07</td>\n",
       "      <td>1.855903e-05</td>\n",
       "      <td>1.651030e-04</td>\n",
       "      <td>8.269942e-05</td>\n",
       "      <td>-5.657993e-07</td>\n",
       "      <td>2.837736e-05</td>\n",
       "      <td>1.147631e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.788399e-06</td>\n",
       "      <td>2.137112e-06</td>\n",
       "      <td>2.518835e-05</td>\n",
       "      <td>-6.887282e-07</td>\n",
       "      <td>3.290108e-05</td>\n",
       "      <td>1.268224e-05</td>\n",
       "      <td>6.228122e-06</td>\n",
       "      <td>4.102095e-06</td>\n",
       "      <td>1.319615e-06</td>\n",
       "      <td>5.027280e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.287270e-07</td>\n",
       "      <td>2.042652e-05</td>\n",
       "      <td>2.495701e-05</td>\n",
       "      <td>-1.394046e-07</td>\n",
       "      <td>3.935835e-06</td>\n",
       "      <td>3.883270e-05</td>\n",
       "      <td>1.744398e-05</td>\n",
       "      <td>-1.358764e-08</td>\n",
       "      <td>6.055770e-06</td>\n",
       "      <td>1.702771e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.047729e-06</td>\n",
       "      <td>3.393895e-06</td>\n",
       "      <td>2.822921e-05</td>\n",
       "      <td>-1.320159e-06</td>\n",
       "      <td>2.524953e-05</td>\n",
       "      <td>6.228122e-06</td>\n",
       "      <td>7.140864e-06</td>\n",
       "      <td>4.950833e-06</td>\n",
       "      <td>1.360618e-06</td>\n",
       "      <td>6.310981e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.392152e-07</td>\n",
       "      <td>2.326375e-05</td>\n",
       "      <td>3.101525e-05</td>\n",
       "      <td>4.557602e-08</td>\n",
       "      <td>4.270544e-06</td>\n",
       "      <td>3.853775e-05</td>\n",
       "      <td>2.727766e-05</td>\n",
       "      <td>-9.584251e-08</td>\n",
       "      <td>7.635130e-06</td>\n",
       "      <td>2.631249e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.591271e-06</td>\n",
       "      <td>2.688773e-06</td>\n",
       "      <td>2.134629e-05</td>\n",
       "      <td>-3.263381e-07</td>\n",
       "      <td>1.855228e-05</td>\n",
       "      <td>4.102095e-06</td>\n",
       "      <td>4.950833e-06</td>\n",
       "      <td>4.311114e-06</td>\n",
       "      <td>1.292042e-06</td>\n",
       "      <td>4.739723e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.264111e-08</td>\n",
       "      <td>1.968560e-05</td>\n",
       "      <td>2.358019e-05</td>\n",
       "      <td>1.334633e-08</td>\n",
       "      <td>3.621594e-06</td>\n",
       "      <td>3.084361e-05</td>\n",
       "      <td>2.016689e-05</td>\n",
       "      <td>-5.603630e-08</td>\n",
       "      <td>6.039815e-06</td>\n",
       "      <td>2.139391e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.880643e-06</td>\n",
       "      <td>1.156395e-06</td>\n",
       "      <td>8.970613e-06</td>\n",
       "      <td>2.567877e-06</td>\n",
       "      <td>7.742040e-06</td>\n",
       "      <td>1.319615e-06</td>\n",
       "      <td>1.360618e-06</td>\n",
       "      <td>1.292042e-06</td>\n",
       "      <td>1.706870e-06</td>\n",
       "      <td>1.614760e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.127331e-08</td>\n",
       "      <td>8.097007e-06</td>\n",
       "      <td>9.010338e-06</td>\n",
       "      <td>5.985103e-08</td>\n",
       "      <td>1.446686e-06</td>\n",
       "      <td>1.159561e-05</td>\n",
       "      <td>4.840439e-06</td>\n",
       "      <td>4.383513e-08</td>\n",
       "      <td>1.935934e-06</td>\n",
       "      <td>9.039833e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.345950e-06</td>\n",
       "      <td>3.420878e-06</td>\n",
       "      <td>2.727159e-05</td>\n",
       "      <td>-1.163435e-06</td>\n",
       "      <td>2.264926e-05</td>\n",
       "      <td>5.027280e-06</td>\n",
       "      <td>6.310981e-06</td>\n",
       "      <td>4.739723e-06</td>\n",
       "      <td>1.614760e-06</td>\n",
       "      <td>6.492682e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.825942e-07</td>\n",
       "      <td>2.264110e-05</td>\n",
       "      <td>2.906542e-05</td>\n",
       "      <td>5.892814e-08</td>\n",
       "      <td>4.121944e-06</td>\n",
       "      <td>3.536379e-05</td>\n",
       "      <td>2.814172e-05</td>\n",
       "      <td>-1.195512e-07</td>\n",
       "      <td>7.364574e-06</td>\n",
       "      <td>2.638559e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.532050e-07</td>\n",
       "      <td>1.228490e-07</td>\n",
       "      <td>5.446985e-07</td>\n",
       "      <td>4.229582e-07</td>\n",
       "      <td>6.378346e-07</td>\n",
       "      <td>2.210161e-07</td>\n",
       "      <td>1.338374e-07</td>\n",
       "      <td>1.617427e-07</td>\n",
       "      <td>1.534772e-07</td>\n",
       "      <td>1.107448e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.281485e-08</td>\n",
       "      <td>7.339274e-07</td>\n",
       "      <td>5.856148e-07</td>\n",
       "      <td>-1.975836e-08</td>\n",
       "      <td>1.851068e-07</td>\n",
       "      <td>1.260478e-06</td>\n",
       "      <td>2.536804e-07</td>\n",
       "      <td>1.366678e-08</td>\n",
       "      <td>1.951502e-07</td>\n",
       "      <td>4.076881e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.525807e-05</td>\n",
       "      <td>6.196375e-06</td>\n",
       "      <td>4.349406e-05</td>\n",
       "      <td>-9.328892e-06</td>\n",
       "      <td>5.239594e-05</td>\n",
       "      <td>1.535479e-05</td>\n",
       "      <td>1.391260e-05</td>\n",
       "      <td>1.079193e-05</td>\n",
       "      <td>-1.048492e-06</td>\n",
       "      <td>1.269423e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.372840e-07</td>\n",
       "      <td>4.178020e-05</td>\n",
       "      <td>4.706760e-05</td>\n",
       "      <td>1.441242e-07</td>\n",
       "      <td>5.571787e-06</td>\n",
       "      <td>6.974419e-05</td>\n",
       "      <td>4.869052e-05</td>\n",
       "      <td>-1.454954e-07</td>\n",
       "      <td>1.545578e-05</td>\n",
       "      <td>2.884958e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.997733e-05</td>\n",
       "      <td>1.635505e-05</td>\n",
       "      <td>1.393017e-04</td>\n",
       "      <td>-1.348928e-06</td>\n",
       "      <td>1.200957e-04</td>\n",
       "      <td>2.315193e-05</td>\n",
       "      <td>3.000550e-05</td>\n",
       "      <td>2.326221e-05</td>\n",
       "      <td>9.074403e-06</td>\n",
       "      <td>2.828260e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.198161e-07</td>\n",
       "      <td>1.266631e-04</td>\n",
       "      <td>1.619159e-04</td>\n",
       "      <td>2.732996e-07</td>\n",
       "      <td>2.148093e-05</td>\n",
       "      <td>1.927441e-04</td>\n",
       "      <td>1.210796e-04</td>\n",
       "      <td>-3.404477e-07</td>\n",
       "      <td>3.527928e-05</td>\n",
       "      <td>1.422933e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-8.594628e-06</td>\n",
       "      <td>-1.730655e-06</td>\n",
       "      <td>-2.983611e-05</td>\n",
       "      <td>-5.553854e-07</td>\n",
       "      <td>-1.270460e-05</td>\n",
       "      <td>-2.132178e-06</td>\n",
       "      <td>-4.720025e-06</td>\n",
       "      <td>-2.150652e-06</td>\n",
       "      <td>-3.347039e-06</td>\n",
       "      <td>-4.409131e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.583392e-07</td>\n",
       "      <td>-1.743488e-05</td>\n",
       "      <td>-3.398285e-05</td>\n",
       "      <td>-2.598742e-07</td>\n",
       "      <td>-4.713538e-06</td>\n",
       "      <td>-2.700635e-05</td>\n",
       "      <td>-2.031900e-05</td>\n",
       "      <td>1.868915e-07</td>\n",
       "      <td>-5.462313e-06</td>\n",
       "      <td>-3.151738e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.035659e-06</td>\n",
       "      <td>4.163527e-07</td>\n",
       "      <td>2.641736e-06</td>\n",
       "      <td>4.473707e-07</td>\n",
       "      <td>2.482425e-06</td>\n",
       "      <td>4.687731e-07</td>\n",
       "      <td>7.304960e-07</td>\n",
       "      <td>5.453701e-07</td>\n",
       "      <td>2.520082e-07</td>\n",
       "      <td>6.199188e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>4.329125e-08</td>\n",
       "      <td>2.537301e-06</td>\n",
       "      <td>2.996994e-06</td>\n",
       "      <td>2.654370e-08</td>\n",
       "      <td>4.685266e-07</td>\n",
       "      <td>4.234174e-06</td>\n",
       "      <td>2.772962e-06</td>\n",
       "      <td>1.508215e-10</td>\n",
       "      <td>8.412698e-07</td>\n",
       "      <td>2.912580e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.195469e-07</td>\n",
       "      <td>9.351819e-08</td>\n",
       "      <td>2.031768e-07</td>\n",
       "      <td>3.058839e-07</td>\n",
       "      <td>1.435229e-07</td>\n",
       "      <td>1.444882e-07</td>\n",
       "      <td>5.886854e-08</td>\n",
       "      <td>7.018814e-08</td>\n",
       "      <td>8.748987e-08</td>\n",
       "      <td>1.075791e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.761933e-09</td>\n",
       "      <td>3.117627e-07</td>\n",
       "      <td>-2.835031e-07</td>\n",
       "      <td>7.929087e-09</td>\n",
       "      <td>8.771152e-09</td>\n",
       "      <td>-6.396714e-08</td>\n",
       "      <td>4.002564e-07</td>\n",
       "      <td>1.637248e-09</td>\n",
       "      <td>1.198567e-07</td>\n",
       "      <td>-5.320583e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.327680e-06</td>\n",
       "      <td>1.355262e-06</td>\n",
       "      <td>2.613365e-05</td>\n",
       "      <td>2.741063e-06</td>\n",
       "      <td>3.383579e-05</td>\n",
       "      <td>1.945849e-05</td>\n",
       "      <td>7.869959e-06</td>\n",
       "      <td>5.345713e-06</td>\n",
       "      <td>3.360055e-06</td>\n",
       "      <td>6.527940e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.989288e-06</td>\n",
       "      <td>2.304378e-05</td>\n",
       "      <td>3.303562e-05</td>\n",
       "      <td>4.498566e-08</td>\n",
       "      <td>5.744841e-06</td>\n",
       "      <td>7.981873e-05</td>\n",
       "      <td>2.244575e-05</td>\n",
       "      <td>1.398358e-07</td>\n",
       "      <td>7.936551e-06</td>\n",
       "      <td>2.339640e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.006198e-06</td>\n",
       "      <td>5.391374e-07</td>\n",
       "      <td>2.487192e-06</td>\n",
       "      <td>2.168980e-06</td>\n",
       "      <td>3.126638e-06</td>\n",
       "      <td>6.551230e-07</td>\n",
       "      <td>4.037846e-07</td>\n",
       "      <td>4.288468e-07</td>\n",
       "      <td>8.080016e-07</td>\n",
       "      <td>3.616590e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.454789e-08</td>\n",
       "      <td>3.357720e-06</td>\n",
       "      <td>2.516566e-06</td>\n",
       "      <td>1.729631e-08</td>\n",
       "      <td>5.404814e-07</td>\n",
       "      <td>4.500416e-06</td>\n",
       "      <td>1.519336e-06</td>\n",
       "      <td>2.458522e-08</td>\n",
       "      <td>5.716557e-07</td>\n",
       "      <td>2.265046e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.969972e-06</td>\n",
       "      <td>2.838541e-06</td>\n",
       "      <td>2.166229e-05</td>\n",
       "      <td>-3.355036e-07</td>\n",
       "      <td>1.985915e-05</td>\n",
       "      <td>4.052770e-06</td>\n",
       "      <td>4.840918e-06</td>\n",
       "      <td>3.597675e-06</td>\n",
       "      <td>1.253365e-06</td>\n",
       "      <td>4.711701e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>7.815415e-08</td>\n",
       "      <td>1.898887e-05</td>\n",
       "      <td>2.363300e-05</td>\n",
       "      <td>6.239649e-08</td>\n",
       "      <td>3.139751e-06</td>\n",
       "      <td>2.806285e-05</td>\n",
       "      <td>2.035434e-05</td>\n",
       "      <td>-9.175527e-08</td>\n",
       "      <td>5.628174e-06</td>\n",
       "      <td>2.075893e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.760597e-06</td>\n",
       "      <td>-1.193910e-06</td>\n",
       "      <td>1.798207e-05</td>\n",
       "      <td>1.509921e-05</td>\n",
       "      <td>6.346278e-05</td>\n",
       "      <td>2.411977e-05</td>\n",
       "      <td>-4.925032e-06</td>\n",
       "      <td>-1.205968e-06</td>\n",
       "      <td>5.346116e-06</td>\n",
       "      <td>-3.041043e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.999857e-06</td>\n",
       "      <td>2.931672e-05</td>\n",
       "      <td>1.077524e-05</td>\n",
       "      <td>-3.406889e-07</td>\n",
       "      <td>2.500226e-06</td>\n",
       "      <td>2.023407e-05</td>\n",
       "      <td>-3.543584e-05</td>\n",
       "      <td>1.135695e-06</td>\n",
       "      <td>-4.467637e-06</td>\n",
       "      <td>-1.374026e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.270806e-05</td>\n",
       "      <td>7.636838e-06</td>\n",
       "      <td>6.975921e-05</td>\n",
       "      <td>-4.796566e-07</td>\n",
       "      <td>6.322171e-05</td>\n",
       "      <td>1.397891e-05</td>\n",
       "      <td>1.570810e-05</td>\n",
       "      <td>1.144752e-05</td>\n",
       "      <td>4.474883e-06</td>\n",
       "      <td>1.503815e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.978723e-07</td>\n",
       "      <td>5.514143e-05</td>\n",
       "      <td>7.431373e-05</td>\n",
       "      <td>6.807558e-08</td>\n",
       "      <td>1.091159e-05</td>\n",
       "      <td>9.094629e-05</td>\n",
       "      <td>6.407485e-05</td>\n",
       "      <td>4.407066e-08</td>\n",
       "      <td>1.796289e-05</td>\n",
       "      <td>6.897932e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.493942e-05</td>\n",
       "      <td>1.871328e-05</td>\n",
       "      <td>1.569851e-04</td>\n",
       "      <td>-7.512126e-07</td>\n",
       "      <td>1.368278e-04</td>\n",
       "      <td>2.613212e-05</td>\n",
       "      <td>3.392916e-05</td>\n",
       "      <td>2.754899e-05</td>\n",
       "      <td>9.812051e-06</td>\n",
       "      <td>3.176271e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>5.285548e-07</td>\n",
       "      <td>1.483333e-04</td>\n",
       "      <td>1.847349e-04</td>\n",
       "      <td>4.219855e-07</td>\n",
       "      <td>2.496216e-05</td>\n",
       "      <td>2.238376e-04</td>\n",
       "      <td>1.368209e-04</td>\n",
       "      <td>-9.346718e-07</td>\n",
       "      <td>4.134386e-05</td>\n",
       "      <td>1.592718e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-3.025520e-07</td>\n",
       "      <td>1.518477e-08</td>\n",
       "      <td>3.461713e-08</td>\n",
       "      <td>4.161279e-07</td>\n",
       "      <td>-1.430844e-06</td>\n",
       "      <td>-3.890826e-07</td>\n",
       "      <td>1.896625e-08</td>\n",
       "      <td>7.140453e-08</td>\n",
       "      <td>1.790463e-07</td>\n",
       "      <td>2.573076e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>5.539541e-08</td>\n",
       "      <td>4.188556e-08</td>\n",
       "      <td>5.496288e-07</td>\n",
       "      <td>1.745347e-08</td>\n",
       "      <td>-4.405545e-08</td>\n",
       "      <td>-4.607562e-07</td>\n",
       "      <td>1.472602e-06</td>\n",
       "      <td>-7.961566e-09</td>\n",
       "      <td>2.125598e-07</td>\n",
       "      <td>6.156519e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.945462e-06</td>\n",
       "      <td>1.255200e-06</td>\n",
       "      <td>9.286232e-06</td>\n",
       "      <td>4.297001e-07</td>\n",
       "      <td>8.086034e-06</td>\n",
       "      <td>1.786594e-06</td>\n",
       "      <td>2.157090e-06</td>\n",
       "      <td>1.666811e-06</td>\n",
       "      <td>7.344409e-07</td>\n",
       "      <td>2.084838e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.787978e-08</td>\n",
       "      <td>8.400033e-06</td>\n",
       "      <td>1.035434e-05</td>\n",
       "      <td>1.300190e-08</td>\n",
       "      <td>1.479037e-06</td>\n",
       "      <td>1.298437e-05</td>\n",
       "      <td>8.923740e-06</td>\n",
       "      <td>-3.996238e-08</td>\n",
       "      <td>2.573953e-06</td>\n",
       "      <td>9.028067e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.186531e-07</td>\n",
       "      <td>7.011435e-08</td>\n",
       "      <td>3.045742e-07</td>\n",
       "      <td>3.330239e-07</td>\n",
       "      <td>-2.395413e-07</td>\n",
       "      <td>-4.458431e-07</td>\n",
       "      <td>2.306894e-07</td>\n",
       "      <td>-9.884448e-08</td>\n",
       "      <td>-2.197279e-08</td>\n",
       "      <td>8.553842e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.639458e-08</td>\n",
       "      <td>2.136823e-07</td>\n",
       "      <td>1.960618e-06</td>\n",
       "      <td>2.874904e-08</td>\n",
       "      <td>-7.705711e-08</td>\n",
       "      <td>5.738838e-07</td>\n",
       "      <td>3.477088e-07</td>\n",
       "      <td>-4.406566e-09</td>\n",
       "      <td>2.418680e-07</td>\n",
       "      <td>1.137172e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.489732e-05</td>\n",
       "      <td>1.483009e-05</td>\n",
       "      <td>1.148287e-04</td>\n",
       "      <td>-1.523740e-06</td>\n",
       "      <td>9.941812e-05</td>\n",
       "      <td>1.885915e-05</td>\n",
       "      <td>2.512078e-05</td>\n",
       "      <td>1.957528e-05</td>\n",
       "      <td>7.141506e-06</td>\n",
       "      <td>2.487265e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>5.646363e-07</td>\n",
       "      <td>1.020281e-04</td>\n",
       "      <td>1.280276e-04</td>\n",
       "      <td>2.319671e-07</td>\n",
       "      <td>1.705611e-05</td>\n",
       "      <td>1.525999e-04</td>\n",
       "      <td>1.091175e-04</td>\n",
       "      <td>-6.107879e-07</td>\n",
       "      <td>3.027460e-05</td>\n",
       "      <td>1.162478e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.755029e-05</td>\n",
       "      <td>1.284024e-05</td>\n",
       "      <td>1.082569e-04</td>\n",
       "      <td>1.999922e-06</td>\n",
       "      <td>1.154366e-04</td>\n",
       "      <td>2.271074e-05</td>\n",
       "      <td>2.239983e-05</td>\n",
       "      <td>1.704419e-05</td>\n",
       "      <td>7.363616e-06</td>\n",
       "      <td>2.098501e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.799154e-07</td>\n",
       "      <td>9.281656e-05</td>\n",
       "      <td>1.134348e-04</td>\n",
       "      <td>-1.086520e-07</td>\n",
       "      <td>1.622335e-05</td>\n",
       "      <td>1.402023e-04</td>\n",
       "      <td>7.824374e-05</td>\n",
       "      <td>-2.108744e-07</td>\n",
       "      <td>2.619516e-05</td>\n",
       "      <td>1.036047e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.920329e-05</td>\n",
       "      <td>1.639357e-05</td>\n",
       "      <td>1.440721e-04</td>\n",
       "      <td>-2.555974e-07</td>\n",
       "      <td>1.254327e-04</td>\n",
       "      <td>2.358687e-05</td>\n",
       "      <td>3.064008e-05</td>\n",
       "      <td>2.622786e-05</td>\n",
       "      <td>9.509292e-06</td>\n",
       "      <td>2.832799e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.759321e-07</td>\n",
       "      <td>1.409017e-04</td>\n",
       "      <td>1.730726e-04</td>\n",
       "      <td>3.366692e-07</td>\n",
       "      <td>2.402740e-05</td>\n",
       "      <td>2.144832e-04</td>\n",
       "      <td>1.229714e-04</td>\n",
       "      <td>-5.867357e-07</td>\n",
       "      <td>3.693378e-05</td>\n",
       "      <td>1.551432e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.638020e-06</td>\n",
       "      <td>8.157051e-07</td>\n",
       "      <td>5.609563e-06</td>\n",
       "      <td>-2.795150e-06</td>\n",
       "      <td>6.221237e-06</td>\n",
       "      <td>-1.412021e-06</td>\n",
       "      <td>1.176178e-06</td>\n",
       "      <td>-7.716717e-08</td>\n",
       "      <td>-4.834903e-07</td>\n",
       "      <td>1.733209e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000811e-07</td>\n",
       "      <td>4.922642e-06</td>\n",
       "      <td>5.748430e-06</td>\n",
       "      <td>-1.024139e-08</td>\n",
       "      <td>1.938834e-08</td>\n",
       "      <td>2.873112e-06</td>\n",
       "      <td>8.017441e-06</td>\n",
       "      <td>-2.024556e-07</td>\n",
       "      <td>9.023898e-07</td>\n",
       "      <td>7.511855e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3.872848e-05</td>\n",
       "      <td>1.555694e-05</td>\n",
       "      <td>1.230303e-04</td>\n",
       "      <td>-1.638040e-06</td>\n",
       "      <td>1.072043e-04</td>\n",
       "      <td>2.177144e-05</td>\n",
       "      <td>2.728942e-05</td>\n",
       "      <td>2.084997e-05</td>\n",
       "      <td>7.439340e-06</td>\n",
       "      <td>2.662918e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.728053e-07</td>\n",
       "      <td>1.045082e-04</td>\n",
       "      <td>1.325772e-04</td>\n",
       "      <td>3.000588e-07</td>\n",
       "      <td>1.814923e-05</td>\n",
       "      <td>1.583127e-04</td>\n",
       "      <td>1.167704e-04</td>\n",
       "      <td>-5.100576e-07</td>\n",
       "      <td>3.225458e-05</td>\n",
       "      <td>1.219852e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4093</th>\n",
       "      <td>2.586793e-05</td>\n",
       "      <td>1.109210e-05</td>\n",
       "      <td>9.308339e-05</td>\n",
       "      <td>-6.144371e-07</td>\n",
       "      <td>7.850826e-05</td>\n",
       "      <td>1.879410e-05</td>\n",
       "      <td>1.875896e-05</td>\n",
       "      <td>1.367156e-05</td>\n",
       "      <td>5.204149e-06</td>\n",
       "      <td>1.792224e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>5.641898e-08</td>\n",
       "      <td>8.110684e-05</td>\n",
       "      <td>1.014698e-04</td>\n",
       "      <td>1.519443e-07</td>\n",
       "      <td>1.358071e-05</td>\n",
       "      <td>1.185127e-04</td>\n",
       "      <td>9.156844e-05</td>\n",
       "      <td>-5.714817e-07</td>\n",
       "      <td>2.150045e-05</td>\n",
       "      <td>8.966917e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4094</th>\n",
       "      <td>4.558727e-05</td>\n",
       "      <td>2.014173e-05</td>\n",
       "      <td>1.465104e-04</td>\n",
       "      <td>3.010458e-06</td>\n",
       "      <td>1.180302e-04</td>\n",
       "      <td>2.354543e-05</td>\n",
       "      <td>3.366911e-05</td>\n",
       "      <td>2.600474e-05</td>\n",
       "      <td>1.043690e-05</td>\n",
       "      <td>3.261114e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.212629e-07</td>\n",
       "      <td>1.307694e-04</td>\n",
       "      <td>1.613279e-04</td>\n",
       "      <td>6.949925e-07</td>\n",
       "      <td>2.189297e-05</td>\n",
       "      <td>1.953968e-04</td>\n",
       "      <td>1.520137e-04</td>\n",
       "      <td>-4.878855e-07</td>\n",
       "      <td>3.936963e-05</td>\n",
       "      <td>1.499409e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4095</th>\n",
       "      <td>3.547772e-05</td>\n",
       "      <td>1.425629e-05</td>\n",
       "      <td>1.162222e-04</td>\n",
       "      <td>3.361096e-06</td>\n",
       "      <td>1.071408e-04</td>\n",
       "      <td>1.723934e-05</td>\n",
       "      <td>2.279232e-05</td>\n",
       "      <td>1.757160e-05</td>\n",
       "      <td>8.739828e-06</td>\n",
       "      <td>2.236052e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.523761e-07</td>\n",
       "      <td>9.499312e-05</td>\n",
       "      <td>1.263218e-04</td>\n",
       "      <td>-1.808669e-07</td>\n",
       "      <td>1.721469e-05</td>\n",
       "      <td>1.542316e-04</td>\n",
       "      <td>1.005544e-04</td>\n",
       "      <td>-4.469896e-07</td>\n",
       "      <td>2.684135e-05</td>\n",
       "      <td>1.412660e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4096</th>\n",
       "      <td>1.881032e-05</td>\n",
       "      <td>6.744387e-06</td>\n",
       "      <td>6.013527e-05</td>\n",
       "      <td>-9.908233e-07</td>\n",
       "      <td>5.697378e-05</td>\n",
       "      <td>1.123702e-05</td>\n",
       "      <td>1.241453e-05</td>\n",
       "      <td>9.838813e-06</td>\n",
       "      <td>3.583238e-06</td>\n",
       "      <td>1.175391e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.120832e-08</td>\n",
       "      <td>5.165116e-05</td>\n",
       "      <td>6.599072e-05</td>\n",
       "      <td>3.989528e-08</td>\n",
       "      <td>9.132043e-06</td>\n",
       "      <td>7.993076e-05</td>\n",
       "      <td>4.755854e-05</td>\n",
       "      <td>-1.623801e-07</td>\n",
       "      <td>1.488344e-05</td>\n",
       "      <td>6.033145e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4097</th>\n",
       "      <td>4.250725e-05</td>\n",
       "      <td>1.774742e-05</td>\n",
       "      <td>1.412982e-04</td>\n",
       "      <td>-6.143095e-08</td>\n",
       "      <td>1.294573e-04</td>\n",
       "      <td>2.337761e-05</td>\n",
       "      <td>3.026032e-05</td>\n",
       "      <td>2.343254e-05</td>\n",
       "      <td>8.549245e-06</td>\n",
       "      <td>2.891009e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.207822e-07</td>\n",
       "      <td>1.303281e-04</td>\n",
       "      <td>1.630859e-04</td>\n",
       "      <td>4.428083e-07</td>\n",
       "      <td>2.134651e-05</td>\n",
       "      <td>1.934541e-04</td>\n",
       "      <td>1.301731e-04</td>\n",
       "      <td>-7.770277e-07</td>\n",
       "      <td>3.580458e-05</td>\n",
       "      <td>1.464218e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4098</th>\n",
       "      <td>1.015093e-06</td>\n",
       "      <td>4.828413e-07</td>\n",
       "      <td>2.547294e-06</td>\n",
       "      <td>1.035720e-06</td>\n",
       "      <td>3.357927e-06</td>\n",
       "      <td>7.607248e-07</td>\n",
       "      <td>4.249189e-07</td>\n",
       "      <td>4.917585e-07</td>\n",
       "      <td>3.835568e-07</td>\n",
       "      <td>4.068485e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>4.549063e-08</td>\n",
       "      <td>2.757882e-06</td>\n",
       "      <td>1.940138e-06</td>\n",
       "      <td>-3.452441e-08</td>\n",
       "      <td>4.750004e-07</td>\n",
       "      <td>4.071463e-06</td>\n",
       "      <td>1.519936e-06</td>\n",
       "      <td>1.484500e-08</td>\n",
       "      <td>6.681759e-07</td>\n",
       "      <td>2.079247e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4099</th>\n",
       "      <td>4.155373e-05</td>\n",
       "      <td>1.665479e-05</td>\n",
       "      <td>1.318744e-04</td>\n",
       "      <td>-1.674552e-06</td>\n",
       "      <td>1.150982e-04</td>\n",
       "      <td>2.339123e-05</td>\n",
       "      <td>2.922678e-05</td>\n",
       "      <td>2.226983e-05</td>\n",
       "      <td>8.004293e-06</td>\n",
       "      <td>2.847672e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.180425e-07</td>\n",
       "      <td>1.117336e-04</td>\n",
       "      <td>1.420141e-04</td>\n",
       "      <td>3.236353e-07</td>\n",
       "      <td>1.942981e-05</td>\n",
       "      <td>1.696614e-04</td>\n",
       "      <td>1.249192e-04</td>\n",
       "      <td>-5.298777e-07</td>\n",
       "      <td>3.447358e-05</td>\n",
       "      <td>1.308266e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4100</th>\n",
       "      <td>5.080256e-05</td>\n",
       "      <td>1.814053e-05</td>\n",
       "      <td>1.587908e-04</td>\n",
       "      <td>9.913619e-07</td>\n",
       "      <td>1.581796e-04</td>\n",
       "      <td>3.408913e-05</td>\n",
       "      <td>3.302245e-05</td>\n",
       "      <td>2.702521e-05</td>\n",
       "      <td>1.050042e-05</td>\n",
       "      <td>3.127294e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.888989e-07</td>\n",
       "      <td>1.406761e-04</td>\n",
       "      <td>1.682578e-04</td>\n",
       "      <td>9.349222e-08</td>\n",
       "      <td>2.479239e-05</td>\n",
       "      <td>2.166195e-04</td>\n",
       "      <td>1.227876e-04</td>\n",
       "      <td>-5.250752e-07</td>\n",
       "      <td>3.996727e-05</td>\n",
       "      <td>1.542530e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4101</th>\n",
       "      <td>1.524689e-05</td>\n",
       "      <td>6.467879e-06</td>\n",
       "      <td>5.052593e-05</td>\n",
       "      <td>2.209504e-06</td>\n",
       "      <td>4.813239e-05</td>\n",
       "      <td>1.044824e-05</td>\n",
       "      <td>1.026324e-05</td>\n",
       "      <td>7.998512e-06</td>\n",
       "      <td>4.473185e-06</td>\n",
       "      <td>1.056798e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.767312e-07</td>\n",
       "      <td>4.543401e-05</td>\n",
       "      <td>5.757598e-05</td>\n",
       "      <td>7.534218e-08</td>\n",
       "      <td>7.554369e-06</td>\n",
       "      <td>7.220193e-05</td>\n",
       "      <td>4.037016e-05</td>\n",
       "      <td>-1.945027e-07</td>\n",
       "      <td>1.262211e-05</td>\n",
       "      <td>4.896127e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4102</th>\n",
       "      <td>9.118984e-08</td>\n",
       "      <td>3.537852e-08</td>\n",
       "      <td>2.750748e-07</td>\n",
       "      <td>-4.496579e-08</td>\n",
       "      <td>2.881256e-07</td>\n",
       "      <td>2.203323e-08</td>\n",
       "      <td>9.876029e-08</td>\n",
       "      <td>1.096079e-07</td>\n",
       "      <td>-1.509526e-08</td>\n",
       "      <td>8.517030e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>9.115726e-09</td>\n",
       "      <td>3.355309e-07</td>\n",
       "      <td>4.083490e-07</td>\n",
       "      <td>1.926631e-10</td>\n",
       "      <td>7.225911e-08</td>\n",
       "      <td>7.189061e-07</td>\n",
       "      <td>3.888539e-07</td>\n",
       "      <td>-1.112881e-08</td>\n",
       "      <td>1.479028e-07</td>\n",
       "      <td>3.723892e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4103</th>\n",
       "      <td>4.700248e-05</td>\n",
       "      <td>2.000327e-05</td>\n",
       "      <td>1.571192e-04</td>\n",
       "      <td>2.828120e-06</td>\n",
       "      <td>1.435639e-04</td>\n",
       "      <td>2.525141e-05</td>\n",
       "      <td>3.211320e-05</td>\n",
       "      <td>2.564692e-05</td>\n",
       "      <td>1.031836e-05</td>\n",
       "      <td>2.998662e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.562045e-07</td>\n",
       "      <td>1.411025e-04</td>\n",
       "      <td>1.757605e-04</td>\n",
       "      <td>3.330161e-07</td>\n",
       "      <td>2.298042e-05</td>\n",
       "      <td>2.168385e-04</td>\n",
       "      <td>1.384067e-04</td>\n",
       "      <td>-7.086873e-07</td>\n",
       "      <td>3.812776e-05</td>\n",
       "      <td>1.777722e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4104</th>\n",
       "      <td>5.968177e-05</td>\n",
       "      <td>2.220903e-05</td>\n",
       "      <td>1.795039e-04</td>\n",
       "      <td>4.634061e-06</td>\n",
       "      <td>1.750557e-04</td>\n",
       "      <td>3.461711e-05</td>\n",
       "      <td>3.534384e-05</td>\n",
       "      <td>2.834975e-05</td>\n",
       "      <td>1.351920e-05</td>\n",
       "      <td>3.580626e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.444194e-06</td>\n",
       "      <td>1.509167e-04</td>\n",
       "      <td>1.857310e-04</td>\n",
       "      <td>2.692447e-07</td>\n",
       "      <td>2.602179e-05</td>\n",
       "      <td>2.191253e-04</td>\n",
       "      <td>1.382824e-04</td>\n",
       "      <td>-3.354024e-07</td>\n",
       "      <td>4.365394e-05</td>\n",
       "      <td>1.804848e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105</th>\n",
       "      <td>4.335505e-05</td>\n",
       "      <td>1.656422e-05</td>\n",
       "      <td>1.384259e-04</td>\n",
       "      <td>-2.385486e-06</td>\n",
       "      <td>1.268134e-04</td>\n",
       "      <td>2.363564e-05</td>\n",
       "      <td>2.890871e-05</td>\n",
       "      <td>2.302810e-05</td>\n",
       "      <td>8.696943e-06</td>\n",
       "      <td>2.859692e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.081459e-06</td>\n",
       "      <td>1.201022e-04</td>\n",
       "      <td>1.511815e-04</td>\n",
       "      <td>1.789895e-07</td>\n",
       "      <td>2.112757e-05</td>\n",
       "      <td>1.835553e-04</td>\n",
       "      <td>1.166695e-04</td>\n",
       "      <td>-5.068240e-07</td>\n",
       "      <td>3.476826e-05</td>\n",
       "      <td>1.448068e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4106</th>\n",
       "      <td>-1.244506e-07</td>\n",
       "      <td>-6.081859e-08</td>\n",
       "      <td>3.067964e-06</td>\n",
       "      <td>1.473690e-07</td>\n",
       "      <td>-5.342789e-06</td>\n",
       "      <td>-1.514140e-06</td>\n",
       "      <td>6.041885e-07</td>\n",
       "      <td>5.595394e-07</td>\n",
       "      <td>8.335929e-07</td>\n",
       "      <td>8.674495e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.605682e-07</td>\n",
       "      <td>2.494357e-06</td>\n",
       "      <td>5.429331e-06</td>\n",
       "      <td>2.138950e-07</td>\n",
       "      <td>9.014305e-07</td>\n",
       "      <td>3.560145e-06</td>\n",
       "      <td>5.850167e-06</td>\n",
       "      <td>1.905758e-07</td>\n",
       "      <td>7.005726e-07</td>\n",
       "      <td>5.791645e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4107</th>\n",
       "      <td>5.022587e-07</td>\n",
       "      <td>1.210191e-07</td>\n",
       "      <td>8.017069e-07</td>\n",
       "      <td>6.714430e-07</td>\n",
       "      <td>1.872506e-06</td>\n",
       "      <td>6.728450e-07</td>\n",
       "      <td>1.493048e-07</td>\n",
       "      <td>1.724174e-07</td>\n",
       "      <td>1.972226e-07</td>\n",
       "      <td>1.448897e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>2.916891e-08</td>\n",
       "      <td>8.811575e-07</td>\n",
       "      <td>4.196882e-07</td>\n",
       "      <td>-3.188384e-08</td>\n",
       "      <td>3.011884e-07</td>\n",
       "      <td>2.068258e-06</td>\n",
       "      <td>5.163051e-07</td>\n",
       "      <td>1.087944e-08</td>\n",
       "      <td>1.587784e-07</td>\n",
       "      <td>7.612888e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108</th>\n",
       "      <td>-3.650095e-07</td>\n",
       "      <td>-6.778382e-08</td>\n",
       "      <td>-2.248506e-06</td>\n",
       "      <td>1.925279e-06</td>\n",
       "      <td>-2.356792e-06</td>\n",
       "      <td>9.169487e-08</td>\n",
       "      <td>-5.909597e-07</td>\n",
       "      <td>-5.558967e-07</td>\n",
       "      <td>4.663648e-07</td>\n",
       "      <td>-4.553576e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.568726e-09</td>\n",
       "      <td>-1.367533e-06</td>\n",
       "      <td>-2.992453e-06</td>\n",
       "      <td>-9.923075e-09</td>\n",
       "      <td>-2.384316e-07</td>\n",
       "      <td>-4.276662e-06</td>\n",
       "      <td>-2.101101e-06</td>\n",
       "      <td>1.023666e-07</td>\n",
       "      <td>-6.360004e-07</td>\n",
       "      <td>-3.901478e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4109</th>\n",
       "      <td>3.187612e-06</td>\n",
       "      <td>1.264190e-06</td>\n",
       "      <td>9.761194e-06</td>\n",
       "      <td>1.359577e-07</td>\n",
       "      <td>9.635010e-06</td>\n",
       "      <td>1.764873e-06</td>\n",
       "      <td>2.349179e-06</td>\n",
       "      <td>1.468791e-06</td>\n",
       "      <td>3.697140e-07</td>\n",
       "      <td>1.765980e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.067384e-07</td>\n",
       "      <td>8.703366e-06</td>\n",
       "      <td>1.151264e-05</td>\n",
       "      <td>1.339562e-08</td>\n",
       "      <td>1.440335e-06</td>\n",
       "      <td>1.381170e-05</td>\n",
       "      <td>8.616027e-06</td>\n",
       "      <td>-3.721829e-08</td>\n",
       "      <td>2.474946e-06</td>\n",
       "      <td>9.503417e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4110</th>\n",
       "      <td>7.803883e-07</td>\n",
       "      <td>3.756147e-07</td>\n",
       "      <td>2.573181e-06</td>\n",
       "      <td>2.967936e-08</td>\n",
       "      <td>2.073372e-06</td>\n",
       "      <td>4.747089e-07</td>\n",
       "      <td>5.524432e-07</td>\n",
       "      <td>5.522014e-07</td>\n",
       "      <td>2.086124e-07</td>\n",
       "      <td>5.807709e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>2.763357e-08</td>\n",
       "      <td>2.335211e-06</td>\n",
       "      <td>2.151247e-06</td>\n",
       "      <td>-1.826665e-08</td>\n",
       "      <td>4.763493e-07</td>\n",
       "      <td>3.290626e-06</td>\n",
       "      <td>2.647094e-06</td>\n",
       "      <td>3.577488e-08</td>\n",
       "      <td>6.332176e-07</td>\n",
       "      <td>2.664977e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4111</th>\n",
       "      <td>3.900742e-05</td>\n",
       "      <td>1.481476e-05</td>\n",
       "      <td>1.252843e-04</td>\n",
       "      <td>3.067927e-07</td>\n",
       "      <td>1.144003e-04</td>\n",
       "      <td>2.245973e-05</td>\n",
       "      <td>2.599874e-05</td>\n",
       "      <td>2.046005e-05</td>\n",
       "      <td>8.307288e-06</td>\n",
       "      <td>2.510576e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.844322e-07</td>\n",
       "      <td>1.092420e-04</td>\n",
       "      <td>1.360217e-04</td>\n",
       "      <td>1.941279e-07</td>\n",
       "      <td>1.938619e-05</td>\n",
       "      <td>1.637931e-04</td>\n",
       "      <td>1.060322e-04</td>\n",
       "      <td>-3.546922e-07</td>\n",
       "      <td>3.123628e-05</td>\n",
       "      <td>1.237005e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4112</th>\n",
       "      <td>1.251807e-05</td>\n",
       "      <td>4.930478e-06</td>\n",
       "      <td>4.029809e-05</td>\n",
       "      <td>-5.457854e-07</td>\n",
       "      <td>3.407309e-05</td>\n",
       "      <td>5.476084e-06</td>\n",
       "      <td>8.320215e-06</td>\n",
       "      <td>6.401445e-06</td>\n",
       "      <td>2.475014e-06</td>\n",
       "      <td>8.250556e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.706674e-07</td>\n",
       "      <td>3.355546e-05</td>\n",
       "      <td>4.174185e-05</td>\n",
       "      <td>1.041960e-07</td>\n",
       "      <td>5.990363e-06</td>\n",
       "      <td>4.877401e-05</td>\n",
       "      <td>3.581775e-05</td>\n",
       "      <td>-1.149841e-07</td>\n",
       "      <td>1.005483e-05</td>\n",
       "      <td>3.761700e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4113</th>\n",
       "      <td>7.605373e-09</td>\n",
       "      <td>2.662288e-07</td>\n",
       "      <td>-1.345247e-07</td>\n",
       "      <td>-5.491191e-08</td>\n",
       "      <td>-2.715533e-07</td>\n",
       "      <td>-6.287270e-07</td>\n",
       "      <td>-1.392152e-07</td>\n",
       "      <td>3.264111e-08</td>\n",
       "      <td>2.127331e-08</td>\n",
       "      <td>1.825942e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>5.661509e-07</td>\n",
       "      <td>5.091142e-07</td>\n",
       "      <td>-4.013205e-07</td>\n",
       "      <td>-2.215444e-08</td>\n",
       "      <td>7.610189e-08</td>\n",
       "      <td>-3.902470e-07</td>\n",
       "      <td>5.354222e-07</td>\n",
       "      <td>-7.211146e-08</td>\n",
       "      <td>9.107445e-08</td>\n",
       "      <td>6.266360e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4114</th>\n",
       "      <td>3.434817e-05</td>\n",
       "      <td>1.455464e-05</td>\n",
       "      <td>1.170551e-04</td>\n",
       "      <td>2.526525e-06</td>\n",
       "      <td>1.109097e-04</td>\n",
       "      <td>2.042652e-05</td>\n",
       "      <td>2.326375e-05</td>\n",
       "      <td>1.968560e-05</td>\n",
       "      <td>8.097007e-06</td>\n",
       "      <td>2.264110e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>5.091142e-07</td>\n",
       "      <td>1.140766e-04</td>\n",
       "      <td>1.325252e-04</td>\n",
       "      <td>1.925754e-07</td>\n",
       "      <td>1.821989e-05</td>\n",
       "      <td>1.608154e-04</td>\n",
       "      <td>9.596221e-05</td>\n",
       "      <td>-5.285049e-07</td>\n",
       "      <td>2.911289e-05</td>\n",
       "      <td>1.145478e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4115</th>\n",
       "      <td>4.311914e-05</td>\n",
       "      <td>1.675443e-05</td>\n",
       "      <td>1.474027e-04</td>\n",
       "      <td>-9.075807e-07</td>\n",
       "      <td>1.293060e-04</td>\n",
       "      <td>2.495701e-05</td>\n",
       "      <td>3.101525e-05</td>\n",
       "      <td>2.358019e-05</td>\n",
       "      <td>9.010338e-06</td>\n",
       "      <td>2.906542e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.013205e-07</td>\n",
       "      <td>1.325252e-04</td>\n",
       "      <td>1.776663e-04</td>\n",
       "      <td>4.647673e-07</td>\n",
       "      <td>2.219837e-05</td>\n",
       "      <td>1.998872e-04</td>\n",
       "      <td>1.234325e-04</td>\n",
       "      <td>-6.459635e-07</td>\n",
       "      <td>3.737102e-05</td>\n",
       "      <td>1.485998e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4116</th>\n",
       "      <td>3.750477e-08</td>\n",
       "      <td>2.522211e-08</td>\n",
       "      <td>1.920412e-07</td>\n",
       "      <td>9.678345e-08</td>\n",
       "      <td>-5.239562e-07</td>\n",
       "      <td>-1.394046e-07</td>\n",
       "      <td>4.557602e-08</td>\n",
       "      <td>1.334633e-08</td>\n",
       "      <td>5.985103e-08</td>\n",
       "      <td>5.892814e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.215444e-08</td>\n",
       "      <td>1.925754e-07</td>\n",
       "      <td>4.647673e-07</td>\n",
       "      <td>7.629833e-08</td>\n",
       "      <td>-2.577361e-08</td>\n",
       "      <td>2.442481e-07</td>\n",
       "      <td>5.896372e-07</td>\n",
       "      <td>1.064590e-08</td>\n",
       "      <td>4.384324e-08</td>\n",
       "      <td>4.468026e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4117</th>\n",
       "      <td>6.303670e-06</td>\n",
       "      <td>2.312782e-06</td>\n",
       "      <td>2.002937e-05</td>\n",
       "      <td>2.096404e-07</td>\n",
       "      <td>1.855903e-05</td>\n",
       "      <td>3.935835e-06</td>\n",
       "      <td>4.270544e-06</td>\n",
       "      <td>3.621594e-06</td>\n",
       "      <td>1.446686e-06</td>\n",
       "      <td>4.121944e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>7.610189e-08</td>\n",
       "      <td>1.821989e-05</td>\n",
       "      <td>2.219837e-05</td>\n",
       "      <td>-2.577361e-08</td>\n",
       "      <td>3.626363e-06</td>\n",
       "      <td>2.834494e-05</td>\n",
       "      <td>1.694113e-05</td>\n",
       "      <td>-3.844492e-09</td>\n",
       "      <td>5.148351e-06</td>\n",
       "      <td>1.983015e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4118</th>\n",
       "      <td>5.159674e-05</td>\n",
       "      <td>1.994313e-05</td>\n",
       "      <td>1.726787e-04</td>\n",
       "      <td>9.634211e-07</td>\n",
       "      <td>1.651030e-04</td>\n",
       "      <td>3.883270e-05</td>\n",
       "      <td>3.853775e-05</td>\n",
       "      <td>3.084361e-05</td>\n",
       "      <td>1.159561e-05</td>\n",
       "      <td>3.536379e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.902470e-07</td>\n",
       "      <td>1.608154e-04</td>\n",
       "      <td>1.998872e-04</td>\n",
       "      <td>2.442481e-07</td>\n",
       "      <td>2.834494e-05</td>\n",
       "      <td>2.685276e-04</td>\n",
       "      <td>1.431478e-04</td>\n",
       "      <td>-6.105099e-07</td>\n",
       "      <td>4.546616e-05</td>\n",
       "      <td>1.756112e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4119</th>\n",
       "      <td>3.162165e-05</td>\n",
       "      <td>1.551247e-05</td>\n",
       "      <td>1.138861e-04</td>\n",
       "      <td>-6.051356e-06</td>\n",
       "      <td>8.269942e-05</td>\n",
       "      <td>1.744398e-05</td>\n",
       "      <td>2.727766e-05</td>\n",
       "      <td>2.016689e-05</td>\n",
       "      <td>4.840439e-06</td>\n",
       "      <td>2.814172e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>5.354222e-07</td>\n",
       "      <td>9.596221e-05</td>\n",
       "      <td>1.234325e-04</td>\n",
       "      <td>5.896372e-07</td>\n",
       "      <td>1.694113e-05</td>\n",
       "      <td>1.431478e-04</td>\n",
       "      <td>1.565440e-04</td>\n",
       "      <td>-7.955045e-07</td>\n",
       "      <td>3.118503e-05</td>\n",
       "      <td>1.206691e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4120</th>\n",
       "      <td>-3.619137e-08</td>\n",
       "      <td>-6.556827e-08</td>\n",
       "      <td>-4.596297e-07</td>\n",
       "      <td>4.906621e-08</td>\n",
       "      <td>-5.657993e-07</td>\n",
       "      <td>-1.358764e-08</td>\n",
       "      <td>-9.584251e-08</td>\n",
       "      <td>-5.603630e-08</td>\n",
       "      <td>4.383513e-08</td>\n",
       "      <td>-1.195512e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.211146e-08</td>\n",
       "      <td>-5.285049e-07</td>\n",
       "      <td>-6.459635e-07</td>\n",
       "      <td>1.064590e-08</td>\n",
       "      <td>-3.844492e-09</td>\n",
       "      <td>-6.105099e-07</td>\n",
       "      <td>-7.955045e-07</td>\n",
       "      <td>7.058564e-08</td>\n",
       "      <td>-2.099414e-07</td>\n",
       "      <td>-6.560546e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4121</th>\n",
       "      <td>1.017623e-05</td>\n",
       "      <td>4.018776e-06</td>\n",
       "      <td>3.324988e-05</td>\n",
       "      <td>-4.956119e-07</td>\n",
       "      <td>2.837736e-05</td>\n",
       "      <td>6.055770e-06</td>\n",
       "      <td>7.635130e-06</td>\n",
       "      <td>6.039815e-06</td>\n",
       "      <td>1.935934e-06</td>\n",
       "      <td>7.364574e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>9.107445e-08</td>\n",
       "      <td>2.911289e-05</td>\n",
       "      <td>3.737102e-05</td>\n",
       "      <td>4.384324e-08</td>\n",
       "      <td>5.148351e-06</td>\n",
       "      <td>4.546616e-05</td>\n",
       "      <td>3.118503e-05</td>\n",
       "      <td>-2.099414e-07</td>\n",
       "      <td>9.415230e-06</td>\n",
       "      <td>3.272467e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4122</th>\n",
       "      <td>3.997685e-05</td>\n",
       "      <td>1.634418e-05</td>\n",
       "      <td>1.327023e-04</td>\n",
       "      <td>2.486381e-06</td>\n",
       "      <td>1.147631e-04</td>\n",
       "      <td>1.702771e-05</td>\n",
       "      <td>2.631249e-05</td>\n",
       "      <td>2.139391e-05</td>\n",
       "      <td>9.039833e-06</td>\n",
       "      <td>2.638559e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>6.266360e-07</td>\n",
       "      <td>1.145478e-04</td>\n",
       "      <td>1.485998e-04</td>\n",
       "      <td>4.468026e-07</td>\n",
       "      <td>1.983015e-05</td>\n",
       "      <td>1.756112e-04</td>\n",
       "      <td>1.206691e-04</td>\n",
       "      <td>-6.560546e-07</td>\n",
       "      <td>3.272467e-05</td>\n",
       "      <td>1.592592e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4122 rows × 4122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1             2             3             4             5     \\\n",
       "1     1.568744e-05  5.224974e-06  4.250895e-05  7.418458e-07  4.404731e-05   \n",
       "2     5.224974e-06  2.588201e-06  1.626361e-05  4.338848e-07  1.426579e-05   \n",
       "3     4.250895e-05  1.626361e-05  1.393627e-04 -6.169997e-07  1.281993e-04   \n",
       "4     7.418458e-07  4.338848e-07 -6.169997e-07  8.757740e-06  1.528506e-06   \n",
       "5     4.404731e-05  1.426579e-05  1.281993e-04  1.528506e-06  1.581213e-04   \n",
       "6     8.788399e-06  2.137112e-06  2.518835e-05 -6.887282e-07  3.290108e-05   \n",
       "7     9.047729e-06  3.393895e-06  2.822921e-05 -1.320159e-06  2.524953e-05   \n",
       "8     6.591271e-06  2.688773e-06  2.134629e-05 -3.263381e-07  1.855228e-05   \n",
       "9     2.880643e-06  1.156395e-06  8.970613e-06  2.567877e-06  7.742040e-06   \n",
       "10    8.345950e-06  3.420878e-06  2.727159e-05 -1.163435e-06  2.264926e-05   \n",
       "11    2.532050e-07  1.228490e-07  5.446985e-07  4.229582e-07  6.378346e-07   \n",
       "12    1.525807e-05  6.196375e-06  4.349406e-05 -9.328892e-06  5.239594e-05   \n",
       "13    3.997733e-05  1.635505e-05  1.393017e-04 -1.348928e-06  1.200957e-04   \n",
       "14   -8.594628e-06 -1.730655e-06 -2.983611e-05 -5.553854e-07 -1.270460e-05   \n",
       "15    1.035659e-06  4.163527e-07  2.641736e-06  4.473707e-07  2.482425e-06   \n",
       "16    1.195469e-07  9.351819e-08  2.031768e-07  3.058839e-07  1.435229e-07   \n",
       "17    6.327680e-06  1.355262e-06  2.613365e-05  2.741063e-06  3.383579e-05   \n",
       "18    1.006198e-06  5.391374e-07  2.487192e-06  2.168980e-06  3.126638e-06   \n",
       "19    6.969972e-06  2.838541e-06  2.166229e-05 -3.355036e-07  1.985915e-05   \n",
       "20    5.760597e-06 -1.193910e-06  1.798207e-05  1.509921e-05  6.346278e-05   \n",
       "21    2.270806e-05  7.636838e-06  6.975921e-05 -4.796566e-07  6.322171e-05   \n",
       "22    4.493942e-05  1.871328e-05  1.569851e-04 -7.512126e-07  1.368278e-04   \n",
       "23   -3.025520e-07  1.518477e-08  3.461713e-08  4.161279e-07 -1.430844e-06   \n",
       "24    2.945462e-06  1.255200e-06  9.286232e-06  4.297001e-07  8.086034e-06   \n",
       "25    3.186531e-07  7.011435e-08  3.045742e-07  3.330239e-07 -2.395413e-07   \n",
       "26    3.489732e-05  1.483009e-05  1.148287e-04 -1.523740e-06  9.941812e-05   \n",
       "27    3.755029e-05  1.284024e-05  1.082569e-04  1.999922e-06  1.154366e-04   \n",
       "28    3.920329e-05  1.639357e-05  1.440721e-04 -2.555974e-07  1.254327e-04   \n",
       "29    1.638020e-06  8.157051e-07  5.609563e-06 -2.795150e-06  6.221237e-06   \n",
       "30    3.872848e-05  1.555694e-05  1.230303e-04 -1.638040e-06  1.072043e-04   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4093  2.586793e-05  1.109210e-05  9.308339e-05 -6.144371e-07  7.850826e-05   \n",
       "4094  4.558727e-05  2.014173e-05  1.465104e-04  3.010458e-06  1.180302e-04   \n",
       "4095  3.547772e-05  1.425629e-05  1.162222e-04  3.361096e-06  1.071408e-04   \n",
       "4096  1.881032e-05  6.744387e-06  6.013527e-05 -9.908233e-07  5.697378e-05   \n",
       "4097  4.250725e-05  1.774742e-05  1.412982e-04 -6.143095e-08  1.294573e-04   \n",
       "4098  1.015093e-06  4.828413e-07  2.547294e-06  1.035720e-06  3.357927e-06   \n",
       "4099  4.155373e-05  1.665479e-05  1.318744e-04 -1.674552e-06  1.150982e-04   \n",
       "4100  5.080256e-05  1.814053e-05  1.587908e-04  9.913619e-07  1.581796e-04   \n",
       "4101  1.524689e-05  6.467879e-06  5.052593e-05  2.209504e-06  4.813239e-05   \n",
       "4102  9.118984e-08  3.537852e-08  2.750748e-07 -4.496579e-08  2.881256e-07   \n",
       "4103  4.700248e-05  2.000327e-05  1.571192e-04  2.828120e-06  1.435639e-04   \n",
       "4104  5.968177e-05  2.220903e-05  1.795039e-04  4.634061e-06  1.750557e-04   \n",
       "4105  4.335505e-05  1.656422e-05  1.384259e-04 -2.385486e-06  1.268134e-04   \n",
       "4106 -1.244506e-07 -6.081859e-08  3.067964e-06  1.473690e-07 -5.342789e-06   \n",
       "4107  5.022587e-07  1.210191e-07  8.017069e-07  6.714430e-07  1.872506e-06   \n",
       "4108 -3.650095e-07 -6.778382e-08 -2.248506e-06  1.925279e-06 -2.356792e-06   \n",
       "4109  3.187612e-06  1.264190e-06  9.761194e-06  1.359577e-07  9.635010e-06   \n",
       "4110  7.803883e-07  3.756147e-07  2.573181e-06  2.967936e-08  2.073372e-06   \n",
       "4111  3.900742e-05  1.481476e-05  1.252843e-04  3.067927e-07  1.144003e-04   \n",
       "4112  1.251807e-05  4.930478e-06  4.029809e-05 -5.457854e-07  3.407309e-05   \n",
       "4113  7.605373e-09  2.662288e-07 -1.345247e-07 -5.491191e-08 -2.715533e-07   \n",
       "4114  3.434817e-05  1.455464e-05  1.170551e-04  2.526525e-06  1.109097e-04   \n",
       "4115  4.311914e-05  1.675443e-05  1.474027e-04 -9.075807e-07  1.293060e-04   \n",
       "4116  3.750477e-08  2.522211e-08  1.920412e-07  9.678345e-08 -5.239562e-07   \n",
       "4117  6.303670e-06  2.312782e-06  2.002937e-05  2.096404e-07  1.855903e-05   \n",
       "4118  5.159674e-05  1.994313e-05  1.726787e-04  9.634211e-07  1.651030e-04   \n",
       "4119  3.162165e-05  1.551247e-05  1.138861e-04 -6.051356e-06  8.269942e-05   \n",
       "4120 -3.619137e-08 -6.556827e-08 -4.596297e-07  4.906621e-08 -5.657993e-07   \n",
       "4121  1.017623e-05  4.018776e-06  3.324988e-05 -4.956119e-07  2.837736e-05   \n",
       "4122  3.997685e-05  1.634418e-05  1.327023e-04  2.486381e-06  1.147631e-04   \n",
       "\n",
       "              6             7             8             9             10    \\\n",
       "1     8.788399e-06  9.047729e-06  6.591271e-06  2.880643e-06  8.345950e-06   \n",
       "2     2.137112e-06  3.393895e-06  2.688773e-06  1.156395e-06  3.420878e-06   \n",
       "3     2.518835e-05  2.822921e-05  2.134629e-05  8.970613e-06  2.727159e-05   \n",
       "4    -6.887282e-07 -1.320159e-06 -3.263381e-07  2.567877e-06 -1.163435e-06   \n",
       "5     3.290108e-05  2.524953e-05  1.855228e-05  7.742040e-06  2.264926e-05   \n",
       "6     1.268224e-05  6.228122e-06  4.102095e-06  1.319615e-06  5.027280e-06   \n",
       "7     6.228122e-06  7.140864e-06  4.950833e-06  1.360618e-06  6.310981e-06   \n",
       "8     4.102095e-06  4.950833e-06  4.311114e-06  1.292042e-06  4.739723e-06   \n",
       "9     1.319615e-06  1.360618e-06  1.292042e-06  1.706870e-06  1.614760e-06   \n",
       "10    5.027280e-06  6.310981e-06  4.739723e-06  1.614760e-06  6.492682e-06   \n",
       "11    2.210161e-07  1.338374e-07  1.617427e-07  1.534772e-07  1.107448e-07   \n",
       "12    1.535479e-05  1.391260e-05  1.079193e-05 -1.048492e-06  1.269423e-05   \n",
       "13    2.315193e-05  3.000550e-05  2.326221e-05  9.074403e-06  2.828260e-05   \n",
       "14   -2.132178e-06 -4.720025e-06 -2.150652e-06 -3.347039e-06 -4.409131e-06   \n",
       "15    4.687731e-07  7.304960e-07  5.453701e-07  2.520082e-07  6.199188e-07   \n",
       "16    1.444882e-07  5.886854e-08  7.018814e-08  8.748987e-08  1.075791e-07   \n",
       "17    1.945849e-05  7.869959e-06  5.345713e-06  3.360055e-06  6.527940e-06   \n",
       "18    6.551230e-07  4.037846e-07  4.288468e-07  8.080016e-07  3.616590e-07   \n",
       "19    4.052770e-06  4.840918e-06  3.597675e-06  1.253365e-06  4.711701e-06   \n",
       "20    2.411977e-05 -4.925032e-06 -1.205968e-06  5.346116e-06 -3.041043e-06   \n",
       "21    1.397891e-05  1.570810e-05  1.144752e-05  4.474883e-06  1.503815e-05   \n",
       "22    2.613212e-05  3.392916e-05  2.754899e-05  9.812051e-06  3.176271e-05   \n",
       "23   -3.890826e-07  1.896625e-08  7.140453e-08  1.790463e-07  2.573076e-07   \n",
       "24    1.786594e-06  2.157090e-06  1.666811e-06  7.344409e-07  2.084838e-06   \n",
       "25   -4.458431e-07  2.306894e-07 -9.884448e-08 -2.197279e-08  8.553842e-08   \n",
       "26    1.885915e-05  2.512078e-05  1.957528e-05  7.141506e-06  2.487265e-05   \n",
       "27    2.271074e-05  2.239983e-05  1.704419e-05  7.363616e-06  2.098501e-05   \n",
       "28    2.358687e-05  3.064008e-05  2.622786e-05  9.509292e-06  2.832799e-05   \n",
       "29   -1.412021e-06  1.176178e-06 -7.716717e-08 -4.834903e-07  1.733209e-06   \n",
       "30    2.177144e-05  2.728942e-05  2.084997e-05  7.439340e-06  2.662918e-05   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4093  1.879410e-05  1.875896e-05  1.367156e-05  5.204149e-06  1.792224e-05   \n",
       "4094  2.354543e-05  3.366911e-05  2.600474e-05  1.043690e-05  3.261114e-05   \n",
       "4095  1.723934e-05  2.279232e-05  1.757160e-05  8.739828e-06  2.236052e-05   \n",
       "4096  1.123702e-05  1.241453e-05  9.838813e-06  3.583238e-06  1.175391e-05   \n",
       "4097  2.337761e-05  3.026032e-05  2.343254e-05  8.549245e-06  2.891009e-05   \n",
       "4098  7.607248e-07  4.249189e-07  4.917585e-07  3.835568e-07  4.068485e-07   \n",
       "4099  2.339123e-05  2.922678e-05  2.226983e-05  8.004293e-06  2.847672e-05   \n",
       "4100  3.408913e-05  3.302245e-05  2.702521e-05  1.050042e-05  3.127294e-05   \n",
       "4101  1.044824e-05  1.026324e-05  7.998512e-06  4.473185e-06  1.056798e-05   \n",
       "4102  2.203323e-08  9.876029e-08  1.096079e-07 -1.509526e-08  8.517030e-08   \n",
       "4103  2.525141e-05  3.211320e-05  2.564692e-05  1.031836e-05  2.998662e-05   \n",
       "4104  3.461711e-05  3.534384e-05  2.834975e-05  1.351920e-05  3.580626e-05   \n",
       "4105  2.363564e-05  2.890871e-05  2.302810e-05  8.696943e-06  2.859692e-05   \n",
       "4106 -1.514140e-06  6.041885e-07  5.595394e-07  8.335929e-07  8.674495e-07   \n",
       "4107  6.728450e-07  1.493048e-07  1.724174e-07  1.972226e-07  1.448897e-07   \n",
       "4108  9.169487e-08 -5.909597e-07 -5.558967e-07  4.663648e-07 -4.553576e-07   \n",
       "4109  1.764873e-06  2.349179e-06  1.468791e-06  3.697140e-07  1.765980e-06   \n",
       "4110  4.747089e-07  5.524432e-07  5.522014e-07  2.086124e-07  5.807709e-07   \n",
       "4111  2.245973e-05  2.599874e-05  2.046005e-05  8.307288e-06  2.510576e-05   \n",
       "4112  5.476084e-06  8.320215e-06  6.401445e-06  2.475014e-06  8.250556e-06   \n",
       "4113 -6.287270e-07 -1.392152e-07  3.264111e-08  2.127331e-08  1.825942e-07   \n",
       "4114  2.042652e-05  2.326375e-05  1.968560e-05  8.097007e-06  2.264110e-05   \n",
       "4115  2.495701e-05  3.101525e-05  2.358019e-05  9.010338e-06  2.906542e-05   \n",
       "4116 -1.394046e-07  4.557602e-08  1.334633e-08  5.985103e-08  5.892814e-08   \n",
       "4117  3.935835e-06  4.270544e-06  3.621594e-06  1.446686e-06  4.121944e-06   \n",
       "4118  3.883270e-05  3.853775e-05  3.084361e-05  1.159561e-05  3.536379e-05   \n",
       "4119  1.744398e-05  2.727766e-05  2.016689e-05  4.840439e-06  2.814172e-05   \n",
       "4120 -1.358764e-08 -9.584251e-08 -5.603630e-08  4.383513e-08 -1.195512e-07   \n",
       "4121  6.055770e-06  7.635130e-06  6.039815e-06  1.935934e-06  7.364574e-06   \n",
       "4122  1.702771e-05  2.631249e-05  2.139391e-05  9.039833e-06  2.638559e-05   \n",
       "\n",
       "          ...               4113          4114          4115          4116  \\\n",
       "1         ...       7.605373e-09  3.434817e-05  4.311914e-05  3.750477e-08   \n",
       "2         ...       2.662288e-07  1.455464e-05  1.675443e-05  2.522211e-08   \n",
       "3         ...      -1.345247e-07  1.170551e-04  1.474027e-04  1.920412e-07   \n",
       "4         ...      -5.491191e-08  2.526525e-06 -9.075807e-07  9.678345e-08   \n",
       "5         ...      -2.715533e-07  1.109097e-04  1.293060e-04 -5.239562e-07   \n",
       "6         ...      -6.287270e-07  2.042652e-05  2.495701e-05 -1.394046e-07   \n",
       "7         ...      -1.392152e-07  2.326375e-05  3.101525e-05  4.557602e-08   \n",
       "8         ...       3.264111e-08  1.968560e-05  2.358019e-05  1.334633e-08   \n",
       "9         ...       2.127331e-08  8.097007e-06  9.010338e-06  5.985103e-08   \n",
       "10        ...       1.825942e-07  2.264110e-05  2.906542e-05  5.892814e-08   \n",
       "11        ...       1.281485e-08  7.339274e-07  5.856148e-07 -1.975836e-08   \n",
       "12        ...      -5.372840e-07  4.178020e-05  4.706760e-05  1.441242e-07   \n",
       "13        ...      -6.198161e-07  1.266631e-04  1.619159e-04  2.732996e-07   \n",
       "14        ...      -2.583392e-07 -1.743488e-05 -3.398285e-05 -2.598742e-07   \n",
       "15        ...       4.329125e-08  2.537301e-06  2.996994e-06  2.654370e-08   \n",
       "16        ...      -7.761933e-09  3.117627e-07 -2.835031e-07  7.929087e-09   \n",
       "17        ...      -1.989288e-06  2.304378e-05  3.303562e-05  4.498566e-08   \n",
       "18        ...      -2.454789e-08  3.357720e-06  2.516566e-06  1.729631e-08   \n",
       "19        ...       7.815415e-08  1.898887e-05  2.363300e-05  6.239649e-08   \n",
       "20        ...      -4.999857e-06  2.931672e-05  1.077524e-05 -3.406889e-07   \n",
       "21        ...      -9.978723e-07  5.514143e-05  7.431373e-05  6.807558e-08   \n",
       "22        ...       5.285548e-07  1.483333e-04  1.847349e-04  4.219855e-07   \n",
       "23        ...       5.539541e-08  4.188556e-08  5.496288e-07  1.745347e-08   \n",
       "24        ...       1.787978e-08  8.400033e-06  1.035434e-05  1.300190e-08   \n",
       "25        ...      -8.639458e-08  2.136823e-07  1.960618e-06  2.874904e-08   \n",
       "26        ...       5.646363e-07  1.020281e-04  1.280276e-04  2.319671e-07   \n",
       "27        ...      -1.799154e-07  9.281656e-05  1.134348e-04 -1.086520e-07   \n",
       "28        ...      -1.759321e-07  1.409017e-04  1.730726e-04  3.366692e-07   \n",
       "29        ...       4.000811e-07  4.922642e-06  5.748430e-06 -1.024139e-08   \n",
       "30        ...       1.728053e-07  1.045082e-04  1.325772e-04  3.000588e-07   \n",
       "...       ...                ...           ...           ...           ...   \n",
       "4093      ...       5.641898e-08  8.110684e-05  1.014698e-04  1.519443e-07   \n",
       "4094      ...      -1.212629e-07  1.307694e-04  1.613279e-04  6.949925e-07   \n",
       "4095      ...      -5.523761e-07  9.499312e-05  1.263218e-04 -1.808669e-07   \n",
       "4096      ...      -4.120832e-08  5.165116e-05  6.599072e-05  3.989528e-08   \n",
       "4097      ...       1.207822e-07  1.303281e-04  1.630859e-04  4.428083e-07   \n",
       "4098      ...       4.549063e-08  2.757882e-06  1.940138e-06 -3.452441e-08   \n",
       "4099      ...       1.180425e-07  1.117336e-04  1.420141e-04  3.236353e-07   \n",
       "4100      ...      -1.888989e-07  1.406761e-04  1.682578e-04  9.349222e-08   \n",
       "4101      ...       2.767312e-07  4.543401e-05  5.757598e-05  7.534218e-08   \n",
       "4102      ...       9.115726e-09  3.355309e-07  4.083490e-07  1.926631e-10   \n",
       "4103      ...      -6.562045e-07  1.411025e-04  1.757605e-04  3.330161e-07   \n",
       "4104      ...       1.444194e-06  1.509167e-04  1.857310e-04  2.692447e-07   \n",
       "4105      ...       1.081459e-06  1.201022e-04  1.511815e-04  1.789895e-07   \n",
       "4106      ...      -2.605682e-07  2.494357e-06  5.429331e-06  2.138950e-07   \n",
       "4107      ...       2.916891e-08  8.811575e-07  4.196882e-07 -3.188384e-08   \n",
       "4108      ...      -4.568726e-09 -1.367533e-06 -2.992453e-06 -9.923075e-09   \n",
       "4109      ...      -2.067384e-07  8.703366e-06  1.151264e-05  1.339562e-08   \n",
       "4110      ...       2.763357e-08  2.335211e-06  2.151247e-06 -1.826665e-08   \n",
       "4111      ...       2.844322e-07  1.092420e-04  1.360217e-04  1.941279e-07   \n",
       "4112      ...       1.706674e-07  3.355546e-05  4.174185e-05  1.041960e-07   \n",
       "4113      ...       5.661509e-07  5.091142e-07 -4.013205e-07 -2.215444e-08   \n",
       "4114      ...       5.091142e-07  1.140766e-04  1.325252e-04  1.925754e-07   \n",
       "4115      ...      -4.013205e-07  1.325252e-04  1.776663e-04  4.647673e-07   \n",
       "4116      ...      -2.215444e-08  1.925754e-07  4.647673e-07  7.629833e-08   \n",
       "4117      ...       7.610189e-08  1.821989e-05  2.219837e-05 -2.577361e-08   \n",
       "4118      ...      -3.902470e-07  1.608154e-04  1.998872e-04  2.442481e-07   \n",
       "4119      ...       5.354222e-07  9.596221e-05  1.234325e-04  5.896372e-07   \n",
       "4120      ...      -7.211146e-08 -5.285049e-07 -6.459635e-07  1.064590e-08   \n",
       "4121      ...       9.107445e-08  2.911289e-05  3.737102e-05  4.384324e-08   \n",
       "4122      ...       6.266360e-07  1.145478e-04  1.485998e-04  4.468026e-07   \n",
       "\n",
       "              4117          4118          4119          4120          4121  \\\n",
       "1     6.303670e-06  5.159674e-05  3.162165e-05 -3.619137e-08  1.017623e-05   \n",
       "2     2.312782e-06  1.994313e-05  1.551247e-05 -6.556827e-08  4.018776e-06   \n",
       "3     2.002937e-05  1.726787e-04  1.138861e-04 -4.596297e-07  3.324988e-05   \n",
       "4     2.096404e-07  9.634211e-07 -6.051356e-06  4.906621e-08 -4.956119e-07   \n",
       "5     1.855903e-05  1.651030e-04  8.269942e-05 -5.657993e-07  2.837736e-05   \n",
       "6     3.935835e-06  3.883270e-05  1.744398e-05 -1.358764e-08  6.055770e-06   \n",
       "7     4.270544e-06  3.853775e-05  2.727766e-05 -9.584251e-08  7.635130e-06   \n",
       "8     3.621594e-06  3.084361e-05  2.016689e-05 -5.603630e-08  6.039815e-06   \n",
       "9     1.446686e-06  1.159561e-05  4.840439e-06  4.383513e-08  1.935934e-06   \n",
       "10    4.121944e-06  3.536379e-05  2.814172e-05 -1.195512e-07  7.364574e-06   \n",
       "11    1.851068e-07  1.260478e-06  2.536804e-07  1.366678e-08  1.951502e-07   \n",
       "12    5.571787e-06  6.974419e-05  4.869052e-05 -1.454954e-07  1.545578e-05   \n",
       "13    2.148093e-05  1.927441e-04  1.210796e-04 -3.404477e-07  3.527928e-05   \n",
       "14   -4.713538e-06 -2.700635e-05 -2.031900e-05  1.868915e-07 -5.462313e-06   \n",
       "15    4.685266e-07  4.234174e-06  2.772962e-06  1.508215e-10  8.412698e-07   \n",
       "16    8.771152e-09 -6.396714e-08  4.002564e-07  1.637248e-09  1.198567e-07   \n",
       "17    5.744841e-06  7.981873e-05  2.244575e-05  1.398358e-07  7.936551e-06   \n",
       "18    5.404814e-07  4.500416e-06  1.519336e-06  2.458522e-08  5.716557e-07   \n",
       "19    3.139751e-06  2.806285e-05  2.035434e-05 -9.175527e-08  5.628174e-06   \n",
       "20    2.500226e-06  2.023407e-05 -3.543584e-05  1.135695e-06 -4.467637e-06   \n",
       "21    1.091159e-05  9.094629e-05  6.407485e-05  4.407066e-08  1.796289e-05   \n",
       "22    2.496216e-05  2.238376e-04  1.368209e-04 -9.346718e-07  4.134386e-05   \n",
       "23   -4.405545e-08 -4.607562e-07  1.472602e-06 -7.961566e-09  2.125598e-07   \n",
       "24    1.479037e-06  1.298437e-05  8.923740e-06 -3.996238e-08  2.573953e-06   \n",
       "25   -7.705711e-08  5.738838e-07  3.477088e-07 -4.406566e-09  2.418680e-07   \n",
       "26    1.705611e-05  1.525999e-04  1.091175e-04 -6.107879e-07  3.027460e-05   \n",
       "27    1.622335e-05  1.402023e-04  7.824374e-05 -2.108744e-07  2.619516e-05   \n",
       "28    2.402740e-05  2.144832e-04  1.229714e-04 -5.867357e-07  3.693378e-05   \n",
       "29    1.938834e-08  2.873112e-06  8.017441e-06 -2.024556e-07  9.023898e-07   \n",
       "30    1.814923e-05  1.583127e-04  1.167704e-04 -5.100576e-07  3.225458e-05   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4093  1.358071e-05  1.185127e-04  9.156844e-05 -5.714817e-07  2.150045e-05   \n",
       "4094  2.189297e-05  1.953968e-04  1.520137e-04 -4.878855e-07  3.936963e-05   \n",
       "4095  1.721469e-05  1.542316e-04  1.005544e-04 -4.469896e-07  2.684135e-05   \n",
       "4096  9.132043e-06  7.993076e-05  4.755854e-05 -1.623801e-07  1.488344e-05   \n",
       "4097  2.134651e-05  1.934541e-04  1.301731e-04 -7.770277e-07  3.580458e-05   \n",
       "4098  4.750004e-07  4.071463e-06  1.519936e-06  1.484500e-08  6.681759e-07   \n",
       "4099  1.942981e-05  1.696614e-04  1.249192e-04 -5.298777e-07  3.447358e-05   \n",
       "4100  2.479239e-05  2.166195e-04  1.227876e-04 -5.250752e-07  3.996727e-05   \n",
       "4101  7.554369e-06  7.220193e-05  4.037016e-05 -1.945027e-07  1.262211e-05   \n",
       "4102  7.225911e-08  7.189061e-07  3.888539e-07 -1.112881e-08  1.479028e-07   \n",
       "4103  2.298042e-05  2.168385e-04  1.384067e-04 -7.086873e-07  3.812776e-05   \n",
       "4104  2.602179e-05  2.191253e-04  1.382824e-04 -3.354024e-07  4.365394e-05   \n",
       "4105  2.112757e-05  1.835553e-04  1.166695e-04 -5.068240e-07  3.476826e-05   \n",
       "4106  9.014305e-07  3.560145e-06  5.850167e-06  1.905758e-07  7.005726e-07   \n",
       "4107  3.011884e-07  2.068258e-06  5.163051e-07  1.087944e-08  1.587784e-07   \n",
       "4108 -2.384316e-07 -4.276662e-06 -2.101101e-06  1.023666e-07 -6.360004e-07   \n",
       "4109  1.440335e-06  1.381170e-05  8.616027e-06 -3.721829e-08  2.474946e-06   \n",
       "4110  4.763493e-07  3.290626e-06  2.647094e-06  3.577488e-08  6.332176e-07   \n",
       "4111  1.938619e-05  1.637931e-04  1.060322e-04 -3.546922e-07  3.123628e-05   \n",
       "4112  5.990363e-06  4.877401e-05  3.581775e-05 -1.149841e-07  1.005483e-05   \n",
       "4113  7.610189e-08 -3.902470e-07  5.354222e-07 -7.211146e-08  9.107445e-08   \n",
       "4114  1.821989e-05  1.608154e-04  9.596221e-05 -5.285049e-07  2.911289e-05   \n",
       "4115  2.219837e-05  1.998872e-04  1.234325e-04 -6.459635e-07  3.737102e-05   \n",
       "4116 -2.577361e-08  2.442481e-07  5.896372e-07  1.064590e-08  4.384324e-08   \n",
       "4117  3.626363e-06  2.834494e-05  1.694113e-05 -3.844492e-09  5.148351e-06   \n",
       "4118  2.834494e-05  2.685276e-04  1.431478e-04 -6.105099e-07  4.546616e-05   \n",
       "4119  1.694113e-05  1.431478e-04  1.565440e-04 -7.955045e-07  3.118503e-05   \n",
       "4120 -3.844492e-09 -6.105099e-07 -7.955045e-07  7.058564e-08 -2.099414e-07   \n",
       "4121  5.148351e-06  4.546616e-05  3.118503e-05 -2.099414e-07  9.415230e-06   \n",
       "4122  1.983015e-05  1.756112e-04  1.206691e-04 -6.560546e-07  3.272467e-05   \n",
       "\n",
       "              4122  \n",
       "1     3.997685e-05  \n",
       "2     1.634418e-05  \n",
       "3     1.327023e-04  \n",
       "4     2.486381e-06  \n",
       "5     1.147631e-04  \n",
       "6     1.702771e-05  \n",
       "7     2.631249e-05  \n",
       "8     2.139391e-05  \n",
       "9     9.039833e-06  \n",
       "10    2.638559e-05  \n",
       "11    4.076881e-07  \n",
       "12    2.884958e-05  \n",
       "13    1.422933e-04  \n",
       "14   -3.151738e-05  \n",
       "15    2.912580e-06  \n",
       "16   -5.320583e-07  \n",
       "17    2.339640e-05  \n",
       "18    2.265046e-06  \n",
       "19    2.075893e-05  \n",
       "20   -1.374026e-05  \n",
       "21    6.897932e-05  \n",
       "22    1.592718e-04  \n",
       "23    6.156519e-07  \n",
       "24    9.028067e-06  \n",
       "25    1.137172e-06  \n",
       "26    1.162478e-04  \n",
       "27    1.036047e-04  \n",
       "28    1.551432e-04  \n",
       "29    7.511855e-06  \n",
       "30    1.219852e-04  \n",
       "...            ...  \n",
       "4093  8.966917e-05  \n",
       "4094  1.499409e-04  \n",
       "4095  1.412660e-04  \n",
       "4096  6.033145e-05  \n",
       "4097  1.464218e-04  \n",
       "4098  2.079247e-06  \n",
       "4099  1.308266e-04  \n",
       "4100  1.542530e-04  \n",
       "4101  4.896127e-05  \n",
       "4102  3.723892e-07  \n",
       "4103  1.777722e-04  \n",
       "4104  1.804848e-04  \n",
       "4105  1.448068e-04  \n",
       "4106  5.791645e-06  \n",
       "4107  7.612888e-07  \n",
       "4108 -3.901478e-06  \n",
       "4109  9.503417e-06  \n",
       "4110  2.664977e-06  \n",
       "4111  1.237005e-04  \n",
       "4112  3.761700e-05  \n",
       "4113  6.266360e-07  \n",
       "4114  1.145478e-04  \n",
       "4115  1.485998e-04  \n",
       "4116  4.468026e-07  \n",
       "4117  1.983015e-05  \n",
       "4118  1.756112e-04  \n",
       "4119  1.206691e-04  \n",
       "4120 -6.560546e-07  \n",
       "4121  3.272467e-05  \n",
       "4122  1.592592e-04  \n",
       "\n",
       "[4122 rows x 4122 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_annualised_performance(weights, mean_returns, cov_matrix):\n",
    "    returns = np.sum(mean_returns*weights ) *30\n",
    "    std = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights))) * np.sqrt(30)\n",
    "    return std, returns\n",
    "\n",
    "def random_portfolios(num_portfolios, mean_returns, cov_matrix, risk_free_rate):\n",
    "    results = np.zeros((3,num_portfolios))\n",
    "    weights_record = []\n",
    "    for i in range(num_portfolios):\n",
    "        weights = np.random.random(4122) #初始化权重个数\n",
    "        weights /= np.sum(weights)\n",
    "        weights_record.append(weights)\n",
    "        portfolio_std_dev, portfolio_return = portfolio_annualised_performance(weights, mean_returns, cov_matrix)\n",
    "        results[0,i] = portfolio_std_dev\n",
    "        results[1,i] = portfolio_return\n",
    "        results[2,i] = (portfolio_return - risk_free_rate) / portfolio_std_dev\n",
    "    return results, weights_record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_simulated_ef_with_random(mean_returns, cov_matrix, num_portfolios, risk_free_rate):\n",
    "    results, weights = random_portfolios(num_portfolios,mean_returns, cov_matrix, risk_free_rate)\n",
    "    \n",
    "    max_sharpe_idx = np.argmax(results[2])\n",
    "    sdp, rp = results[0,max_sharpe_idx], results[1,max_sharpe_idx]\n",
    "    max_sharpe_allocation = pd.DataFrame(weights[max_sharpe_idx],index=table.columns,columns=['allocation'])\n",
    "    max_sharpe_allocation.allocation = [round(i*100,2)for i in max_sharpe_allocation.allocation]\n",
    "    max_sharpe_allocation = max_sharpe_allocation.T\n",
    "    \n",
    "    min_vol_idx = np.argmin(results[0])\n",
    "    sdp_min, rp_min = results[0,min_vol_idx], results[1,min_vol_idx]\n",
    "    min_vol_allocation = pd.DataFrame(weights[min_vol_idx],index=table.columns,columns=['allocation'])\n",
    "    min_vol_allocation.allocation = [round(i*100,2)for i in min_vol_allocation.allocation]\n",
    "    min_vol_allocation = min_vol_allocation.T\n",
    "    \n",
    "    print(\"-\"*80)\n",
    "    print(\"Maximum Sharpe Ratio Portfolio Allocation\\n\")\n",
    "    print(\"Annualised Return:\", round(rp,2))\n",
    "    print(\"Annualised Volatility:\", round(sdp,2))\n",
    "    print(\"\\n\")\n",
    "    print(max_sharpe_allocation)\n",
    "    print(\"-\"*80)\n",
    "    print(\"Minimum Volatility Portfolio Allocation\\n\")\n",
    "    print(\"Annualised Return:\", round(rp_min,2))\n",
    "    print(\"Annualised Volatility:\", round(sdp_min,2))\n",
    "    print(\"\\n\")\n",
    "    print(min_vol_allocation)\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(results[0,:],results[1,:],c=results[2,:],cmap='YlGnBu', marker='o', s=10, alpha=0.3)\n",
    "    plt.colorbar()\n",
    "    plt.scatter(sdp,rp,marker='*',color='r',s=500, label='Maximum Sharpe ratio')\n",
    "    plt.scatter(sdp_min,rp_min,marker='*',color='g',s=500, label='Minimum volatility')\n",
    "    plt.title('Simulated Portfolio Optimization based on Efficient Frontier')\n",
    "    plt.xlabel('annualised volatility')\n",
    "    plt.ylabel('annualised returns')\n",
    "    plt.legend(labelspacing=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Maximum Sharpe Ratio Portfolio Allocation\n",
      "\n",
      "Annualised Return: -0.04\n",
      "Annualised Volatility: 0.03\n",
      "\n",
      "\n",
      "            1     2     3     4     5     6     7     8     9     10    ...   \\\n",
      "allocation  0.05  0.02  0.03  0.03  0.05  0.03  0.02  0.02   0.0  0.01  ...    \n",
      "\n",
      "            4113  4114  4115  4116  4117  4118  4119  4120  4121  4122  \n",
      "allocation  0.01  0.03  0.04  0.05   0.0  0.02  0.01  0.05  0.05  0.01  \n",
      "\n",
      "[1 rows x 4122 columns]\n",
      "--------------------------------------------------------------------------------\n",
      "Minimum Volatility Portfolio Allocation\n",
      "\n",
      "Annualised Return: -0.04\n",
      "Annualised Volatility: 0.03\n",
      "\n",
      "\n",
      "            1     2     3     4     5     6     7     8     9     10    ...   \\\n",
      "allocation   0.0  0.01  0.03  0.03  0.03  0.03  0.02  0.03  0.04  0.05  ...    \n",
      "\n",
      "            4113  4114  4115  4116  4117  4118  4119  4120  4121  4122  \n",
      "allocation  0.03   0.0  0.05  0.01  0.03   0.0  0.04  0.05  0.01  0.04  \n",
      "\n",
      "[1 rows x 4122 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "display_simulated_ef_with_random(mean_returns, cov_matrix, num_portfolios, risk_free_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_sharpe_ratio(weights, mean_returns, cov_matrix, risk_free_rate):\n",
    "    p_var, p_ret = portfolio_annualised_performance(weights, mean_returns, cov_matrix)\n",
    "    return -(p_ret - risk_free_rate) / p_var\n",
    "\n",
    "def max_sharpe_ratio(mean_returns, cov_matrix, risk_free_rate):\n",
    "    num_assets = len(mean_returns)\n",
    "    args = (mean_returns, cov_matrix, risk_free_rate)\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bound = (0.0,1.0)\n",
    "    bounds = tuple(bound for asset in range(num_assets))\n",
    "    result = sco.minimize(neg_sharpe_ratio, num_assets*[1./num_assets,], args=args,\n",
    "                        method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return result\n",
    "\n",
    "def portfolio_volatility(weights, mean_returns, cov_matrix):\n",
    "    return portfolio_annualised_performance(weights, mean_returns, cov_matrix)[0]\n",
    "\n",
    "def min_variance(mean_returns, cov_matrix):\n",
    "    num_assets = len(mean_returns)\n",
    "    args = (mean_returns, cov_matrix)\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bound = (0.0,1.0)\n",
    "    bounds = tuple(bound for asset in range(num_assets))\n",
    "\n",
    "    result = sco.minimize(portfolio_volatility, num_assets*[1./num_assets,], args=args,\n",
    "                        method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "\n",
    "    return result\n",
    "\n",
    "def efficient_return(mean_returns, cov_matrix, target):\n",
    "    num_assets = len(mean_returns)\n",
    "    args = (mean_returns, cov_matrix)\n",
    "\n",
    "    def portfolio_return(weights):\n",
    "        return portfolio_annualised_performance(weights, mean_returns, cov_matrix)[1]\n",
    "\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: portfolio_return(x) - target},\n",
    "                   {'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bounds = tuple((0,1) for asset in range(num_assets))\n",
    "    result = sco.minimize(portfolio_volatility, num_assets*[1./num_assets,], args=args, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return result\n",
    "\n",
    "\n",
    "def efficient_frontier(mean_returns, cov_matrix, returns_range):\n",
    "    efficients = []\n",
    "    for ret in returns_range:\n",
    "        efficients.append(efficient_return(mean_returns, cov_matrix, ret))\n",
    "    return efficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_calculated_ef_with_random_update(mean_returns, cov_matrix, num_portfolios, risk_free_rate):\n",
    "    results, _ = random_portfolios(num_portfolios,mean_returns, cov_matrix, risk_free_rate)\n",
    "    \n",
    "    max_sharpe = max_sharpe_ratio(mean_returns, cov_matrix, risk_free_rate)\n",
    "    sdp, rp = portfolio_annualised_performance(max_sharpe['x'], mean_returns, cov_matrix)\n",
    "    max_sharpe_allocation = pd.DataFrame(max_sharpe.x,index=table.columns,columns=['allocation'])\n",
    "    max_sharpe_allocation.allocation = [round(i*100,2)for i in max_sharpe_allocation.allocation]\n",
    "    max_sharpe_allocation = max_sharpe_allocation.T\n",
    "    max_sharpe_allocation\n",
    "\n",
    "    min_vol = min_variance(mean_returns, cov_matrix)\n",
    "    sdp_min, rp_min = portfolio_annualised_performance(min_vol['x'], mean_returns, cov_matrix)\n",
    "    min_vol_allocation = pd.DataFrame(min_vol.x,index=table.columns,columns=['allocation'])\n",
    "    min_vol_allocation.allocation = [round(i*100,2)for i in min_vol_allocation.allocation]\n",
    "    min_vol_allocation = min_vol_allocation.T\n",
    "    \n",
    "    print(\"-\"*80)\n",
    "    print(\"Maximum Sharpe Ratio Portfolio Allocation\\n\")\n",
    "    print(\"Annualised Return:\", round(rp,2))\n",
    "    print(\"Annualised Volatility:\", round(sdp,2))\n",
    "    print(\"\\n\")\n",
    "    print(max_sharpe_allocation)\n",
    "    print(\"-\"*80)\n",
    "    print(\"Minimum Volatility Portfolio Allocation\\n\")\n",
    "    print(\"Annualised Return:\", round(rp_min,2))\n",
    "    print(\"Annualised Volatility:\", round(sdp_min,2))\n",
    "    print(\"\\n\")\n",
    "    print(min_vol_allocation)\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(results[0,:],results[1,:],c=results[2,:],cmap='YlGnBu', marker='o', s=10, alpha=0.3)\n",
    "    plt.colorbar()\n",
    "    plt.scatter(sdp,rp,marker='*',color='r',s=500, label='Maximum Sharpe ratio')\n",
    "    plt.scatter(sdp_min,rp_min,marker='*',color='g',s=500, label='Minimum volatility')\n",
    "\n",
    "    target = np.linspace(rp_min, 0.32, 50)\n",
    "    efficient_portfolios = efficient_frontier(mean_returns, cov_matrix, target)\n",
    "    plt.plot([p['fun'] for p in efficient_portfolios], target, linestyle='-.', color='black', label='efficient frontier')\n",
    "    plt.title('Calculated Portfolio Optimization based on Efficient Frontier')\n",
    "    plt.xlabel('annualised volatility')\n",
    "    plt.ylabel('annualised returns')\n",
    "    plt.legend(labelspacing=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display_calculated_ef_with_random_update(mean_returns, cov_matrix, num_portfolios, risk_free_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
